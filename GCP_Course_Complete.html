
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>GCP Course Complete</title>
        
        <!-- Fonts & Icons -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
        
        <!-- Syntax Highlighting -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
        
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #1a73e8;
            --secondary: #ea4335;
            --success: #34a853;
            --text-main: #202124;
            --text-muted: #5f6368;
            --bg-body: #f8f9fa;
            --bg-card: #ffffff;
            --code-bg: #2d2d2d;
            --border: #e0e0e0;
        }
        
        body {
            font-family: 'Inter', system-ui, -apple-system, sans-serif;
            line-height: 1.7;
            color: var(--text-main);
            background-color: var(--bg-body);
            margin: 0;
            padding: 40px;
        }

        /* Container for readability */
        article {
            max-width: 800px;
            margin: 0 auto 60px auto;
            background: var(--bg-card);
            padding: 60px;
            border-radius: 12px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        /* Typography */
        h1, h2, h3, h4 { color: #202124; font-weight: 700; letter-spacing: -0.02em; margin-top: 1.5em; }
        h1 { 
            text-align: center; font-size: 2.5rem; 
            border-bottom: 3px solid var(--primary); padding-bottom: 20px; color: var(--primary); 
            margin-top: 0;
        }
        h2 { font-size: 1.8rem; border-left: 5px solid var(--primary); padding-left: 15px; margin-top: 2.5em; }
        h3 { font-size: 1.4rem; color: #444; margin-top: 2em; }
        p, li { font-size: 1.05rem; color: #374151; }
        strong { color: #111; font-weight: 600; }

        /* Code Blocks */
        pre {
            background-color: var(--code-bg);
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            border: 1px solid #444;
        }
        code {
            font-family: 'JetBrains Mono', monospace;
            background-color: #f1f3f4;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
            color: #d63384;
        }
        pre code { background: none; color: inherit; padding: 0; }

        /* Tables */
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 30px 0;
            font-size: 0.95rem;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 1px 2px rgba(0,0,0,0.05);
        }
        th { background-color: var(--primary); color: white; padding: 15px; text-align: left; font-weight: 600; }
        td { padding: 12px 15px; border-bottom: 1px solid var(--border); }
        tr:nth-child(even) { background-color: #f8f9fa; }
        tr:hover { background-color: #f1f5f9; }

        /* Blockquotes / Alerts */
        blockquote {
            background: #f0f7ff;
            border-left: 6px solid var(--primary);
            margin: 30px 0;
            padding: 20px 25px;
            border-radius: 0 8px 8px 0;
            color: #2c3e50;
            font-style: normal;
        }
        
        /* Links */
        a { color: var(--primary); text-decoration: none; border-bottom: 1px solid transparent; transition: all 0.2s; }
        a:hover { border-bottom-color: var(--primary); opacity: 0.8; }

        /* Divider & Page Breaks */
        hr { border: 0; height: 1px; background: #e5e7eb; margin: 50px 0; }
        .page-break { page-break-after: always; display: block; height: 0; margin: 0; }

        /* Print Optimization */
        @media print {
            body { background: white; padding: 0; }
            article { box-shadow: none; padding: 0; margin: 0; max-width: 100%; }
            h1, h2 { color: black !important; border-color: #000 !important; }
            pre { background: #f5f5f5; color: black; border: 1px solid #ccc; }
            code { color: #000; }
            a { color: #000; text-decoration: underline; }
            .page-break { page-break-after: always; }
            /* Hide nav links in print */
            a[href^="#"] { display: none; } 
        }

        /* Progress Bar */
        .progress-container {
            padding: 0 20px 20px 20px;
            border-bottom: 1px solid var(--border);
            margin-bottom: 20px;
        }
        .progress-text {
            display: flex; justify-content: space-between;
            font-size: 0.85rem; color: var(--text); opacity: 0.8; margin-bottom: 8px;
        }
        .progress-bar-bg {
            background: var(--border); height: 8px; border-radius: 4px; overflow: hidden;
        }
        .progress-bar-fill {
            height: 100%; background: var(--success); width: 0%;
            transition: width 0.5s ease-in-out;
        }

        /* Scroll Behavior */
        html { scroll-behavior: smooth; }

        /* Mobile & Responsive */
        .mobile-toggle {
            display: none; position: fixed; top: 15px; left: 15px; z-index: 200;
            background: var(--card-bg); border: 1px solid var(--border);
            padding: 8px; border-radius: 6px; cursor: pointer; color: var(--text);
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        @media (max-width: 768px) {
            #sidebar { transform: translateX(-100%); transition: transform 0.3s; box-shadow: 2px 0 10px rgba(0,0,0,0.1); }
            #sidebar.open { transform: translateX(0); }
            main { margin-left: 0; padding: 20px 15px; margin-top: 40px; }
            article { padding: 20px; }
            .mobile-toggle { display: block; }
            h1 { font-size: 1.75rem; }
        }

        /* Back to Top */
        .back-to-top {
            position: fixed; bottom: 30px; right: 30px;
            background: var(--primary); color: white;
            width: 45px; height: 45px; border-radius: 50%;
            display: flex; align-items: center; justify-content: center;
            cursor: pointer; opacity: 0; pointer-events: none;
            transition: all 0.3s; z-index: 90;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15); border: none; font-size: 1.2rem;
        }
        .back-to-top.visible { opacity: 1; pointer-events: auto; }
        .back-to-top:hover { transform: translateY(-2px); background: var(--primary-dark); }

        /* Print Optimization */
        @media print {
            #sidebar, .copy-btn, .mobile-toggle, .back-to-top { display: none; }
            main { margin: 0; padding: 0; max-width: 100%; }
            article { box-shadow: none; border: none; margin-bottom: 2rem; page-break-inside: avoid; }
            a { text-decoration: none; color: #000; }
            body { background: #fff; color: #000; }
            pre { border: 1px solid #ccc; }
        }
    </style>
    
    </head>
    <body onload="initApp()">
    
    <!-- Mobile Toggle -->
    <button class="mobile-toggle" onclick="toggleSidebar()">â˜°</button>

    <nav id="sidebar">
        <div class="sidebar-header">
            <input type="text" id="search-input" placeholder="Search modules... (/)" onkeyup="filterModules()">
        </div>
        
        <!-- Progress Stats -->
        <div class="progress-container">
            <div class="progress-text">
                <span id="progress-count">0/0 Completed</span>
                <span id="progress-percent">0%</span>
            </div>
            <div class="progress-bar-bg">
                <div id="progress-fill" class="progress-bar-fill"></div>
            </div>
        </div>

        <div id="toc-container">
            <ul id="toc"></ul>
        </div>
        <div class="controls">
            <button class="btn" onclick="toggleTheme()">ğŸŒ— Theme</button>
            <button class="btn" onclick="resetProgress()">â†º Reset</button>
        </div>
    </nav>

    <main>
    <article id="MODULE_INDEX">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 9 min read</div>
<h1>GCP Associate Cloud Engineer - Course Module Index</h1>
<blockquote>
<p><strong>Industry-Focused Learning Tracks</strong> organized by job role and skill progression</p>
</blockquote>
<hr />
<h2>ğŸ“š How to Use This Guide</h2>
<p>This course is organized into <strong>7 learning tracks</strong> instead of a strict day-by-day sequence. You can:
- Follow the <strong>recommended order</strong> for structured learning
- <strong>Jump to specific tracks</strong> based on your career focus
- Use <strong>time estimates</strong> to plan your study schedule</p>
<p><strong>Total Course Duration:</strong> 60-80 hours (6-8 weeks at 10-12 hrs/week)</p>
<hr />
<h2>ğŸ¯ Track 1: GCP Core Foundations</h2>
<p><strong>Duration:</strong> 12-15 hours | <strong>ACE Exam Weight:</strong> 20%</p>
<p>Master the fundamentals of Google Cloud Platform before diving into specific services.</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Fundamentals</strong></td>
<td><a href="section_1_cloud_foundations.md">section_1_cloud_foundations.md</a></td>
<td>90 min</td>
<td>Cloud models, GCP vs AWS/Azure, regions</td>
</tr>
<tr>
<td><strong>GCP Project Structure</strong></td>
<td><a href="section_2_gcp_structure.md">section_2_gcp_structure.md</a></td>
<td>60 min</td>
<td>Organization hierarchy, folders, IAM basics</td>
</tr>
<tr>
<td><strong>Billing &amp; Cost Management</strong></td>
<td><a href="section_2_gcp_projects_billing.md">section_2_gcp_projects_billing.md</a></td>
<td>60 min</td>
<td>Budgets, billing accounts, cost optimization</td>
</tr>
<tr>
<td><strong>Cloud Shell &amp; CLI</strong></td>
<td><a href="section_21_cloud_shell.md">section_21_cloud_shell.md</a></td>
<td>90 min</td>
<td>gcloud commands, Cloud Shell editor</td>
</tr>
</tbody>
</table>
<h3>ğŸ“ Learning Outcomes</h3>
<ul>
<li>[ ] Explain GCP's global infrastructure</li>
<li>[ ] Create and manage projects</li>
<li>[ ] Set up billing alerts</li>
<li>[ ] Use gcloud CLI confidently</li>
</ul>
<h3>ğŸ” Job Roles Focus</h3>
<ul>
<li><strong>Cloud Engineer:</strong> All modules critical</li>
<li><strong>DevOps:</strong> Focus on CLI and scripting</li>
<li><strong>FinOps:</strong> Deep dive on billing module</li>
</ul>
<hr />
<h2>ğŸ¯ Track 2: Compute &amp; App Hosting</h2>
<p><strong>Duration:</strong> 15-18 hours | <strong>ACE Exam Weight:</strong> 25%</p>
<p>Learn how to deploy and manage applications on GCP compute platforms.</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Compute Engine Basics</strong></td>
<td><a href="section_4_compute_engine.md">section_4_compute_engine.md</a></td>
<td>120 min</td>
<td>VMs, machine types, Spot VMs, Live Migration</td>
</tr>
<tr>
<td><strong>Instance Groups &amp; Auto-scaling</strong></td>
<td><a href="section_8_instance_groups.md">section_8_instance_groups.md</a></td>
<td>90 min</td>
<td>MIGs, auto-healing, scaling policies</td>
</tr>
<tr>
<td><strong>Load Balancing</strong></td>
<td><a href="section_9_load_balancing.md">section_9_load_balancing.md</a></td>
<td>120 min</td>
<td>Global/Regional LB, health checks</td>
</tr>
<tr>
<td><strong>Containers Introduction</strong></td>
<td><a href="section_15_containers.md">section_15_containers.md</a></td>
<td>90 min</td>
<td>Docker basics, Artifact Registry</td>
</tr>
<tr>
<td><strong>GKE Architecture</strong></td>
<td><a href="section_16_kubernetes_arch.md">section_16_kubernetes_arch.md</a></td>
<td>120 min</td>
<td>Control plane, nodes, Autopilot vs Standard</td>
</tr>
<tr>
<td><strong>Cloud Run</strong></td>
<td><a href="section_13_cloud_run.md">section_13_cloud_run.md</a></td>
<td>90 min</td>
<td>Serverless containers, auto-scaling</td>
</tr>
<tr>
<td><strong>App Engine</strong></td>
<td><a href="section_12_app_engine.md">section_12_app_engine.md</a></td>
<td>90 min</td>
<td>Standard vs Flexible, traffic splitting</td>
</tr>
<tr>
<td><strong>Cloud Functions</strong></td>
<td><a href="section_23_cloud_functions.md">section_23_cloud_functions.md</a></td>
<td>90 min</td>
<td>Event-driven, Eventarc, triggers</td>
</tr>
</tbody>
</table>
<h3>ğŸ“Š Service Comparison Decision Table</h3>
<table>
<thead>
<tr>
<th>Need</th>
<th>Use</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>Full VM control</td>
<td><strong>Compute Engine</strong></td>
<td>Custom OS, SSH access, GPU workloads</td>
</tr>
<tr>
<td>High availability web tier</td>
<td><strong>MIG + Load Balancer</strong></td>
<td>Auto-healing, multi-zone</td>
</tr>
<tr>
<td>Stateless containers</td>
<td><strong>Cloud Run</strong></td>
<td>Serverless, pay-per-use, fastest deploy</td>
</tr>
<tr>
<td>Kubernetes workloads</td>
<td><strong>GKE Autopilot</strong></td>
<td>Managed K8s, no node management</td>
</tr>
<tr>
<td>Simple web app</td>
<td><strong>App Engine Standard</strong></td>
<td>PaaS, zero config scaling</td>
</tr>
<tr>
<td>Event-driven functions</td>
<td><strong>Cloud Functions</strong></td>
<td>Sub-second invocations</td>
</tr>
</tbody>
</table>
<h3>ğŸ“ Learning Outcomes</h3>
<ul>
<li>[ ] Choose the right compute service for different workloads</li>
<li>[ ] Deploy auto-scaling, self-healing applications</li>
<li>[ ] Configure load balancers for high availability</li>
<li>[ ] Containerize and deploy apps</li>
</ul>
<h3>ğŸ” Job Roles Focus</h3>
<ul>
<li><strong>Cloud Engineer:</strong> All modules</li>
<li><strong>DevOps Engineer:</strong> Focus on containers, GKE, Cloud Build</li>
<li><strong>SRE:</strong> Deep dive on MIG, load balancing, monitoring</li>
</ul>
<hr />
<h2>ğŸ¯ Track 3: Storage &amp; Databases</h2>
<p><strong>Duration:</strong> 10-12 hours | <strong>ACE Exam Weight:</strong> 15%</p>
<p>Understand GCP's storage options and when to use each.</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Storage Basics</strong></td>
<td><a href="section_6_cloud_storage.md">section_6_cloud_storage.md</a></td>
<td>90 min</td>
<td>Buckets, storage classes, versioning</td>
</tr>
<tr>
<td><strong>Storage Advanced</strong></td>
<td><a href="section_11_storage_advanced.md">section_11_storage_advanced.md</a></td>
<td>120 min</td>
<td>Lifecycle policies, Signed URLs, retention</td>
</tr>
<tr>
<td><strong>Persistent Disks</strong></td>
<td><a href="section_5_storage_basics.md">section_5_storage_basics.md</a></td>
<td>60 min</td>
<td>Zonal vs regional, snapshots</td>
</tr>
<tr>
<td><strong>Cloud SQL</strong></td>
<td><a href="section_10_cloud_sql.md">section_10_cloud_sql.md</a></td>
<td>120 min</td>
<td>HA setup, backups, read replicas</td>
</tr>
<tr>
<td><strong>Cloud Spanner &amp; Bigtable</strong></td>
<td><a href="section_23_cloud_spanner_bigtable.md">section_23_cloud_spanner_bigtable.md</a></td>
<td>90 min</td>
<td>When to use each, scaling patterns</td>
</tr>
</tbody>
</table>
<h3>ğŸ“Š Storage Decision Table</h3>
<table>
<thead>
<tr>
<th>Data Type</th>
<th>Best Service</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>Object storage (images, backups)</td>
<td><strong>Cloud Storage</strong></td>
<td>Durable, cheap, global access</td>
</tr>
<tr>
<td>VM boot disk</td>
<td><strong>Persistent Disk</strong></td>
<td>High IOPS, snapshots</td>
</tr>
<tr>
<td>Relational database</td>
<td><strong>Cloud SQL</strong></td>
<td>Managed MySQL/Postgres</td>
</tr>
<tr>
<td>Global transactions</td>
<td><strong>Cloud Spanner</strong></td>
<td>99.999% availability, global scale</td>
</tr>
<tr>
<td>Time-series / IoT</td>
<td><strong>Bigtable</strong></td>
<td>Millions of ops/sec, HBase compatible</td>
</tr>
<tr>
<td>NoSQL documents</td>
<td><strong>Firestore</strong></td>
<td>Real-time sync, mobile SDKs</td>
</tr>
</tbody>
</table>
<h3>ğŸ“ Learning Outcomes</h3>
<ul>
<li>[ ] Select appropriate storage for different use cases</li>
<li>[ ] Implement lifecycle policies for cost optimization</li>
<li>[ ] Configure database high availability</li>
<li>[ ] Manage backups and disaster recovery</li>
</ul>
<hr />
<h2>ğŸ¯ Track 4: Networking &amp; Security</h2>
<p><strong>Duration:</strong> 15-18 hours | <strong>ACE Exam Weight:</strong> 25%</p>
<p>Master VPC networking and implement enterprise security.</p>
<h3>Networking Modules</h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VPC Fundamentals</strong></td>
<td><a href="section_5_vpc_networking.md">section_5_vpc_networking.md</a></td>
<td>120 min</td>
<td>Subnets, routes, firewall rules</td>
</tr>
<tr>
<td><strong>Hybrid Connectivity</strong></td>
<td><a href="section_14_hybrid_connectivity.md">section_14_hybrid_connectivity.md</a></td>
<td>120 min</td>
<td>Cloud VPN, Cloud Interconnect</td>
</tr>
<tr>
<td><strong>DNS &amp; CDN</strong></td>
<td><a href="section_13_dns_cdn.md">section_13_dns_cdn.md</a></td>
<td>90 min</td>
<td>Cloud DNS, Cloud CDN</td>
</tr>
<tr>
<td><strong>Network Security</strong></td>
<td><a href="section_24_network_security.md">section_24_network_security.md</a></td>
<td>90 min</td>
<td>Private Google Access, Cloud NAT</td>
</tr>
</tbody>
</table>
<h3>Security Modules</h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IAM Fundamentals</strong></td>
<td><a href="section_6_iam_identity.md">section_6_iam_identity.md</a></td>
<td>120 min</td>
<td>Roles, service accounts, policies</td>
</tr>
<tr>
<td><strong>Advanced IAM</strong></td>
<td><a href="section_17_advanced_iam.md">section_17_advanced_iam.md</a></td>
<td>90 min</td>
<td>Workload Identity, Conditions, Deny Policies</td>
</tr>
<tr>
<td><strong>KMS &amp; Encryption</strong></td>
<td><a href="section_18_kms_encryption.md">section_18_kms_encryption.md</a></td>
<td>90 min</td>
<td>CMEK, envelope encryption, Cloud HSM</td>
</tr>
<tr>
<td><strong>Cloud Armor</strong></td>
<td><a href="section_25_cloud_armor.md">section_25_cloud_armor.md</a></td>
<td>60 min</td>
<td>WAF, DDoS protection</td>
</tr>
<tr>
<td><strong>Security Operations</strong></td>
<td><a href="section_20_security_operations.md">section_20_security_operations.md</a></td>
<td>90 min</td>
<td>Security Command Center, VPC Flow Logs</td>
</tr>
</tbody>
</table>
<h3>ğŸ“ Learning Outcomes</h3>
<ul>
<li>[ ] Design secure VPC architectures</li>
<li>[ ] Implement least-privilege IAM policies</li>
<li>[ ] Configure hybrid cloud connectivity</li>
<li>[ ] Encrypt data at rest and in transit</li>
</ul>
<h3>ğŸ” Job Roles Focus</h3>
<ul>
<li><strong>Security Engineer:</strong> All security modules + IAM deep dive</li>
<li><strong>Network Engineer:</strong> Focus on VPC, hybrid connectivity</li>
<li><strong>Cloud Engineer:</strong> Balanced focus across all modules</li>
</ul>
<hr />
<h2>ğŸ¯ Track 5: Operations &amp; Monitoring</h2>
<p><strong>Duration:</strong> 8-10 hours | <strong>ACE Exam Weight:</strong> 15%</p>
<p>Implement SRE practices and production monitoring.</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Operations</strong></td>
<td><a href="section_22_cloud_ops.md">section_22_cloud_ops.md</a></td>
<td>120 min</td>
<td>Logging, Monitoring, Trace, Profiler</td>
</tr>
<tr>
<td><strong>Backup &amp; DR</strong></td>
<td><a href="section_20_backup_dr.md">section_20_backup_dr.md</a></td>
<td>90 min</td>
<td>Snapshots, disaster recovery patterns</td>
</tr>
<tr>
<td><strong>SRE Operations</strong></td>
<td><a href="section_36_sre_ops.md">section_36_sre_ops.md</a></td>
<td>90 min</td>
<td>SLOs, error budgets, incident response</td>
</tr>
<tr>
<td><strong>FinOps</strong></td>
<td><a href="section_37_finops.md">section_37_finops.md</a></td>
<td>60 min</td>
<td>Cost optimization, billing analysis</td>
</tr>
</tbody>
</table>
<h3>ğŸ“ Learning Outcomes</h3>
<ul>
<li>[ ] Create monitoring dashboards and alerts</li>
<li>[ ] Implement log-based metrics</li>
<li>[ ] Design disaster recovery strategies</li>
<li>[ ] Optimize cloud costs</li>
</ul>
<hr />
<h2>ğŸ¯ Track 6: Data &amp; DevOps</h2>
<p><strong>Duration:</strong> 10-12 hours | <strong>ACE Exam Weight:</strong> 10%</p>
<p>Build data pipelines and CI/CD workflows.</p>
<h3>Data Modules</h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Pub/Sub</strong></td>
<td><a href="section_31_pubsub.md">section_31_pubsub.md</a></td>
<td>90 min</td>
<td>Messaging patterns, DLQ, exactly-once</td>
</tr>
<tr>
<td><strong>BigQuery</strong></td>
<td><a href="section_24_bigquery_data_warehousing.md">section_24_bigquery_data_warehousing.md</a></td>
<td>120 min</td>
<td>Partitioning, clustering, cost optimization</td>
</tr>
<tr>
<td><strong>Dataflow &amp; Dataproc</strong></td>
<td><a href="section_32_dataflow_dataproc.md">section_32_dataflow_dataproc.md</a></td>
<td>90 min</td>
<td>Batch vs streaming, when to use each</td>
</tr>
</tbody>
</table>
<h3>DevOps Modules</h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Terraform/IaC</strong></td>
<td><a href="section_26_infrastructure_as_code_terraform.md">section_26_infrastructure_as_code_terraform.md</a></td>
<td>120 min</td>
<td>State management, modules, best practices</td>
</tr>
<tr>
<td><strong>Cloud Build CI/CD</strong></td>
<td><a href="section_27_cloud_build_ci_cd.md">section_27_cloud_build_ci_cd.md</a></td>
<td>90 min</td>
<td>Build triggers, deployment pipelines</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¯ Track 7: Capstone Projects &amp; Exam Prep</h2>
<p><strong>Duration:</strong> 12-15 hours | <strong>Pass/Fail</strong></p>
<p>Apply everything you've learned in real-world projects.</p>
<h3>Capstone Projects</h3>
<table>
<thead>
<tr>
<th>Project</th>
<th>File</th>
<th>Time</th>
<th>Skills Practiced</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Static Website + CDN</strong></td>
<td><a href="capstone_1_static_website.md">capstone_1_static_website.md</a></td>
<td>240 min</td>
<td>GCS, CDN, Load Balancer, DNS, SSL</td>
</tr>
<tr>
<td><strong>Serverless API</strong></td>
<td><a href="capstone_2_serverless_api.md">capstone_2_serverless_api.md</a></td>
<td>240 min</td>
<td>Cloud Run, Cloud SQL, Secret Manager, CI/CD</td>
</tr>
<tr>
<td><strong>Enterprise Network</strong></td>
<td><a href="capstone_3_enterprise_network.md">capstone_3_enterprise_network.md</a></td>
<td>180 min</td>
<td>VPC, subnets, firewall, IAM, logging</td>
</tr>
</tbody>
</table>
<h3>Mini-Projects &amp; Practice</h3>
<table>
<thead>
<tr>
<th>Resource</th>
<th>File</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mini-Projects</strong></td>
<td><a href="mini_projects.md">mini_projects.md</a></td>
<td>5 quick portfolio projects</td>
</tr>
<tr>
<td><strong>Interview Prep</strong></td>
<td><a href="interview_question_bank.md">interview_question_bank.md</a></td>
<td>60+ questions with answers</td>
</tr>
<tr>
<td><strong>Interview Strategy</strong></td>
<td><a href="interview_guide.md">interview_guide.md</a></td>
<td>How to ace GCP interviews</td>
</tr>
</tbody>
</table>
<h3>Exam Preparation</h3>
<table>
<thead>
<tr>
<th>Module</th>
<th>File</th>
<th>Time</th>
<th>Focus</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mock Exam 1</strong></td>
<td><a href="section_43_mock_exam_1.md">section_43_mock_exam_1.md</a></td>
<td>120 min</td>
<td>50 questions, timed</td>
</tr>
<tr>
<td><strong>Mock Exam 2</strong></td>
<td><a href="section_44_mock_exam_2.md">section_44_mock_exam_2.md</a></td>
<td>120 min</td>
<td>50 questions, timed</td>
</tr>
<tr>
<td><strong>Exam Strategy</strong></td>
<td><a href="section_45_exam_strategy.md">section_45_exam_strategy.md</a></td>
<td>60 min</td>
<td>Tips, traps, time management</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ºï¸ Recommended Learning Paths</h2>
<h3>Path 1: Complete Beginner (8 weeks)</h3>
<pre><code>Week 1-2: Track 1 (Foundations)
Week 3-4: Track 2 (Compute) + Track 3 (Storage)
Week 5-6: Track 4 (Networking &amp; Security)
Week 7: Track 5 (Operations) + Track 6 (Data/DevOps)
Week 8: Track 7 (Projects + Exam Prep)
</code></pre>
<h3>Path 2: Already Know AWS/Azure (4 weeks)</h3>
<pre><code>Week 1: Tracks 1-2 (focus on GCP differences)
Week 2: Tracks 3-4 (networking model is VERY different)
Week 3: Track 6 (IaC with Terraform) + Capstone
Week 4: Exam prep + Mock exams
</code></pre>
<h3>Path 3: Job-Focused (Pick Your Role)</h3>
<p><strong>Cloud Engineer Track:</strong></p>
<blockquote>
<p>Tracks 1, 2, 4, 5 â†’ Capstone 1 &amp; 3 â†’ Interview prep</p>
</blockquote>
<p><strong>DevOps Engineer Track:</strong></p>
<blockquote>
<p>Tracks 1, 2, 6 â†’ All mini-projects â†’ Capstone 2 â†’ Interview prep</p>
</blockquote>
<p><strong>Data Engineer Track:</strong></p>
<blockquote>
<p>Tracks 1, 3, 6 (Data modules only) â†’ BigQuery deep dive â†’ Custom data project</p>
</blockquote>
<hr />
<h2>ğŸ“ Study Tips</h2>
<h3>Daily Routine</h3>
<ol>
<li><strong>Theory (30 min):</strong> Read module content</li>
<li><strong>Hands-On Lab (60 min):</strong> Follow CLI steps in YOUR project</li>
<li><strong>Quiz (15 min):</strong> Test knowledge</li>
<li><strong>Review (15 min):</strong> Note tricky concepts</li>
</ol>
<h3>Weekly Milestones</h3>
<ul>
<li>[ ] Complete one full track</li>
<li>[ ] Build a mini-project</li>
<li>[ ] Answer 10 interview questions out loud</li>
</ul>
<h3>Pre-Exam Checklist</h3>
<ul>
<li>[  ] Completed all 7 tracks</li>
<li>[ ] Built 3 capstone projects</li>
<li>[ ] Scored 80%+ on both mock exams</li>
<li>[ ] Can explain 20+ interview questions</li>
<li>[ ] Reviewed common exam traps</li>
</ul>
<hr />
<h2>ğŸ¯ Success Metrics</h2>
<p>You're ready for the ACE exam when:
- âœ… You can design a 3-tier architecture from scratch
- âœ… You've deployed at least 3 real projects
- âœ… You score 80%+ consistently on practice exams
- âœ… You can explain WHY you chose a service, not just WHAT it does
- âœ… You've troubleshot 10+ production-like scenarios</p>
<hr />
<h2>ğŸ“š Additional Resources</h2>
<table>
<thead>
<tr>
<th>Resource</th>
<th>File</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Production Checklists</strong></td>
<td>Each module</td>
<td>Before deploying to production</td>
</tr>
<tr>
<td><strong>Decision Tables</strong></td>
<td>Throughout modules</td>
<td>When choosing between services</td>
</tr>
<tr>
<td><strong>Troubleshooting Guides</strong></td>
<td>IAM, VPC, Compute</td>
<td>When things break</td>
</tr>
<tr>
<td><strong>Cost Calculators</strong></td>
<td>Billing module</td>
<td>Before provisioning resources</td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Last Updated:</strong> 2026-01-21<br />
<strong>Course Version:</strong> 4.0 (Industry-Ready Edition)</p>
</article>
<article id="section_1_cloud_foundations">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 10 min read</div>
<h1>Module 1: Cloud Foundations</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Absolute Beginner<br />
<strong>ACE Exam Weight:</strong> â­ High (Foundational concepts appear across the exam)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Too Long; Didn't Read)</strong><br />
Cloud computing = Renting computers over the internet instead of buying them. You pay monthly like electricity, not upfront like buying a generator. GCP is Google's cloud platform with services like Compute Engine (VMs), Cloud Storage (files), and App Engine (apps).</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will confidently:</p>
<table>
<thead>
<tr>
<th>âœ… Objective</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explain</strong> cloud computing in simple terms</td>
<td>Foundation for every GCP concept</td>
</tr>
<tr>
<td><strong>Compare</strong> On-Premise vs Cloud infrastructure</td>
<td>Common exam scenario questions</td>
</tr>
<tr>
<td><strong>Distinguish</strong> IaaS, PaaS, SaaS models</td>
<td>Helps choose the right GCP service</td>
</tr>
<tr>
<td><strong>Identify</strong> why enterprises choose GCP</td>
<td>Context for architecture decisions</td>
</tr>
<tr>
<td><strong>Navigate</strong> the Google Cloud Console</td>
<td>Essential hands-on skill</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What Is Cloud Computing? (Plain-English)</h2>
<p><strong>Cloud Computing = Renting computing resources over the internet.</strong></p>
<p>Think of it this way: Instead of buying and managing physical computers in your office, you <em>rent</em> them from Google, Amazon, or Microsoft. They handle the hardware; you just use it.</p>
<h3>ğŸš« The Old Way (Buying Physical Hardware)</h3>
<table>
<thead>
<tr>
<th>Resource</th>
<th>What You Had To Do</th>
</tr>
</thead>
<tbody>
<tr>
<td>ğŸ–¥ï¸ <strong>Servers</strong></td>
<td>Purchase machines, rack them in a room</td>
</tr>
<tr>
<td>ğŸ’¾ <strong>Storage</strong></td>
<td>Buy hard drives, set up backup systems</td>
</tr>
<tr>
<td>ğŸ”Œ <strong>Networking</strong></td>
<td>Run cables, configure routers &amp; switches</td>
</tr>
<tr>
<td>ğŸ¢ <strong>Data Centers</strong></td>
<td>Rent space, pay for cooling &amp; electricity</td>
</tr>
</tbody>
</table>
<h3>âœ… The New Way (Renting from the Cloud)</h3>
<p>You access these same resources via the internet from a provider like Google Cloud.</p>
<blockquote>
<p><strong>ğŸ’¡ Key Insight:</strong> You pay only for what you use, when you use it â€” like a utility bill, not a giant upfront purchase.</p>
</blockquote>
<hr />
<h2>ğŸŒ 2. Real-World Analogy: Electricity âš¡</h2>
<p>Understanding the shift from On-Premise to Cloud is easier with an analogy.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">ğŸ­ Old Way (On-Premise)</th>
<th style="text-align: left;">ğŸ”Œ New Way (Cloud)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Source</strong></td>
<td style="text-align: left;">Build your own power plant.</td>
<td style="text-align: left;">Plug into the public grid.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Cost</strong></td>
<td style="text-align: left;">Buy generators &amp; fuel upfront.</td>
<td style="text-align: left;">Pay a monthly bill based on usage.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Maintenance</strong></td>
<td style="text-align: left;">You fix it when it breaks.</td>
<td style="text-align: left;">The utility provider maintains it.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Capacity</strong></td>
<td style="text-align: left;">Fixed (Power outages if overloaded).</td>
<td style="text-align: left;">Scales instantly (Unlimited power).</td>
</tr>
</tbody>
</table>
<p><strong>Cloud works exactly the same way.</strong> You don't build the data center; you just plug in and use the power (compute/storage) you need.</p>
<hr />
<h2>ğŸ¢ 3. On-Premise vs. Cloud (Exam Favorite)</h2>
<p>The ACE exam frequently tests your understanding of <em>why</em> a company would move to the cloud.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">On-Premise (Traditional)</th>
<th style="text-align: left;">Cloud</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Upfront Cost</strong></td>
<td style="text-align: left;">ğŸ’° <strong>Very High (CapEx)</strong><br>Capital Expenditure (owning assets).</td>
<td style="text-align: left;">ğŸ“‰ <strong>Low (OpEx)</strong><br>Operational Expenditure (renting services).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Scaling</strong></td>
<td style="text-align: left;">ğŸ¢ <strong>Slow</strong><br>Weeks/Months to order hardware.</td>
<td style="text-align: left;">ğŸš€ <strong>Instant</strong><br>Minutes to spin up thousands of VMs.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Maintenance</strong></td>
<td style="text-align: left;">ğŸ”§ <strong>Your Responsibility</strong><br>Patching, hardware replacement.</td>
<td style="text-align: left;">â˜ï¸ <strong>Provider's Responsibility</strong><br>Automated updates and repairs.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Availability</strong></td>
<td style="text-align: left;">âš ï¸ <strong>Limited</strong><br>Single point of failure.</td>
<td style="text-align: left;">ğŸŒ <strong>Global</strong><br>Redundant across multiple regions.</td>
</tr>
</tbody>
</table>
<h2>&gt; <strong>ğŸ¯ ACE Tip:</strong> If a question mentions "cost optimization", "scalability", or "global reach" â†’ <strong>Cloud</strong> is standardly the correct answer.</h2>
<h2>ğŸ§© 4. Cloud Service Models (IaaS, PaaS, SaaS)</h2>
<p><strong>The Big Question:</strong> Who manages what? This is the #1 confusion for beginners.</p>
<h3>Quick Reference Table</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>One-Liner</th>
<th>You Manage</th>
<th>Provider Manages</th>
<th>GCP Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IaaS</strong></td>
<td>"Rent the hardware"</td>
<td>OS, Apps, Data</td>
<td>Hardware, Network</td>
<td><strong>Compute Engine</strong></td>
</tr>
<tr>
<td><strong>PaaS</strong></td>
<td>"Just bring code"</td>
<td>Code only</td>
<td>Everything else</td>
<td><strong>App Engine, Cloud Run</strong></td>
</tr>
<tr>
<td><strong>SaaS</strong></td>
<td>"Just use it"</td>
<td>Configuration</td>
<td>Everything</td>
<td><strong>Gmail, Google Docs</strong></td>
</tr>
</tbody>
</table>
<h3>ğŸ”¹ IaaS â€“ Infrastructure as a Service</h3>
<p><strong>Think:</strong> "Virtual hardware rental"<br />
<strong>Reality:</strong> You get a virtual machine. You install the OS, apps, and manage everything on top.<br />
<strong>Best for:</strong> When you need full control (custom software, legacy apps).</p>
<h3>ğŸ”¹ PaaS â€“ Platform as a Service</h3>
<p><strong>Think:</strong> "Just deploy your code"<br />
<strong>Reality:</strong> You upload your application code. The platform handles servers, scaling, patching.<br />
<strong>Best for:</strong> Modern web apps, APIs, microservices.</p>
<h3>ğŸ”¹ SaaS â€“ Software as a Service</h3>
<p><strong>Think:</strong> "Log in and use it"<br />
<strong>Reality:</strong> The software is ready to use in your browser. No installation needed.<br />
<strong>Best for:</strong> Email, documents, CRM systems.</p>
<h3>Responsibility Pyramid (Visual)</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;SaaS (You manage: Nothing)&quot;
        S[Gmail / Docs]
    end

    subgraph &quot;PaaS (You manage: Code)&quot;
        P[App Engine / Cloud Run]
    end

    subgraph &quot;IaaS (You manage: OS + App)&quot;
        I[Compute Engine VMs]
    end

    subgraph &quot;On-Premise (You manage: Everything)&quot;
        O[Your Data Center]
    end

    S --&gt; P --&gt; I --&gt; O

    style S fill:#dcfce7,stroke:#16a34a,stroke-width:2px
    style P fill:#dbeafe,stroke:#2563eb,stroke-width:2px
    style I fill:#fef3c7,stroke:#d97706,stroke-width:2px
    style O fill:#fee2e2,stroke:#dc2626,stroke-width:2px
</code></pre>
<blockquote>
<p><strong>ğŸ¯ Exam Shortcut:</strong>
*   â€œNo server management at allâ€ â†’ <strong>SaaS</strong>
*   â€œDeploy code onlyâ€ â†’ <strong>PaaS</strong>
*   â€œFull control over VM / OSâ€ â†’ <strong>IaaS</strong></p>
</blockquote>
<hr />
<h2>â˜ï¸ 5. Why Google Cloud Platform (GCP)?</h2>
<p>Companies choose Google Cloud specifically for these advantages:</p>
<ol>
<li><strong>ğŸŒ Global Network:</strong> Google's private fiber network provides low-latency global connectivity.</li>
<li><strong>ğŸ”’ Security:</strong> "Secure by Design" infrastructure (encrypted at rest &amp; in transit by default).</li>
<li><strong>ğŸ“Š Data &amp; AI:</strong> Best-in-class tools for Big Data (BigQuery) and ML (Vertex AI).</li>
<li><strong>ğŸ’° Discounts:</strong> Automatic savings with <em>Sustained Use Discounts</em> (no action needed).</li>
<li><strong>ğŸ§© Developer-Friendly:</strong> Modern, container-first approach (Kubernetes was born here).</li>
</ol>
<hr />
<h2>ğŸ› ï¸ 6. Hands-On Lab: Explore Google Cloud Console</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Get familiar with the GCP Console UI navigation.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Open the Console</strong><ul>
<li>Navigate to <a href="https://console.cloud.google.com">console.cloud.google.com</a>.</li>
</ul>
</li>
<li><strong>Sign In</strong><ul>
<li>Use your Google account credentials.</li>
</ul>
</li>
<li><strong>Explore the Navigation Menu (â˜°)</strong><ul>
<li>Located in the top-left corner. This is your primary map.</li>
<li>Click it to see the "Pinned" products like Compute Engine and Storage.</li>
</ul>
</li>
<li><strong>Check the Project Selector</strong><ul>
<li>Located in the top bar. Every resource in GCP <em>must</em> belong to a Project.</li>
</ul>
</li>
<li><strong>Use the Search Bar</strong><ul>
<li>Top middle. Try searching for "Billing" or "Support".</li>
</ul>
</li>
<li><strong>Visit Key Services (View Only)</strong><ul>
<li>Click <strong>Compute Engine</strong> (Virtual Machines).</li>
<li>Click <strong>Cloud Storage</strong> (Buckets).</li>
<li>Click <strong>IAM &amp; Admin</strong> (Permissions).</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>â›” CAUTION:</strong> Do <strong>NOT</strong> create resources yet (cost safety). Just look around!</p>
</blockquote>
<hr />
<h2>âš ï¸ 7. Common Beginner Mistakes</h2>
<p>Avoid these traps that catch many first-time learners:</p>
<ul>
<li>âŒ <strong>Thinking cloud is â€œfree foreverâ€:</strong> Always check the Free Tier limits.</li>
<li>âŒ <strong>Forgetting to delete resources:</strong> Leaving a 64-core VM running can cost $$$ overnight.</li>
<li>âŒ <strong>Confusing GCP with Google Workspace:</strong> GCP is for building apps; Workspace (Gmail/Docs) is for business productivity.</li>
<li>âŒ <strong>Skipping hands-on practice:</strong> You cannot pass the ACE exam just by reading theory.</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Quick Knowledge Check (Quiz)</h2>
<ol>
<li>
<p><strong>What is cloud computing?</strong></p>
<ul>
<li>A. <strong>Remote servers / On-demand IT resources</strong> âœ…</li>
<li>B. Physical hardware</li>
<li>C. Local storage</li>
<li>D. None</li>
<li><strong>Explanation:</strong> Cloud computing is the on-demand delivery of compute, storage, and other IT resources via the internet with pay-as-you-go pricing.</li>
</ul>
</li>
<li>
<p><strong>Which is a Google Cloud region?</strong></p>
<ul>
<li>A. <strong>us-east1</strong> âœ…</li>
<li>B. aws-west</li>
<li>C. azure-central</li>
<li>D. None</li>
<li><strong>Explanation:</strong> us-east1 (South Carolina) is a standard GCP region. aws-west and azure-central belong to other providers.</li>
</ul>
</li>
<li>
<p><strong>What is GCP Console?</strong></p>
<ul>
<li>A. <strong>Web UI</strong> âœ…</li>
<li>B. Command line</li>
<li>C. API</li>
<li>D. SDK</li>
<li><strong>Explanation:</strong> The Google Cloud Console is the primary web interface used to manage your GCP resources visually.</li>
</ul>
</li>
<li>
<p><strong>Cloud storage benefit?</strong></p>
<ul>
<li>A. <strong>Scalability</strong> âœ…</li>
<li>B. Fixed cost</li>
<li>C. Local only</li>
<li>D. Limited</li>
<li><strong>Explanation:</strong> Cloud Storage is designed for 'Exabyte' scale, allowing you to store virtually unlimited data that grows with your needs.</li>
</ul>
</li>
<li>
<p><strong>GCP stands for?</strong></p>
<ul>
<li>A. <strong>Google Cloud Platform</strong> âœ…</li>
<li>B. General Computing</li>
<li>C. Global CPU</li>
<li>D. None</li>
<li><strong>Explanation:</strong> GCP stands for Google Cloud Platform.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<h2>ğŸ¯ 9. ACE Exam Tips (Gold)</h2>
<ul>
<li><strong>Scenario Questions:</strong> The exam will ask questions like <em>"Company X wants to move to the cloud to reduce maintenance overhead..."</em><ul>
<li>Look for <strong>PaaS</strong> or <strong>SaaS</strong> options first.</li>
</ul>
</li>
<li><strong>Keywords to Watch:</strong><ul>
<li>"Cost-effective"</li>
<li>"Scalable"</li>
<li>"Minimal management"</li>
</ul>
</li>
<li><strong>Elimination Strategy:</strong> If a requirement includes "Auto-scaling" or "Global reach", eliminate typical <strong>On-Premise</strong> answers immediately.</li>
</ul>
<hr />
<h2>âœ… 10. Day 1 Checklist</h2>
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'Understand cloud basics.', checked: false },
        { text: 'Know the difference between IaaS / PaaS / SaaS.', checked: false },
        { text: 'Log in to GCP Console.', checked: false },
        { text: 'Explore the Navigation Menu.', checked: false },
        { text: 'Complete the Quiz.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 1 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<h3>ğŸš€ Whatâ€™s Next?</h3>
<p><strong>Day 2: GCP Projects, Billing &amp; Free Tier</strong>
*   What a GCP Project is ğŸ—ï¸
*   How billing works ğŸ’³
*   How to avoid surprise charges ğŸ’¸</p>
<!-- FLASHCARDS
[
  {
    "term": "Cloud Computing",
    "def": "On-demand delivery of compute, storage, applications via the internet. Pay-as-you-go."
  },
  {
    "term": "CapEx",
    "def": "Capital Expenditure. Upfront cost for physical hardware (Data Centers)."
  },
  {
    "term": "OpEx",
    "def": "Operational Expenditure. Ongoing cost for services (Cloud). Pay for what you use."
  },
  {
    "term": "TCO",
    "def": "Total Cost of Ownership. Hidden costs (AC, Security, Staff) + Hardware."
  },
  {
    "term": "GCP",
    "def": "Google Cloud Platform. A suite of cloud services hosted on Google's infrastructure."
  }
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_2_gcp_projects_billing">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Module 2: Projects &amp; Billing</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Absolute Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ Very High (Projects &amp; Billing appear across the exam)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 2, learners will be able to:</p>
<ul>
<li><strong>Explain</strong> what a GCP Project is and why it is required.</li>
<li><strong>Understand</strong> how billing accounts work in Google Cloud.</li>
<li><strong>Use</strong> the GCP Free Tier safely.</li>
<li><strong>Apply</strong> cost-control best practices to avoid surprise bills.</li>
<li><strong>Create</strong> a project and set budgets &amp; alerts correctly.</li>
</ul>
<hr />
<h2>ğŸ§  1. What Is a GCP Project? (Plain-English)</h2>
<p><strong>A GCP Project is a logical container that holds all your cloud resources.</strong></p>
<p>Everything you create in Google Cloud <em>must</em> belong to a project:</p>
<ul>
<li>ğŸ–¥ï¸ <strong>Virtual Machines</strong> (Compute)</li>
<li>ğŸ’¾ <strong>Storage Buckets</strong> (Data)</li>
<li>ğŸŒ <strong>Networks</strong> (Connectivity)</li>
<li>ğŸ” <strong>IAM Permissions</strong> (Access Control)</li>
</ul>
<p>ğŸ‘‰ <strong>Rule:</strong> No Project = No Resources.</p>
<hr />
<h2>ğŸŒ 2. Real-World Analogy: The Office File Cabinet ğŸ—„ï¸</h2>
<ul>
<li><strong>Company</strong> â†’ Google Cloud Account (The Organization).</li>
<li><strong>File Cabinet</strong> â†’ <strong>GCP Project</strong> (Holds related stuff).</li>
<li><strong>Files/Folders</strong> â†’ <strong>Resources</strong> (VMs, Buckets, Databases).</li>
</ul>
<h3>Why do we use projects?</h3>
<ol>
<li><strong>Isolation:</strong> Separate "Dev", "Test", and "Prod" environments completely.</li>
<li><strong>Cost Tracking:</strong> See exactly how much "Project A" costs vs "Project B".</li>
<li><strong>Access Control:</strong> Give a developer access to "Dev" but not "Prod".</li>
</ol>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If a question mentions "isolation", "billing separation", or "distinct environments" â†’ The answer is almost always <strong>Projects</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 3. GCP Resource Hierarchy (Simplified)</h2>
<p>Think of it like a folder structure on your computer:</p>
<ol>
<li><strong>Google Account</strong> (You)</li>
<li>â””â”€â”€ <strong>Billing Account</strong> (Your Credit Card)</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;â””â”€â”€ <strong>Project</strong> (The Container)</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â”œâ”€â”€ <strong>Compute Engine</strong></li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â”œâ”€â”€ <strong>Cloud Storage</strong></li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â””â”€â”€ <strong>IAM &amp; Admin</strong></li>
</ol>
<h3>Key Rules to Remember:</h3>
<ul>
<li>A Project can have only <strong>ONE</strong> Billing Account.</li>
<li>A Billing Account can pay for <strong>MULTIPLE</strong> Projects.</li>
</ul>
<hr />
<h2>ğŸ’³ 4. Understanding Cloud Billing</h2>
<p>GCP uses a <strong>Pay-As-You-Go</strong> model.</p>
<h3>How You Are Charged</h3>
<ul>
<li><strong>Usage:</strong> How much CPU/RAM you use.</li>
<li><strong>Time:</strong> How long a resource runs (per second).</li>
<li><strong>Region:</strong> Some regions (e.g., Zurich) are more expensive than others (e.g., Iowa).</li>
</ul>
<h3>The Billing Account ğŸ’¼</h3>
<ul>
<li>Holds your payment method (Credit Card / Bank Account).</li>
<li>Pays for all linked projects.</li>
<li>Can be <strong>disabled</strong> to stop all spending (and stop all resources).</li>
</ul>
<blockquote>
<p><strong>ğŸ¯ Exam Shortcut:</strong> No active Billing Account = Paid resources <strong>cannot</strong> run.</p>
</blockquote>
<hr />
<h2>ğŸ†“ 5. GCP Free Tier (Safe Learning Zone)</h2>
<p>Google gives you two ways to learn for free:</p>
<h3>1ï¸âƒ£ Always Free (No Expiry)</h3>
<p>Resources you can use <em>every month</em> without paying:
*   <strong>e2-micro VM:</strong> 1 instance (US regions).
*   <strong>Cloud Storage:</strong> 5 GB Standard Storage.
*   <strong>Cloud Functions:</strong> 2 million invocations.</p>
<h3>2ï¸âƒ£ Free Trial Credits ($300)</h3>
<ul>
<li><strong>Amount:</strong> $300 USD (or local equivalent).</li>
<li><strong>Validity:</strong> 90 Days.</li>
<li><strong>Usage:</strong> Can be used on almost any GCP service.</li>
</ul>
<blockquote>
<p><strong>âš ï¸ Warning:</strong> The Free Tier is <strong>limited</strong>. If you start a massive 64-core server, you <em>will</em> burn through your credits instantly.</p>
</blockquote>
<hr />
<h2>ğŸš¨ 6. Cost Control Rules (Critically Important)</h2>
<p>Follow these rules to avoid "Cloud Shock" bills:</p>
<ol>
<li>âœ… <strong>Stop/Delete Unused Resources:</strong> Don't leave VMs running overnight unless needed.</li>
<li>âœ… <strong>Use Small Instances:</strong> Stick to <code>e2-micro</code> or <code>e2-small</code> for practice.</li>
<li>âœ… <strong>Create Budgets:</strong> Always set a budget to get warned <em>before</em> you overspend.</li>
<li>âœ… <strong>Clean Up:</strong> Delete projects when you are done with them.</li>
</ol>
<blockquote>
<p><strong>ğŸ¯ ACE Exam Tip:</strong> If a question asks <em>"How to avoid unexpected charges?"</em> â†’ The answer is <strong>Budgets &amp; Alerts</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 7. Hands-On Lab: Create a Project &amp; Enable Billing</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Create your first GCP project and set up a budget to stay safe.</p>
<h3>âœ… Part 1: Create a Project</h3>
<ol>
<li><strong>Open</strong> the <a href="https://console.cloud.google.com">GCP Console</a>.</li>
<li><strong>Click</strong> the <strong>Project Selector</strong> dropdown (top bar, next to the Google Cloud logo).</li>
<li><strong>Click</strong> <strong>"New Project"</strong>.</li>
<li><strong>Project Name:</strong> Enter <code>gcp-learning-day2</code>.</li>
<li><strong>Billing Account:</strong> Ensure your active account is selected.</li>
<li><strong>Click</strong> <strong>Create</strong>. (Wait ~30 seconds).</li>
</ol>
<h3>âœ… Part 2: Verify Billing Link</h3>
<ol>
<li><strong>Search</strong> for "Billing" in the top search bar.</li>
<li><strong>Select</strong> "Billing" from the results.</li>
<li><strong>Verify</strong> that <code>gcp-learning-day2</code> appears in the list of "Projects linked to this billing account".</li>
</ol>
<h3>âœ… Part 3: Set a Budget (Best Practice)</h3>
<ol>
<li>In the Billing section, click <strong>"Budgets &amp; alerts"</strong> (left menu).</li>
<li>Click <strong>"Create Budget"</strong>.</li>
<li><strong>Name:</strong> <code>Monthly-Safety-Budget</code>.</li>
<li><strong>Amount:</strong> Set to <code>Target amount: â‚¹500</code> (or $10 USD).</li>
<li><strong>Actions:</strong> Keep default alerts (50%, 90%, 100%).</li>
<li><strong>Click</strong> <strong>Finish</strong>.</li>
</ol>
<blockquote>
<p><strong>ğŸ‰ Success!</strong> You typically receive an email alert if your spend usually hits 50% of this amount. You are now safer to experiment!</p>
</blockquote>
<hr />
<h2>âš ï¸ 8. Common Exam Traps</h2>
<p>Don't fall for these common misconceptions on the ACE exam:</p>
<ul>
<li>âŒ <strong>Trap:</strong> "Stopping a VM stops all costs."<ul>
<li><strong>Truth:</strong> You still pay for the <strong>Disk (Storage)</strong> attached to it!</li>
</ul>
</li>
<li>âŒ <strong>Trap:</strong> "Data transfer is free."<ul>
<li><strong>Truth:</strong> Data coming <strong>IN</strong> (Ingress) is usually free. Data going <strong>OUT</strong> (Egress) usually costs money.</li>
</ul>
</li>
<li>âŒ <strong>Trap:</strong> "Deleting a VM deletes the Project."<ul>
<li><strong>Truth:</strong> No. The Project remains. To delete everything, delete the <strong>Project</strong>.</li>
</ul>
</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 9. Quick Knowledge Check (Quiz)</h2>
<ol>
<li>
<p><strong>Every GCP resource must belong to a:</strong></p>
<ul>
<li>A. Folder</li>
<li>B. <strong>Project</strong> âœ…</li>
<li>C. Billing Account</li>
</ul>
</li>
<li>
<p><strong>Can one Billing Account pay for multiple Projects?</strong></p>
<ul>
<li>A. <strong>Yes</strong> âœ…</li>
<li>B. No</li>
</ul>
</li>
<li>
<p><strong>What happens if you disable the Billing Account?</strong></p>
<ul>
<li>A. Resources run for free</li>
<li>B. <strong>All paid resources stop working</strong> âœ…</li>
<li>C. Nothing happens</li>
</ul>
</li>
<li>
<p><strong>What is the best way to prevent surprise bills?</strong></p>
<ul>
<li>A. Check the console every hour</li>
<li>B. <strong>Set up Budgets &amp; Alerts</strong> âœ…</li>
<li>C. Only use the Free Tier</li>
</ul>
</li>
<li>
<p><strong>True or False: The Free Tier allows unlimited usage of all services.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain what a GCP Project is.', checked: false },
        { text: 'I understand how Billing Accounts link to Projects.', checked: false },
        { text: 'I have created my first Project (gcp-learning-day2).', checked: false },
        { text: 'I have set up a Budget to track spending.', checked: false },
        { text: 'I completed the Quiz.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 2 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_2_gcp_structure">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Module 3: Resource Hierarchy</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Foundational)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 2, you will be able to:
*   <strong>Differentiate</strong> between physical infrastructure (Regions/Zones) and logical organization.
*   <strong>Master</strong> the GCP Resource Hierarchy (the "Tree of Governance").
*   <strong>Identify</strong> the 3 project identifiers and when to use them.
*   <strong>Understand</strong> how Organization Policies set global guardrails.</p>
<hr />
<h2>ğŸ§  1. The Physical Layer: Regions &amp; Zones ğŸŒ</h2>
<p>GCP isn't just "in the sky"; it's a massive mesh of fiber optic cables and concrete buildings.</p>
<h3>The Breakdown</h3>
<ul>
<li><strong>Region:</strong> A specific geographical location (e.g., <code>us-central1</code>, <code>asia-south1</code>).</li>
<li><strong>Zone:</strong> A deployment area <em>within</em> a region (e.g., <code>us-central1-a</code>). Think of a Zone as one or more <strong>Data Center Buildings</strong>.</li>
<li><strong>Edge Points of Presence (PoPs):</strong> These are locations that connect Google's network to the rest of the internet. They host <strong>Cloud CDN</strong> and <strong>Cloud IDS</strong>.</li>
</ul>
<blockquote>
<p>[!IMPORTANT]
<strong>High Availability (HA) Rule of Thumb:</strong>
Always deploy your application across at least <strong>two zones</strong> in a region to survive a data center outage. For legendary reliability, go <strong>Multi-Region</strong>.</p>
</blockquote>
<pre><code class="language-mermaid">graph TD
    subgraph Geography [&quot;ğŸŒ Geography (e.g., Americas)&quot;]
        direction TB
        Region1[&quot;ğŸ“ Region: us-central1 (Iowa)&quot;]
        Region2[&quot;ğŸ“ Region: us-east1 (S. Carolina)&quot;]
    end

    subgraph us_central1 [&quot;Building the Infrastructure&quot;]
        direction LR
        ZoneA[&quot;ğŸ¢ Zone A&quot;]
        ZoneB[&quot;ğŸ¢ Zone B&quot;]
        ZoneC[&quot;ğŸ¢ Zone C&quot;]
    end

    Region1 --&gt; ZoneA
    Region1 --&gt; ZoneB
    Region1 --&gt; ZoneC

    style Geography fill:#f8fafc,stroke:#94a3b8,stroke-width:2px
    style us_central1 fill:#f0f9ff,stroke:#0369a1,stroke-width:2px
    style ZoneA fill:#ecfdf5,stroke:#10b981
    style ZoneB fill:#ecfdf5,stroke:#10b981
    style ZoneC fill:#ecfdf5,stroke:#10b981
</code></pre>
<hr />
<h2>ğŸŒ³ 2. The Logical Layer: Resource Hierarchy</h2>
<p>This is how Google Cloud manages access and billing. It follows a strict <strong>Parent-Child</strong> relationship.</p>
<blockquote>
<p>[!TIP]
<strong>Inheritance is Power:</strong> If you assign a permission at the Folder level, it "flows down" to all Projects and Resources inside it.</p>
</blockquote>
<pre><code class="language-mermaid">graph TD
    Org[&quot;ğŸ¢ Organization&lt;br/&gt;(company.com)&quot;]

    Folder_Prod[&quot;ğŸ“ Folder: Production&quot;]
    Folder_Dev[&quot;ğŸ“ Folder: Development&quot;]

    Proj_App[&quot;ğŸš€ Project: Web-App-Prod&quot;]
    Proj_DB[&quot;ğŸ’¾ Project: SQL-Static&quot;]

    Res_VM[&quot;ğŸ–¥ï¸ Compute VM&quot;]
    Res_Bkt[&quot;ğŸ“¦ Storage Bucket&quot;]

    Org --&gt; Folder_Prod
    Org --&gt; Folder_Dev

    Folder_Prod --&gt; Proj_App
    Folder_Prod --&gt; Proj_DB

    Proj_App --&gt; Res_VM
    Proj_App --&gt; Res_Bkt

    style Org fill:#fefce8,stroke:#eab308,stroke-width:2px
    style Folder_Prod fill:#f0f9ff,stroke:#0369a1
    style Folder_Dev fill:#f0f9ff,stroke:#0369a1
    style Proj_App fill:#ecfdf5,stroke:#10b981
</code></pre>
<h3>The 4 Pillars</h3>
<ol>
<li><strong>Organization:</strong> The root node (requires Google Workspace or Cloud Identity).</li>
<li><strong>Folders:</strong> Optional but recommended for team-based isolation (e.g., Apps, Data, Security).</li>
<li><strong>Projects:</strong> The fundamental "container". <strong>Billing and APIs are managed here.</strong></li>
<li><strong>Resources:</strong> The individual services (VMs, Buckets, Pub/Sub topics).</li>
</ol>
<hr />
<h2>ğŸ†” 3. Project Identifiers (Exam Gold ğŸ¥‡)</h2>
<p>You will be asked which ID to use in different scenarios.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Identifier</th>
<th style="text-align: left;">Mutable?</th>
<th style="text-align: left;">Unique?</th>
<th style="text-align: left;">Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Project Name</strong></td>
<td style="text-align: left;">âœ… Yes</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">Human-friendly name (e.g., "My Demo").</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Project ID</strong></td>
<td style="text-align: left;">âŒ <strong>No</strong></td>
<td style="text-align: left;"><strong>Globally</strong></td>
<td style="text-align: left;"><strong>CLI, Terraform, APIs.</strong> (e.g., <code>my-project-123</code>).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Project Number</strong></td>
<td style="text-align: left;">âŒ <strong>No</strong></td>
<td style="text-align: left;"><strong>Globally</strong></td>
<td style="text-align: left;"><strong>Internal Google use.</strong> (e.g., <code>103948572</code>).</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!CAUTION]
Once you create a Project ID, you <strong>cannot change it</strong>. Most people append numbers to their desired name to ensure global uniqueness.</p>
</blockquote>
<hr />
<h2>ğŸ›¡ï¸ 4. Organization Policies (The Guardrails)</h2>
<p>Organization Policies give you central control over your cloud environment.</p>
<ul>
<li><strong>IAM</strong> controls <strong>WHO</strong> can do things.</li>
<li><strong>Org Policy</strong> controls <strong>WHAT</strong> can be done.</li>
</ul>
<blockquote>
<p>[!WARNING]
An Organization Policy <strong>overrides</strong> IAM. If an Org Policy says "No Public IPs", even the Project Owner cannot create a VM with a Public IP.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Resource Discovery</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Discover your project's "DNA" and verify regional availability.</p>
<ol>
<li><strong>Open Cloud Shell</strong> (The <code>&gt;_</code> icon in the top right).</li>
<li><strong>List your projects:</strong>
    <code>bash
    gcloud projects list</code></li>
<li><strong>Find your Project Number:</strong>
    <code>bash
    gcloud projects describe $(gcloud config get-value project) --format="value(projectNumber)"</code></li>
<li><strong>Explore Regions:</strong>
    <code>bash
    gcloud compute regions list --filter="name~us"</code></li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>What is a GCP Project?</strong></p>
<ul>
<li>A. <strong>Resource container</strong> âœ… (A project is the fundamental unit for organizing resources.)</li>
<li>B. VM only</li>
<li>C. User account</li>
<li>D. Billing</li>
<li><strong>Explanation:</strong> A project is the fundamental container for all resources in Google Cloud. Billing and APIs are managed at this level.</li>
</ul>
</li>
<li>
<p><strong>What is the top level of the Resource Hierarchy?</strong></p>
<ul>
<li>A. <strong>Organization</strong> âœ…</li>
<li>B. Folder</li>
<li>C. Project</li>
<li>D. Resource</li>
<li><strong>Explanation:</strong> The Organization is the root node of the Google Cloud resource hierarchy, typically representing a company.</li>
</ul>
</li>
<li>
<p><strong>What is a Zone in Google Cloud?</strong></p>
<ul>
<li>A. A group of regions</li>
<li>B. <strong>A single failure domain (datacenter building)</strong> âœ…</li>
<li>C. A region</li>
<li>D. A project</li>
<li><strong>Explanation:</strong> A zone is a deployment area within a region. Deploying across multiple zones ensures High Availability (HA).</li>
</ul>
</li>
<li>
<p><strong>What is the primary benefit of a Multi-Region deployment?</strong></p>
<ul>
<li>A. Low cost</li>
<li>B. <strong>Maximum High Availability</strong> âœ…</li>
<li>C. Simplicity</li>
<li>D. Local access</li>
<li><strong>Explanation:</strong> Multi-region deployments provide the highest level of availability and disaster recovery across geographical distances.</li>
</ul>
</li>
<li>
<p><strong>What does a Region contain?</strong></p>
<ul>
<li>A. <strong>Multiple zones</strong> âœ…</li>
<li>B. One zone</li>
<li>C. Projects</li>
<li>D. Users</li>
<li><strong>Explanation:</strong> A region is a geographical location that consists of three or more zones.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain the difference between a Region and a Zone.', checked: false },
        { text: 'I know the 4 layers of the Resource Hierarchy.', checked: false },
        { text: 'I understand when to use Project ID vs Project Number.', checked: false },
        { text: 'I know that Org Policies override IAM permissions.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 2 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_3_compute_engine">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 3: Compute Engine (VMs) &amp; Machine Types</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (VM questions are everywhere)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 3, you will be able to:
*   <strong>Explain</strong> the Infrastructure as a Service (IaaS) model.
*   <strong>Select</strong> the right Machine Family for any workload.
*   <strong>Understand</strong> the difference between Zonal and Regional availability.
*   <strong>Deploy</strong> a functional web server using a Linux VM.</p>
<hr />
<h2>ğŸ§  1. What is Compute Engine?</h2>
<p><strong>Compute Engine</strong> is Google's <strong>IaaS</strong> (Infrastructure as a Service) powerhouse. </p>
<blockquote>
<p>[!NOTE]
Think of it as renting a "raw" computer in Google's data center. You get to choose the CPU, RAM, Disk, and Operating System.</p>
</blockquote>
<h3>Core Architecture</h3>
<pre><code class="language-mermaid">graph LR
    User[User] --&gt; Internet((Internet))
    Internet --&gt; Firewall[Firewall Rules]
    Firewall --&gt; VM[Compute Engine VM]

    subgraph VM_Internal [&quot;Inside the VM&quot;]
        OS[OS: Linux/Windows]
        App[Your App: Nginx/MySQL]
    end

    VM --&gt; PD[(Persistent Disk)]

    style VM fill:#dbeafe,stroke:#1e40af,stroke-width:2px
    style VM_Internal fill:#f8fafc,stroke:#94a3b8
</code></pre>
<hr />
<h2>ğŸ• 2. The "Pizza as a Service" Analogy</h2>
<p>How does <strong>Compute Engine (IaaS)</strong> compare to other models?</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;"><strong>IaaS (Compute Engine)</strong></th>
<th style="text-align: left;"><strong>PaaS (App Engine)</strong></th>
<th style="text-align: left;"><strong>FaaS (Cloud Functions)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Analogy</strong></td>
<td style="text-align: left;">Making Pizza at Home</td>
<td style="text-align: left;">Pizza Delivery</td>
<td style="text-align: left;">Eating at a Buffet</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Control</strong></td>
<td style="text-align: left;">High (Dough, Sauce, Oven)</td>
<td style="text-align: left;">Medium (Just Toppings)</td>
<td style="text-align: left;">Low (Just Eat)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Effort</strong></td>
<td style="text-align: left;">High (Clean the kitchen)</td>
<td style="text-align: left;">Low (Just wait)</td>
<td style="text-align: left;">Zero (Disposable)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Pricing</strong></td>
<td style="text-align: left;">By the Hour/Minute</td>
<td style="text-align: left;">By Instance/Request</td>
<td style="text-align: left;">By Execution Time</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
Use <strong>IaaS (Compute Engine)</strong> when you need total control over the OS or have legacy software that requires specific configuration.</p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 3. Machine Families: The "Right Tool for the Job"</h2>
<p>Google offers three main families of virtual machines. Choosing the wrong one can waste thousands of dollars!</p>
<pre><code class="language-mermaid">mindmap
  root((Machine Families))
    (General Purpose)
      E2: Balanced &amp; Cost Effective
      N2: Performance &amp; Scalability
      Analogy: The Toyota Camry
    (Compute Optimized)
      C2: High Clock Speed
      Best for: Gaming, Video Encoding
      Analogy: The Sports Car
    (Memory Optimized)
      M2: Massive RAM (up to 12TB)
      Best for: SAP HANA, In-Memory DBs
      Analogy: The Freight Truck
</code></pre>
<blockquote>
<p>[!IMPORTANT]
<strong>E2 Series</strong> is your best friend for learning. It's cost-optimized and part of the <strong>GCP Free Tier</strong> (e2-micro).</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Your First Cloud Server</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Create a Linux VM and install a web server that says "Hello World".</p>
<h3>âœ… Step 1: Configuration</h3>
<ol>
<li>Go to <strong>Compute Engine &gt; VM Instances</strong>.</li>
<li>Click <strong>Create Instance</strong>.</li>
<li>Name: <code>web-server-1</code>.</li>
<li>Region: <code>us-central1</code>.</li>
<li>Machine type: <strong>e2-micro</strong> (Look for the "Free Tier" badge!).</li>
</ol>
<h3>âœ… Step 2: The Firewall (Critical!)</h3>
<p>Scroll down to <strong>Networking</strong>.
*   [x] <strong>Allow HTTP traffic</strong>
*   [x] <strong>Allow HTTPS traffic</strong></p>
<blockquote>
<p>[!WARNING]
If you forget to check these boxes, your web server will be "UP" but nobody will be able to see it!</p>
</blockquote>
<h3>âœ… Step 3: Automation (Startup Script)</h3>
<p>Expand <strong>Advanced Options &gt; Management</strong>. In the <strong>Startup Script</strong> box, paste:</p>
<pre><code class="language-bash">#! /bin/bash
apt update
apt install -y apache2
echo &quot;&lt;h1&gt;Deployed via Compute Engine ğŸš€&lt;/h1&gt;&quot; &gt; /var/www/html/index.html
</code></pre>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>You need a VM for a high-performance video rendering app. Which family should you choose?</strong></p>
<ul>
<li>A. E2</li>
<li>B. <strong>C2</strong> âœ…</li>
<li>C. M2</li>
</ul>
</li>
<li>
<p><strong>Which service model requires the MOST management effort from you?</strong></p>
<ul>
<li>A. <strong>IaaS</strong> âœ…</li>
<li>B. PaaS</li>
<li>C. SaaS</li>
</ul>
</li>
<li>
<p><strong>True or False: A VM's Ephemeral IP Address remains the same if you stop and restart the VM.</strong></p>
<ul>
<li><em>Answer:</em> <strong>False.</strong> It changes. Use a <strong>Static IP</strong> if you need it to stay the same.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand what IaaS stands for.', checked: false },
        { text: 'I know when to use C2 vs E2 machine types.', checked: false },
        { text: 'I successfully launched a VM and saw the Hello page.', checked: false },
        { text: 'I know that allowing HTTP traffic creates a firewall rule.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 3 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_3_gcp_billing">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>SECTION 3: Billing, Budgets &amp; Cost Management</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/billing/docs">Cloud Billing Docs</a></p>
</blockquote>
<h2>1ï¸âƒ£ How Google Charges You ğŸ’¸</h2>
<h3>The Relationship: Billing Account &lt;-&gt; Project</h3>
<p>The most common point of confusion: <strong>Projects DO NOT hold money. Billing Accounts do.</strong></p>
<pre><code class="language-mermaid">graph LR
    CC[&quot;ğŸ’³ Credit Card / Invoice&quot;] --&gt; BA[&quot;Billing Account&quot;]
    BA -- Pays for --&gt; P1[&quot;Project A (Dev)&quot;]
    BA -- Pays for --&gt; P2[&quot;Project B (Prod)&quot;]
    BA -- Pays for --&gt; P3[&quot;Project C (Test)&quot;]

    style CC fill:#bbf7d0,stroke:#16a34a
    style BA fill:#fef08a,stroke:#ca8a04,stroke-width:2px
    style P1 fill:#e0f2fe,stroke:#0284c7
    style P2 fill:#e0f2fe,stroke:#0284c7
    style P3 fill:#e0f2fe,stroke:#0284c7
</code></pre>
<ul>
<li><strong>One-to-Many:</strong> One Billing Account can pay for huge numbers of projects.</li>
<li><strong>Many-to-One:</strong> A Project can only be linked to <strong>ONE</strong> Billing Account at a time.</li>
<li><strong>Linking:</strong> You "link" a project to a billing account to enable services. If you "unlink" it, everything stops.</li>
</ul>
<hr />
<h2>2ï¸âƒ£ Cost Controls: Quotas vs Budgets ğŸ›¡ï¸</h2>
<p>These are your two shields against bankruptcy.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Example</th>
<th style="text-align: left;">Action on Trigger</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Quota</strong></td>
<td style="text-align: left;"><strong>Hard Limit</strong></td>
<td style="text-align: left;">"Max 5 GPUs per Region"</td>
<td style="text-align: left;"><strong>Stops Deployment.</strong> "Error: Quota Exceeded".</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Budget</strong></td>
<td style="text-align: left;"><strong>Warning</strong></td>
<td style="text-align: left;">"$500 Monthly Budget"</td>
<td style="text-align: left;"><strong>Sends Email.</strong> "Alert: You have spent $450".</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>IMPORTANT:</strong> A Budget Notification does <strong>NOT</strong> stop your services. It just emails you. If you sleep through the email, you keep paying.</p>
</blockquote>
<hr />
<h2>3ï¸âƒ£ Free Tier vs Free Trial ğŸ†“</h2>
<ul>
<li><strong>Free Trial:</strong> $300 credit for 90 days. Once it's gone, it's gone.</li>
<li><strong>Free Tier (Always Free):</strong> Generous limits available to everyone, forever.<ul>
<li><em>Example:</em> <code>e2-micro</code> instance in <code>us-central1</code>, <code>us-west1</code>, or <code>us-east1</code> (check specifics, they change!).</li>
<li><em>Storage:</em> 5GB Regional Storage.</li>
</ul>
</li>
</ul>
<hr />
<h2>4ï¸âƒ£ Hands-On Lab: Setting a Safety Net ğŸª‚</h2>
<p><strong>Mission:</strong> Create a Budget Alert to prevent surprises.</p>
<ol>
<li><strong>Navigate:</strong> Hamburger Menu &gt; <strong>Billing</strong>.</li>
<li><strong>Select:</strong> Go to <strong>Budgets &amp; alerts</strong> (Left sidebar).</li>
<li><strong>Create:</strong> Click <strong>Create Budget</strong>.</li>
<li><strong>Scope:</strong> Select your Project (or "All Projects").</li>
<li><strong>Amount:</strong> Set Target amount to <strong>$10</strong> (or your currency equivalent).</li>
<li><strong>Actions:</strong><ul>
<li>Set thresholds at 50% ($5), 90% ($9), and 100% ($10).</li>
<li>Check "Email alerts to billing admins".</li>
</ul>
</li>
<li><strong>Finish:</strong> Click Save. Use this for every personal project!</li>
</ol>
<hr />
<h2>5ï¸âƒ£ Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>True or False: If you exceed your configured Budget Alert, Google Cloud will automatically shut down your virtual machines to prevent further charges.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False</strong> âœ…</li>
</ul>
</li>
<li>
<p><strong>You try to create a TPU (Tensor Processing Unit) for AI training but receive a "Quota Exceeded" error. You have a valid credit card attached. What is the issue?</strong></p>
<ul>
<li>A. Your credit card failed.</li>
<li>B. <strong>You hit a default Rate/Allocation Quota.</strong> âœ…</li>
<li>C. TPUs are only for Enterprises.</li>
<li>D. You must enable the "AI API" first.</li>
</ul>
</li>
<li>
<p><strong>Which of the following is an example of CapEx (Capital Expenditure)?</strong></p>
<ul>
<li>A. Monthly Cloud SQL bill.</li>
<li>B. <strong>Buying a physical server rack for $50,000.</strong> âœ…</li>
<li>C. Pay-as-you-go Network egress fees.</li>
<li>D. Spot VM instances.</li>
</ul>
</li>
</ol>
<hr />
<h3>âš¡ Zero-to-Hero: Pro Tips</h3>
<ul>
<li><strong>The "BigQuery Export":</strong> Professional Cloud Architects enable "Billing Export to BigQuery" on Day 1. It allows you to run SQL queries on your costs (e.g., "Show me costs by Label in June"). The standard Console UI cannot answer complex questions.</li>
<li><strong>Labels:</strong> Tag everything! Add labels like <code>env:prod</code> or <code>team:marketing</code> to resources so you can split the bill later.</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Billing Account", "def": "The entity that performs the actual payment (Credit Card/Invoice). linked to Projects."},
  {"term": "Quota", "def": "Hard limit on resource usage (e.g. 5 VMs max). Protects against accidental overspend."},
  {"term": "Budget", "def": "A soft limit that sends alerts (emails) when thresholds are met. Does NOT stop spending."},
  {"term": "Free Tier", "def": "Always Free resource limits available to all users (separate from Free Trial)."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_4_cloud_storage">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 4: Cloud Storage (GCS) &amp; Storage Classes</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Very High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 4, you will be able to:
*   <strong>Differentiate</strong> between Object Storage and Block Storage.
*   <strong>Select</strong> the optimal Storage Class based on access frequency.
*   <strong>Deploy</strong> a static website using a globally unique bucket.
*   <strong>Configure</strong> IAM permissions for public object access.</p>
<hr />
<h2>ğŸ§  1. What is Cloud Storage?</h2>
<p><strong>Cloud Storage (GCS)</strong> is "Object Storage". Unlike a hard drive (which stores bits of files in blocks), GCS stores the entire file as an "Object" along with metadata.</p>
<h3>Object vs. Block Storage</h3>
<pre><code class="language-mermaid">graph TD
    subgraph Object_Storage [&quot;ğŸ“¦ Object Storage (GCS)&quot;]
        Obj1[&quot;File + Metadata + ID&quot;]
        Obj2[&quot;File + Metadata + ID&quot;]
    end

    subgraph Block_Storage [&quot;ğŸ’¾ Block Storage (Persistent Disk)&quot;]
        Block1[&quot;Data Segment&quot;]
        Block2[&quot;Data Segment&quot;]
    end

    Object_Storage -- &quot;Accessed via API/URL&quot; --&gt; Internet((Internet))
    Block_Storage -- &quot;Attached to VM&quot; --&gt; VM[Compute Engine VM]
</code></pre>
<blockquote>
<p>[!NOTE]
<strong>Key Rule:</strong> If you need to run an OS or a high-performance DB, use <strong>Block Storage</strong>. If you need to store billions of images or backups, use <strong>Object Storage</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 2. The Storage Hierarchy: Buckets &amp; Objects</h2>
<ul>
<li><strong>Bucket:</strong> A container for your objects. </li>
<li><strong>Object:</strong> The actual file (image, video, log).</li>
</ul>
<blockquote>
<p>[!IMPORTANT]
<strong>The Global Rule:</strong>
Bucket names must be <strong>globally unique</strong>. This means if I name my bucket <code>test-bucket</code>, nobody else on the planet can use that name.</p>
</blockquote>
<hr />
<h2>ğŸ”¥ 3. Storage Classes: The "Temperature" of Data</h2>
<p>Google allows you to trade accessibility for cost. The less you access it, the less you pay.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Class</th>
<th style="text-align: left;">Analogy</th>
<th style="text-align: left;">Use Case</th>
<th style="text-align: left;">Min Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Standard</strong></td>
<td style="text-align: left;">ğŸ”¥ Hot</td>
<td style="text-align: left;">Streaming, Websites, Daily use.</td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Nearline</strong></td>
<td style="text-align: left;">ğŸŒ¦ï¸ Warm</td>
<td style="text-align: left;">Backups (accessed &lt; once / mo).</td>
<td style="text-align: left;">30 Days</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Coldline</strong></td>
<td style="text-align: left;">â„ï¸ Cold</td>
<td style="text-align: left;">Disaster Recovery (&lt; once / quarter).</td>
<td style="text-align: left;">90 Days</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Archive</strong></td>
<td style="text-align: left;">ğŸ§Š Frozen</td>
<td style="text-align: left;">Regulatory compliance (&lt; once / year).</td>
<td style="text-align: left;">365 Days</td>
</tr>
</tbody>
</table>
<pre><code class="language-mermaid">graph LR
    S[Standard] --&gt; N[Nearline]
    N --&gt; C[Coldline]
    C --&gt; A[Archive]

    style S fill:#ef4444,color:#fff
    style N fill:#fbbf24
    style C fill:#60a5fa
    style A fill:#1e40af,color:#fff
</code></pre>
<blockquote>
<p>[!TIP]
<strong>Lifecycle Policies:</strong> You can automate this! You can set a rule to move files from <strong>Standard</strong> to <strong>Archive</strong> automatically after 365 days.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Host a Static Website</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Create a bucket and host a public image/file.</p>
<h3>âœ… Step 1: Create the Bucket</h3>
<ol>
<li>Go to <strong>Cloud Storage &gt; Buckets</strong>.</li>
<li>Click <strong>Create</strong>.</li>
<li>Name: <code>gcp-hero-website-{{RANDOM_NUM}}</code>.</li>
<li>Choose <strong>Regional</strong> and pick <code>us-central1</code>.</li>
</ol>
<h3>âœ… Step 2: Public Access (Security)</h3>
<ol>
<li><strong>Uncheck</strong> "Enforce public access prevention on this bucket".</li>
<li>Select <strong>Uniform</strong> access control.</li>
</ol>
<blockquote>
<p>[!CAUTION]
In a production environment, you should almost always use <strong>Enforce Public Access Prevention</strong> unless you specifically intend to host a public website.</p>
</blockquote>
<h3>âœ… Step 3: Make it Public</h3>
<p>After uploading a file (e.g., <code>index.html</code>):
1.  Go to the <strong>Permissions</strong> tab.
2.  Click <strong>Grant Access</strong>.
3.  New Principal: <code>allUsers</code>.
4.  Role: <strong>Storage &gt; Storage Object Viewer</strong>.</p>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>You need to store 10TB of tax records that legal says you must keep for 7 years, but will likely never look at. Which class?</strong></p>
<ul>
<li>A. Standard</li>
<li>B. Nearline</li>
<li>C. <strong>Archive</strong> âœ…</li>
<li>D. Coldline</li>
</ul>
</li>
<li>
<p><strong>What happens if you delete a file in a bucket that has 'Object Versioning' enabled?</strong></p>
<ul>
<li><em>Answer:</em> The file becomes a <strong>Noncurrent Version</strong>. It isn't actually gone; it's just hidden. You can restore it later.</li>
</ul>
</li>
<li>
<p><strong>True or False: Bucket names can be duplicated as long as they are in different regions.</strong></p>
<ul>
<li><em>Answer:</em> <strong>False.</strong> Names are globally unique.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand why bucket names must be unique.', checked: false },
        { text: 'I successfully hosted a file and viewed it via Public URL.', checked: false },
        { text: 'I can name the 4 storage classes in order of cost.', checked: false },
        { text: 'I know the difference between allUsers and allAuthenticatedUsers.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 4 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_4_compute_engine">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 13 min read</div>
<h1>Module 5: Compute Engine Basics</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (The backbone of GCP compute)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Quick Summary)</strong><br />
Compute Engine = Virtual Machines (VMs) in Google's data centers. Pick the right <strong>machine family</strong> (E2 for cheap, N2 for consistent, M2 for huge RAM). Save money with <strong>Spot VMs</strong> (60-91% off but can be stopped) or <strong>CUDs</strong> (commit for 1-3 years). Google's <strong>Live Migration</strong> moves your VM during maintenance with &lt;1 second of downtime.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Select</strong> the right machine family</td>
<td>Match workload to VM type = optimal cost</td>
</tr>
<tr>
<td><strong>Implement</strong> Spot VMs and CUDs</td>
<td>Save up to 91% on compute costs</td>
</tr>
<tr>
<td><strong>Configure</strong> startup scripts</td>
<td>Automate VM configuration on boot</td>
</tr>
<tr>
<td><strong>Understand</strong> Live Migration</td>
<td>Know how Google handles maintenance</td>
</tr>
<tr>
<td><strong>Create</strong> VMs using gcloud CLI</td>
<td>Essential hands-on skill for ACE exam</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¢ Industry Context: Compute Engine in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Every Cloud Engineer manages VMs daily. This is your bread and butter.</p>
</blockquote>
<h3>Job Roles &amp; Compute Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Compute</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Provision, resize, troubleshoot VMs</td>
<td>Creating templates, managing MIGs</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Automate VM deployments</td>
<td>Golden images, startup scripts</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Capacity planning, incident response</td>
<td>Auto-scaling, health monitoring</td>
</tr>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Compute for ETL jobs</td>
<td>Batch processing on Spot VMs</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Standardize VM configurations</td>
<td>Instance policies, org constraints</td>
</tr>
</tbody>
</table>
<h3>Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MIG + Load Balancer</strong></td>
<td>Auto-scaling VM fleet behind LB</td>
<td>Web apps, APIs</td>
</tr>
<tr>
<td><strong>Spot for Batch</strong></td>
<td>Checkpoint-enabled batch on Spot VMs</td>
<td>ETL, ML training</td>
</tr>
<tr>
<td><strong>Golden Image Pipeline</strong></td>
<td>Packer â†’ Custom Image â†’ MIG</td>
<td>Standardized deployments</td>
</tr>
<tr>
<td><strong>Preemptible Rendering</strong></td>
<td>GPU Spot VMs with checkpointing</td>
<td>Video encoding, 3D rendering</td>
</tr>
</tbody>
</table>
<h3>âŒ Mistakes Interview Panels Reject</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I always use E2 because it's cheapest"</td>
<td>Shows no workload analysis</td>
<td>"I match machine family to workload characteristics"</td>
</tr>
<tr>
<td>"I manually configure each VM via SSH"</td>
<td>Doesn't scale, not reproducible</td>
<td>"I use startup scripts and instance templates"</td>
</tr>
<tr>
<td>"Spot VMs are unreliable so I avoid them"</td>
<td>Missing 60-91% cost savings</td>
<td>"I use Spot for fault-tolerant batch jobs with checkpoints"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What is Compute Engine? (Plain-English)</h2>
<p><strong>Compute Engine = Virtual machines on Google's infrastructure.</strong></p>
<p>You get raw computing power (CPU, RAM, disk), and you control everything else.</p>
<h3>ğŸ’¡ Real-World Analogy</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Physical Server</strong></td>
<td>Buying a house - total ownership</td>
</tr>
<tr>
<td><strong>Compute Engine</strong></td>
<td>Renting an apartment - flexible, managed building</td>
</tr>
<tr>
<td><strong>App Engine</strong></td>
<td>Staying in a hotel - fully managed, limited control</td>
</tr>
<tr>
<td><strong>Cloud Functions</strong></td>
<td>Airbnb for a few hours - pay only when used</td>
</tr>
</tbody>
</table>
<h3>What You Manage vs Google Manages</h3>
<table>
<thead>
<tr>
<th>Layer</th>
<th>You</th>
<th>Google</th>
</tr>
</thead>
<tbody>
<tr>
<td>Application</td>
<td>âœ…</td>
<td></td>
</tr>
<tr>
<td>Runtime</td>
<td>âœ…</td>
<td></td>
</tr>
<tr>
<td>OS</td>
<td>âœ…</td>
<td></td>
</tr>
<tr>
<td>Virtualization</td>
<td></td>
<td>âœ…</td>
</tr>
<tr>
<td>Hardware</td>
<td></td>
<td>âœ…</td>
</tr>
<tr>
<td>Network</td>
<td></td>
<td>âœ…</td>
</tr>
<tr>
<td>Security (physical)</td>
<td></td>
<td>âœ…</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¤– 2. Machine Families (Choose Your Fighter)</h2>
<p>Don't memorize specs. <strong>Memorize workloads.</strong></p>
<h3>Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[What's your workload?] --&gt; B{In-Memory Database?}
    B --&gt;|Yes| M[Memory Optimized&lt;br/&gt;M1/M2/M3]
    B --&gt;|No| C{HPC/Gaming/Video?}

    C --&gt;|Yes| CO[Compute Optimized&lt;br/&gt;C2/C3]
    C --&gt;|No| D{AI/ML Training?}

    D --&gt;|Yes| ACC[Accelerator Optimized&lt;br/&gt;A2/A3 with GPUs]
    D --&gt;|No| GP[General Purpose&lt;br/&gt;E2/N2/T2A]

    style GP fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Machine Family Comparison</h3>
<table>
<thead>
<tr>
<th>Family</th>
<th>Series</th>
<th>Best For</th>
<th>Max RAM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General Purpose</strong></td>
<td>E2, N2, N2D, T2A</td>
<td>Web servers, dev/test, microservices</td>
<td>128 GB</td>
</tr>
<tr>
<td><strong>Compute Optimized</strong></td>
<td>C2, C3</td>
<td>Gaming, video encoding, HPC</td>
<td>192 GB</td>
</tr>
<tr>
<td><strong>Memory Optimized</strong></td>
<td>M1, M2, M3</td>
<td>SAP HANA, large databases</td>
<td><strong>12 TB</strong></td>
</tr>
<tr>
<td><strong>Accelerator</strong></td>
<td>A2, A3</td>
<td>ML training, AI inference</td>
<td>1.3 TB</td>
</tr>
</tbody>
</table>
<h3>E2 vs N2: Quick Guide</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>E2</th>
<th>N2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cost</strong></td>
<td>Cheapest</td>
<td>10-20% more</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>Variable</td>
<td>Consistent</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Dev/test, variable loads</td>
<td>Production, consistent loads</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ’° 3. Pricing Strategies (Save 91%!)</h2>
<h3>Pricing Options Comparison</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Discount</th>
<th>Commitment</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>On-Demand</strong></td>
<td>0%</td>
<td>None</td>
<td>Short, unpredictable workloads</td>
</tr>
<tr>
<td><strong>Spot/Preemptible</strong></td>
<td>60-91%</td>
<td>None (can be stopped)</td>
<td>Batch processing, fault-tolerant</td>
</tr>
<tr>
<td><strong>CUD (1 year)</strong></td>
<td>37-57%</td>
<td>1 year</td>
<td>Predictable baseline</td>
</tr>
<tr>
<td><strong>CUD (3 year)</strong></td>
<td>52-70%</td>
<td>3 years</td>
<td>Long-term production</td>
</tr>
<tr>
<td><strong>SUD</strong></td>
<td>Up to 30%</td>
<td>Auto (run &gt;25% month)</td>
<td>N1 family only</td>
</tr>
</tbody>
</table>
<h3>Spot VMs Deep Dive</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Spot[&quot;Spot VM Lifecycle&quot;]
        RUN[Running&lt;br/&gt;60-91% off] --&gt;|30s notice| STOP[Preempted]
        STOP --&gt;|Your job| RETRY[Restart from checkpoint]
    end

    style RUN fill:#e8f5e9,stroke:#4caf50
    style STOP fill:#ffebee,stroke:#f44336
</code></pre>
<p><strong>When to Use Spot VMs:</strong>
*   âœ… Batch processing that can be restarted
*   âœ… CI/CD build workers
*   âœ… Video rendering
*   âœ… Data analysis jobs
*   âŒ Databases
*   âŒ User-facing production apps</p>
<hr />
<h2>âš¡ 4. Live Migration (Google's Superpower)</h2>
<p><strong>Google patches hardware without rebooting your VM.</strong></p>
<h3>How It Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant VM as Your VM
    participant H1 as Host 1 (Maintenance)
    participant H2 as Host 2 (Healthy)

    H1-&gt;&gt;H2: 1. Copy RAM state
    H1-&gt;&gt;H2: 2. Sync remaining changes
    H1-&gt;&gt;H2: 3. Switch network traffic
    Note over VM: Downtime: &lt;1 second
    VM-&gt;&gt;H2: 4. Resume on new host
</code></pre>
<h3>Maintenance Policies</h3>
<table>
<thead>
<tr>
<th>Policy</th>
<th>Behavior</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Migrate (default)</strong></td>
<td>Live migrate to healthy host</td>
<td>Most workloads</td>
</tr>
<tr>
<td><strong>Terminate</strong></td>
<td>Stop and optionally restart</td>
<td>Spot VMs, stateless apps</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Competitors often require scheduled downtime for maintenance. Google's Live Migration is a major differentiator!</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Deploy a Web Server</h2>
<h3>Step 1: Create VM with Startup Script</h3>
<pre><code class="language-bash">gcloud compute instances create web-server \
    --zone=us-central1-a \
    --machine-type=e2-micro \
    --tags=http-server \
    --metadata=startup-script='#!/bin/bash
apt-get update
apt-get install -y nginx
echo &quot;&lt;h1&gt;Hello from Compute Engine! ğŸš€&lt;/h1&gt;&quot; &gt; /var/www/html/index.html
systemctl start nginx'
</code></pre>
<h3>Step 2: Create Firewall Rule</h3>
<pre><code class="language-bash">gcloud compute firewall-rules create allow-http \
    --direction=INGRESS \
    --action=ALLOW \
    --rules=tcp:80 \
    --target-tags=http-server
</code></pre>
<h3>Step 3: Get External IP and Test</h3>
<pre><code class="language-bash"># Get the external IP
gcloud compute instances list --format=&quot;value(EXTERNAL_IP)&quot;

# Test (or open in browser)
curl http://EXTERNAL_IP
</code></pre>
<h3>Step 4: View Startup Script Logs</h3>
<pre><code class="language-bash"># SSH into VM
gcloud compute ssh web-server --zone=us-central1-a

# View startup script output
sudo journalctl -u google-startup-scripts.service
</code></pre>
<h3>Step 5: Cleanup</h3>
<pre><code class="language-bash">gcloud compute instances delete web-server --zone=us-central1-a --quiet
gcloud compute firewall-rules delete allow-http --quiet
</code></pre>
<hr />
<h2>âš ï¸ 6. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Spot VMs are reliable"</td>
<td>No! They can be preempted anytime</td>
</tr>
<tr>
<td>"E2 is always best"</td>
<td>Not for consistent performance needs</td>
</tr>
<tr>
<td>"Live Migration works for GPUs"</td>
<td>No! GPU VMs must terminate</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use startup scripts</strong> instead of manual SSH setup</li>
<li><strong>Use Spot VMs</strong> for batch jobs (60-91% savings!)</li>
<li><strong>Use instance templates</strong> for reproducibility</li>
<li><strong>Check serial console logs</strong> when startup script fails</li>
</ul>
<hr />
<h2>ğŸ”§ 7. Troubleshooting: "VM Won't Work" Scenarios</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> These are the most common issues you'll debug as a Cloud Engineer.</p>
</blockquote>
<h3>Scenario 1: Startup Script Not Running</h3>
<pre><code class="language-bash"># Check if script ran
sudo journalctl -u google-startup-scripts.service

# Check metadata for script
gcloud compute instances describe VM_NAME --format=&quot;get(metadata.items[startup-script])&quot;
</code></pre>
<p><strong>Common causes:</strong> Script syntax error, missing shebang, wrong metadata key</p>
<h3>Scenario 2: VM Not Responding After Boot</h3>
<pre><code class="language-bash"># Check serial output (works even if VM seems stuck)
gcloud compute instances get-serial-port-output VM_NAME --zone=ZONE

# Check if VM is actually running
gcloud compute instances describe VM_NAME --format=&quot;get(status)&quot;
</code></pre>
<p><strong>Common causes:</strong> Disk full, OS kernel panic, misconfigured network</p>
<h3>Scenario 3: SSH Connection Refused</h3>
<pre><code class="language-bash"># Check firewall rules
gcloud compute firewall-rules list --filter=&quot;ALLOW:22&quot;

# Check if SSH key is in metadata
gcloud compute instances describe VM_NAME --format=&quot;get(metadata.items[ssh-keys])&quot;
</code></pre>
<p><strong>Common causes:</strong> No firewall rule for port 22, wrong SSH key, IAP not configured</p>
<hr />
<h2>ğŸ’¼ 8. Interview Question Bank</h2>
<h3>Beginner Level (Conceptual)</h3>
<p><strong>Q1: When would you use E2 vs N2 machine types?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "E2 is cheapest but has variable performanceâ€”great for dev/test and workloads that can tolerate some inconsistency. N2 provides consistent performance at a 10-20% premiumâ€”I use it for production databases and apps with SLAs. I always test both before deciding."</p>
</blockquote>
<p><strong>Q2: How do you save money on VMs for a batch pipeline that takes 8 hours?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I'd use Spot VMs with checkpointing. Spot gives 60-91% discount. Since batch jobs can be interrupted, I design the job to save progress periodically. If preempted, it restarts from the last checkpoint. I also right-size the machine to avoid paying for unused capacity."</p>
</blockquote>
<h3>Intermediate Level (Trade-offs)</h3>
<p><strong>Q3: Your VM needs to survive host maintenance. How do you configure it?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I set the availability policy to use Live Migration, which is the default. Google moves the VM to healthy hardware with less than 1 second of downtime. Exception: GPU VMs don't support Live Migrationâ€”those must be restarted. For critical workloads, I'd also put them in a Managed Instance Group for auto-healing."</p>
</blockquote>
<p><strong>Q4: Should you use custom images or startup scripts for VM configuration?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "It depends on boot time requirements. Custom images bake everything inâ€”faster boot, better for production. Startup scripts run on every bootâ€”more flexible, better for dev/test. My pattern: create a base custom image with foundational software, then use startup scripts for environment-specific config like secrets."</p>
</blockquote>
<h3>Advanced Level (Scenario-Based)</h3>
<p><strong>Q5: Design a solution for a video encoding workload that processes 1000 videos/day, tolerates delays, and needs to minimize cost.</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
- Use Spot VMs with C2 (compute-optimized) family for encoding performance
- Create an autoscaling MIG that scales to 0 when idle
- Use Pub/Sub queue to buffer video jobs
- Implement checkpointing every 5 minutes to Cloud Storage
- If Spot VM preempted, job re-queues and picks up from checkpoint
- "This gives 60-91% savings with fault tolerance."</p>
</blockquote>
<p><strong>Q6: A production VM's performance degrades every afternoon. How do you troubleshoot?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
1. Check Cloud Monitoring CPU/memory graphs for patterns
2. Check if it's an E2 (variable performance) vs N2
3. Look for noisy neighbor if using shared-core
4. Check for scheduled jobs that spike at that time
5. Review network egressâ€”could be hitting quotas
"If pattern correlates with traffic, I'd scale vertically or add auto-scaling."</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check</h2>
<h3>Level 1: Beginner (Recall)</h3>
<ol>
<li>
<p><strong>Which Compute Engine machine family is best for cost-effective batch processing?</strong></p>
<ul>
<li>A. E2</li>
<li>B. C2</li>
<li>C. <strong>Spot VMs</strong> âœ…</li>
<li>D. N2</li>
</ul>
</li>
<li>
<p><strong>How do you enable a VM to automatically restart on a different host after a hardware failure?</strong></p>
<ul>
<li>A. Enable "Preemptibility"</li>
<li>B. <strong>Set "On Host Maintenance" to "Migrate" and "Automatic Restart" to "On"</strong> âœ…</li>
<li>C. Use a Shielded VM</li>
<li>D. Use a Local SSD</li>
</ul>
</li>
</ol>
<h3>Level 2: ACE Exam (Scenario)</h3>
<ol>
<li>
<p><strong>You need to deploy a web application that requires high availability across three zones. The application is stateless. Which configuration should you choose?</strong></p>
<ul>
<li>A. Three standalone VMs in different zones with a DNS round-robin.</li>
<li>B. <strong>A Regional Managed Instance Group (MIG) with an HTTP Load Balancer.</strong> âœ…</li>
<li>C. A Zonal MIG with a Network Load Balancer.</li>
<li>D. An Unmanaged Instance Group with a Regional external IP.</li>
</ul>
</li>
<li>
<p><strong>A developer wants to SSH into a VM that has no external IP address. The VM is in a private subnet. What is the most secure way to allow access?</strong></p>
<ul>
<li>A. Create a firewall rule allowing 0.0.0.0/0 on port 22.</li>
<li>B. Assign a public IP to the VM temporarily.</li>
<li>C. <strong>Use Identity-Aware Proxy (IAP) TCP forwarding.</strong> âœ…</li>
<li>D. Set up a VPN connection just for this single user.</li>
</ul>
</li>
</ol>
<h3>Level 3: Interview (Reasoning)</h3>
<ol>
<li><strong>Interviewer: "Why would you choose a Custom Machine Type over a Predefined one?"</strong><ul>
<li><strong>Strong Answer:</strong> "I would choose a Custom Machine Type when my workload's resource ratio doesn't match predefined typesâ€”for example, a memory-intensive cache that needs 64GB RAM but only 2 vCPUs. Using a standard <code>n2-highmem-8</code> would force me to pay for 6 extra vCPUs I don't need. Custom types save money by right-sizing resources to the exact application profile."</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 4 Checklist</h2>
<ul>
<li>[ ] Know which machine family for each workload</li>
<li>[ ] Understand Spot VM tradeoffs</li>
<li>[ ] Create a VM with a startup script</li>
<li>[ ] Connect a firewall rule to a VM</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Compute Engine", "def": "IaaS. Virtual machines on Google infrastructure. You manage OS and up."},
  {"term": "Spot VM", "def": "Up to 91% discount. Can be preempted with 30s notice. For fault-tolerant jobs."},
  {"term": "CUD", "def": "Committed Use Discount. 1 or 3 year commitment for 37-70% savings."},
  {"term": "Live Migration", "def": "Google moves your VM to healthy host during maintenance. <1s downtime."},
  {"term": "Startup Script", "def": "Script that runs when VM boots. Use for automated configuration."},
  {"term": "Machine Family", "def": "Category of VM types optimized for different workloads (E2, N2, C2, M2)."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_5_storage_basics">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 5: Block Storage (Persistent Disks)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Performance &amp; Persistence)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 5, you will be able to:
*   <strong>Master</strong> the difference between Block Storage and Object Storage.
*   <strong>Identify</strong> which Persistent Disk type is right for your throughput needs.
*   <strong>Understand</strong> the critical danger of using Local SSDs.
*   <strong>Perform</strong> a "Hot Resize" on a running VM disk.</p>
<hr />
<h2>ğŸ§  1. Block vs Object: The #1 Exam Topic ğŸ“¦</h2>
<p>If you remember nothing else from this week, remember this table.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;"><strong>Block Storage</strong> (Persistent Disk)</th>
<th style="text-align: left;"><strong>Object Storage</strong> (Cloud Storage)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Analogy</strong></td>
<td style="text-align: left;">A Hard Drive (C: Drive)</td>
<td style="text-align: left;">Google Drive / Dropbox</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Data Type</strong></td>
<td style="text-align: left;">Operating Systems, Database Files.</td>
<td style="text-align: left;">Photos, Videos, Backups.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Editability</strong></td>
<td style="text-align: left;">You can change a <strong>single bit</strong> of a file.</td>
<td style="text-align: left;">You must re-upload the <strong>whole</strong> file.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Connectivity</strong></td>
<td style="text-align: left;">Physically/Network attached to ONE VM.</td>
<td style="text-align: left;">Accessible via URL from anywhere.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Persistent Disk Types: Choosing Speed</h2>
<p>Google offers a ladder of performance. Generally, the more you pay, the more IOPS (Input/Output Operations per Second) you get.</p>
<pre><code class="language-mermaid">graph TD
    H[Standard HDD] -- &quot;Slow / Backup&quot; --&gt; S[SSD Persistent Disk]
    S -- &quot;Web Servers&quot; --&gt; B[Balanced SSD]
    B -- &quot;Standard DBs&quot; --&gt; E[Extreme PD]
    E -- &quot;Modern Apps&quot; --&gt; HY[ğŸš€ Hyperdisk]

    style H fill:#f1f5f9,stroke:#64748b
    style B fill:#dcfce7,stroke:#16a34a,stroke-width:2px
    style HY fill:#fef9c3,stroke:#ef4444,stroke-width:2px
</code></pre>
<blockquote>
<p>[!TIP]
<strong>The New King: Hyperdisk</strong> 
Historically, disk speed was tied to disk size (bigger disk = faster). <strong>Hyperdisk</strong> changes this, allowing you to buy a small disk but provision massive speed independently.</p>
</blockquote>
<h3>Persistent Disk Types: Quick Reference</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>IOPS</th>
<th>Throughput</th>
<th>Best For</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Standard HDD</strong></td>
<td>Low</td>
<td>Low</td>
<td>Boot disks, cold data, backups</td>
<td>$</td>
</tr>
<tr>
<td><strong>Balanced PD</strong></td>
<td>Medium</td>
<td>Medium</td>
<td>General workloads, web servers</td>
<td>$$</td>
</tr>
<tr>
<td><strong>SSD PD</strong></td>
<td>High</td>
<td>High</td>
<td>Databases, enterprise apps</td>
<td>$$$</td>
</tr>
<tr>
<td><strong>Extreme PD</strong></td>
<td>Very High</td>
<td>Very High</td>
<td>SAP HANA, Oracle, max performance</td>
<td>$$$$</td>
</tr>
<tr>
<td><strong>Hyperdisk</strong></td>
<td>Configurable</td>
<td>Configurable</td>
<td>Any workload, decouple IOPS from size</td>
<td>$$$$$</td>
</tr>
</tbody>
</table>
<h3>Zonal vs Regional Persistent Disk</h3>
<table>
<thead>
<tr>
<th>Disk Type</th>
<th>Zonal</th>
<th>Regional (HA)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Standard PD</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td>Balanced PD</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td>SSD PD</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td>Extreme PD</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td>Local SSD</td>
<td>âœ… (Ephemeral)</td>
<td>âŒ</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> "High availability for database disk" â†’ <strong>Regional SSD Persistent Disk</strong></p>
</blockquote>
<hr />
<h2>ğŸ“ Filestore: Managed NFS (ReadWriteMany)</h2>
<p><strong>Why Does Filestore Exist?</strong></p>
<p>Persistent Disks can only be attached to <strong>one VM at a time</strong> (ReadWriteOnce). But what if 10 web servers need to share the same <code>/var/www/html</code> folder?</p>
<h3>Storage Access Modes Comparison</h3>
<table>
<thead>
<tr>
<th>Storage Type</th>
<th>Access Mode</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Persistent Disk</strong></td>
<td>ReadWriteOnce (RWO)</td>
<td>Single VM boot disk, databases</td>
</tr>
<tr>
<td><strong>Filestore</strong></td>
<td><strong>ReadWriteMany (RWX)</strong></td>
<td>Shared config files, CMS, legacy NFS apps</td>
</tr>
<tr>
<td><strong>Cloud Storage</strong></td>
<td>Object-based (HTTP)</td>
<td>Unstructured data, backups, static assets</td>
</tr>
</tbody>
</table>
<h3>When to Use Filestore</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Use Filestore?</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multiple VMs sharing same file system</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td>WordPress with multiple web servers</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td>Legacy application expecting NFS mount</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td>Single VM boot disk</td>
<td>âŒ No (use Persistent Disk)</td>
</tr>
<tr>
<td>Storing images/videos for web access</td>
<td>âŒ No (use Cloud Storage)</td>
</tr>
</tbody>
</table>
<h3>Filestore Tiers</h3>
<table>
<thead>
<tr>
<th>Tier</th>
<th>Capacity</th>
<th>Performance</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Basic HDD</strong></td>
<td>1-63 TB</td>
<td>Lower</td>
<td>File shares, home directories</td>
</tr>
<tr>
<td><strong>Basic SSD</strong></td>
<td>2.5-63 TB</td>
<td>Medium</td>
<td>General purpose</td>
</tr>
<tr>
<td><strong>Zonal</strong></td>
<td>1-100 TB</td>
<td>High</td>
<td>Enterprise workloads</td>
</tr>
<tr>
<td><strong>Enterprise</strong></td>
<td>1-10 TB</td>
<td>Highest</td>
<td>Mission-critical</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash"># Create a Filestore instance
gcloud filestore instances create my-filestore \
    --tier=BASIC_SSD \
    --file-share=name=vol1,capacity=2560GB \
    --network=name=default \
    --zone=us-central1-a

# Mount on VM (after creating)
sudo mount 10.0.0.2:/vol1 /mnt/filestore
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If the exam mentions "multiple VMs need shared file access" or "NFS", the answer is <strong>Filestore</strong>.</p>
</blockquote>
<h2>ğŸ”Œ 3. Persistent Disk vs Local SSD (The Danger Zone)</h2>
<p>This is a classic exam "trap" question.</p>
<ul>
<li><strong>Persistent Disk (Network Attached):</strong> Safe. If your VM hardware dies, Google just moves your disk to new hardware. Data survives a VM stop.</li>
<li><strong>Local SSD (Physically Attached):</strong> <strong>DANGEROUS.</strong> It is physically glued to the server box. If you STOP the VM, the data is <strong>WIPED</strong>.</li>
</ul>
<blockquote>
<p>[!CAUTION]
<strong>Local SSD Data Loss:</strong>
Only use Local SSDs for temporary data like "Scratch Space", "Swap Files", or "Caches". Never store a database on a Local SSD unless you have real-time replication to a safe place!</p>
</blockquote>
<pre><code class="language-mermaid">graph LR
    VM[Your VM] -- &quot;Network (Fiber)&quot; --- PD[(Persistent Disk)]
    VM -- &quot;SATA/NVMe (Physical)&quot; --- LSSD[&quot;Local SSD&quot;]

    style PD fill:#dcfce7,stroke:#16a34a
    style LSSD fill:#fee2e2,stroke:#ef4444
</code></pre>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: The "Hot Resize" Trick ğŸ”¥</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Increase the size of a disk while the VM is still running.</p>
<h3>âœ… Step 1: Check Current Size</h3>
<ol>
<li>SSH into your VM from Day 3.</li>
<li>Run: <code>df -h</code><ul>
<li>Observe that your main disk is roughly 10GB.</li>
</ul>
</li>
</ol>
<h3>âœ… Step 2: Resize in Console</h3>
<ol>
<li>Go to <strong>Compute Engine &gt; Storage &gt; Disks</strong>.</li>
<li>Click on the name of your VM's boot disk.</li>
<li>Click <strong>EDIT</strong>.</li>
<li>Change size to <strong>20GB</strong> and click Save.</li>
</ol>
<h3>âœ… Step 3: Verify (No Reboot Required!)</h3>
<ol>
<li>Go back to your SSH terminal.</li>
<li>Run: <code>lsblk</code><ul>
<li><em>Result:</em> You will see the physical device is now 20GB. (Note: Depending on the OS, you might need to run <code>sudo resize2fs</code> to tell the filesystem to use the new space).</li>
</ul>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>Which storage type would you use for a high-performance database requiring millisecond latency and data persistence across VM restarts?</strong></p>
<ul>
<li>A. Local SSD</li>
<li>B. <strong>SSD Persistent Disk</strong> âœ…</li>
<li>C. Cloud Storage Standard</li>
<li>D. Archive Storage</li>
</ul>
</li>
<li>
<p><strong>You have a 100GB disk. You realize you only need 50GB. What is the easiest way to shrink it?</strong></p>
<ul>
<li>A. Click Edit and type 50GB.</li>
<li>B. <strong>You cannot decrease disk size.</strong> âœ… You must create a new smaller disk and migrate data.</li>
<li>C. Run the <code>gcloud compute disks shrink</code> command.</li>
</ul>
</li>
<li>
<p><strong>What is the main benefit of Hyperdisk?</strong></p>
<ul>
<li>A. It's the cheapest option.</li>
<li>B. It works with personal Gmail accounts.</li>
<li>C. <strong>It decouples performance (IOPS) from storage capacity (GB).</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I know that Persistent Disks are network-attached.', checked: false },
        { text: 'I understand that stopping a VM wipes Local SSD data.', checked: false },
        { text: 'I successfully resized a disk without stopping the VM.', checked: false },
        { text: 'I can explain why IaaS needs Block Storage.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 5 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_5_vpc_networking">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 14 min read</div>
<h1>Module 6: VPC Networking</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Networking is the backbone of GCP)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Key Takeaways)</strong><br />
VPCs in GCP are <strong>GLOBAL</strong> (unlike AWS/Azure). Subnets are <strong>REGIONAL</strong>. Firewall rules are <strong>per-VPC</strong>. By default: outbound traffic is ALLOWED, inbound traffic is BLOCKED. Use <strong>Cloud NAT</strong> for private VMs to reach the internet. Never open SSH (port 22) to <code>0.0.0.0/0</code> â€” use <strong>IAP</strong> instead.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Define</strong> VPC and its global nature</td>
<td>Core networking concept, unique to GCP</td>
</tr>
<tr>
<td><strong>Understand</strong> Subnets and CIDR</td>
<td>Design proper IP address ranges</td>
</tr>
<tr>
<td><strong>Create</strong> Firewall Rules</td>
<td>Control what traffic gets in/out</td>
</tr>
<tr>
<td><strong>Differentiate</strong> IP types</td>
<td>Know when to use internal vs external</td>
</tr>
<tr>
<td><strong>Design</strong> VPC peering vs Shared VPC</td>
<td>Connect multiple projects securely</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¢ Industry Context: Networking in Real Companies</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> VPC networking is where most interview failures happen. Master this section thoroughly.</p>
</blockquote>
<h3>Job Roles &amp; VPC Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use VPC</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Design subnets, firewall rules</td>
<td>Creating VPCs, troubleshooting connectivity</td>
</tr>
<tr>
<td><strong>Network Engineer</strong></td>
<td>Hybrid connectivity, routing</td>
<td>VPN, Interconnect, peering setup</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Firewall audits, network policies</td>
<td>Private Google Access, VPC Service Controls</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Load balancer health, latency</td>
<td>Debugging "VM can't reach X" issues</td>
</tr>
<tr>
<td><strong>Solutions Architect</strong></td>
<td>Multi-region design</td>
<td>Hub-spoke patterns, Shared VPC</td>
</tr>
</tbody>
</table>
<h3>Production Networking Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Shared VPC</strong></td>
<td>Host project â†’ Service projects</td>
<td>Large organizations, central network control</td>
</tr>
<tr>
<td><strong>Hub-and-Spoke</strong></td>
<td>Central VPC peered to workload VPCs</td>
<td>Multi-team, many projects</td>
</tr>
<tr>
<td><strong>Private-Only</strong></td>
<td>No external IPs + Cloud NAT</td>
<td>Security-first production</td>
</tr>
<tr>
<td><strong>Multi-Region Active-Active</strong></td>
<td>Global LB â†’ Regional MIGs</td>
<td>High availability apps</td>
</tr>
</tbody>
</table>
<h3>âŒ Mistakes That Fail Interviews</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I open port 22 to 0.0.0.0/0 for SSH"</td>
<td>Security disaster</td>
<td>"I use IAP tunneling, source range 35.235.240.0/20"</td>
</tr>
<tr>
<td>"VPCs are regional like AWS"</td>
<td>Shows you don't know GCP</td>
<td>"GCP VPCs are global, subnets are regional"</td>
</tr>
<tr>
<td>"I give VMs external IPs"</td>
<td>Unnecessary attack surface</td>
<td>"I use Cloud NAT for outbound-only internet access"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What Is a VPC? (Plain-English)</h2>
<p><strong>VPC (Virtual Private Cloud) = Your private network inside Google Cloud.</strong></p>
<p>It isolates your resources from other customers and provides the foundation for all networking. </p>
<blockquote>
<p>[!NOTE]
<strong>GCP Differentiator:</strong> Unlike AWS or Azure where VPCs are regional, <strong>GCP VPCs are Global</strong>. You can have a single network spanning the entire planet without complex peering.</p>
</blockquote>
<h3>ğŸ’¡ Real-World Analogy: Office Building</h3>
<table>
<thead>
<tr>
<th>VPC Concept</th>
<th>Office Building Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VPC</strong></td>
<td>The entire building</td>
</tr>
<tr>
<td><strong>Subnet</strong></td>
<td>Individual floors (one per city/region)</td>
</tr>
<tr>
<td><strong>Firewall</strong></td>
<td>Security guards at entrances</td>
</tr>
<tr>
<td><strong>Routes</strong></td>
<td>Hallway signs directing traffic</td>
</tr>
<tr>
<td><strong>VM</strong></td>
<td>An office on a specific floor</td>
</tr>
</tbody>
</table>
<h3>Key VPC Facts for the Exam</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VPC Scope</strong></td>
<td><strong>GLOBAL</strong> (spans all regions)</td>
</tr>
<tr>
<td><strong>Subnet Scope</strong></td>
<td><strong>REGIONAL</strong> (tied to one region)</td>
</tr>
<tr>
<td><strong>Firewall Rules</strong></td>
<td><strong>GLOBAL</strong> (apply across VPC)</td>
</tr>
<tr>
<td><strong>Default VPC</strong></td>
<td>Created automatically (can be deleted)</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. VPC Architecture Deep Dive</h2>
<h3>VPC Components</h3>
<pre><code class="language-mermaid">graph TD
    subgraph VPC[&quot;VPC Network (Global)&quot;]
        subgraph US[&quot;us-central1 (Region)&quot;]
            SUB1[Subnet: 10.0.1.0/24]
            VM1[ğŸ–¥ï¸ VM-1]
            VM2[ğŸ–¥ï¸ VM-2]
        end

        subgraph EU[&quot;europe-west1 (Region)&quot;]
            SUB2[Subnet: 10.0.2.0/24]
            VM3[ğŸ–¥ï¸ VM-3]
        end

        subgraph ASIA[&quot;asia-south1 (Region)&quot;]
            SUB3[Subnet: 10.0.3.0/24]
            VM4[ğŸ–¥ï¸ VM-4]
        end

        FW[ğŸ›¡ï¸ Firewall Rules]
        RT[ğŸ—ºï¸ Routes]
    end

    INET[ğŸŒ Internet] --&gt; FW
    FW --&gt; SUB1 &amp; SUB2 &amp; SUB3
    SUB1 --&gt; VM1 &amp; VM2
    SUB2 --&gt; VM3
    SUB3 --&gt; VM4

    style VPC fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style FW fill:#ffebee,stroke:#f44336,stroke-width:2px
</code></pre>
<h3>Subnet Modes</h3>
<table>
<thead>
<tr>
<th>Mode</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Auto Mode</strong></td>
<td>Google creates subnets in all regions automatically</td>
<td>Quick start, dev/test</td>
</tr>
<tr>
<td><strong>Custom Mode</strong></td>
<td>You create subnets only where needed</td>
<td>Production, compliance</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Production environments should use <strong>Custom Mode</strong> for better control and security.</p>
</blockquote>
<hr />
<h2>ğŸ”¢ 3. IP Addressing &amp; CIDR Notation</h2>
<h3>CIDR Basics</h3>
<table>
<thead>
<tr>
<th>CIDR</th>
<th>Available IPs</th>
<th>Example Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/24</code></td>
<td>256 (254 usable)</td>
<td>Small subnet</td>
</tr>
<tr>
<td><code>/20</code></td>
<td>4,096 (4,094 usable)</td>
<td>Medium workload</td>
</tr>
<tr>
<td><code>/16</code></td>
<td>65,536 IPs</td>
<td>Large enterprise</td>
</tr>
<tr>
<td><code>/8</code></td>
<td>16 million IPs</td>
<td>Massive scale</td>
</tr>
</tbody>
</table>
<h3>IP Types in GCP</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;IP Types&quot;
        INT[Internal IP&lt;br/&gt;Private, auto-assigned]
        EXT[External IP&lt;br/&gt;Public, internet-facing]
        PGA[Private Google Access&lt;br/&gt;Access Google APIs privately]
    end

    INT --&gt; |Free| VM[VM Instance]
    EXT --&gt; |$$$| VM
    PGA --&gt; |Free| GAPI[Google APIs]

    style INT fill:#e8f5e9,stroke:#4caf50
    style EXT fill:#fff3e0,stroke:#ff9800
    style PGA fill:#e3f2fd,stroke:#2196f3
</code></pre>
<h3>Reserved IP Ranges</h3>
<ul>
<li><code>10.0.0.0/8</code> - RFC 1918 Private</li>
<li><code>172.16.0.0/12</code> - RFC 1918 Private  </li>
<li><code>192.168.0.0/16</code> - RFC 1918 Private</li>
<li><code>0.0.0.0/0</code> - "The entire internet"</li>
</ul>
<hr />
<h2>ğŸ›¡ï¸ 4. Firewall Rules (The Security Guards)</h2>
<h3>Default Behavior</h3>
<ul>
<li>âœ… <strong>Egress (outbound):</strong> ALLOWED by default</li>
<li>âŒ <strong>Ingress (inbound):</strong> BLOCKED by default</li>
</ul>
<h3>Firewall Rule Components</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Description</th>
<th>ACE Exam Trap</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Direction</strong></td>
<td>Ingress (in) or Egress (out)</td>
<td>Default Egress is ALLOW, Ingress is DENY.</td>
</tr>
<tr>
<td><strong>Priority</strong></td>
<td>0-65535 (lower = higher priority)</td>
<td><strong>Shadowing:</strong> A rule with priority 1000 will "hide" a rule with priority 2000.</td>
</tr>
<tr>
<td><strong>Action</strong></td>
<td>Allow or Deny</td>
<td>Always use "Deny" for blocking specific bad actors.</td>
</tr>
<tr>
<td><strong>Target</strong></td>
<td>All instances, tags, or service accounts</td>
<td><strong>Tags</strong> are best for dynamic environments.</td>
</tr>
</tbody>
</table>
<h3>ğŸ› ï¸ Pro-Tip: The "Shadowing" Trap</h3>
<p>If you have:
1.  <strong>Rule A:</strong> Priority 100, DENY port 80 (Target: all)
2.  <strong>Rule B:</strong> Priority 500, ALLOW port 80 (Target: tag 'web')</p>
<p><strong>Result:</strong> Traffic to the 'web' tag on port 80 will be <strong>DENIED</strong>. The lower number (100) wins, regardless of the tag.</p>
<h3>ğŸ•¸ï¸ Essential Networking Add-ons</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Purpose</th>
<th>Exam Keyword</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud NAT</strong></td>
<td>Allows private VMs (no external IP) to download updates from the internet.</td>
<td>"Outbound only", "No public IP"</td>
</tr>
<tr>
<td><strong>VPC Flow Logs</strong></td>
<td>Records network traffic for a subnet.</td>
<td>"Troubleshooting", "Audit", "Connectivity checks"</td>
</tr>
<tr>
<td><strong>Cloud Router</strong></td>
<td>Handles BGP for hybrid connections.</td>
<td>"Dynamic routing", "Enterprise connectivity"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Build a Secure VPC</h2>
<h3>Step 1: Create Custom VPC</h3>
<pre><code class="language-bash"># Create VPC with custom mode
gcloud compute networks create my-secure-vpc \
    --subnet-mode=custom \
    --bgp-routing-mode=regional

# Create subnet
gcloud compute networks subnets create web-subnet \
    --network=my-secure-vpc \
    --region=us-central1 \
    --range=10.0.1.0/24 \
    --enable-private-ip-google-access
</code></pre>
<h3>Step 2: Create Firewall Rules</h3>
<pre><code class="language-bash"># Allow HTTP from internet
gcloud compute firewall-rules create allow-http \
    --network=my-secure-vpc \
    --direction=INGRESS \
    --priority=1000 \
    --action=ALLOW \
    --rules=tcp:80 \
    --source-ranges=0.0.0.0/0 \
    --target-tags=web-server

# Allow SSH from IAP only (secure!)
gcloud compute firewall-rules create allow-ssh-iap \
    --network=my-secure-vpc \
    --direction=INGRESS \
    --priority=1000 \
    --action=ALLOW \
    --rules=tcp:22 \
    --source-ranges=35.235.240.0/20 \
    --target-tags=allow-ssh

# Allow internal communication
gcloud compute firewall-rules create allow-internal \
    --network=my-secure-vpc \
    --direction=INGRESS \
    --priority=1000 \
    --action=ALLOW \
    --rules=all \
    --source-ranges=10.0.0.0/8
</code></pre>
<h3>Step 3: Create a VM</h3>
<pre><code class="language-bash">gcloud compute instances create web-vm \
    --zone=us-central1-a \
    --machine-type=e2-micro \
    --subnet=web-subnet \
    --tags=web-server,allow-ssh \
    --no-address  # No external IP (use IAP)
</code></pre>
<h3>Step 4: Connect via IAP</h3>
<pre><code class="language-bash">gcloud compute ssh web-vm --zone=us-central1-a --tunnel-through-iap
</code></pre>
<hr />
<h2>ğŸ”— 6. VPC Connectivity Options</h2>
<h3>VPC Peering vs Shared VPC</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;VPC Peering&quot;
        VPC1[VPC A] &lt;--&gt; VPC2[VPC B]
    end

    subgraph &quot;Shared VPC&quot;
        HOST[Host Project VPC] --&gt; SP1[Service Project 1]
        HOST --&gt; SP2[Service Project 2]
    end

    style HOST fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<table>
<thead>
<tr>
<th>Feature</th>
<th>VPC Peering</th>
<th>Shared VPC</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Relationship</strong></td>
<td>Peer-to-peer</td>
<td>Host-Service</td>
</tr>
<tr>
<td><strong>Admin</strong></td>
<td>Each VPC managed separately</td>
<td>Central network admin</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>Connect different orgs</td>
<td>Single org, multiple projects</td>
</tr>
<tr>
<td><strong>Transitive</strong></td>
<td>âŒ Not transitive</td>
<td>âœ… Centralized</td>
</tr>
</tbody>
</table>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"VPCs are regional"</td>
<td>No! VPCs are <strong>global</strong></td>
</tr>
<tr>
<td>"Firewall rules are per-subnet"</td>
<td>No! Firewall rules are <strong>per-VPC</strong></td>
</tr>
<tr>
<td>"0.0.0.0/0 means localhost"</td>
<td>No! It means <strong>the entire internet</strong></td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Never use 0.0.0.0/0 for SSH</strong> - Use IAP or specific IPs</li>
<li><strong>Enable Private Google Access</strong> on subnets for VMs without external IPs</li>
<li><strong>Use tags</strong> to target firewall rules instead of IP ranges</li>
<li><strong>Custom mode VPCs</strong> for production environments</li>
</ul>
<hr />
<h2>ğŸ”§ 8. Troubleshooting: "VM Can't Reach X" Decision Tree</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> This is the #1 interview question for Cloud Engineers and SREs. Memorize this flow.</p>
</blockquote>
<pre><code class="language-mermaid">flowchart TD
    A[VM connectivity issue] --&gt; B{Can ping 8.8.8.8?}
    B --&gt;|No| C{Has external IP?}
    B --&gt;|Yes| D{Can resolve DNS?}

    C --&gt;|No| E[Check Cloud NAT config]
    C --&gt;|Yes| F[Check egress firewall rules]

    D --&gt;|No| G[Check DNS settings/VPC DNS policy]
    D --&gt;|Yes| H{Can reach target?}

    H --&gt;|No| I{Same VPC?}
    H --&gt;|Yes| J[Issue is application-side]

    I --&gt;|No| K[Check VPC peering/routes]
    I --&gt;|Yes| L[Check ingress firewall on target]

    style E fill:#fff3e0,stroke:#ff9800
    style L fill:#fff3e0,stroke:#ff9800
</code></pre>
<h3>Quick Diagnostic Commands</h3>
<pre><code class="language-bash"># Check if VM has external IP
gcloud compute instances describe VM_NAME --format=&quot;get(networkInterfaces[0].accessConfigs[0].natIP)&quot;

# Check Cloud NAT status
gcloud compute routers get-nat-mapping-info ROUTER_NAME --region=REGION

# Test connectivity
gcloud compute ssh VM_NAME -- &quot;curl -v http://target-ip:80&quot;

# Check firewall rules hitting the VM
gcloud compute firewall-rules list --filter=&quot;network:VPC_NAME&quot;
</code></pre>
<hr />
<h2>ğŸ’¼ 9. Interview Question Bank</h2>
<h3>Beginner Level (Conceptual)</h3>
<p><strong>Q1: What's the difference between a VPC and a Subnet in GCP?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "A VPC is a global network that spans all regionsâ€”it's like the entire road network. A subnet is regionalâ€”it's like a neighborhood within that network. VMs are placed in subnets, not directly in VPCs. This is different from AWS where VPCs are regional."</p>
</blockquote>
<p><strong>Q2: What happens if you don't create any firewall rules in a new VPC?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "All ingress (incoming) traffic is blocked by default, but egress (outgoing) is allowed. So VMs can reach the internet but nothing can reach them. I always have to explicitly allow traffic like HTTP (80) or HTTPS (443)."</p>
</blockquote>
<h3>Intermediate Level (Trade-offs)</h3>
<p><strong>Q3: When would you use VPC Peering vs Shared VPC?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "VPC Peering is for connecting separate VPCs, often across different organizations or projects that need isolation. Shared VPC is for a single organization where one team (usually network/platform) controls the network and other teams deploy resources into it. Shared VPC gives better central control; Peering gives better isolation."</p>
</blockquote>
<p><strong>Q4: A VM needs to download updates from the internet but shouldn't have a public IP. How do you configure this?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I use Cloud NAT with a Cloud Router. Cloud NAT provides outbound-only internet access without exposing the VM. I also enable Private Google Access on the subnet so the VM can reach Google APIs like Cloud Storage without going through NAT."</p>
</blockquote>
<h3>Advanced Level (Scenario-Based)</h3>
<p><strong>Q5: You have VMs in VPC-A that can't reach VMs in VPC-B, even though peering is configured. How do you troubleshoot?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
1. Check peering is ACTIVE on both sides: <code>gcloud compute networks peerings list</code>
2. Check if custom routes are exported/imported in peering config
3. Verify no CIDR overlap between the VPCs
4. Check firewall rules on BOTH VPCs allow the traffic
5. Verify the source VM has the correct route to the destination subnet
"Most common issue is firewall rules only exist in one VPC, or routes aren't being exported."</p>
</blockquote>
<p><strong>Q6: Design a network for a company with 50 projects across 3 teams. They want central network management but teams should deploy their own VMs.</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I'd use Shared VPC with a Host Project for networking. The platform team owns the Host Project, creates the VPC, defines subnets per team/environment, and sets firewall policies. Each team gets a Service Project attached to the Shared VPC. They can deploy VMs but can't modify the network. This gives control + flexibility."</p>
</blockquote>
<p><strong>Q7: Your load balancer health checks are failing but you can curl the backend VMs directly. What's wrong?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "Health check traffic comes from specific Google IP ranges: 35.191.0.0/16 and 130.211.0.0/22. The firewall rule needs to allow these ranges, not just the load balancer's IP. I'd check if there's a rule allowing TCP on the health check port from these source ranges."</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check</h2>
<h3>Level 1: Beginner (Recall)</h3>
<ol>
<li>
<p><strong>What is the scope of a VPC network in GCP?</strong></p>
<ul>
<li>A. Zonal</li>
<li>B. Regional</li>
<li>C. <strong>Global</strong> âœ…</li>
<li>D. Multi-Cloud</li>
</ul>
</li>
<li>
<p><strong>Which GCP resource creates a private connection between your VPC and on-premises network?</strong></p>
<ul>
<li>A. Cloud NAT</li>
<li>B. <strong>Cloud VPN</strong> âœ…</li>
<li>C. VPC Peering</li>
<li>D. Cloud CDN</li>
</ul>
</li>
</ol>
<h3>Level 2: ACE Exam (Scenario)</h3>
<ol>
<li>
<p><strong>You have created a new custom VPC. You create a subnet in <code>us-central1</code>. You try to create a VM in <code>us-east1</code> but the subnet dropdown is empty. Why?</strong></p>
<ul>
<li>A. You reached your quota for subnets.</li>
<li>B. <strong>Subnets are regional. You must create a subnet in <code>us-east1</code> first.</strong> âœ…</li>
<li>C. The VPC needs to be in "Auto Mode" to support multiple regions.</li>
<li>D. You need to enable "Global Routing" on the VPC.</li>
</ul>
</li>
<li>
<p><strong>You need to allow a web server in a private subnet to download patches from the internet. The server must NOT be accessible from the internet. What should you configure?</strong></p>
<ul>
<li>A. Assign an External IP to the VM.</li>
<li>B. Configure a Proxy VM.</li>
<li>C. <strong>Configure Cloud NAT.</strong> âœ…</li>
<li>D. Enable Private Google Access.</li>
</ul>
</li>
</ol>
<h3>Level 3: Interview (Reasoning)</h3>
<ol>
<li><strong>Interviewer: "Explain the difference between VPC Peering and Shared VPC. When would you use each?"</strong><ul>
<li><strong>Strong Answer:</strong> "VPC Peering connects two independent VPCs allowing them to talk via private IPs. It's decentralized and good for connecting different organizations (e.g., SaaS provider to customer). Shared VPC is centralizedâ€”it allows multiple service projects to consume a single network managed by a host project. I'd use Shared VPC for my company's internal structure to enforce central firewall/security policies while letting devs manage their own resources."</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 5 Checklist</h2>
<ul>
<li>[ ] Understand VPC is Global, Subnets are Regional</li>
<li>[ ] Create a custom VPC with proper CIDR</li>
<li>[ ] Configure secure firewall rules (no 0.0.0.0/0 for SSH!)</li>
<li>[ ] Enable Private Google Access</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 6: IAM &amp; Identity Security</strong>
*   Principals, Roles, and Policies
*   Service Accounts best practices
*   Least Privilege principle</p>
<!-- FLASHCARDS
[
  {"term": "VPC", "def": "Virtual Private Cloud. Global network that spans all regions. Isolates your resources."},
  {"term": "Subnet", "def": "Regional resource within a VPC. Defines IP range for resources in that region."},
  {"term": "Firewall Rule", "def": "Controls traffic in/out of VPC. Ingress blocked by default, egress allowed."},
  {"term": "CIDR", "def": "Classless Inter-Domain Routing. Notation like /24 defines IP range size."},
  {"term": "Private Google Access", "def": "Allows VMs without external IPs to reach Google APIs privately."},
  {"term": "0.0.0.0/0", "def": "CIDR for 'the entire internet'. Use with caution in firewall rules."},
  {"term": "IAP", "def": "Identity-Aware Proxy. Secure alternative to opening SSH to the internet."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_6_cloud_storage">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>SECTION 6: Cloud Storage (Buckets)</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Storage decisions appear in every exam)</p>
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/storage/docs">Cloud Storage Documentation</a></p>
</blockquote>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Cloud Storage Essentials)</strong><br />
Cloud Storage = Object storage (not a filesystem). 11 nines durability. <strong>Storage classes:</strong> Standard (hot, $0 retrieval) â†’ Nearline (30 days) â†’ Coldline (90 days) â†’ Archive (365 days). Use <strong>Signed URLs</strong> for temporary access. <strong>Bucket Lock</strong> for compliance (WORM). Global strong consistencyâ€”upload in NY, read in Tokyo instantly.</p>
</blockquote>
<hr />
<h2>ğŸ¢ Industry Context: Storage in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Every cloud role touches Cloud Storage daily. Know this service cold.</p>
</blockquote>
<h3>Job Roles &amp; Storage Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Storage</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Manage buckets, lifecycle rules</td>
<td>Creating buckets, IAM, cross-project access</td>
</tr>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Data lake storage</td>
<td>Ingestion, partitioned data, BigQuery integration</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Artifact storage, backups</td>
<td>Build artifacts, log archival</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Access control, compliance</td>
<td>UBLA, retention policies, audit logs</td>
</tr>
</tbody>
</table>
<h3>Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Lake</strong></td>
<td>Standard for hot data + Lifecycle to Archive</td>
<td>Analytics, ML training data</td>
</tr>
<tr>
<td><strong>Static Website</strong></td>
<td>Public bucket + Cloud CDN</td>
<td>Marketing sites, docs</td>
</tr>
<tr>
<td><strong>Backup Pipeline</strong></td>
<td>Upload â†’ Nearline (30d) â†’ Coldline (90d) â†’ Archive</td>
<td>Cost-optimized DR</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I make buckets public for sharing"</td>
<td>Security disaster</td>
<td>"I use Signed URLs for temporary access"</td>
</tr>
<tr>
<td>"I use Standard for everything"</td>
<td>Wasting money on cold data</td>
<td>"I set lifecycle rules to transition to Nearline/Coldline"</td>
</tr>
<tr>
<td>"I use ACLs for access control"</td>
<td>Outdated approach</td>
<td>"I use Uniform Bucket-Level Access with IAM"</td>
</tr>
</tbody>
</table>
<hr />
<h2>1ï¸âƒ£ Overview: The "Infinite" Drive â™¾ï¸</h2>
<h2>2ï¸âƒ£ Storage Classes (The Cost Ladder) ğŸ“‰</h2>
<p>Memorize the "Minimums".</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Class</th>
<th style="text-align: left;">Minimum Storage Duration</th>
<th style="text-align: left;">Use Case</th>
<th style="text-align: left;">Retrieval Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Standard</strong></td>
<td style="text-align: left;">None</td>
<td style="text-align: left;">Frequent access. Hosting Websites. Streaming Video.</td>
<td style="text-align: left;">$0</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Nearline</strong></td>
<td style="text-align: left;"><strong>30 Days</strong></td>
<td style="text-align: left;">Backups (1x/month).</td>
<td style="text-align: left;">Low</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Coldline</strong></td>
<td style="text-align: left;"><strong>90 Days</strong></td>
<td style="text-align: left;">Disaster Recovery (1x/quarter).</td>
<td style="text-align: left;">Medium</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Archive</strong></td>
<td style="text-align: left;"><strong>365 Days</strong></td>
<td style="text-align: left;">Regulatory Logs (1x/year).</td>
<td style="text-align: left;">High</td>
</tr>
</tbody>
</table>
<h3>Lifecycle Visualization</h3>
<pre><code class="language-mermaid">graph LR
    Std[Standard: Hot Data] -- &quot;30+ days&quot; --&gt; Near[Nearline: Backups]
    Near -- &quot;90+ days&quot; --&gt; Cold[Coldline: DR]
    Cold -- &quot;365+ days&quot; --&gt; Arch[Archive: Compliance]
    Arch -- &quot;Expires&quot; --&gt; Del((Deletion))

    style Std fill:#fce8e6,stroke:#ea4335,stroke-width:2px
    style Arch fill:#e8f0fe,stroke:#4285f4,stroke-width:2px
</code></pre>
<hr />
<h2>3ï¸âƒ£ Location Types (Resilience)</h2>
<ol>
<li><strong>Region:</strong> One location (e.g., <code>us-central1</code>). Lowest cost.</li>
<li><strong>Dual-Region:</strong> Two specific regions (e.g., <code>us-central1</code> + <code>us-east1</code>).<ul>
<li><em>Superpower:</em> If one region goes offline (hurricane), your data is available in the other. <strong>99.99% SLA</strong>.</li>
</ul>
</li>
<li><strong>Multi-Region:</strong> A large area (e.g., <code>US</code> or <code>EU</code>). Good for content delivery.</li>
</ol>
<hr />
<h2>4ï¸âƒ£ Security &amp; Access ğŸ”</h2>
<ul>
<li><strong>Uniform Bucket-Level Access (UBLA):</strong> The modern standard. "Everyone in Group X can read ALL files." (Simpler).</li>
<li><strong>Signed URLs:</strong> Creating a temporary "Key" to access a file.<ul>
<li><em>Usage:</em> Let a user upload a profile picture <em>directly</em> to the bucket without giving them your password.</li>
</ul>
</li>
<li><strong>Retention Policy (Bucket Lock):</strong><ul>
<li><strong>WORM</strong> (Write Once, Read Many).</li>
<li><em>Regulatory:</em> "This file CANNOT be deleted for 7 years." (SEC Rule 17a-4).</li>
<li><em>Warning:</em> If you lock it, <strong>even YOU cannot delete it.</strong></li>
</ul>
</li>
</ul>
<hr />
<h2>5ï¸âƒ£ Hands-On Lab: Host a Serverless Website ğŸŒ</h2>
<p><strong>Mission:</strong> Host a public website for almost $0/month. No servers to manage!</p>
<ol>
<li><strong>Create Bucket:</strong><ul>
<li>Go to <strong>Cloud Storage</strong> &gt; <strong>Buckets</strong> &gt; <strong>Create</strong>.</li>
<li><strong>Name:</strong> <code>my-cool-website-[YOUR_NAME]</code> (Must be globally unique!).</li>
<li><strong>Services:</strong> Uncheck "Enforce public access prevention" (Because we want it public).</li>
</ul>
</li>
<li><strong>Grant Access:</strong><ul>
<li>Go to <strong>Permissions</strong> tab.</li>
<li>Click <strong>Grant Access</strong>.</li>
<li><strong>New Principals:</strong> <code>allUsers</code> (This means "The Internet").</li>
<li><strong>Role:</strong> <code>Storage Object Viewer</code> (Read Only).</li>
<li><strong>Save.</strong></li>
</ul>
</li>
<li><strong>Upload Files:</strong><ul>
<li>Create a file <code>index.html</code> on your desktop: <code>&lt;h1&gt;Hello from Cloud Storage!&lt;/h1&gt;</code></li>
<li>Upload it to the bucket.</li>
</ul>
</li>
<li><strong>Visit It:</strong><ul>
<li>Click <code>index.html</code>. Copy the <strong>Public URL</strong>.</li>
<li>Paste it in Chrome. You have a live website!</li>
</ul>
</li>
</ol>
<hr />
<h2>6ï¸âƒ£ Checkpoint Quiz</h2>
<ol>
<li>
<p><strong>You need to store tax records for exactly 7 years to meet legal requirements. No one, not even the admin, should be able to delete them. What feature do you use?</strong></p>
<ul>
<li>A. Standard Storage Class</li>
<li>B. Lifecycle Rule</li>
<li>C. <strong>Retention Policy (Bucket Lock)</strong> âœ…</li>
<li>D. Signed URL</li>
</ul>
</li>
<li>
<p><strong>Your application allows users to upload profile photos. You want the user to upload directly to the bucket without routing traffic through your web server. What should you generate?</strong></p>
<ul>
<li>A. A Service Account Key</li>
<li>B. <strong>A Signed URL</strong> âœ…</li>
<li>C. A Public Bucket</li>
<li>D. An ACL (Access Control List)</li>
</ul>
</li>
<li>
<p><strong>What is the retrieval cost for "Standard" storage?</strong></p>
<ul>
<li>A. <strong>$0 (Free retrieval)</strong> âœ…</li>
<li>B. High cost</li>
<li>C. Depends on the file type</li>
</ul>
</li>
</ol>
<hr />
<h3>âš¡ Zero-to-Hero: Pro Tips</h3>
<ul>
<li><strong>Dual-Region:</strong> Always use Dual-Region for production data. It costs slightly more than Region, but it saves your life if a region goes down.</li>
<li><strong>Command Line:</strong> <code>gcloud storage cp file.txt gs://my-bucket/</code> is the command you'll use 1000 times a day. Learn it.</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Bucket", "def": "A container for objects. Must have a globally unique name."},
  {"term": "Standard Storage", "def": "Hot data. Frequent access. No retrieval fee."},
  {"term": "Archive Storage", "def": "Coldest data. Backup once a year. High retrieval fee."},
  {"term": "Signed URL", "def": "A URL that gives temporary permission to upload/download an object."},
  {"term": "Uniform Bucket-Level Access", "def": "Disables ACLs. Uses IAM for the whole bucket. Recommended."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_6_iam_identity">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 13 min read</div>
<h1>Module 7: IAM &amp; Identity</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Security is 19% of the exam!)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (IAM in 30 Seconds)</strong><br />
IAM answers: <strong>WHO</strong> (Principal) can do <strong>WHAT</strong> (Role/Permissions) on <strong>WHICH</strong> resource. Never use Basic roles (Owner/Editor/Viewer) in production â€” use Predefined roles. Never download Service Account JSON keys â€” use Workload Identity instead. Permissions flow <strong>DOWN</strong> the hierarchy (Org â†’ Folder â†’ Project â†’ Resource).</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explain</strong> WHO/WHAT/WHERE of IAM</td>
<td>Foundation of all GCP security</td>
</tr>
<tr>
<td><strong>Differentiate</strong> role types</td>
<td>Pick the right level of access</td>
</tr>
<tr>
<td><strong>Apply</strong> Least Privilege</td>
<td>Core security principle for ACE exam</td>
</tr>
<tr>
<td><strong>Secure</strong> Service Accounts</td>
<td>Prevent crypto-mining attacks!</td>
</tr>
<tr>
<td><strong>Use</strong> IAM Conditions</td>
<td>Time/IP-based access control</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¢ Industry Context: Who Uses IAM Daily?</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> This section is critical for ALL cloud roles. Master this, and you'll stand out in interviews.</p>
</blockquote>
<h3>Job Roles &amp; IAM Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use IAM</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Grant developers access to resources</td>
<td>Creating SAs, assigning predefined roles</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Audit permissions, enforce least privilege</td>
<td>Running IAM Recommender, reviewing policies</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Set up CI/CD service accounts</td>
<td>Workload Identity for GitHub/GitLab</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Incident response, permission audits</td>
<td>Investigating compromised credentials</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Design org-wide IAM strategy</td>
<td>Custom roles, Org Policies</td>
</tr>
</tbody>
</table>
<h3>Real Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Team-Based Access</strong></td>
<td>Google Group â†’ Predefined Role â†’ Project</td>
<td>Standard team permissions</td>
</tr>
<tr>
<td><strong>Service Mesh</strong></td>
<td>SA per microservice â†’ least privilege</td>
<td>Microservices on GKE</td>
</tr>
<tr>
<td><strong>Cross-Project Access</strong></td>
<td>SA impersonation across projects</td>
<td>Shared services (logging, monitoring)</td>
</tr>
<tr>
<td><strong>External CI/CD</strong></td>
<td>Workload Identity Federation</td>
<td>GitHub Actions, GitLab CI</td>
</tr>
</tbody>
</table>
<h3>âŒ Beginner Mistakes That Get You Rejected in Interviews</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use Owner role for simplicity"</td>
<td>Shows no security awareness</td>
<td>"I use predefined roles with least privilege"</td>
</tr>
<tr>
<td>"I download JSON keys for CI/CD"</td>
<td>Security red flag</td>
<td>"I use Workload Identity Federation"</td>
</tr>
<tr>
<td>"I grant to individual users"</td>
<td>Doesn't scale</td>
<td>"I use Google Groups for scalability"</td>
</tr>
</tbody>
</table>
<h3>ğŸ” Role Lens: What Each Role Focuses On</h3>
<blockquote>
<p><strong>ğŸ”µ Cloud Engineer:</strong> Focus on granting access correctly. Know predefined roles by heart. Understand Service Accounts for VMs.</p>
<p><strong>ğŸŸ¢ DevOps Engineer:</strong> Master Workload Identity Federation for CI/CD. Know how to eliminate JSON keys from your pipelines.</p>
<p><strong>ğŸŸ  Security Engineer:</strong> Know IAM Recommender, how to audit policies, and incident response for leaked credentials.</p>
<p><strong>ğŸ”´ SRE:</strong> Focus on least privilege for production workloads and how to quickly revoke compromised credentials.</p>
</blockquote>
<hr />
<h2>ğŸ§  1. What Is IAM? (Plain-English)</h2>
<p><strong>IAM = The bouncer at your cloud's door.</strong></p>
<p>It controls <strong>WHO</strong> (Identity) can do <strong>WHAT</strong> (Permissions) on <strong>WHICH</strong> resource.</p>
<h3>The IAM Equation</h3>
<pre><code>Principal + Role = Access (at a specific level in the Hierarchy)
</code></pre>
<blockquote>
<p>[!IMPORTANT]
<strong>Policy Inheritance:</strong> Permissions flow <strong>DOWN</strong> the tree (Org â†’ Folder â†’ Project â†’ Resource). If you are an Editor at the Project level, you are an Editor on every VM in that project. <strong>You cannot "un-grant" a permission further down.</strong></p>
</blockquote>
<h3>ğŸ’¡ Real-World Analogy: Hotel Key Card</h3>
<table>
<thead>
<tr>
<th>IAM Concept</th>
<th>Hotel Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Principal</strong></td>
<td>The guest (you)</td>
</tr>
<tr>
<td><strong>Role</strong></td>
<td>Access level (Guest, VIP, Housekeeping)</td>
</tr>
<tr>
<td><strong>Permissions</strong></td>
<td>Individual actions (open gym, open room 202)</td>
</tr>
<tr>
<td><strong>Resource</strong></td>
<td>The hotel room or facility</td>
</tr>
<tr>
<td><strong>Policy</strong></td>
<td>The key card programming</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ‘¥ 2. Who Can Access? (Principals)</h2>
<h3>Types of Principals</h3>
<pre><code class="language-mermaid">graph TD
    P[Principals] --&gt; GA[Google Account&lt;br/&gt;user@gmail.com]
    P --&gt; SA[Service Account&lt;br/&gt;sa@project.iam.gserviceaccount.com]
    P --&gt; GG[Google Group&lt;br/&gt;team@domain.com]
    P --&gt; WS[Google Workspace&lt;br/&gt;domain.com]
    P --&gt; AL[allUsers&lt;br/&gt;Anyone on internet]
    P --&gt; AU[allAuthenticatedUsers&lt;br/&gt;Any Google account]

    style SA fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    style AL fill:#ffebee,stroke:#f44336,stroke-width:2px
</code></pre>
<blockquote>
<p><strong>âš ï¸ Warning:</strong> <code>allUsers</code> and <code>allAuthenticatedUsers</code> can expose resources publicly. Use with extreme caution!</p>
</blockquote>
<hr />
<h2>ğŸ“œ 3. Types of Roles</h2>
<h3>Role Comparison</h3>
<table>
<thead>
<tr>
<th>Role Type</th>
<th>Created By</th>
<th>Maintenance</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Basic (Primitive)</strong></td>
<td>Google</td>
<td>None</td>
<td>â›” Avoid in production</td>
</tr>
<tr>
<td><strong>Predefined</strong></td>
<td>Google</td>
<td>Auto-updated</td>
<td>âœ… Most use cases</td>
</tr>
<tr>
<td><strong>Custom</strong></td>
<td>You</td>
<td>Manual</td>
<td>ğŸ› ï¸ Specific needs</td>
</tr>
</tbody>
</table>
<h3>Basic Roles (Avoid These!)</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>Permissions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Viewer</strong></td>
<td>Read-only access</td>
</tr>
<tr>
<td><strong>Editor</strong></td>
<td>Read + Write (but not IAM)</td>
</tr>
<tr>
<td><strong>Owner</strong></td>
<td>Full control including IAM &amp; billing</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If an exam question uses Basic roles as an answer, it's usually WRONG. Look for the Predefined role option.</p>
</blockquote>
<h3>Predefined Roles (Use These!)</h3>
<pre><code>roles/storage.objectViewer     # Only view objects
roles/storage.objectAdmin      # Manage objects
roles/compute.instanceAdmin    # Manage VMs
roles/bigquery.dataViewer      # Query BigQuery
</code></pre>
<h3>Custom Roles</h3>
<pre><code class="language-bash"># Create custom role with specific permissions
gcloud iam roles create customStorageViewer \
    --project=my-project \
    --title=&quot;Custom Storage Viewer&quot; \
    --permissions=&quot;storage.objects.get,storage.objects.list&quot; \
    --stage=GA
</code></pre>
<hr />
<h2>ğŸ¤– 4. Service Accounts (Machine Identities)</h2>
<p><strong>Humans use passwords. Machines use Service Accounts.</strong></p>
<h3>Types of Service Accounts</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Created By</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Default</strong></td>
<td>GCP (auto)</td>
<td>Compute Engine default SA</td>
</tr>
<tr>
<td><strong>User-managed</strong></td>
<td>You</td>
<td>Custom app SA</td>
</tr>
<tr>
<td><strong>Google-managed</strong></td>
<td>Google</td>
<td>Cloud Build service agent</td>
</tr>
</tbody>
</table>
<h3>âš ï¸ The JSON Key Problem</h3>
<pre><code class="language-mermaid">graph LR
    DEV[Developer] --&gt;|Downloads| JSON[JSON Key]
    JSON --&gt;|Commits to| GH[GitHub]
    GH --&gt;|Scanned by| HACKER[Hackers]
    HACKER --&gt;|Mines crypto with| YOUR_PROJECT[Your Project $$$]

    style JSON fill:#ffebee,stroke:#f44336,stroke-width:2px
    style HACKER fill:#ffcdd2,stroke:#f44336
</code></pre>
<h3>Best Practices</h3>
<pre><code class="language-bash"># âœ… GOOD: Use attached service account
gcloud compute instances create my-vm \
    --service-account=my-sa@project.iam.gserviceaccount.com

# âœ… BEST: Use Workload Identity Federation (WIF)
# Allows external identities (GitHub, Azure) to assume a GCP role WITHOUT long-lived JSON keys.
</code></pre>
<h3>ğŸ§  Strategic Comparison: IAM vs. Org Policy</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>IAM</th>
<th>Org Policy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Focus</strong></td>
<td><strong>Identity</strong> (Who can do it?)</td>
<td><strong>Resource</strong> (What can be done?)</td>
</tr>
<tr>
<td><strong>Action</strong></td>
<td><strong>Allow-only</strong></td>
<td><strong>Allow or Deny</strong> (often used for Deny)</td>
</tr>
<tr>
<td><strong>Logic</strong></td>
<td><strong>Union:</strong> If any policy allows it, it's allowed.</td>
<td><strong>Restriction:</strong> If any policy denies it, it's blocked.</td>
</tr>
<tr>
<td><strong>Precedence</strong></td>
<td>Lower levels add permissions.</td>
<td>Higher levels set guardrails that lower levels cannot break.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¯ 5. IAM Conditions (Context-Aware Access)</h2>
<p>Add <strong>WHEN</strong> and <strong>WHERE</strong> to your access rules.</p>
<h3>Condition Types</h3>
<table>
<thead>
<tr>
<th>Condition</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Time-based</strong></td>
<td>Access only during business hours</td>
</tr>
<tr>
<td><strong>IP-based</strong></td>
<td>Access only from corporate VPN</td>
</tr>
<tr>
<td><strong>Resource-based</strong></td>
<td>Access only to <code>dev-*</code> resources</td>
</tr>
<tr>
<td><strong>Expiring</strong></td>
<td>Temporary contractor access</td>
</tr>
</tbody>
</table>
<h3>Example: Weekdays Only Access</h3>
<pre><code class="language-bash">gcloud projects add-iam-policy-binding my-project \
    --member=&quot;user:contractor@example.com&quot; \
    --role=&quot;roles/storage.objectViewer&quot; \
    --condition='
      expression=request.time.getDayOfWeek() &gt;= 1 &amp;&amp; request.time.getDayOfWeek() &lt;= 5,
      title=WeekdaysOnly,
      description=Access only on weekdays'
</code></pre>
<hr />
<h2>ğŸ› ï¸ 6. Hands-On Lab: Least Privilege in Action</h2>
<h3>Step 1: Create a Service Account</h3>
<pre><code class="language-bash">gcloud iam service-accounts create storage-reader \
    --display-name=&quot;Storage Reader SA&quot;
</code></pre>
<h3>Step 2: Grant Minimal Permissions</h3>
<pre><code class="language-bash"># Only grant what's needed - object viewer, not admin
gcloud projects add-iam-policy-binding my-project \
    --member=&quot;serviceAccount:storage-reader@my-project.iam.gserviceaccount.com&quot; \
    --role=&quot;roles/storage.objectViewer&quot;
</code></pre>
<h3>Step 3: Create VM with SA</h3>
<pre><code class="language-bash">gcloud compute instances create reader-vm \
    --service-account=storage-reader@my-project.iam.gserviceaccount.com \
    --scopes=storage-ro \
    --zone=us-central1-a
</code></pre>
<h3>Step 4: Verify Permissions</h3>
<pre><code class="language-bash"># SSH into VM
gcloud compute ssh reader-vm --zone=us-central1-a

# This should work
gcloud storage ls gs://my-bucket/

# This should FAIL (no write permission)
echo &quot;test&quot; | gcloud storage cp - gs://my-bucket/test.txt
</code></pre>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Use Owner role for simplicity"</td>
<td>No! Always use Predefined roles</td>
</tr>
<tr>
<td>"Download SA keys for CI/CD"</td>
<td>No! Use Workload Identity Federation</td>
</tr>
<tr>
<td>"Grant permissions to users directly"</td>
<td>No! Use Google Groups for scalability</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use Groups</strong> - Add permissions to groups, add users to groups</li>
<li><strong>Audit with IAM Recommender</strong> - Find unused permissions</li>
<li><strong>Never use Basic roles</strong> in production</li>
<li><strong>Rotate SA keys</strong> if you must use them (ideally, don't)</li>
</ul>
<hr />
<h2>ğŸš¨ 8. Incident Response: JSON Key Leaked to GitHub</h2>
<blockquote>
<p>[!CAUTION]
<strong>Real-World Scenario:</strong> Your security team alerts you that a service account JSON key was committed to a public GitHub repository. The key has Editor permissions on your production project.</p>
</blockquote>
<h3>Immediate Response (&lt; 5 minutes)</h3>
<pre><code class="language-bash"># Step 1: Disable the key IMMEDIATELY
gcloud iam service-accounts keys disable KEY_ID \
    --iam-account=compromised-sa@PROJECT.iam.gserviceaccount.com

# Step 2: Delete the key
gcloud iam service-accounts keys delete KEY_ID \
    --iam-account=compromised-sa@PROJECT.iam.gserviceaccount.com

# Step 3: Check for suspicious activity
gcloud logging read 'protoPayload.authenticationInfo.principalEmail=&quot;compromised-sa@PROJECT.iam.gserviceaccount.com&quot;' \
    --limit=50 --format=&quot;table(timestamp,protoPayload.methodName)&quot;
</code></pre>
<h3>Investigate Impact</h3>
<pre><code class="language-bash"># What did they access?
gcloud logging read 'protoPayload.authenticationInfo.principalEmail=&quot;compromised-sa@PROJECT.iam.gserviceaccount.com&quot; AND timestamp&gt;=&quot;2024-01-01T00:00:00Z&quot;' \
    --format=json &gt; incident_log.json
</code></pre>
<h3>Post-Incident</h3>
<ol>
<li>Create new SA with <strong>least privilege</strong> (not Editor!)</li>
<li>Implement <strong>Workload Identity</strong> instead of JSON keys</li>
<li>Set up <strong>Secret Manager</strong> for any remaining secrets</li>
<li>Add <strong>IAM Recommender</strong> alerts</li>
</ol>
<blockquote>
<p><strong>ğŸ’¼ Interview Tip:</strong> When asked about incident response, always mention: Disable â†’ Delete â†’ Investigate â†’ Prevent Recurrence.</p>
</blockquote>
<hr />
<h2>ğŸ’¼ 9. Interview Question Bank</h2>
<h3>Beginner Level (Conceptual)</h3>
<p><strong>Q1: What is the difference between a Role and a Permission?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "A permission is a single action like <code>storage.objects.get</code>. A role is a collection of permissions bundled together. For example, <code>roles/storage.objectViewer</code> contains multiple read permissions. I always use predefined roles instead of granting individual permissions for maintainability."</p>
</blockquote>
<p><strong>Q2: Why should you avoid using Basic Roles (Owner/Editor/Viewer)?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "Basic roles are too broad. Editor grants write access to almost everything in a project, including resources the user doesn't need. This violates least privilege and increases blast radius if credentials are compromised. I use predefined roles like <code>roles/compute.instanceAdmin</code> for specific access."</p>
</blockquote>
<h3>Intermediate Level (Trade-offs)</h3>
<p><strong>Q3: When would you create a Custom Role vs using a Predefined Role?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I use predefined roles 95% of the time because Google maintains them and adds new permissions automatically. I create custom roles only when predefined roles are too permissive AND there's no narrower option. The trade-off is maintenanceâ€”I have to update custom roles when APIs change."</p>
</blockquote>
<p><strong>Q4: How do you decide between granting permissions to individual users vs Google Groups?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I always use Google Groups. It scales betterâ€”when someone joins or leaves a team, I update group membership, not project IAM. It also creates a cleaner audit trail. The trade-off is the extra step of group management, but it's worth it for any team larger than 3 people."</p>
</blockquote>
<h3>Advanced Level (Scenario-Based)</h3>
<p><strong>Q5: Your CI/CD pipeline needs to deploy to GKE and push images to Artifact Registry. How do you set this up securely?</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "I use Workload Identity Federation to eliminate JSON keys. For GitHub Actions, I create a Workload Identity Pool, configure the OIDC provider with GitHub's issuer URL, and grant the pool permission to impersonate a service account. The SA gets <code>roles/artifactregistry.writer</code> and <code>roles/container.developer</code>â€”no more, no less."</p>
</blockquote>
<p><strong>Q6: A developer reports 'Permission Denied' when trying to create a VM. Walk me through troubleshooting.</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
1. <strong>Check their identity:</strong> <code>gcloud auth list</code> to confirm which account they're using
2. <strong>Check project:</strong> <code>gcloud config get-value project</code> 
3. <strong>Check IAM binding:</strong> <code>gcloud projects get-iam-policy PROJECT | grep -A2 developer@</code>
4. <strong>Test permissions:</strong> <code>gcloud alpha iam test-iam-permissions --project=PROJECT --permissions=compute.instances.create</code>
5. <strong>Check Org Policies:</strong> Could be blocked at org/folder level
"Most common cause is wrong project or wrong account. Second is the role is bound at resource level, not project level."</p>
</blockquote>
<p><strong>Q7: Design IAM for a startup with 3 teams: Dev, QA, and Ops. Each needs different access to 2 projects: dev-project and prod-project.</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
- Create 3 Google Groups: <code>dev@company.com</code>, <code>qa@company.com</code>, <code>ops@company.com</code>
- <strong>dev-project:</strong>
  - Dev â†’ <code>roles/editor</code> (they build here)
  - QA â†’ <code>roles/viewer</code> (read-only)
  - Ops â†’ <code>roles/compute.admin</code> (manage infra)
- <strong>prod-project:</strong>
  - Dev â†’ <code>roles/viewer</code> (can debug, can't change)
  - QA â†’ <code>roles/viewer</code>
  - Ops â†’ <code>roles/owner</code> (full control)
- Use Org Policy to prevent public buckets in prod
"I'd also set up IAM Conditions so Dev can only access prod during incidents with approval."</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which role type should you generally AVOID in production?</strong></p>
<ul>
<li>A. Predefined</li>
<li>B. <strong>Basic (Primitive)</strong> âœ…</li>
<li>C. Custom</li>
<li>D. Viewer</li>
</ul>
</li>
<li>
<p><strong>What is the "Principle of Least Privilege"?</strong></p>
<ul>
<li>A. <strong>Give only the permissions needed to do the job</strong> âœ…</li>
<li>B. Give everyone Owner access</li>
<li>C. Use only Service Accounts</li>
<li>D. Always use custom roles</li>
</ul>
</li>
<li>
<p><strong>An identity for an application to make API calls is called a:</strong></p>
<ul>
<li>A. User Account</li>
<li>B. <strong>Service Account</strong> âœ…</li>
<li>C. Billing Account</li>
<li>D. Organization Account</li>
</ul>
</li>
<li>
<p><strong>You need to grant temporary access to a contractor that expires automatically. What should you use?</strong></p>
<ul>
<li>A. Basic Roles</li>
<li>B. Custom Roles</li>
<li>C. <strong>IAM Conditions with expiration</strong> âœ…</li>
<li>D. Service Account keys</li>
</ul>
</li>
<li>
<p><strong>Which feature allows access based on the user's IP address or time of day?</strong></p>
<ul>
<li>A. Basic Roles</li>
<li>B. <strong>IAM Conditions</strong> âœ…</li>
<li>C. Service Accounts</li>
<li>D. VPC Firewall Rules</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 6 Checklist</h2>
<ul>
<li>[ ] Understand Principal, Role, and Policy</li>
<li>[ ] Know why Basic roles are risky</li>
<li>[ ] Create a least-privilege Service Account</li>
<li>[ ] Apply an IAM Condition</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Principal", "def": "WHO can access. User, Service Account, Group, or Domain."},
  {"term": "Role", "def": "WHAT permissions. Collection of specific actions allowed."},
  {"term": "Policy", "def": "Binding that attaches Principal to Role on a Resource."},
  {"term": "Least Privilege", "def": "Grant only the minimum permissions needed. Core security principle."},
  {"term": "Service Account", "def": "Identity for applications. Use instead of user accounts for machines."},
  {"term": "IAM Conditions", "def": "Context-aware access. Add TIME, IP, or RESOURCE constraints to policies."},
  {"term": "Basic Roles", "def": "Owner/Editor/Viewer. Too broad for production. Use Predefined instead."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_7_week_1_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<p>ï»¿# Day 7: Week 1 Review &amp; Exam Strategy</p>
<p><strong>Level:</strong> Review<br />
<strong>Milestone:</strong> ğŸ Week 1 Complete!</p>
<hr />
<h2>ğŸ¯ 1. Week 1 Recap: The Foundations</h2>
<p>You have survived the first week of Google Cloud! You've gone from "What is the Cloud?" to deploying multi-zone web servers.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Day</th>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Key Takeaway</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>1</strong></td>
<td style="text-align: left;"><strong>Foundations</strong></td>
<td style="text-align: left;">Cloud = Renting resources. OpEx &gt; CapEx.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>2</strong></td>
<td style="text-align: left;"><strong>Hierarchy</strong></td>
<td style="text-align: left;">Org &gt; Folder &gt; Project. Policies flow DOWN.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>3</strong></td>
<td style="text-align: left;"><strong>Compute</strong></td>
<td style="text-align: left;">IaaS. Use E2 for general work, C2 for compute.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>4</strong></td>
<td style="text-align: left;"><strong>Storage</strong></td>
<td style="text-align: left;">GCS = Object Storage. Buckets must be globally unique.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>5</strong></td>
<td style="text-align: left;"><strong>Disk</strong></td>
<td style="text-align: left;">PD (Safe/Network) vs Local SSD (Fast/Wipes on Stop).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>6</strong></td>
<td style="text-align: left;"><strong>IAM</strong></td>
<td style="text-align: left;">Identity + Role. Always use Least Privilege.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š 2. Visual Recap: Decision Logic</h2>
<h3>The Resource Hierarchy (Governance)</h3>
<pre><code class="language-mermaid">graph TD
    Org[&quot;ğŸ¢ Organization&lt;br/&gt;(company.com)&quot;] --&gt; Folder[&quot;ğŸ“ Folders&lt;br/&gt;(Depts: HR, IT)&quot;]
    Folder --&gt; Project[&quot;ğŸš€ Projects&lt;br/&gt;(The Billing Boundary)&quot;]
    Project --&gt; Res1[&quot;ğŸ–¥ï¸ VM&quot;]
    Project --&gt; Res2[&quot;ğŸ“¦ Bucket&quot;]

    style Org fill:#fefce8,stroke:#eab308,stroke-width:2px
    style Project fill:#ecfdf5,stroke:#10b981,stroke-width:2px
</code></pre>
<h3>Storage Decision Tree (Exam Gold)</h3>
<pre><code class="language-mermaid">graph TD
    Start{Store Data?} --&gt; HowOften{Access Frequency?}
    HowOften -- &quot;Daily&quot; --&gt; Standard[ğŸ”¥ Standard]
    HowOften -- &quot;Monthly&quot; --&gt; Nearline[ğŸŒ¤ï¸ Nearline]
    HowOften -- &quot;Quarterly&quot; --&gt; Coldline[â„ï¸ Coldline]
    HowOften -- &quot;Yearly&quot; --&gt; Archive[ğŸ§Š Archive]

    style Standard fill:#fee2e2,stroke:#ef4444
    style Archive fill:#dbeafe,stroke:#1e40af
</code></pre>
<hr />
<h2>âš ï¸ 3. Common Exam Traps</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Trap #1: The Immutable Disk</strong>
You can <strong>upsize</strong> a Persistent Disk while the VM is running, but you can <strong>never downsize</strong> it. To shrink, you must create a new disk and copy data.</p>
<p>[!TIP]
<strong>Trap #2: Global vs Regional</strong>
VPCs are <strong>Global</strong>. Subnets are <strong>Regional</strong>. Buckets are <strong>Regional/Multi-Regional</strong> but their <em>Names</em> are <strong>Global</strong>.</p>
<p>[!CAUTION]
<strong>Trap #3: Role Inheritance</strong>
If you give a user "Storage Admin" at the Folder level, they can delete every bucket in every project within that folder. <strong>Avoid primitive roles (Owner/Editor) whenever possible.</strong></p>
</blockquote>
<hr />
<h2>ğŸ§ª 4. Weekend Capstone Lab: Multi-Zone Web App</h2>
<p><strong>Scenario:</strong> Create a highly available web server across two zones using <code>gcloud</code>.</p>
<h3>âœ… Step 1: Network Prep</h3>
<pre><code class="language-bash"># Create the VPC
gcloud compute networks create week1-vpc --subnet-mode=custom

# Create a Subnet in your region
gcloud compute networks subnets create week1-subnet \
  --network=week1-vpc \
  --region=us-central1 \
  --range=10.0.1.0/24

# Allow HTTP Traffic (Port 80)
gcloud compute firewall-rules create allow-http \
  --network=week1-vpc \
  --allow=tcp:80 \
  --source-ranges=0.0.0.0/0 \
  --target-tags=web-server
</code></pre>
<h3>âœ… Step 2: Deploy HA Servers</h3>
<pre><code class="language-bash"># Create VM in Zone A
gcloud compute instances create web-vm-a \
  --zone=us-central1-a \
  --subnet=week1-subnet \
  --tags=web-server \
  --metadata=startup-script='#!/bin/bash
  apt-get update &amp;&amp; apt-get install -y apache2
  echo &quot;Hello from Zone A&quot; &gt; /var/www/html/index.html'

# Create VM in Zone B
gcloud compute instances create web-vm-b \
  --zone=us-central1-b \
  --subnet=week1-subnet \
  --tags=web-server \
  --metadata=startup-script='#!/bin/bash
  apt-get update &amp;&amp; apt-get install -y apache2
  echo &quot;Hello from Zone B&quot; &gt; /var/www/html/index.html'
</code></pre>
<h3>âœ… Step 3: Test &amp; Clean Up</h3>
<ol>
<li>Get the External IP of both: <code>gcloud compute instances list</code></li>
<li>Open them in a browser. </li>
<li><strong>DELETE EVERYTHING</strong> to save money:</li>
</ol>
<pre><code class="language-bash">gcloud compute instances delete web-vm-a web-vm-b --quiet
gcloud compute networks delete week1-vpc --quiet
</code></pre>
<hr />
<h2>ğŸ† 5. What's Next? (Week 2 Preview)</h2>
<p>Week 1 was about <strong>Basics</strong>. Week 2 is about <strong>Management at Scale</strong>.</p>
<ul>
<li><strong>Managed Instance Groups (MIGs):</strong> Auto-healing and auto-scaling.</li>
<li><strong>Load Balancing:</strong> High-performance global distribution.</li>
<li><strong>Cloud SQL:</strong> Letting Google manage your databases.</li>
<li><strong>Kubernetes (GKE):</strong> The future of container management.</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Week 1 Knowledge Check</h2>
<ol>
<li>
<p><strong>Which pricing model is most associated with Cloud computing?</strong></p>
<ul>
<li>A. Capital Expenditure (CapEx)</li>
<li>B. <strong>Operational Expenditure (OpEx)</strong> âœ…</li>
<li>C. One-time License Fee</li>
<li>D. Hardware Depreciation</li>
</ul>
</li>
<li>
<p><strong>At which level of the GCP Resource Hierarchy is billing managed?</strong></p>
<ul>
<li>A. Organization</li>
<li>B. Folder</li>
<li>C. <strong>Project</strong> âœ…</li>
<li>D. Resource</li>
</ul>
</li>
<li>
<p><strong>You need to store large media files that will be accessed daily. Which Cloud Storage class is most cost-effective?</strong></p>
<ul>
<li>A. Coldline</li>
<li>B. Archive</li>
<li>C. <strong>Standard</strong> âœ…</li>
<li>D. Nearline</li>
</ul>
</li>
<li>
<p><strong>What happens to data on a Local SSD when you STOP the VM?</strong></p>
<ul>
<li>A. Data is preserved</li>
<li>B. <strong>Data is permanently deleted</strong> âœ…</li>
<li>C. Data is moved to Cloud Storage</li>
<li>D. Data is compressed</li>
</ul>
</li>
<li>
<p><strong>You want to give a developer read-only access to a specific Cloud Storage bucket. What is the recommended approach?</strong></p>
<ul>
<li>A. Grant the Owner role at the Project level</li>
<li>B. <strong>Grant the Storage Object Viewer role on that specific bucket</strong> âœ…</li>
<li>C. Share your credentials with the developer</li>
<li>D. Create a new project for the developer</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the Resource Hierarchy (Org > Folder > Project).', checked: false },
        { text: 'I know when to use Standard vs Archive storage.', checked: false },
        { text: 'I can launch a VM using the gcloud CLI.', checked: false },
        { text: 'I understand why Least Privilege is critical for IAM.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Week 1 Milestone Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_8_instance_groups">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Day 8: Instance Groups &amp; Auto-Scaling</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Scaling is heavily tested)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 8, you will be able to:</p>
<ul>
<li><strong>Differentiate</strong> between Unmanaged and Managed Instance Groups</li>
<li><strong>Configure</strong> Zonal vs Regional MIGs for high availability</li>
<li><strong>Implement</strong> auto-scaling based on CPU, LB, or custom metrics</li>
<li><strong>Enable</strong> auto-healing to detect and replace unhealthy VMs</li>
<li><strong>Apply</strong> the "Cattle vs Pets" philosophy</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: Auto-Scaling in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> MIGs are the foundation of production deployments. Every Cloud Engineer must master this.</p>
</blockquote>
<h3>Job Roles &amp; MIG Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use MIGs</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Deploy production workloads</td>
<td>Creating MIGs, configuring scaling</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Automate infrastructure</td>
<td>Instance templates, rolling updates</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Ensure reliability</td>
<td>Health checks, auto-healing configs</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Standardize deployments</td>
<td>Template management, policies</td>
</tr>
</tbody>
</table>
<h3>Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Regional MIG + LB</strong></td>
<td>3-zone MIG behind Global LB</td>
<td>Production web apps</td>
</tr>
<tr>
<td><strong>Scheduled Scaling</strong></td>
<td>Scale up before traffic peak</td>
<td>Predictable load patterns</td>
</tr>
<tr>
<td><strong>Custom Metrics</strong></td>
<td>Scale on queue depth</td>
<td>Job processing systems</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use Zonal MIG for production"</td>
<td>Single zone = single point of failure</td>
<td>"I use Regional MIG for zone redundancy"</td>
</tr>
<tr>
<td>"I store session data on VM disk"</td>
<td>Data lost when VM is replaced</td>
<td>"I use external state: Cloud SQL, Redis"</td>
</tr>
<tr>
<td>"I don't set initial delay for health checks"</td>
<td>VMs fail before app starts</td>
<td>"I set initial delay to allow boot time"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What Are Instance Groups? (Plain-English)</h2>
<p><strong>Instance Group = Collection of VMs treated as one unit.</strong></p>
<h3>Types of Instance Groups</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Unmanaged</strong></td>
<td>Bag of different VMs</td>
<td>Legacy apps, heterogeneous VMs</td>
</tr>
<tr>
<td><strong>Managed (MIG)</strong></td>
<td>Identical VMs from a template</td>
<td>Production, auto-scaling</td>
</tr>
</tbody>
</table>
<h3>ğŸ’¡ Real-World Analogy: Army vs Mercenaries</h3>
<table>
<thead>
<tr>
<th>Unmanaged</th>
<th>Managed Instance Group</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mercenaries: different skills, different equipment</td>
<td>Army: identical training, identical gear</td>
</tr>
<tr>
<td>Hard to replace</td>
<td>Easy to replace</td>
</tr>
<tr>
<td>Manual management</td>
<td>Automated management</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Managed Instance Group Architecture</h2>
<pre><code class="language-mermaid">flowchart TD
    subgraph Template[&quot;Instance Template&quot;]
        SPEC[Machine Type + Image + Startup Script]
    end

    subgraph MIG[&quot;Managed Instance Group&quot;]
        VM1[vm-a1b2]
        VM2[vm-c3d4]
        VM3[vm-e5f6]
    end

    subgraph Features[&quot;MIG Features&quot;]
        AS[Auto-Scaling]
        AH[Auto-Healing]
        RU[Rolling Updates]
    end

    Template --&gt; MIG
    Features --&gt; MIG

    style MIG fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>MIG Types</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Zones</th>
<th>Availability</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Zonal MIG</strong></td>
<td>1 zone</td>
<td>Low</td>
<td>Dev/test, cost savings</td>
</tr>
<tr>
<td><strong>Regional MIG</strong></td>
<td>3 zones</td>
<td>High</td>
<td>Production workloads</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Always choose <strong>Regional MIG</strong> for production to survive zone failures.</p>
</blockquote>
<hr />
<h2>ğŸ„ 3. Cattle vs Pets Philosophy</h2>
<p>In the cloud, VMs are <strong>cattle</strong>, not <strong>pets</strong>.</p>
<h3>The Philosophy</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Pets (Old Way)</th>
<th>Cattle (Cloud Way)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Naming</strong></td>
<td>prod-db-server-1</td>
<td>vm-a8f2c3d1</td>
</tr>
<tr>
<td><strong>Failure</strong></td>
<td>Panic! Fix manually</td>
<td>Shrug. Auto-replace.</td>
</tr>
<tr>
<td><strong>Scaling</strong></td>
<td>Buy bigger server</td>
<td>Add more servers</td>
</tr>
<tr>
<td><strong>State</strong></td>
<td>On VM disk</td>
<td>In Cloud SQL/Storage</td>
</tr>
</tbody>
</table>
<h3>The Stateless Requirement</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Wrong[&quot;âŒ Stateful (Don't)&quot;]
        VM1[VM] --&gt; DISK[Local Disk]
    end

    subgraph Right[&quot;âœ… Stateless (Do)&quot;]
        VM2[VM] --&gt; SQL[Cloud SQL]
        VM2 --&gt; GCS[Cloud Storage]
    end

    style Wrong fill:#ffebee,stroke:#f44336
    style Right fill:#e8f5e9,stroke:#4caf50
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If your app stores data locally, MIG cannot auto-heal properly. Always use external storage!</p>
</blockquote>
<hr />
<h2>âš¡ 4. Auto-Scaling Deep Dive</h2>
<h3>Scaling Triggers</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Description</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CPU Utilization</strong></td>
<td>Scale when CPU &gt; threshold</td>
<td>Most workloads</td>
</tr>
<tr>
<td><strong>Load Balancer Capacity</strong></td>
<td>Scale based on LB requests</td>
<td>Web apps</td>
</tr>
<tr>
<td><strong>Cloud Monitoring Metric</strong></td>
<td>Custom metrics</td>
<td>Custom apps</td>
</tr>
<tr>
<td><strong>Schedule</strong></td>
<td>Time-based scaling</td>
<td>Predictable traffic</td>
</tr>
</tbody>
</table>
<h3>Scaling Configuration</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Config[&quot;Auto-Scaling Config&quot;]
        MIN[Min Instances: 2]
        MAX[Max Instances: 10]
        TARGET[Target CPU: 60%]
        COOL[Cool-down: 60s]
    end

    subgraph Scale[&quot;Scaling Action&quot;]
        UP[CPU &gt; 60%&lt;br/&gt;Add instances]
        DOWN[CPU &lt; 60%&lt;br/&gt;Remove instances]
    end

    Config --&gt; Scale

    style UP fill:#fff3e0,stroke:#ff9800
    style DOWN fill:#e3f2fd,stroke:#2196f3
</code></pre>
<h3>gcloud Commands</h3>
<pre><code class="language-bash"># Create autoscaler
gcloud compute instance-groups managed set-autoscaling my-mig \
    --zone=us-central1-a \
    --min-num-replicas=2 \
    --max-num-replicas=10 \
    --target-cpu-utilization=0.6 \
    --cool-down-period=60
</code></pre>
<hr />
<h2>ğŸ¥ 5. Auto-Healing</h2>
<p>Auto-healing automatically replaces unhealthy VMs.</p>
<h3>How It Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant HC as Health Check
    participant MIG as Instance Group
    participant VM as VM Instance
    participant NEW as New VM

    loop Every 10 seconds
        HC-&gt;&gt;VM: Are you healthy?
        alt Healthy
            VM--&gt;&gt;HC: HTTP 200 OK
        else Unhealthy (3 failures)
            VM--&gt;&gt;HC: Timeout/Error
            MIG-&gt;&gt;VM: Terminate
            MIG-&gt;&gt;NEW: Create from template
        end
    end
</code></pre>
<h3>Health Check Configuration</h3>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Recommended</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Check Interval</strong></td>
<td>10 seconds</td>
<td>How often to check</td>
</tr>
<tr>
<td><strong>Timeout</strong></td>
<td>5 seconds</td>
<td>Wait time for response</td>
</tr>
<tr>
<td><strong>Unhealthy Threshold</strong></td>
<td>3</td>
<td>Failures before action</td>
</tr>
<tr>
<td><strong>Healthy Threshold</strong></td>
<td>2</td>
<td>Successes to recover</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 6. Hands-On Lab: Self-Healing Cluster</h2>
<h3>Step 1: Create Instance Template</h3>
<pre><code class="language-bash">gcloud compute instance-templates create web-template \
    --machine-type=e2-micro \
    --tags=http-server \
    --metadata=startup-script='#!/bin/bash
apt-get update &amp;&amp; apt-get install -y apache2
echo &quot;Healthy at $(date)&quot; &gt; /var/www/html/index.html
echo &quot;OK&quot; &gt; /var/www/html/health'
</code></pre>
<h3>Step 2: Create Regional MIG</h3>
<pre><code class="language-bash">gcloud compute instance-groups managed create web-mig \
    --template=web-template \
    --size=2 \
    --region=us-central1 \
    --zones=us-central1-a,us-central1-b,us-central1-c
</code></pre>
<h3>Step 3: Create Health Check</h3>
<pre><code class="language-bash">gcloud compute health-checks create http web-health-check \
    --port=80 \
    --request-path=/health
</code></pre>
<h3>Step 4: Enable Auto-healing</h3>
<pre><code class="language-bash">gcloud compute instance-groups managed update web-mig \
    --region=us-central1 \
    --health-check=web-health-check \
    --initial-delay=60
</code></pre>
<h3>Step 5: Configure Auto-scaling</h3>
<pre><code class="language-bash">gcloud compute instance-groups managed set-autoscaling web-mig \
    --region=us-central1 \
    --min-num-replicas=2 \
    --max-num-replicas=5 \
    --target-cpu-utilization=0.6
</code></pre>
<h3>Step 6: Test Auto-healing</h3>
<pre><code class="language-bash"># List instances
gcloud compute instances list --filter=&quot;name~web-mig&quot;

# Delete one instance and watch it recreate
gcloud compute instances delete &lt;instance-name&gt; --zone=us-central1-a --quiet

# Watch the MIG recreate it
watch gcloud compute instances list --filter=&quot;name~web-mig&quot;
</code></pre>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"MIG can survive region failure"</td>
<td>No! MIG is regional at most. Need multi-region with Global LB.</td>
</tr>
<tr>
<td>"Auto-healing = Auto-scaling"</td>
<td>No! Healing replaces sick VMs. Scaling adds/removes VMs.</td>
</tr>
<tr>
<td>"Rolling updates need downtime"</td>
<td>No! Rolling updates replace VMs gradually.</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Always use Regional MIGs</strong> for production</li>
<li><strong>Set initial delay</strong> for auto-healing to allow boot time</li>
<li><strong>Use health checks</strong> that test actual application health</li>
<li><strong>Update templates</strong> and do rolling updates (don't destroy MIG)</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which MIG feature ensures a VM is replaced if the application crashes?</strong></p>
<ul>
<li>A. Auto-scaling</li>
<li>B. <strong>Auto-healing</strong> âœ…</li>
<li>C. Rolling Updates</li>
<li>D. Load Balancing</li>
</ul>
</li>
<li>
<p><strong>Your app must survive a complete zone failure. What should you create?</strong></p>
<ul>
<li>A. Zonal MIG</li>
<li>B. <strong>Regional MIG</strong> âœ…</li>
<li>C. Unmanaged Instance Group</li>
<li>D. Single VM with Spot pricing</li>
</ul>
</li>
<li>
<p><strong>To update the OS on 100 VMs in a MIG, you should:</strong></p>
<ul>
<li>A. Delete and recreate the MIG</li>
<li>B. SSH into each VM manually</li>
<li>C. <strong>Update the template and do a rolling update</strong> âœ…</li>
<li>D. Stop all VMs and upgrade</li>
</ul>
</li>
<li>
<p><strong>Which scaling metric is best for a web application behind a load balancer?</strong></p>
<ul>
<li>A. Memory utilization</li>
<li>B. Disk I/O</li>
<li>C. <strong>Load Balancer capacity</strong> âœ…</li>
<li>D. Network bandwidth</li>
</ul>
</li>
<li>
<p><strong>Your MIG VMs store user sessions on local disk. What's the problem?</strong></p>
<ul>
<li>A. Higher cost</li>
<li>B. <strong>Data loss when auto-healing replaces VMs</strong> âœ…</li>
<li>C. Slower performance</li>
<li>D. No external IP</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 8 Checklist</h2>
<ul>
<li>[ ] Understand Cattle vs Pets philosophy</li>
<li>[ ] Create an instance template with startup script</li>
<li>[ ] Create a Regional MIG</li>
<li>[ ] Configure auto-scaling and auto-healing</li>
<li>[ ] Test auto-healing by deleting an instance</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "MIG", "def": "Managed Instance Group. Identical VMs from a template with auto-scaling and auto-healing."},
  {"term": "Instance Template", "def": "Blueprint for creating identical VMs. Defines machine type, image, and scripts."},
  {"term": "Auto-healing", "def": "Automatically replaces unhealthy VMs based on health check failures."},
  {"term": "Auto-scaling", "def": "Automatically adds/removes VMs based on load metrics (CPU, LB, custom)."},
  {"term": "Regional MIG", "def": "MIG spread across 3 zones. Survives single zone failure."},
  {"term": "Cattle vs Pets", "def": "Treat VMs as disposable (cattle) not precious (pets). Store state externally."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_9_load_balancing">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Module 9: Load Balancing</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Load Balancing is heavily tested)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Load Balancing Decision Guide)</strong><br />
<strong>Layer 7</strong> (HTTP/S LB) = Web apps, can inspect headers/cookies. <strong>Layer 4</strong> (Network LB) = TCP/UDP, gaming, non-HTTP. <strong>Global HTTP(S) LB</strong> gives you an <strong>Anycast IP</strong> (single IP, routes to nearest backend). <strong>Cloud CDN</strong> caches static content at edge. <strong>Cloud Armor</strong> = WAF + DDoS protection (only works with External HTTP(S) LB). Global LB takes <strong>5-10 minutes</strong> to start working.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Understand</strong> Layer 4 vs Layer 7</td>
<td>Pick the right LB type</td>
</tr>
<tr>
<td><strong>Explain</strong> Anycast IPs</td>
<td>How global routing works</td>
</tr>
<tr>
<td><strong>Choose</strong> the right load balancer</td>
<td>Match scenario to LB type</td>
</tr>
<tr>
<td><strong>Configure</strong> Cloud CDN</td>
<td>Cache static content at edge</td>
</tr>
<tr>
<td><strong>Implement</strong> SSL termination</td>
<td>Offload encryption from backends</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Why Load Balancing? (Plain-English)</h2>
<p><strong>Problem:</strong> You have 10,000 users but only 1 web server â†’ it crashes.<br />
<strong>Solution:</strong> Use 10 servers and a Load Balancer to distribute traffic.</p>
<h3>ğŸ’¡ Real-World Analogy: Airport Check-In</h3>
<table>
<thead>
<tr>
<th>LB Concept</th>
<th>Airport Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Load Balancer</strong></td>
<td>Check-in counter manager</td>
</tr>
<tr>
<td><strong>Backend Servers</strong></td>
<td>Individual check-in counters</td>
</tr>
<tr>
<td><strong>Health Check</strong></td>
<td>"Counter Open/Closed" sign</td>
</tr>
<tr>
<td><strong>Anycast IP</strong></td>
<td>Single airport entrance that routes to nearest terminal</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. GCP Load Balancer Types</h2>
<h3>The "ACE Master" Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    Start([Need Load Balancing?]) --&gt; Traffic{Traffic Type?}
    Traffic -- HTTP/HTTPS --&gt; L7[Layer 7: Application LB]
    Traffic -- TCP/UDP/SSL --&gt; L4[Layer 4: Network LB]

    L7 --&gt; L7Scope{Scope?}
    L7Scope -- Global --&gt; G7[Global External HTTP/S LB]
    L7Scope -- Regional --&gt; R7[Regional External HTTP/S LB]
    L7Scope -- Private --&gt; I7[Internal HTTP/S LB]

    L4 --&gt; L4Ext{External?}
    L4Ext -- Yes --&gt; L4Proxy{Proxy or Pass thru?}
    L4Proxy -- Proxy / Anycast --&gt; G4[Global External Proxy LB]
    L4Proxy -- Pass through --&gt; RN4[Regional Network LB]
    L4Ext -- No --&gt; I4[Internal TCP/UDP LB]

    style G7 fill:#dcfce7,stroke:#16a34a,stroke-width:2px
    style G4 fill:#dcfce7,stroke:#16a34a,stroke-width:2px
    style Start fill:#f1f5f9
</code></pre>
<h3>Complete LB Comparison</h3>
<table>
<thead>
<tr>
<th>Load Balancer</th>
<th>Layer</th>
<th>Scope</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Global External HTTP(S)</strong></td>
<td>L7</td>
<td>Global</td>
<td>Web apps, APIs, mobile backends</td>
</tr>
<tr>
<td><strong>Global External TCP/SSL</strong></td>
<td>L4</td>
<td>Global</td>
<td>Non-HTTP TCP (gaming, IoT)</td>
</tr>
<tr>
<td><strong>Regional External HTTP(S)</strong></td>
<td>L7</td>
<td>Regional</td>
<td>Compliance (data must stay in region)</td>
</tr>
<tr>
<td><strong>Regional External Network</strong></td>
<td>L4</td>
<td>Regional</td>
<td>UDP, non-HTTP protocols</td>
</tr>
<tr>
<td><strong>Internal HTTP(S)</strong></td>
<td>L7</td>
<td>Regional</td>
<td>Private microservices</td>
</tr>
<tr>
<td><strong>Internal TCP/UDP</strong></td>
<td>L4</td>
<td>Regional</td>
<td>Internal databases, apps</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If the question says "global" and "web app" â†’ <strong>Global HTTP(S) LB</strong>. If it says "gaming" or "UDP" â†’ <strong>Network LB</strong>.</p>
</blockquote>
<hr />
<h2>ğŸŒ 3. Anycast IP: The Magic of Global Load Balancing</h2>
<h3>How Anycast Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant US as User (US)
    participant EU as User (EU)
    participant IP as Single Anycast IP
    participant GLB as Global LB
    participant MUS as MIG (US)
    participant MEU as MIG (EU)

    US-&gt;&gt;IP: Request
    IP-&gt;&gt;GLB: Routes to nearest
    GLB-&gt;&gt;MUS: Forward to US backend

    EU-&gt;&gt;IP: Request (same IP!)
    IP-&gt;&gt;GLB: Routes to nearest
    GLB-&gt;&gt;MEU: Forward to EU backend
</code></pre>
<p><strong>Key Benefits:</strong>
*   Single IP address for global reach
*   Automatic routing to nearest healthy backend
*   No DNS changes needed for failover</p>
<hr />
<h2>ğŸ”’ 4. SSL Termination &amp; Certificates</h2>
<h3>SSL Offloading Architecture</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Internet
        U[User]
    end

    subgraph Edge[&quot;Google Edge&quot;]
        LB[Load Balancer&lt;br/&gt;SSL Termination]
    end

    subgraph Backend
        VM1[VM 1]
        VM2[VM 2]
    end

    U --&gt;|HTTPS encrypted| LB
    LB --&gt;|HTTP unencrypted| VM1 &amp; VM2

    style LB fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<p><strong>Benefits:</strong>
*   Offload CPU-intensive SSL from backend VMs
*   Centralized certificate management
*   Use Google-managed certificates (auto-renewing)</p>
<hr />
<hr />
<h2>ğŸ›¡ï¸ 6. Cloud Armor: The Bodyguard</h2>
<p>When using the <strong>Global HTTP(S) Load Balancer</strong>, you can enable <strong>Cloud Armor</strong>.</p>
<ul>
<li><strong>DDoS Protection:</strong> Blocks volumetric attacks at the edge.</li>
<li><strong>WAF (Web Application Firewall):</strong> Blocks common attacks like SQL Injection (SQLi) and Cross-Site Scripting (XSS).</li>
<li><strong>IP Whitelisting/Blacklisting:</strong> Allow or block specific CIDR ranges.</li>
</ul>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Tip:</strong> Cloud Armor only works with <strong>External HTTP(S) Load Balancers</strong>. It cannot be used directly on VMs or Internal LBs.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 6. Hands-On Lab: Create Global HTTP(S) LB</h2>
<h3>Step 1: Create Instance Template</h3>
<pre><code class="language-bash">gcloud compute instance-templates create web-template \
    --machine-type=e2-micro \
    --tags=http-server \
    --metadata=startup-script='#!/bin/bash
apt-get update &amp;&amp; apt-get install -y nginx
echo &quot;&lt;h1&gt;Hello from $(hostname)&lt;/h1&gt;&quot; &gt; /var/www/html/index.html'
</code></pre>
<h3>Step 2: Create Managed Instance Groups</h3>
<pre><code class="language-bash"># US region
gcloud compute instance-groups managed create mig-us \
    --template=web-template \
    --size=2 \
    --zone=us-central1-a

# EU region  
gcloud compute instance-groups managed create mig-eu \
    --template=web-template \
    --size=2 \
    --zone=europe-west1-b
</code></pre>
<h3>Step 3: Create Health Check</h3>
<pre><code class="language-bash">gcloud compute health-checks create http http-health-check \
    --port=80 \
    --request-path=/
</code></pre>
<h3>Step 4: Create Backend Service</h3>
<pre><code class="language-bash">gcloud compute backend-services create web-backend \
    --protocol=HTTP \
    --health-checks=http-health-check \
    --global

gcloud compute backend-services add-backend web-backend \
    --instance-group=mig-us \
    --instance-group-zone=us-central1-a \
    --global

gcloud compute backend-services add-backend web-backend \
    --instance-group=mig-eu \
    --instance-group-zone=europe-west1-b \
    --global
</code></pre>
<h3>Step 5: Create URL Map and Frontend</h3>
<pre><code class="language-bash"># URL map
gcloud compute url-maps create web-map \
    --default-service=web-backend

# HTTP proxy
gcloud compute target-http-proxies create http-proxy \
    --url-map=web-map

# Global forwarding rule (gets Anycast IP)
gcloud compute forwarding-rules create http-rule \
    --global \
    --target-http-proxy=http-proxy \
    --ports=80
</code></pre>
<h3>Step 6: Test</h3>
<pre><code class="language-bash"># Get the external IP
gcloud compute forwarding-rules describe http-rule --global --format=&quot;value(IPAddress)&quot;

# Wait 5-10 minutes for propagation, then curl
curl http://YOUR_IP
</code></pre>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Network LB is for web apps"</td>
<td>No! Network LB is for non-HTTP (Layer 4)</td>
</tr>
<tr>
<td>"Health checks are optional"</td>
<td>No! LB can't function properly without them</td>
</tr>
<tr>
<td>"LB starts working immediately"</td>
<td>No! Global LB takes 5-10 minutes</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use Google-managed SSL certificates</strong> - auto-renewing, free</li>
<li><strong>Enable Cloud CDN</strong> on static content for 50-90% latency reduction</li>
<li><strong>Use named ports</strong> in instance groups for flexibility</li>
<li><strong>Set appropriate health check intervals</strong> (not too aggressive)</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which Load Balancer would you use for a global mobile app with a single IP address?</strong></p>
<ul>
<li>A. Regional Network LB</li>
<li>B. <strong>Global External HTTP(S) LB</strong> âœ…</li>
<li>C. Internal TCP LB</li>
<li>D. Regional HTTP(S) LB</li>
</ul>
</li>
<li>
<p><strong>At which OSI layer does a Network Load Balancer operate?</strong></p>
<ul>
<li>A. Layer 7 (Application)</li>
<li>B. <strong>Layer 4 (Transport)</strong> âœ…</li>
<li>C. Layer 3 (Network)</li>
<li>D. Layer 2 (Data Link)</li>
</ul>
</li>
<li>
<p><strong>What does SSL termination at the Load Balancer provide?</strong></p>
<ul>
<li>A. End-to-end encryption</li>
<li>B. <strong>Offloads SSL decryption from backend VMs</strong> âœ…</li>
<li>C. Automatic firewall rules</li>
<li>D. DDoS protection only</li>
</ul>
</li>
<li>
<p><strong>You need to cache static images globally to reduce latency. What should you enable?</strong></p>
<ul>
<li>A. VPC Peering</li>
<li>B. Cloud Armor</li>
<li>C. <strong>Cloud CDN</strong> âœ…</li>
<li>D. Cloud NAT</li>
</ul>
</li>
<li>
<p><strong>How long should you wait for a Global HTTP(S) LB to start working after creation?</strong></p>
<ul>
<li>A. Instant</li>
<li>B. 1 minute</li>
<li>C. <strong>5-10 minutes</strong> âœ…</li>
<li>D. 1 hour</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 9 Checklist</h2>
<ul>
<li>[ ] Understand Layer 4 vs Layer 7 differences</li>
<li>[ ] Know which LB type for each scenario</li>
<li>[ ] Configure health checks</li>
<li>[ ] Set up Cloud CDN for caching</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Anycast IP", "def": "Single IP that routes users to the nearest Google edge location automatically."},
  {"term": "Layer 7 LB", "def": "Application layer. Can inspect HTTP headers, URLs, cookies for routing."},
  {"term": "Layer 4 LB", "def": "Transport layer. Routes based on IP/port only. For TCP/UDP."},
  {"term": "Health Check", "def": "Periodic probe to verify backend is healthy. Unhealthy = no traffic."},
  {"term": "SSL Termination", "def": "Decrypting HTTPS at the LB, sending HTTP to backends. Reduces backend CPU."},
  {"term": "Cloud CDN", "def": "Caches content at Google edge. Reduces latency for static content."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_10_cloud_sql">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Module 10: Cloud SQL Database</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Database selection is heavily tested)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Cloud SQL Essentials)</strong><br />
Cloud SQL = Fully managed MySQL, PostgreSQL, or SQL Server. Google handles patching, backups, and failover. <strong>Read Replicas</strong> improve READ performance. <strong>Vertical scaling</strong> (more CPU/RAM) improves WRITE performance. Cloud SQL is <strong>regional</strong> (max 64TB). Need global? Use <strong>Cloud Spanner</strong>. Always connect via <strong>Cloud SQL Auth Proxy</strong> for security.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explain</strong> managed vs self-managed</td>
<td>Understand the operational benefits</td>
</tr>
<tr>
<td><strong>Select</strong> the right database engine</td>
<td>MySQL, PostgreSQL, or SQL Server</td>
</tr>
<tr>
<td><strong>Implement</strong> HA and Read Replicas</td>
<td>Production-ready configurations</td>
</tr>
<tr>
<td><strong>Connect</strong> securely via Auth Proxy</td>
<td>Security best practice</td>
</tr>
<tr>
<td><strong>Compare</strong> Cloud SQL vs Spanner vs BigQuery</td>
<td>Pick the right service</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What is Cloud SQL? (Plain-English)</h2>
<p><strong>Cloud SQL = You focus on data, Google handles everything else.</strong></p>
<h3>What Google Manages</h3>
<table>
<thead>
<tr>
<th>Task</th>
<th>Self-Managed VM</th>
<th>Cloud SQL</th>
</tr>
</thead>
<tbody>
<tr>
<td>OS Patching</td>
<td>âŒ You</td>
<td>âœ… Google</td>
</tr>
<tr>
<td>Database Patching</td>
<td>âŒ You</td>
<td>âœ… Google</td>
</tr>
<tr>
<td>Backups</td>
<td>âŒ You</td>
<td>âœ… Automated daily</td>
</tr>
<tr>
<td>Failover</td>
<td>âŒ You</td>
<td>âœ… Automatic HA</td>
</tr>
<tr>
<td>Scaling</td>
<td>âŒ You</td>
<td>âœ… One-click</td>
</tr>
<tr>
<td>Security</td>
<td>âŒ You</td>
<td>âœ… Encryption at rest</td>
</tr>
</tbody>
</table>
<h3>ğŸ’¡ Real-World Analogy: Hiring a DBA</h3>
<table>
<thead>
<tr>
<th>MySQL on VM</th>
<th>Cloud SQL</th>
</tr>
</thead>
<tbody>
<tr>
<td>You're the janitor, driver, and chef</td>
<td>You hired a 24/7 expert DBA (Google)</td>
</tr>
<tr>
<td>3 AM crash = you wake up</td>
<td>Google handles the fires</td>
</tr>
<tr>
<td>You manage everything</td>
<td>You focus on writing app code</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Cloud SQL Architecture</h2>
<pre><code class="language-mermaid">flowchart LR
    subgraph App[&quot;Application Layer&quot;]
        GCE[Compute Engine]
        GAE[App Engine]
        GKE[GKE]
        CR[Cloud Run]
    end

    subgraph Proxy[&quot;Secure Connection&quot;]
        PROXY[Cloud SQL Auth Proxy]
    end

    subgraph SQL[&quot;Cloud SQL&quot;]
        PRIMARY[Primary Instance&lt;br/&gt;Zone A]
        STANDBY[Standby Instance&lt;br/&gt;Zone B]
        REPLICA[Read Replica&lt;br/&gt;Region 2]
    end

    App --&gt; PROXY --&gt; PRIMARY
    PRIMARY -.-&gt;|Sync Replication| STANDBY
    PRIMARY --&gt;|Async Replication| REPLICA

    style PRIMARY fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style STANDBY fill:#f5f5f5,stroke:#9e9e9e
</code></pre>
<h3>Supported Engines</h3>
<table>
<thead>
<tr>
<th>Engine</th>
<th>Version</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MySQL</strong></td>
<td>5.7, 8.0</td>
<td>Most common, WordPress, Laravel</td>
</tr>
<tr>
<td><strong>PostgreSQL</strong></td>
<td>9.6 - 15</td>
<td>Advanced features, GIS, JSON</td>
</tr>
<tr>
<td><strong>SQL Server</strong></td>
<td>2017, 2019</td>
<td>.NET apps, Microsoft stack</td>
</tr>
</tbody>
</table>
<hr />
<h2>âš–ï¸ 3. Database Selection Matrix</h2>
<h3>Cloud SQL vs Spanner vs BigQuery</h3>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Cloud SQL</th>
<th>Spanner</th>
<th>BigQuery</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Scale</strong></td>
<td>Regional (~64TB)</td>
<td>Global (unlimited)</td>
<td>Petabytes</td>
</tr>
<tr>
<td><strong>Transactions</strong></td>
<td>âœ… ACID</td>
<td>âœ… ACID + Global</td>
<td>Limited</td>
</tr>
<tr>
<td><strong>SQL</strong></td>
<td>Standard</td>
<td>Standard + extensions</td>
<td>Standard</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>Web apps, ERP</td>
<td>Global finance, inventory</td>
<td>Analytics, BI</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>$$</td>
<td>$$$$</td>
<td>Pay per query</td>
</tr>
<tr>
<td><strong>Exam Keywords</strong></td>
<td>"Lift &amp; shift", "MySQL"</td>
<td>"Global", "Horizontal"</td>
<td>"Warehouse", "OLAP"</td>
</tr>
</tbody>
</table>
<h3>Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Need Relational DB?] --&gt; B{Global Scale?}
    B --&gt;|Yes| SP[Cloud Spanner]
    B --&gt;|No| C{Analytics Workload?}

    C --&gt;|Yes| BQ[BigQuery]
    C --&gt;|No| D{MySQL/PostgreSQL Needed?}

    D --&gt;|Yes| SQL[Cloud SQL]
    D --&gt;|No| E{NoSQL OK?}

    E --&gt;|Yes| FS[Firestore]
    E --&gt;|No| SQL

    style SQL fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style SP fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<hr />
<h2>ğŸ”„ 4. High Availability &amp; Scaling</h2>
<h3>HA Configuration</h3>
<table>
<thead>
<tr>
<th>Configuration</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Single Zone</strong></td>
<td>One instance, one zone</td>
<td>Dev/Test</td>
</tr>
<tr>
<td><strong>High Availability</strong></td>
<td>Primary + standby in different zones</td>
<td>Production</td>
</tr>
<tr>
<td><strong>Cross-Region Replica</strong></td>
<td>Read replica in different region</td>
<td>Disaster recovery</td>
</tr>
</tbody>
</table>
<h3>Scaling Options</h3>
<table>
<thead>
<tr>
<th>Need</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>More Write Performance</td>
<td>Vertical scaling (increase CPU/RAM)</td>
</tr>
<tr>
<td>More Read Performance</td>
<td>Add Read Replicas</td>
</tr>
<tr>
<td>Global Reads</td>
<td>Cross-region replicas</td>
</tr>
<tr>
<td>Beyond 64TB</td>
<td>Migrate to Cloud Spanner</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Read Replicas only help with READ performance. For WRITE performance, you must vertically scale the primary instance.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Create &amp; Query Cloud SQL</h2>
<h3>Step 1: Create Instance</h3>
<pre><code class="language-bash">gcloud sql instances create hero-db \
    --database-version=MYSQL_8_0 \
    --tier=db-f1-micro \
    --region=us-central1 \
    --root-password=SecurePassword123!
</code></pre>
<h3>Step 2: Connect via Cloud SQL Proxy</h3>
<pre><code class="language-bash"># Enable the API
gcloud services enable sqladmin.googleapis.com

# Connect using built-in proxy
gcloud sql connect hero-db --user=root
</code></pre>
<h3>Step 3: Create Database and Table</h3>
<pre><code class="language-sql">CREATE DATABASE hero_corp;
USE hero_corp;

CREATE TABLE users (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100),
    email VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO users (name, email) VALUES ('GCP Student', 'student@gcp.com');
SELECT * FROM users;
</code></pre>
<h3>Step 4: Enable HA (Optional)</h3>
<pre><code class="language-bash">gcloud sql instances patch hero-db \
    --availability-type=REGIONAL \
    --backup-start-time=02:00
</code></pre>
<h3>Step 5: Cleanup</h3>
<pre><code class="language-bash">gcloud sql instances delete hero-db --quiet
</code></pre>
<hr />
<h2>âš ï¸ 6. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Read replicas improve writes"</td>
<td>No! Only vertical scaling improves writes</td>
</tr>
<tr>
<td>"Cloud SQL is global"</td>
<td>No! Cloud SQL is regional (use Spanner for global)</td>
</tr>
<tr>
<td>"Use public IP in production"</td>
<td>No! Use Cloud SQL Proxy or Private IP</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Always enable automated backups</strong> with point-in-time recovery</li>
<li><strong>Use Cloud SQL Auth Proxy</strong> for secure connections</li>
<li><strong>Enable Private IP</strong> for production databases</li>
<li><strong>Set maintenance windows</strong> during low-traffic periods</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which of these is NOT a managed feature of Cloud SQL?</strong></p>
<ul>
<li>A. Automated backups</li>
<li>B. OS Patching</li>
<li>C. <strong>Writing SQL Queries</strong> âœ…</li>
<li>D. High Availability failover</li>
</ul>
</li>
<li>
<p><strong>A global retail company needs a relational database with horizontal scaling across US, Europe, and Asia. Which service?</strong></p>
<ul>
<li>A. Cloud SQL</li>
<li>B. <strong>Cloud Spanner</strong> âœ…</li>
<li>C. Bigtable</li>
<li>D. BigQuery</li>
</ul>
</li>
<li>
<p><strong>Your Cloud SQL database is slow due to too many SELECT queries. What should you add?</strong></p>
<ul>
<li>A. More CPU to primary</li>
<li>B. <strong>Read Replicas</strong> âœ…</li>
<li>C. Cloud CDN</li>
<li>D. More RAM to primary</li>
</ul>
</li>
<li>
<p><strong>What is the most secure way to connect to Cloud SQL from a GKE pod?</strong></p>
<ul>
<li>A. Public IP with firewall</li>
<li>B. VPN tunnel</li>
<li>C. <strong>Cloud SQL Auth Proxy</strong> âœ…</li>
<li>D. SSH tunnel</li>
</ul>
</li>
<li>
<p><strong>Your write performance is poor on Cloud SQL. What should you do?</strong></p>
<ul>
<li>A. Add read replicas</li>
<li>B. <strong>Vertically scale (increase CPU/RAM)</strong> âœ…</li>
<li>C. Add more databases</li>
<li>D. Enable Cloud CDN</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 10 Checklist</h2>
<ul>
<li>[ ] Know the 3 supported database engines</li>
<li>[ ] Understand Cloud SQL vs Spanner use cases</li>
<li>[ ] Connect to Cloud SQL via Cloud Shell</li>
<li>[ ] Understand Read Replicas vs Vertical Scaling</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud SQL", "def": "Managed relational database. Supports MySQL, PostgreSQL, SQL Server. Regional only."},
  {"term": "Read Replica", "def": "Additional read-only copy of database. Improves read performance, not writes."},
  {"term": "Cloud SQL Auth Proxy", "def": "Secure way to connect to Cloud SQL. Handles authentication and encryption."},
  {"term": "High Availability", "def": "Primary + standby in different zones. Automatic failover if primary fails."},
  {"term": "Vertical Scaling", "def": "Increase CPU/RAM of instance. The only way to improve write performance."},
  {"term": "Cloud Spanner", "def": "Global relational database with horizontal scaling. Use when Cloud SQL is too small."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_11_storage_advanced">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Day 11: Cloud Storage Advanced (Lifecycle &amp; Security)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Essential for cost &amp; security questions)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 11, you will be able to:</p>
<ul>
<li><strong>Automate</strong> cost savings with Object Lifecycle Management</li>
<li><strong>Protect</strong> data with Object Versioning</li>
<li><strong>Implement</strong> secure temporary access with Signed URLs</li>
<li><strong>Apply</strong> Retention Policies and Bucket Lock for compliance</li>
<li><strong>Compare</strong> storage classes and choose appropriately</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: Advanced Storage in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Storage cost optimization is a key Cloud Engineer skill. Lifecycle rules save companies millions.</p>
</blockquote>
<h3>Job Roles &amp; Advanced Storage Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use These Features</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Cost optimization, lifecycle</td>
<td>Setting up tiered storage</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Retention, compliance</td>
<td>Bucket Lock, audit requirements</td>
</tr>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Data pipeline storage</td>
<td>Versioning, partitioned uploads</td>
</tr>
<tr>
<td><strong>FinOps Analyst</strong></td>
<td>Storage cost analysis</td>
<td>Lifecycle rules, class transitions</td>
</tr>
</tbody>
</table>
<h3>Cost Optimization Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Savings</th>
<th>Implementation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Auto-Tier</strong></td>
<td>50-90%</td>
<td>Lifecycle: Standard â†’ Nearline â†’ Coldline</td>
</tr>
<tr>
<td><strong>Version Cleanup</strong></td>
<td>80%+</td>
<td>Delete versions older than N days</td>
</tr>
<tr>
<td><strong>Abort Incomplete</strong></td>
<td>10-20%</td>
<td>Delete failed multipart uploads</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use Standard for backups"</td>
<td>Wasting money</td>
<td>"I use Nearline or Coldline with lifecycle rules"</td>
</tr>
<tr>
<td>"Versioning has no cost"</td>
<td>You pay for all versions</td>
<td>"I combine versioning with lifecycle rules to limit versions"</td>
</tr>
<tr>
<td>"I share files by making bucket public"</td>
<td>Security risk</td>
<td>"I generate Signed URLs with short expiration"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Storage Classes Recap</h2>
<h3>Cost vs Access Time Tradeoff</h3>
<table>
<thead>
<tr>
<th>Class</th>
<th>Min Duration</th>
<th>Use Case</th>
<th>Cost (per GB)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Standard</strong></td>
<td>None</td>
<td>Frequently accessed data</td>
<td>$$$</td>
</tr>
<tr>
<td><strong>Nearline</strong></td>
<td>30 days</td>
<td>Monthly access</td>
<td>$$</td>
</tr>
<tr>
<td><strong>Coldline</strong></td>
<td>90 days</td>
<td>Quarterly access</td>
<td>$</td>
</tr>
<tr>
<td><strong>Archive</strong></td>
<td>365 days</td>
<td>Yearly access</td>
<td>Â¢</td>
</tr>
</tbody>
</table>
<h3>The Key Insight</h3>
<pre><code>Storage Cost: Standard &gt; Nearline &gt; Coldline &gt; Archive
Retrieval Cost: Archive &gt; Coldline &gt; Nearline &gt; Standard
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If data is accessed frequently, Standard is cheapest. If rarely accessed, Archive is cheapest.</p>
</blockquote>
<hr />
<h2>ğŸ”„ 2. Object Lifecycle Management</h2>
<p><strong>Automate storage class transitions and deletions to save money.</strong></p>
<h3>Lifecycle State Machine</h3>
<pre><code class="language-mermaid">flowchart LR
    STD[Standard] --&gt;|30 days| NL[Nearline]
    NL --&gt;|60 days| CL[Coldline]
    CL --&gt;|275 days| AR[Archive]
    AR --&gt;|10 years| DEL[âŒ Delete]

    style STD fill:#fee2e2,stroke:#ef4444
    style NL fill:#fff7ed,stroke:#ea580c
    style CL fill:#dbeafe,stroke:#2563eb
    style AR fill:#e0e7ff,stroke:#4338ca
</code></pre>
<h3>Lifecycle Rule Actions</h3>
<table>
<thead>
<tr>
<th>Action</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SetStorageClass</strong></td>
<td>Move to cheaper class</td>
</tr>
<tr>
<td><strong>Delete</strong></td>
<td>Permanently remove object</td>
</tr>
<tr>
<td><strong>AbortIncompleteUpload</strong></td>
<td>Clean up failed uploads</td>
</tr>
</tbody>
</table>
<h3>Lifecycle Rule Conditions</h3>
<table>
<thead>
<tr>
<th>Condition</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Age</strong></td>
<td>Object is &gt;30 days old</td>
</tr>
<tr>
<td><strong>CreatedBefore</strong></td>
<td>Object created before 2023-01-01</td>
</tr>
<tr>
<td><strong>NumNewerVersions</strong></td>
<td>&gt;3 newer versions exist</td>
</tr>
<tr>
<td><strong>IsLive</strong></td>
<td>Is latest version (not archived)</td>
</tr>
</tbody>
</table>
<h3>Create Lifecycle Policy</h3>
<pre><code class="language-bash"># Create lifecycle.json
cat &gt; lifecycle.json &lt;&lt; 'EOF'
{
  &quot;lifecycle&quot;: {
    &quot;rule&quot;: [
      {
        &quot;action&quot;: {&quot;type&quot;: &quot;SetStorageClass&quot;, &quot;storageClass&quot;: &quot;NEARLINE&quot;},
        &quot;condition&quot;: {&quot;age&quot;: 30}
      },
      {
        &quot;action&quot;: {&quot;type&quot;: &quot;SetStorageClass&quot;, &quot;storageClass&quot;: &quot;COLDLINE&quot;},
        &quot;condition&quot;: {&quot;age&quot;: 90}
      },
      {
        &quot;action&quot;: {&quot;type&quot;: &quot;Delete&quot;},
        &quot;condition&quot;: {&quot;age&quot;: 365}
      }
    ]
  }
}
EOF

# Apply to bucket
gcloud storage buckets update gs://my-bucket --lifecycle-file=lifecycle.json
</code></pre>
<hr />
<h2>ğŸ›¡ï¸ 3. Object Versioning</h2>
<p><strong>Keep previous versions of objects for recovery and audit.</strong></p>
<h3>How Versioning Works</h3>
<pre><code class="language-mermaid">flowchart TD
    subgraph Bucket[&quot;Bucket with Versioning&quot;]
        V1[report.pdf&lt;br/&gt;Generation: 1001]
        V2[report.pdf&lt;br/&gt;Generation: 1002]
        V3[report.pdf&lt;br/&gt;Generation: 1003&lt;br/&gt;CURRENT]
    end

    DEL[Delete report.pdf] --&gt;|Creates| DM[Delete Marker]

    style V3 fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Enable Versioning</h3>
<pre><code class="language-bash"># Enable versioning
gcloud storage buckets update gs://my-bucket --versioning

# List all versions
gcloud storage ls --all-versions gs://my-bucket/

# Restore previous version
gcloud storage cp gs://my-bucket/file#1234567890 gs://my-bucket/file
</code></pre>
<h3>âš ï¸ The Cost Trap</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Storage Paid</th>
</tr>
</thead>
<tbody>
<tr>
<td>1GB file, no versioning</td>
<td>1 GB</td>
</tr>
<tr>
<td>1GB file, 10 versions</td>
<td><strong>10 GB</strong></td>
</tr>
<tr>
<td>1GB file, 24 daily versions</td>
<td><strong>24 GB</strong></td>
</tr>
</tbody>
</table>
<p><strong>Solution:</strong> Combine with lifecycle rule to delete old versions:</p>
<pre><code class="language-json">{
  &quot;action&quot;: {&quot;type&quot;: &quot;Delete&quot;},
  &quot;condition&quot;: {&quot;numNewerVersions&quot;: 3}
}
</code></pre>
<hr />
<h2>âœï¸ 4. Signed URLs (Temporary Access)</h2>
<p><strong>Grant time-limited access without requiring Google accounts.</strong></p>
<h3>How Signed URLs Work</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant User as User/Browser
    participant App as Your Backend
    participant GCS as Cloud Storage

    User-&gt;&gt;App: 1. Request download link
    App-&gt;&gt;App: 2. Generate signed URL
    App--&gt;&gt;User: 3. Return signed URL
    User-&gt;&gt;GCS: 4. Direct access with signed URL
    GCS--&gt;&gt;User: 5. Return file
</code></pre>
<h3>Signed URL Properties</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Expiration</strong></td>
<td>1 minute to 7 days</td>
</tr>
<tr>
<td><strong>Method</strong></td>
<td>GET, PUT, DELETE (one per URL)</td>
</tr>
<tr>
<td><strong>Self-authenticating</strong></td>
<td>URL contains signature</td>
</tr>
<tr>
<td><strong>No account needed</strong></td>
<td>Works for anyone with the URL</td>
</tr>
</tbody>
</table>
<h3>Generate Signed URL</h3>
<pre><code class="language-bash"># Generate download URL (valid 1 hour)
gcloud storage sign-url gs://my-bucket/secret-file.pdf \
    --duration=1h \
    --private-key-file=service-account.json

# Generate upload URL
gcloud storage sign-url gs://my-bucket/uploads/ \
    --duration=15m \
    --http-verb=PUT \
    --private-key-file=service-account.json
</code></pre>
<hr />
<h2>ğŸ”’ 5. Retention Policies &amp; Bucket Lock</h2>
<p><strong>For compliance: Ensure data cannot be deleted.</strong></p>
<h3>Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Retention Policy</th>
<th>Bucket Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Purpose</strong></td>
<td>Minimum hold period</td>
<td>Permanent enforcement</td>
</tr>
<tr>
<td><strong>Modifiable</strong></td>
<td>Yes (can extend or remove)</td>
<td><strong>No (irreversible)</strong></td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>Soft compliance</td>
<td>Legal/regulatory hold</td>
</tr>
</tbody>
</table>
<h3>Configure Retention</h3>
<pre><code class="language-bash"># Set 1-year retention
gcloud storage buckets update gs://my-bucket \
    --retention-period=365d

# Lock bucket (IRREVERSIBLE!)
gcloud storage buckets update gs://my-bucket --lock-retention-policy
</code></pre>
<blockquote>
<p><strong>âš ï¸ Warning:</strong> Bucket Lock is <strong>permanent</strong>. Once locked, policy cannot be removed until retention period expires.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 6. Hands-On Lab: Lifecycle &amp; Versioning</h2>
<h3>Step 1: Create Bucket with Versioning</h3>
<pre><code class="language-bash">gcloud storage buckets create gs://my-advanced-bucket-${PROJECT_ID} \
    --location=us-central1 \
    --versioning
</code></pre>
<h3>Step 2: Test Versioning</h3>
<pre><code class="language-bash"># Create initial file
echo &quot;Version 1&quot; &gt; test.txt
gcloud storage cp test.txt gs://my-advanced-bucket-${PROJECT_ID}/

# Create version 2
echo &quot;Version 2&quot; &gt; test.txt
gcloud storage cp test.txt gs://my-advanced-bucket-${PROJECT_ID}/

# List all versions
gcloud storage ls --all-versions gs://my-advanced-bucket-${PROJECT_ID}/
</code></pre>
<h3>Step 3: Add Lifecycle Policy</h3>
<pre><code class="language-bash">cat &gt; lifecycle.json &lt;&lt; 'EOF'
{
  &quot;lifecycle&quot;: {
    &quot;rule&quot;: [
      {
        &quot;action&quot;: {&quot;type&quot;: &quot;Delete&quot;},
        &quot;condition&quot;: {&quot;numNewerVersions&quot;: 2}
      }
    ]
  }
}
EOF

gcloud storage buckets update gs://my-advanced-bucket-${PROJECT_ID} \
    --lifecycle-file=lifecycle.json
</code></pre>
<h3>Step 4: Cleanup</h3>
<pre><code class="language-bash">gcloud storage rm -r gs://my-advanced-bucket-${PROJECT_ID}
</code></pre>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Lifecycle can upgrade to Standard"</td>
<td>No! Only downgrades to colder classes</td>
</tr>
<tr>
<td>"Versioning is free"</td>
<td>No! You pay for every version stored</td>
</tr>
<tr>
<td>"Signed URLs last forever"</td>
<td>No! Maximum 7 days</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Combine versioning + lifecycle</strong> to limit version count</li>
<li><strong>Use Signed URLs</strong> for user uploads/downloads</li>
<li><strong>Never lock a bucket</strong> without legal requirement</li>
<li><strong>Archive class</strong> is 50x cheaper than Standard for long-term storage</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>You need to keep objects for 7 years for legal compliance, preventing any deletion. What should you use?</strong></p>
<ul>
<li>A. Object Versioning</li>
<li>B. Lifecycle Policy</li>
<li>C. <strong>Bucket Lock with Retention Policy</strong> âœ…</li>
<li>D. IAM Deny Policy</li>
</ul>
</li>
<li>
<p><strong>A vendor needs to download 10 files for exactly 2 hours. Most secure method?</strong></p>
<ul>
<li>A. Make bucket public</li>
<li>B. <strong>Generate 10 Signed URLs with 2-hour expiration</strong> âœ…</li>
<li>C. Add vendor's email to IAM</li>
<li>D. Create a service account for vendor</li>
</ul>
</li>
<li>
<p><strong>Lifecycle rules can move data from Coldline to Standard. True or False?</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False (only moves to colder classes)</strong> âœ…</li>
<li>C. Only with versioning enabled</li>
<li>D. Only for Archive to Standard</li>
</ul>
</li>
<li>
<p><strong>Your bucket has 1TB of data with 10 versions each. How much storage are you paying for?</strong></p>
<ul>
<li>A. 1 TB</li>
<li>B. 2 TB</li>
<li>C. <strong>10 TB</strong> âœ…</li>
<li>D. Versioning is free</li>
</ul>
</li>
<li>
<p><strong>Which action prevents you from ever removing a retention policy?</strong></p>
<ul>
<li>A. Enable versioning</li>
<li>B. Set retention period</li>
<li>C. <strong>Lock the bucket</strong> âœ…</li>
<li>D. Enable uniform access</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 11 Checklist</h2>
<ul>
<li>[ ] Understand storage class cost tradeoffs</li>
<li>[ ] Create lifecycle rules for automatic transitions</li>
<li>[ ] Enable and test object versioning</li>
<li>[ ] Generate a signed URL</li>
<li>[ ] Understand when to use Bucket Lock</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Lifecycle Management", "def": "Rules to automatically transition or delete objects based on age or versions."},
  {"term": "Object Versioning", "def": "Keep all versions of objects. Enables recovery but increases storage costs."},
  {"term": "Signed URL", "def": "Time-limited URL that grants temporary access. No Google account needed."},
  {"term": "Retention Policy", "def": "Minimum time objects must be kept. Prevents accidental deletion."},
  {"term": "Bucket Lock", "def": "Permanently enforces retention policy. Cannot be reversed."},
  {"term": "Archive Class", "def": "Cheapest storage for rarely accessed data. 365-day minimum storage."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_12_app_engine">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 12: App Engine (Platform as a Service)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Core PaaS service, heavily tested)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 12, you will be able to:</p>
<ul>
<li><strong>Define</strong> Platform as a Service (PaaS) model</li>
<li><strong>Decide</strong> between Standard and Flexible environments</li>
<li><strong>Deploy</strong> applications using gcloud CLI</li>
<li><strong>Implement</strong> traffic splitting for canary deployments</li>
<li><strong>Compare</strong> App Engine vs Cloud Run vs Cloud Functions</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: App Engine in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> App Engine is less common in new projects (Cloud Run preferred), but critical for exam and legacy systems.</p>
</blockquote>
<h3>Job Roles &amp; App Engine Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use App Engine</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Backend Developer</strong></td>
<td>Quick deployments, simple microservices</td>
<td>Deploy, traffic splitting</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Manage legacy App Engine apps</td>
<td>Version management, migrations</td>
</tr>
<tr>
<td><strong>Cloud Architect</strong></td>
<td>Evaluate PaaS options</td>
<td>Standard vs Flex vs Cloud Run decisions</td>
</tr>
</tbody>
</table>
<h3>When to Use What</h3>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Best Choice</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple app, scale to zero</td>
<td><strong>App Engine Standard</strong></td>
<td>Zero cost when idle</td>
</tr>
<tr>
<td>Custom Docker, VPC access</td>
<td><strong>App Engine Flexible</strong></td>
<td>More control</td>
</tr>
<tr>
<td>Modern serverless, containers</td>
<td><strong>Cloud Run</strong></td>
<td>Industry standard now</td>
</tr>
<tr>
<td>Event-driven glue code</td>
<td><strong>Cloud Functions</strong></td>
<td>Simplest option</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
<strong>Interview Tip:</strong> "For new projects, I recommend Cloud Run over App Engine because it offers more flexibility and industry adoption. I'd only use App Engine Standard when scale-to-zero and legacy compatibility matter."</p>
</blockquote>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"App Engine Flexible scales to zero"</td>
<td>It doesn't, costs ~$40/month minimum</td>
<td>"Only Standard scales to zero"</td>
</tr>
<tr>
<td>"I'd use App Engine for new microservices"</td>
<td>Not modern best practice</td>
<td>"I'd evaluate Cloud Run first for containers"</td>
</tr>
<tr>
<td>"You can create multiple apps per project"</td>
<td>Only one allowed</td>
<td>"One Application per project, multiple services are allowed"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What is App Engine? (Plain-English)</h2>
<p><strong>App Engine = You write code, Google runs it. No servers to manage.</strong></p>
<h3>The App Engine Philosophy</h3>
<ul>
<li>âœ… Upload your code</li>
<li>âœ… Google handles scaling, load balancing, patching</li>
<li>âœ… Pay only for what you use</li>
<li>âŒ No SSH access (you don't need it!)</li>
</ul>
<h3>ğŸ’¡ Real-World Analogy</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Compute Engine</strong></td>
<td>Buying a car - you maintain everything</td>
</tr>
<tr>
<td><strong>App Engine</strong></td>
<td>Taking an Uber - just tell it where to go</td>
</tr>
<tr>
<td><strong>Cloud Functions</strong></td>
<td>Ordering delivery - even less work</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. App Engine Hierarchy</h2>
<p>Understanding this structure is critical for the exam:</p>
<pre><code class="language-mermaid">graph TD
    APP[ğŸ“± Application&lt;br/&gt;One per project] --&gt; SVC1[âš™ï¸ Service: web-frontend]
    APP --&gt; SVC2[âš™ï¸ Service: api-backend]
    APP --&gt; SVC3[âš™ï¸ Service: worker]

    SVC1 --&gt; V1[ğŸ“„ Version: v1]
    SVC1 --&gt; V2[ğŸ“„ Version: v2]
    SVC1 --&gt; V3[ğŸ“„ Version: v3]

    V2 --&gt; I1[ğŸ–¥ï¸ Instance 1]
    V2 --&gt; I2[ğŸ–¥ï¸ Instance 2]
    V2 --&gt; IN[ğŸ–¥ï¸ Instance N]

    style APP fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    style V2 fill:#e8f5e9,stroke:#4caf50
</code></pre>
<h3>Key Facts</h3>
<ul>
<li><strong>One Application</strong> per GCP project</li>
<li><strong>Multiple Services</strong> per application (microservices)</li>
<li><strong>Multiple Versions</strong> per service (for rollback/canary)</li>
<li><strong>Multiple Instances</strong> per version (auto-scaling)</li>
</ul>
<hr />
<h2>âš”ï¸ 3. Standard vs Flexible Environment</h2>
<p>This is THE most common App Engine exam question.</p>
<h3>Comparison Table</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Standard</th>
<th>Flexible</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Startup Time</strong></td>
<td>Milliseconds</td>
<td>Minutes</td>
</tr>
<tr>
<td><strong>Scale to Zero</strong></td>
<td>âœ… Yes</td>
<td>âŒ No (min 1 instance)</td>
</tr>
<tr>
<td><strong>Languages</strong></td>
<td>Specific versions only</td>
<td>Any (via Docker)</td>
</tr>
<tr>
<td><strong>SSH Access</strong></td>
<td>âŒ No</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td><strong>Custom Runtime</strong></td>
<td>âŒ No</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td><strong>Network</strong></td>
<td>App Engine network only</td>
<td>VPC access</td>
</tr>
<tr>
<td><strong>Cost at Idle</strong></td>
<td><strong>Free</strong></td>
<td>~$40/month minimum</td>
</tr>
</tbody>
</table>
<h3>Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Choose Environment] --&gt; B{Need Custom Runtime?}
    B --&gt;|Yes| FLEX[Flexible]
    B --&gt;|No| C{Need Scale to Zero?}

    C --&gt;|Yes| STD[Standard]
    C --&gt;|No| D{Need SSH/VPC?}

    D --&gt;|Yes| FLEX
    D --&gt;|No| STD

    style STD fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style FLEX fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If the question mentions "cost-effective" or "scale to zero" â†’ <strong>Standard</strong>. If it mentions "custom Docker" or "SSH" â†’ <strong>Flexible</strong>.</p>
</blockquote>
<hr />
<h2>ğŸš¦ 4. Traffic Splitting (Canary Deployments)</h2>
<p>Test new versions on a subset of users before full rollout.</p>
<h3>Splitting Architecture</h3>
<pre><code class="language-mermaid">flowchart LR
    USERS[ğŸŒ All Users] --&gt; GAE[App Engine]
    GAE --&gt;|90%| V1[Stable v1]
    GAE --&gt;|10%| V2[New v2]

    style V2 fill:#fff3e0,stroke:#ff9800,stroke-width:2px
</code></pre>
<h3>Split Methods</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Description</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IP Address</strong></td>
<td>Same IP always goes to same version</td>
<td>Anonymous users</td>
</tr>
<tr>
<td><strong>Cookie</strong></td>
<td>Session-consistent routing</td>
<td>Logged-in users</td>
</tr>
<tr>
<td><strong>Random</strong></td>
<td>Truly random distribution</td>
<td>A/B testing</td>
</tr>
</tbody>
</table>
<h3>gcloud Commands</h3>
<pre><code class="language-bash"># Deploy new version without traffic
gcloud app deploy --version=v2 --no-promote

# Split traffic 90/10
gcloud app services set-traffic default \
    --splits=v1=0.9,v2=0.1 \
    --split-by=cookie

# Migrate all traffic to v2
gcloud app services set-traffic default --splits=v2=1
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Deploy Hello World</h2>
<h3>Step 1: Create App Files</h3>
<pre><code class="language-bash">mkdir gcp-hero-app &amp;&amp; cd gcp-hero-app

# Create main.py
cat &gt; main.py &lt;&lt; 'EOF'
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello():
    return '&lt;h1&gt;GCP Hero: App Engine Success! ğŸš€&lt;/h1&gt;'

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
EOF

# Create requirements.txt
echo &quot;Flask==2.3.3&quot; &gt; requirements.txt
</code></pre>
<h3>Step 2: Create app.yaml</h3>
<pre><code class="language-yaml"># app.yaml
runtime: python39
instance_class: F1
automatic_scaling:
  min_instances: 0
  max_instances: 2
  target_cpu_utilization: 0.65
</code></pre>
<h3>Step 3: Deploy</h3>
<pre><code class="language-bash"># Initialize App Engine (first time only)
gcloud app create --region=us-central

# Deploy
gcloud app deploy --quiet

# Open in browser
gcloud app browse
</code></pre>
<h3>Step 4: View Logs</h3>
<pre><code class="language-bash">gcloud app logs tail -s default
</code></pre>
<hr />
<h2>âš ï¸ 6. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Flexible scales to zero"</td>
<td>No! Only Standard scales to zero</td>
</tr>
<tr>
<td>"Multiple apps per project"</td>
<td>No! One app per project only</td>
</tr>
<tr>
<td>"App Engine runs containers"</td>
<td>Standard doesn't; Flexible does</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use Standard for cost savings</strong> when you can</li>
<li><strong>Set min_instances=0</strong> for true scale-to-zero</li>
<li><strong>Use traffic splitting</strong> for safe deployments</li>
<li><strong>Version names are immutable</strong> - use timestamps</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>You're building a microservice that triggers once an hour for 5 minutes. Which environment is most cost-effective?</strong></p>
<ul>
<li>A. Flexible</li>
<li>B. <strong>Standard (scales to zero)</strong> âœ…</li>
<li>C. Compute Engine VM</li>
<li>D. GKE Autopilot</li>
</ul>
</li>
<li>
<p><strong>How many App Engine Applications can you have per GCP Project?</strong></p>
<ul>
<li>A. Unlimited</li>
<li>B. 10</li>
<li>C. <strong>Exactly one</strong> âœ…</li>
<li>D. One per region</li>
</ul>
</li>
<li>
<p><strong>You want to test a new login page on 5% of users before full rollout. What feature do you use?</strong></p>
<ul>
<li>A. Instance Templates</li>
<li>B. <strong>Traffic Splitting</strong> âœ…</li>
<li>C. IAM Roles</li>
<li>D. Cloud DNS</li>
</ul>
</li>
<li>
<p><strong>Which App Engine environment supports SSH access and custom Docker runtimes?</strong></p>
<ul>
<li>A. Standard</li>
<li>B. <strong>Flexible</strong> âœ…</li>
<li>C. Both</li>
<li>D. Neither</li>
</ul>
</li>
<li>
<p><strong>Your App Engine app is idle most of the time. Which configuration minimizes cost?</strong></p>
<ul>
<li>A. Flexible with min_instances=1</li>
<li>B. <strong>Standard with min_instances=0</strong> âœ…</li>
<li>C. Standard with min_instances=1</li>
<li>D. Flexible with max_instances=0</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 12 Checklist</h2>
<ul>
<li>[ ] Understand Standard vs Flexible differences</li>
<li>[ ] Know the App â†’ Service â†’ Version hierarchy</li>
<li>[ ] Deploy an app using app.yaml</li>
<li>[ ] Implement traffic splitting</li>
<li>[ ] Complete the hands-on lab</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "App Engine", "def": "Fully managed PaaS. Upload code, Google handles everything else."},
  {"term": "Standard Environment", "def": "Fast startup, scales to zero, limited runtimes. Best for cost savings."},
  {"term": "Flexible Environment", "def": "Docker-based, SSH access, VPC support. Min 1 instance always running."},
  {"term": "Traffic Splitting", "def": "Route percentage of traffic to different versions. For canary deployments."},
  {"term": "app.yaml", "def": "Configuration file defining runtime, scaling, and environment settings."},
  {"term": "Scale to Zero", "def": "No instances running when idle = no cost. Only Standard environment."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_13_cloud_run">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Module 11: Cloud Run Serverless</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (The future of compute!)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Cloud Run in 30 Seconds)</strong><br />
Cloud Run = Container + Serverless = Best of both worlds. Deploy any Docker container, Google handles scaling (even to zero). Default concurrency: 80 requests/instance. Set <code>min-instances=1</code> to avoid cold starts. It's stateless â€” don't save files locally. For the exam: Cloud Run is for containers WITHOUT Kubernetes.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explain</strong> serverless container model</td>
<td>Core concept for modern GCP</td>
</tr>
<tr>
<td><strong>Compare</strong> Cloud Run vs alternatives</td>
<td>Pick the right compute service</td>
</tr>
<tr>
<td><strong>Deploy</strong> containers</td>
<td>Hands-on skill for ACE exam</td>
</tr>
<tr>
<td><strong>Configure</strong> concurrency/scaling</td>
<td>Optimize cost and performance</td>
</tr>
<tr>
<td><strong>Implement</strong> secure service-to-service</td>
<td>Real-world microservices pattern</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What is Cloud Run? (Plain-English)</h2>
<p><strong>Cloud Run = Docker container flexibility + serverless simplicity.</strong></p>
<p>You bring a container, Google runs it. No clusters, no VMs, no patches.</p>
<h3>The Sweet Spot</h3>
<pre><code class="language-mermaid">graph LR
    subgraph Flexibility
        GKE[GKE&lt;br/&gt;Full Kubernetes]
    end

    subgraph Balance
        CR[Cloud Run&lt;br/&gt;Serverless Containers]
    end

    subgraph Simplicity
        GAE[App Engine&lt;br/&gt;PaaS]
        CF[Functions&lt;br/&gt;FaaS]
    end

    GKE --&gt; CR --&gt; GAE --&gt; CF

    style CR fill:#e8f5e9,stroke:#4caf50,stroke-width:3px
</code></pre>
<h3>ğŸ’¡ Real-World Analogy</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GKE</strong></td>
<td>Owning a restaurant building - you manage everything</td>
</tr>
<tr>
<td><strong>App Engine</strong></td>
<td>Managed food court - their kitchens, their menus</td>
</tr>
<tr>
<td><strong>Cloud Run</strong></td>
<td><strong>Pop-up food truck</strong> - you bring your kitchen, Google provides the parking</td>
</tr>
<tr>
<td><strong>Functions</strong></td>
<td>Vending machine - single purpose, instant</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Cloud Run Architecture</h2>
<pre><code class="language-mermaid">flowchart LR
    subgraph Dev[&quot;Development&quot;]
        CODE[ğŸ’» Your Code]
        DOCKER[ğŸ³ Dockerfile]
    end

    subgraph Build[&quot;Build&quot;]
        CB[Cloud Build]
        AR[Artifact Registry]
    end

    subgraph Run[&quot;Cloud Run&quot;]
        SVC[Service]
        REV1[Revision 1]
        REV2[Revision 2]
    end

    subgraph Scale[&quot;Auto-Scaling&quot;]
        I1[Instance 1]
        I2[Instance 2]
        IN[Instance N]
    end

    CODE --&gt; DOCKER --&gt; CB --&gt; AR --&gt; SVC
    SVC --&gt; REV1 &amp; REV2
    REV2 --&gt; I1 &amp; I2 &amp; IN

    style SVC fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Key Features</h3>
<ul>
<li>âœ… <strong>Scale to Zero</strong> - Pay nothing when idle</li>
<li>âœ… <strong>Container Portability</strong> - Works on any cloud or laptop</li>
<li>âœ… <strong>Auto-scaling</strong> - Handles traffic spikes automatically</li>
<li>âœ… <strong>HTTPS by default</strong> - Automatic TLS certificates</li>
<li>âœ… <strong>Revisions</strong> - Easy rollback and traffic splitting</li>
</ul>
<hr />
<h2>âš¡ 3. Concurrency &amp; Scaling</h2>
<p>Cloud Run scales based on <strong>concurrent requests</strong>, not CPU.</p>
<h3>How Concurrency Works</h3>
<pre><code class="language-mermaid">flowchart LR
    USERS[100 Users] --&gt; CR[Cloud Run]

    subgraph Instances[&quot;With concurrency=80&quot;]
        I1[Instance 1&lt;br/&gt;80 requests]
        I2[Instance 2&lt;br/&gt;20 requests]
    end

    CR --&gt; I1 &amp; I2

    style I1 fill:#e8f5e9,stroke:#4caf50
    style I2 fill:#fff3e0,stroke:#ff9800
</code></pre>
<h3>Concurrency Settings</h3>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Value</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Max Concurrency</strong></td>
<td>1-1000 (default 80)</td>
<td>Requests per instance</td>
</tr>
<tr>
<td><strong>Min Instances</strong></td>
<td>0-N</td>
<td>Cold start prevention</td>
</tr>
<tr>
<td><strong>Max Instances</strong></td>
<td>1-1000</td>
<td>Cost/resource limit</td>
</tr>
</tbody>
</table>
<h3>Scaling Formula</h3>
<pre><code>Instances Needed = Concurrent Requests / Concurrency Setting
Example: 200 requests / 80 concurrency = 3 instances
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Higher concurrency = fewer instances = lower cost. But set it too high and your app might struggle.</p>
</blockquote>
<hr />
<h2>ğŸ”’ 4. Security &amp; Networking</h2>
<h3>Authentication Options</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Allow unauthenticated</strong></td>
<td>Public APIs, websites</td>
</tr>
<tr>
<td><strong>Require authentication</strong></td>
<td>Internal services, admin panels</td>
</tr>
<tr>
<td><strong>IAM + Service account</strong></td>
<td>Service-to-service communication</td>
</tr>
</tbody>
</table>
<h3>Secure Service-to-Service</h3>
<pre><code class="language-bash"># Service A calling Service B
curl -H &quot;Authorization: Bearer $(gcloud auth print-identity-token)&quot; \
    https://service-b-xxx.run.app/api
</code></pre>
<h3>VPC Connectivity</h3>
<pre><code class="language-bash"># Connect Cloud Run to VPC
gcloud run services update my-service \
    --vpc-connector=my-connector \
    --vpc-egress=all-traffic
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Deploy a Container</h2>
<h3>Step 1: Deploy from Public Image</h3>
<pre><code class="language-bash">gcloud run deploy hello-service \
    --image=us-docker.pkg.dev/cloudrun/container/hello \
    --region=us-central1 \
    --allow-unauthenticated
</code></pre>
<h3>Step 2: Build and Deploy Your Own</h3>
<pre><code class="language-bash"># Create a simple app
mkdir my-app &amp;&amp; cd my-app

cat &gt; main.py &lt;&lt; 'EOF'
from flask import Flask
import os

app = Flask(__name__)

@app.route('/')
def hello():
    return f'&lt;h1&gt;Hello from Cloud Run! ğŸš€&lt;/h1&gt;'

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 8080)))
EOF

cat &gt; Dockerfile &lt;&lt; 'EOF'
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install flask gunicorn
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 main:app
EOF

# Build and deploy
gcloud run deploy my-app \
    --source . \
    --region=us-central1 \
    --allow-unauthenticated
</code></pre>
<h3>Step 3: Configure Scaling</h3>
<pre><code class="language-bash">gcloud run services update my-app \
    --min-instances=1 \
    --max-instances=10 \
    --concurrency=100 \
    --region=us-central1
</code></pre>
<h3>Step 4: Split Traffic (Canary)</h3>
<pre><code class="language-bash"># Deploy new revision
gcloud run deploy my-app --source . --no-traffic

# Send 10% traffic to new revision
gcloud run services update-traffic my-app \
    --to-revisions=my-app-00002=10 \
    --region=us-central1
</code></pre>
<hr />
<h2>ğŸ”„ 6. Cloud Run vs Alternatives</h2>
<h3>Compute Service Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Cloud Run</th>
<th>App Engine</th>
<th>GKE</th>
<th>Functions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Container Support</strong></td>
<td>âœ…</td>
<td>Flexible only</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td><strong>Scale to Zero</strong></td>
<td>âœ…</td>
<td>Standard only</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
<tr>
<td><strong>Custom Runtime</strong></td>
<td>âœ…</td>
<td>Flexible only</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td><strong>Kubernetes</strong></td>
<td>âŒ</td>
<td>âŒ</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td><strong>Long-running</strong></td>
<td>âœ… (60 min)</td>
<td>âœ…</td>
<td>âœ…</td>
<td>âŒ (9 min)</td>
</tr>
<tr>
<td><strong>Min Overhead</strong></td>
<td>None</td>
<td>None</td>
<td>Cluster</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3>When to Use What</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Best Choice</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple web app, no containers</td>
<td>App Engine Standard</td>
</tr>
<tr>
<td>Containerized app, serverless</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>Kubernetes required</td>
<td>GKE</td>
</tr>
<tr>
<td>Event handler, short tasks</td>
<td>Cloud Functions</td>
</tr>
<tr>
<td>Full cluster control needed</td>
<td>GKE Standard</td>
</tr>
</tbody>
</table>
<hr />
<h2>âš ï¸ 7. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Cloud Run requires Kubernetes"</td>
<td>No! Cloud Run is serverless</td>
</tr>
<tr>
<td>"Files persist between requests"</td>
<td>No! Must be stateless</td>
</tr>
<tr>
<td>"Concurrency=1 is efficient"</td>
<td>No! Higher concurrency = fewer instances</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use min-instances=1</strong> for production to avoid cold starts</li>
<li><strong>Set concurrency high</strong> if your app handles it (saves money)</li>
<li><strong>Use Cloud Run Jobs</strong> for batch processing</li>
<li><strong>Always use regions close to users</strong> for low latency</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which GCP service runs custom Docker containers in a serverless environment that scales to zero?</strong></p>
<ul>
<li>A. App Engine Standard</li>
<li>B. <strong>Cloud Run</strong> âœ…</li>
<li>C. Compute Engine</li>
<li>D. GKE Autopilot</li>
</ul>
</li>
<li>
<p><strong>What is the default maximum concurrency for a Cloud Run instance?</strong></p>
<ul>
<li>A. 1</li>
<li>B. <strong>80</strong> âœ…</li>
<li>C. 1000</li>
<li>D. Unlimited</li>
</ul>
</li>
<li>
<p><strong>Your Cloud Run service has cold start issues. What configuration helps?</strong></p>
<ul>
<li>A. Increase max concurrency</li>
<li>B. <strong>Set min-instances &gt;= 1</strong> âœ…</li>
<li>C. Use a smaller container</li>
<li>D. Enable Cloud CDN</li>
</ul>
</li>
<li>
<p><strong>You have a Python 2.7 app without Docker. Which service is easiest for migration?</strong></p>
<ul>
<li>A. Cloud Run</li>
<li>B. <strong>App Engine Standard</strong> âœ…</li>
<li>C. Cloud Functions</li>
<li>D. GKE</li>
</ul>
</li>
<li>
<p><strong>What happens to data saved to local disk in Cloud Run?</strong></p>
<ul>
<li>A. It persists forever</li>
<li>B. It's backed up automatically</li>
<li>C. <strong>It's deleted when instance scales down</strong> âœ…</li>
<li>D. It's moved to Cloud Storage</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 13 Checklist</h2>
<ul>
<li>[ ] Understand Cloud Run vs alternatives</li>
<li>[ ] Deploy a container from public image</li>
<li>[ ] Build and deploy your own container</li>
<li>[ ] Configure concurrency and scaling</li>
<li>[ ] Implement traffic splitting</li>
</ul>
<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud Run", "def": "Serverless container platform. Deploy Docker containers without managing infrastructure."},
  {"term": "Concurrency", "def": "Number of simultaneous requests per instance. Default 80, max 1000."},
  {"term": "Revision", "def": "Immutable snapshot of a Cloud Run service. Used for traffic splitting and rollback."},
  {"term": "Scale to Zero", "def": "No instances running when idle. Pay nothing. Cloud Run advantage."},
  {"term": "Stateless", "def": "No local data persists. Store state in Cloud SQL, Firestore, or Storage."},
  {"term": "Cold Start", "def": "Delay when new instance starts. Mitigate with min-instances."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_13_dns_cdn">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Day 13: Cloud DNS &amp; Cloud CDN</h1>
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/dns/docs">Cloud DNS</a> | <a href="https://cloud.google.com/cdn/docs">Cloud CDN</a></p>
</blockquote>
<h2>Learning Objectives</h2>
<p>By the end of this day, you should be able to:
- Configure Cloud DNS managed zones for public and private domains
- Set up Cloud CDN with a Global HTTP(S) Load Balancer
- Understand cache behavior and invalidation strategies
- Troubleshoot DNS and CDN issues</p>
<hr />
<h2>1ï¸âƒ£ Cloud DNS: The Internet's Phonebook ğŸ“</h2>
<p><strong>Cloud DNS</strong> translates human-readable names (google.com) to IP addresses (142.250.x.x). It's Google's <strong>100% SLA</strong> service (the only one!).</p>
<h3>DNS Record Types</h3>
<table>
<thead>
<tr>
<th>Record Type</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>A</strong></td>
<td>Maps domain to IPv4</td>
<td><code>mysite.com â†’ 34.120.1.1</code></td>
</tr>
<tr>
<td><strong>AAAA</strong></td>
<td>Maps domain to IPv6</td>
<td><code>mysite.com â†’ 2001:db8::1</code></td>
</tr>
<tr>
<td><strong>CNAME</strong></td>
<td>Alias to another domain</td>
<td><code>www.mysite.com â†’ mysite.com</code></td>
</tr>
<tr>
<td><strong>MX</strong></td>
<td>Mail server routing</td>
<td><code>mysite.com â†’ mail.google.com</code></td>
</tr>
<tr>
<td><strong>TXT</strong></td>
<td>Verification, SPF, DKIM</td>
<td>Domain ownership proof</td>
</tr>
<tr>
<td><strong>NS</strong></td>
<td>Nameserver delegation</td>
<td>Points to DNS servers</td>
</tr>
</tbody>
</table>
<h3>Zone Types</h3>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;Public Zone&quot;
        PZ[ğŸŒ myapp.com]
        PZ --&gt; ExtUser[ğŸ‘¤ External User]
        PZ --&gt; IntUser[ğŸ‘¤ Internal User]
    end

    subgraph &quot;Private Zone&quot;
        PRZ[ğŸ”’ internal.corp]
        PRZ --&gt; VPC[â˜ï¸ VPC Only]
        PRZ -.-&gt;|âŒ No Access| ExtUser2[ğŸ‘¤ External User]
    end

    subgraph &quot;Split Horizon&quot;
        SH[ğŸ”€ myapp.com]
        SH --&gt;|Public IP| Ext[ğŸŒ Internet: 34.120.1.1]
        SH --&gt;|Private IP| Int[ğŸ  VPC: 10.0.0.5]
    end
</code></pre>
<hr />
<h2>2ï¸âƒ£ Cloud CDN: Your Global Mini-Stores ğŸª</h2>
<p><strong>Cloud CDN</strong> caches content at Google's 100+ edge locations worldwide. Instead of fetching from your origin server every time, users get content from the nearest edge.</p>
<h3>How CDN Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant User as ğŸ‘¤ User (Tokyo)
    participant Edge as ğŸ—¼ Edge (Tokyo)
    participant Origin as ğŸ  Origin (US)

    User-&gt;&gt;Edge: GET /logo.png
    Note over Edge: Cache MISS
    Edge-&gt;&gt;Origin: Fetch /logo.png
    Origin--&gt;&gt;Edge: logo.png + cache headers
    Edge--&gt;&gt;User: logo.png
    Note over Edge: Cached for 1 hour

    User-&gt;&gt;Edge: GET /logo.png (again)
    Note over Edge: Cache HIT âš¡
    Edge--&gt;&gt;User: logo.png (from cache)
</code></pre>
<h3>Key Concepts</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cache Hit</strong></td>
<td>Content served from edge (fast!)</td>
</tr>
<tr>
<td><strong>Cache Miss</strong></td>
<td>Content fetched from origin (slower)</td>
</tr>
<tr>
<td><strong>TTL</strong></td>
<td>Time-to-Live - how long content stays cached</td>
</tr>
<tr>
<td><strong>Cache Invalidation</strong></td>
<td>Force-refresh cached content</td>
</tr>
<tr>
<td><strong>Origin</strong></td>
<td>Your backend (GCS bucket, instance group, etc.)</td>
</tr>
</tbody>
</table>
<hr />
<h2>3ï¸âƒ£ Hands-On Lab: Configure DNS &amp; CDN ğŸ› ï¸</h2>
<h3>Part A: Create a DNS Zone</h3>
<pre><code class="language-bash"># Step 1: Create a public managed zone
gcloud dns managed-zones create my-zone \
    --dns-name=&quot;myapp.example.com.&quot; \
    --description=&quot;My application zone&quot;

# Step 2: Add an A record
gcloud dns record-sets create myapp.example.com. \
    --zone=&quot;my-zone&quot; \
    --type=&quot;A&quot; \
    --ttl=300 \
    --rrdatas=&quot;34.120.1.1&quot;

# Step 3: Verify
gcloud dns record-sets list --zone=&quot;my-zone&quot;
</code></pre>
<h3>Part B: Create a Private Zone (VPC-only)</h3>
<pre><code class="language-bash"># Create private zone visible only to your VPC
gcloud dns managed-zones create internal-zone \
    --dns-name=&quot;internal.corp.&quot; \
    --description=&quot;Internal services&quot; \
    --visibility=private \
    --networks=default

# Add internal service record
gcloud dns record-sets create db.internal.corp. \
    --zone=&quot;internal-zone&quot; \
    --type=&quot;A&quot; \
    --ttl=300 \
    --rrdatas=&quot;10.128.0.5&quot;
</code></pre>
<h3>Part C: Enable Cloud CDN</h3>
<pre><code class="language-bash"># Step 1: Create a backend bucket with Cloud Storage
gcloud compute backend-buckets create my-cdn-bucket \
    --gcs-bucket-name=my-static-assets \
    --enable-cdn

# Step 2: Create URL map
gcloud compute url-maps create my-cdn-map \
    --default-backend-bucket=my-cdn-bucket

# Step 3: Create HTTPS proxy (assumes SSL cert exists)
gcloud compute target-https-proxies create my-cdn-proxy \
    --url-map=my-cdn-map \
    --ssl-certificates=my-cert

# Step 4: Create forwarding rule
gcloud compute forwarding-rules create my-cdn-rule \
    --global \
    --target-https-proxy=my-cdn-proxy \
    --ports=443
</code></pre>
<h3>Part D: Cache Invalidation</h3>
<pre><code class="language-bash"># Invalidate a specific file
gcloud compute url-maps invalidate-cdn-cache my-cdn-map \
    --path=&quot;/images/logo.png&quot;

# Invalidate all content (use sparingly!)
gcloud compute url-maps invalidate-cdn-cache my-cdn-map \
    --path=&quot;/*&quot;
</code></pre>
<hr />
<h2>4ï¸âƒ£ CDN Cache Control Headers</h2>
<table>
<thead>
<tr>
<th>Header</th>
<th>Example</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Cache-Control: max-age=3600</code></td>
<td>Cache for 1 hour</td>
<td>CDN caches for 3600s</td>
</tr>
<tr>
<td><code>Cache-Control: no-cache</code></td>
<td>Always validate</td>
<td>CDN checks origin each time</td>
</tr>
<tr>
<td><code>Cache-Control: no-store</code></td>
<td>Never cache</td>
<td>CDN never caches</td>
</tr>
<tr>
<td><code>Cache-Control: private</code></td>
<td>User-specific</td>
<td>CDN doesn't cache</td>
</tr>
</tbody>
</table>
<hr />
<h2>5ï¸âƒ£ Exam Scenarios &amp; Traps ğŸš¨</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Users complain about stale content"</td>
<td><strong>Invalidate the cache</strong></td>
</tr>
<tr>
<td>"Need internal DNS names for VMs"</td>
<td><strong>Private Managed Zone</strong></td>
</tr>
<tr>
<td>"100% Availability SLA for DNS"</td>
<td><strong>Cloud DNS</strong> (only service with 100%)</td>
</tr>
<tr>
<td>"Speed up global static content delivery"</td>
<td><strong>Cloud CDN</strong></td>
</tr>
<tr>
<td>"CDN with Regional Load Balancer"</td>
<td>âŒ <strong>Not possible</strong> - requires Global HTTP(S) LB</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!WARNING]
<strong>Trap</strong>: Cloud CDN ONLY works with Global HTTP(S) Load Balancer, NOT regional load balancers!</p>
<p>[!TIP]
<strong>Split Horizon DNS</strong>: Same domain returns different IPs based on where the query comes from (internal vs external).</p>
</blockquote>
<hr />
<h2>6ï¸âƒ£ Cheat Sheet</h2>
<pre><code class="language-text">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DNS &amp; CDN CHEAT SHEET                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CLOUD DNS:                                              â”‚
â”‚ gcloud dns managed-zones create ZONE --dns-name=DOMAIN  â”‚
â”‚ gcloud dns record-sets create RECORD --zone=ZONE        â”‚
â”‚ Private Zone: --visibility=private --networks=VPC       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CLOUD CDN:                                              â”‚
â”‚ Requires: Global HTTP(S) Load Balancer                 â”‚
â”‚ Enable: --enable-cdn on backend service/bucket          â”‚
â”‚ Invalidate: gcloud compute url-maps invalidate-cdn-cacheâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cache Hit = Fast (edge) | Cache Miss = Slow (origin)   â”‚
â”‚ Cloud DNS: 100% SLA (only GCP service with this!)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<hr />
<h2>7ï¸âƒ£ Checkpoint Quiz</h2>
<ol>
<li><strong>True or False: Cloud CDN can be used with a Regional Load Balancer.</strong></li>
<li>
<p>Answer: <strong>False</strong> - Requires Global HTTP(S) Load Balancer</p>
</li>
<li>
<p><strong>Which DNS record type points a domain to an IP address?</strong></p>
</li>
<li>
<p>Answer: <strong>A Record</strong> (or AAAA for IPv6)</p>
</li>
<li>
<p><strong>What is the Cloud DNS SLA?</strong></p>
</li>
<li>A) 99.9%</li>
<li>B) 99.95%</li>
<li>C) 99.99%</li>
<li>
<p>D) 100% âœ…</p>
</li>
<li>
<p><strong>How do you force CDN to serve fresh content?</strong></p>
</li>
<li>A) Delete the backend</li>
<li>B) Cache invalidation âœ…</li>
<li>C) Restart the load balancer</li>
<li>
<p>D) Update DNS</p>
</li>
<li>
<p><strong>Your internal VMs need to resolve <code>db.internal.corp</code>. What do you create?</strong></p>
</li>
<li>A) Public managed zone</li>
<li>B) Private managed zone âœ…</li>
<li>C) CNAME record</li>
<li>D) Cloud CDN cache</li>
</ol>
<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud DNS", "def": "Managed DNS service with 100% SLA."},
  {"term": "Private Zone", "def": "DNS zone visible only within specified VPCs."},
  {"term": "Split Horizon", "def": "Same domain returns different IPs for internal vs external queries."},
  {"term": "Cloud CDN", "def": "Content delivery network using Google's 100+ edge locations."},
  {"term": "Cache Invalidation", "def": "Forcing CDN to fetch fresh content from origin."},
  {"term": "TTL", "def": "Time-to-Live - how long DNS/cache records remain valid."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_14_hybrid_connectivity">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 14: Hybrid Connectivity - VPN &amp; Interconnect</h1>
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/network-connectivity/docs/vpn">Cloud VPN</a> | <a href="https://cloud.google.com/network-connectivity/docs/interconnect">Cloud Interconnect</a></p>
</blockquote>
<h2>Learning Objectives</h2>
<p>By the end of this day, you should be able to:
- Compare Cloud VPN vs Cloud Interconnect for on-premises connectivity
- Understand HA VPN architecture and BGP routing
- Choose the right hybrid connectivity option based on requirements
- Configure basic VPN tunnels</p>
<hr />
<h2>ğŸ¢ Industry Context: Hybrid Networking in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Network Engineers and Solutions Architects make these decisions. Know the trade-offs cold.</p>
</blockquote>
<h3>Job Roles &amp; Hybrid Connectivity Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Hybrid</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Network Engineer</strong></td>
<td>Design and maintain connections</td>
<td>VPN tunnels, BGP peering, Interconnect</td>
</tr>
<tr>
<td><strong>Solutions Architect</strong></td>
<td>Choose connectivity strategy</td>
<td>Cost/bandwidth/latency trade-offs</td>
</tr>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Troubleshoot connectivity</td>
<td>Tunnel status, routing issues</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Secure data in transit</td>
<td>IPsec, private connectivity</td>
</tr>
</tbody>
</table>
<h3>Decision Factors</h3>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Best Choice</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>&lt; 3 Gbps, quick setup</td>
<td><strong>Cloud VPN</strong></td>
<td>Hours to set up, encrypted</td>
</tr>
<tr>
<td>&gt; 10 Gbps, dedicated</td>
<td><strong>Dedicated Interconnect</strong></td>
<td>Physical fiber, lowest latency</td>
</tr>
<tr>
<td>No colocation access</td>
<td><strong>Partner Interconnect</strong></td>
<td>Via service provider</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Classic VPN gives 99.99% SLA"</td>
<td>Only HA VPN does</td>
<td>"HA VPN with 4 tunnels + BGP for 99.99%"</td>
</tr>
<tr>
<td>"VPN is always the cheapest"</td>
<td>At scale, Interconnect is cheaper</td>
<td>"VPN for &lt; 3 Gbps; Interconnect for consistent high bandwidth"</td>
</tr>
<tr>
<td>"I don't know what BGP does"</td>
<td>Critical networking knowledge</td>
<td>"BGP dynamically exchanges routes between networks"</td>
</tr>
</tbody>
</table>
<hr />
<h2>1ï¸âƒ£ Why Hybrid Connectivity? ğŸ”—</h2>
<p>Most enterprises don't move 100% to the cloud overnight. <strong>Hybrid connectivity</strong> bridges your on-premises data center with Google Cloud.</p>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;On-Premises Data Center&quot;
        DC[ğŸ¢ Data Center]
        VPN_GW[ğŸ” VPN Gateway]
    end

    subgraph &quot;Connectivity Options&quot;
        Option1[ğŸŒ Cloud VPN]
        Option2[âš¡ Dedicated Interconnect]
        Option3[ğŸ¤ Partner Interconnect]
    end

    subgraph &quot;Google Cloud&quot;
        VPC[â˜ï¸ VPC Network]
        GCE[ğŸ’» Compute Engine]
        GCS[(ğŸ—„ï¸ Cloud Storage)]
    end

    VPN_GW --&gt; Option1 --&gt; VPC
    DC --&gt; Option2 --&gt; VPC
    DC --&gt; Option3 --&gt; VPC
    VPC --&gt; GCE &amp; GCS
</code></pre>
<hr />
<h2>2ï¸âƒ£ Connectivity Options Comparison</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Cloud VPN</th>
<th>Dedicated Interconnect</th>
<th>Partner Interconnect</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Connection</strong></td>
<td>Over public internet</td>
<td>Physical fiber</td>
<td>Via partner network</td>
</tr>
<tr>
<td><strong>Bandwidth</strong></td>
<td>Up to 3 Gbps/tunnel</td>
<td>10-200 Gbps</td>
<td>50 Mbps - 50 Gbps</td>
</tr>
<tr>
<td><strong>Latency</strong></td>
<td>Variable</td>
<td>Low, consistent</td>
<td>Low to moderate</td>
</tr>
<tr>
<td><strong>SLA</strong></td>
<td>99.9% (HA VPN)</td>
<td>99.9% - 99.99%</td>
<td>99.9% - 99.99%</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>Lowest</td>
<td>Highest</td>
<td>Medium</td>
</tr>
<tr>
<td><strong>Setup Time</strong></td>
<td>Hours</td>
<td>Weeks</td>
<td>Days</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Dev/test, small workloads</td>
<td>High-bandwidth production</td>
<td>No colocation access</td>
</tr>
</tbody>
</table>
<hr />
<h2>3ï¸âƒ£ Cloud VPN Deep Dive</h2>
<h3>Classic VPN vs HA VPN</h3>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;Classic VPN (Legacy)&quot;
        CGW1[Single Gateway]
        CT1[1 Tunnel]
        SLA1[99.9% SLA]
    end

    subgraph &quot;HA VPN (Recommended)&quot;
        HGW1[Gateway Interface 0]
        HGW2[Gateway Interface 1]
        HT1[Tunnel 1]
        HT2[Tunnel 2]
        HT3[Tunnel 3]
        HT4[Tunnel 4]
        SLA2[99.99% SLA]
    end

    CGW1 --&gt; CT1
    HGW1 --&gt; HT1 &amp; HT2
    HGW2 --&gt; HT3 &amp; HT4
</code></pre>
<h3>HA VPN Requirements for 99.99% SLA</h3>
<ul>
<li>Two VPN interfaces on GCP side</li>
<li>Two tunnels per interface (4 total)</li>
<li>BGP routing configured</li>
<li>Dual peer gateways on-premises</li>
</ul>
<hr />
<h2>4ï¸âƒ£ Cloud Router &amp; BGP</h2>
<p><strong>Cloud Router</strong> enables dynamic routing using BGP (Border Gateway Protocol).</p>
<table>
<thead>
<tr>
<th>Routing Type</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Static</strong></td>
<td>Manually define routes</td>
<td>Simple, small networks</td>
</tr>
<tr>
<td><strong>Dynamic (BGP)</strong></td>
<td>Routes exchanged automatically</td>
<td>Large, changing networks</td>
</tr>
</tbody>
</table>
<pre><code class="language-mermaid">sequenceDiagram
    participant OnPrem as On-Premises Router
    participant CR as Cloud Router
    participant VPC as VPC Network

    OnPrem-&gt;&gt;CR: BGP: &quot;I have 10.0.0.0/8&quot;
    CR-&gt;&gt;VPC: Add route to 10.0.0.0/8
    CR-&gt;&gt;OnPrem: BGP: &quot;I have 172.16.0.0/16&quot;
    Note over OnPrem,VPC: Routes automatically sync!
</code></pre>
<hr />
<h2>5ï¸âƒ£ Hands-On Lab: Create HA VPN ğŸ› ï¸</h2>
<h3>Step 1: Create HA VPN Gateway</h3>
<pre><code class="language-bash">gcloud compute vpn-gateways create my-ha-vpn \
    --network=my-vpc \
    --region=us-central1
</code></pre>
<h3>Step 2: Create Cloud Router</h3>
<pre><code class="language-bash">gcloud compute routers create my-router \
    --network=my-vpc \
    --region=us-central1 \
    --asn=65001
</code></pre>
<h3>Step 3: Create VPN Tunnels</h3>
<pre><code class="language-bash"># Tunnel 1
gcloud compute vpn-tunnels create tunnel-1 \
    --vpn-gateway=my-ha-vpn \
    --peer-gcp-gateway=peer-vpn-gw \
    --region=us-central1 \
    --ike-version=2 \
    --shared-secret=mysecret123 \
    --router=my-router \
    --vpn-gateway-interface=0

# Tunnel 2 (repeat for interface 1)
gcloud compute vpn-tunnels create tunnel-2 \
    --vpn-gateway=my-ha-vpn \
    --peer-gcp-gateway=peer-vpn-gw \
    --region=us-central1 \
    --ike-version=2 \
    --shared-secret=mysecret456 \
    --router=my-router \
    --vpn-gateway-interface=1
</code></pre>
<h3>Step 4: Configure BGP Sessions</h3>
<pre><code class="language-bash">gcloud compute routers add-bgp-peer my-router \
    --peer-name=bgp-peer-1 \
    --interface=tunnel-1-interface \
    --peer-ip-address=169.254.0.2 \
    --peer-asn=65002 \
    --region=us-central1
</code></pre>
<hr />
<h2>6ï¸âƒ£ Cloud Interconnect</h2>
<h3>Dedicated Interconnect</h3>
<ul>
<li><strong>Direct physical connection</strong> at a colocation facility</li>
<li>10 Gbps or 100 Gbps circuits</li>
<li>You manage the physical connection</li>
</ul>
<h3>Partner Interconnect</h3>
<ul>
<li>Connect via a <strong>service provider</strong> (e.g., AT&amp;T, Equinix)</li>
<li>No physical hardware to manage</li>
<li>Good when you're not near a Google colocation</li>
</ul>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Your Data Center&quot;
        DC[ğŸ¢ Your Equipment]
    end

    subgraph &quot;Colocation Facility&quot;
        COLO[ğŸ—ï¸ Meet-Me Room]
        Google[ğŸ”· Google POP]
    end

    subgraph &quot;Google Cloud&quot;
        VPC[â˜ï¸ VPC]
    end

    DC --&gt;|Your Fiber| COLO
    COLO --&gt; Google
    Google --&gt;|Google Network| VPC
</code></pre>
<hr />
<h2>7ï¸âƒ£ Decision Tree: Which Option?</h2>
<pre><code class="language-mermaid">graph TD
    Start[Need to connect on-prem to GCP?]
    Start --&gt; Q1{Bandwidth needed?}

    Q1 --&gt;|&lt; 3 Gbps| VPN[âœ… Cloud VPN]
    Q1 --&gt;|&gt; 10 Gbps| Q2{Near Google colocation?}

    Q2 --&gt;|Yes| Dedicated[âœ… Dedicated Interconnect]
    Q2 --&gt;|No| Partner[âœ… Partner Interconnect]

    VPN --&gt; Q3{Need 99.99% SLA?}
    Q3 --&gt;|Yes| HAVPN[Use HA VPN with BGP]
    Q3 --&gt;|No| Classic[Classic VPN is fine]
</code></pre>
<hr />
<h2>8ï¸âƒ£ Exam Scenarios &amp; Traps ğŸš¨</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Need encrypted connection over internet"</td>
<td><strong>Cloud VPN</strong></td>
</tr>
<tr>
<td>"Need 50+ Gbps to GCP"</td>
<td><strong>Dedicated Interconnect</strong></td>
</tr>
<tr>
<td>"No colocation access, need private connection"</td>
<td><strong>Partner Interconnect</strong></td>
</tr>
<tr>
<td>"99.99% SLA for VPN"</td>
<td><strong>HA VPN with 4 tunnels + BGP</strong></td>
</tr>
<tr>
<td>"Routes should update automatically"</td>
<td><strong>Cloud Router with BGP</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!WARNING]
<strong>Trap</strong>: Classic VPN only supports 99.9% SLA. For 99.99%, you MUST use HA VPN with proper configuration.</p>
<p>[!TIP]
<strong>Exam Watch</strong>: "Private, dedicated, low-latency" = Interconnect. "Encrypted, over internet" = VPN.</p>
</blockquote>
<hr />
<h2>9ï¸âƒ£ Cheat Sheet</h2>
<pre><code class="language-text">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HYBRID CONNECTIVITY CHEAT SHEET            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CLOUD VPN:                                              â”‚
â”‚ - Uses IPsec over public internet                       â”‚
â”‚ - HA VPN: 99.99% SLA (4 tunnels + BGP)                 â”‚
â”‚ - Classic VPN: 99.9% SLA                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DEDICATED INTERCONNECT:                                 â”‚
â”‚ - Physical fiber at colocation                          â”‚
â”‚ - 10 Gbps or 100 Gbps circuits                         â”‚
â”‚ - Lowest latency, highest bandwidth                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PARTNER INTERCONNECT:                                   â”‚
â”‚ - Via service provider                                  â”‚
â”‚ - 50 Mbps to 50 Gbps                                   â”‚
â”‚ - Good when not near Google POP                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CLOUD ROUTER: Dynamic routing with BGP                 â”‚
â”‚ BGP ASN: 16-bit (1-65534) or 32-bit                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<hr />
<h2>ğŸ”Ÿ Checkpoint Quiz</h2>
<ol>
<li><strong>Which connectivity option uses the public internet?</strong></li>
<li>A) Dedicated Interconnect</li>
<li>B) Partner Interconnect</li>
<li>C) Cloud VPN âœ…</li>
<li>
<p>D) Cloud Router</p>
</li>
<li>
<p><strong>What's required for 99.99% SLA with VPN?</strong></p>
</li>
<li>A) Classic VPN with 2 tunnels</li>
<li>B) HA VPN with 4 tunnels and BGP âœ…</li>
<li>C) Any VPN configuration</li>
<li>
<p>D) Dedicated Interconnect</p>
</li>
<li>
<p><strong>Your company has no presence near Google colocations. Which option?</strong></p>
</li>
<li>A) Dedicated Interconnect</li>
<li>B) Partner Interconnect âœ…</li>
<li>C) Classic VPN only</li>
<li>
<p>D) Cloud Router</p>
</li>
<li>
<p><strong>What protocol does Cloud Router use for dynamic routing?</strong></p>
</li>
<li>
<p>Answer: <strong>BGP (Border Gateway Protocol)</strong></p>
</li>
<li>
<p><strong>A startup needs occasional 1 Gbps connection to GCP. Best option?</strong></p>
</li>
<li>A) Dedicated Interconnect</li>
<li>B) Cloud VPN âœ…</li>
<li>C) Partner Interconnect</li>
<li>D) Direct Peering</li>
</ol>
<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud VPN", "def": "IPsec VPN connecting on-prem to GCP over public internet."},
  {"term": "HA VPN", "def": "High-availability VPN with 99.99% SLA using 4 tunnels."},
  {"term": "Dedicated Interconnect", "def": "Physical fiber connection at Google colocation (10-200 Gbps)."},
  {"term": "Partner Interconnect", "def": "Private connection via service provider (50 Mbps - 50 Gbps)."},
  {"term": "Cloud Router", "def": "Managed router that enables dynamic BGP routing."},
  {"term": "BGP", "def": "Border Gateway Protocol - exchanges routes between networks automatically."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_14_week_2_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 14: Week 2 Review &amp; Exam Strategy</h1>
<p><strong>Level:</strong> Review<br />
<strong>Milestone:</strong> ğŸ Week 2 Complete!</p>
<hr />
<h2>ğŸ¯ 1. Week 2 Recap: Management &amp; Scale</h2>
<p>You've moved from managing single servers to architecting global systems that heal and scale themselves.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Day</th>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Key Takeaway</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>8</strong></td>
<td style="text-align: left;"><strong>MIGs</strong></td>
<td style="text-align: left;">Cattle philosophy. Templates + Auto-healing = Resilience.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>9</strong></td>
<td style="text-align: left;"><strong>LB &amp; CDN</strong></td>
<td style="text-align: left;">Layer 7 vs Layer 4. One Anycast IP for the whole world.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>10</strong></td>
<td style="text-align: left;"><strong>Cloud SQL</strong></td>
<td style="text-align: left;">Managed DBs. HA for failover, Read Replicas for scale.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>11</strong></td>
<td style="text-align: left;"><strong>Storage Adv.</strong></td>
<td style="text-align: left;">Lifecycle policies for cost. Signed URLs for security.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>12</strong></td>
<td style="text-align: left;"><strong>App Engine</strong></td>
<td style="text-align: left;">PaaS. Standard (Scale to 0) vs Flexible (Docker).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>13</strong></td>
<td style="text-align: left;"><strong>Cloud Run</strong></td>
<td style="text-align: left;">Serverless Containers. Portability + Lightning speed.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Visual Decision Matrices (Exam Power-Ups)</h2>
<h3>The Serverless Showdown</h3>
<p>Which serverless product should you use?</p>
<pre><code class="language-mermaid">graph TD
    Start{What are you deploying?} --&gt; Source[Source Code]
    Start --&gt; Container[Container Image]
    Source -- &quot;Simple Function&quot; --&gt; Functions[âš¡ Cloud Functions]
    Source -- &quot;Full Web App&quot; --&gt; GAE[ğŸ—ï¸ App Engine Standard]
    Container -- &quot;Portability Needed&quot; --&gt; Run[ğŸš€ Cloud Run]
    Container -- &quot;Custom OS/Kernel&quot; --&gt; GAEFlex[ğŸ³ App Engine Flex]

    style Run fill:#dcfce7,stroke:#16a34a,stroke-width:2px
    style GAE fill:#f0f9ff,stroke:#0369a1
</code></pre>
<h3>The Load Balancing Tree</h3>
<pre><code class="language-mermaid">graph TD
    Traffic{Traffic Type?} --&gt; HTTP[HTTP/S]
    Traffic --&gt; TCP[TCP/UDP]
    HTTP -- &quot;Global&quot; --&gt; GHTTP[ğŸŒ Global HTTP/S LB]
    HTTP -- &quot;Internal&quot; --&gt; IHTTP[ğŸ”’ Internal HTTP/S LB]
    TCP -- &quot;External&quot; --&gt; NetLB[ğŸŒ Network LB]
    TCP -- &quot;Internal&quot; --&gt; IntLB[ğŸ” Internal TCP LB]

    style GHTTP fill:#fee2e2,stroke:#ef4444,stroke-width:2px
</code></pre>
<hr />
<h2>âš ï¸ 3. Critical Exam "Gotchas"</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Trap #1: The Health Check Firewall</strong>
If you create a Load Balancer and it returns <code>502 Bad Gateway</code>, check your firewall! You MUST allow traffic from Google's probe ranges: <code>130.211.0.0/22</code> and <code>35.191.0.0/16</code>.</p>
<p>[!TIP]
<strong>Trap #2: Scaling to Zero</strong>
Only <strong>App Engine Standard</strong> and <strong>Cloud Run</strong> can scale down to zero instances. <strong>App Engine Flexible</strong> and <strong>GKE</strong> always have a minimum of 1 instance running (and costing money).</p>
<p>[!CAUTION]
<strong>Trap #3: Cloud SQL HA</strong>
High Availability (HA) handles <strong>zonal failure</strong>, but it does not protect against someone accidentally running <code>DROP DATABASE</code>. For that, you need <strong>Backups</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ§ª 4. Weekend Capstone Lab: The Unbreakable App</h2>
<p><strong>Scenario:</strong> Build a Load Balanced, Auto-healing cluster using the CLI.</p>
<h3>âœ… Step 1: Prep the Template</h3>
<pre><code class="language-bash">gcloud compute instance-templates create web-template-v2 \
  --tags=http-server,hc-allow \
  --metadata=startup-script='#!/bin/bash
  apt update &amp;&amp; apt install -y apache2
  echo &quot;Week 2 Champion&quot; &gt; /var/www/html/index.html'
</code></pre>
<h3>âœ… Step 2: Build the Auto-Healing Loop</h3>
<pre><code class="language-bash"># Create Health Check
gcloud compute health-checks create-http champion-hc --port=80

# Create Managed Instance Group
gcloud compute instance-groups managed create global-cluster \
  --template=web-template-v2 \
  --size=2 \
  --region=us-central1 \
  --health-check=champion-hc \
  --initial-delay=300
</code></pre>
<h3>âœ… Step 3: Secure the Perimeter</h3>
<pre><code class="language-bash">gcloud compute firewall-rules create allow-gcp-health-checks \
  --allow=tcp:80 \
  --source-ranges=130.211.0.0/22,35.191.0.0/16 \
  --target-tags=hc-allow
</code></pre>
<hr />
<h2>ğŸ† 5. What's Next? (Week 3! Kubernetes)</h2>
<p>Week 2 was about <strong>Scale</strong>. Week 3 is about <strong>Orchestration</strong>.</p>
<ul>
<li><strong>Docker Mastery:</strong> Packaging any app into a box.</li>
<li><strong>GKE Concepts:</strong> Pods, Nodes, and Clusters.</li>
<li><strong>GKE Autopilot:</strong> The "hands-free" way to run Kubernetes.</li>
<li><strong>Hybrid Networking:</strong> Connecting GCP to your corporate data center.</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Week 2 Knowledge Check</h2>
<ol>
<li>
<p><strong>Your Load Balancer returns a 502 Bad Gateway error. What is the MOST likely cause?</strong></p>
<ul>
<li>A. The backend VMs are too small</li>
<li>B. <strong>Firewall rules are blocking health check probes</strong> âœ…</li>
<li>C. The SSL certificate is expired</li>
<li>D. Cloud CDN is misconfigured</li>
</ul>
</li>
<li>
<p><strong>Which serverless compute option can scale to ZERO instances when not in use?</strong></p>
<ul>
<li>A. GKE Autopilot</li>
<li>B. App Engine Flexible</li>
<li>C. <strong>Cloud Run</strong> âœ…</li>
<li>D. Compute Engine with Autoscaler</li>
</ul>
</li>
<li>
<p><strong>You need to handle read-heavy traffic on Cloud SQL. What should you configure?</strong></p>
<ul>
<li>A. Increase the machine type</li>
<li>B. Enable High Availability</li>
<li>C. <strong>Create Read Replicas</strong> âœ…</li>
<li>D. Switch to Firestore</li>
</ul>
</li>
<li>
<p><strong>A Managed Instance Group (MIG) automatically replaces a crashed VM. What feature enables this?</strong></p>
<ul>
<li>A. Autoscaling</li>
<li>B. <strong>Auto-healing with Health Checks</strong> âœ…</li>
<li>C. Load Balancing</li>
<li>D. Instance Templates</li>
</ul>
</li>
<li>
<p><strong>You need to deploy a containerized application with maximum portability and no vendor lock-in. Which service is best?</strong></p>
<ul>
<li>A. App Engine Standard</li>
<li>B. <strong>Cloud Run</strong> âœ…</li>
<li>C. Cloud Functions</li>
<li>D. App Engine Flexible</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I know when to use Cloud Run vs App Engine.', checked: false },
        { text: 'I understand why Health Checks need specific firewall rules.', checked: false },
        { text: 'I can explain the difference between HA and Read Replicas.', checked: false },
        { text: 'I successfully built a self-healing cluster using gcloud.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Week 2 Milestone Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_15_containers">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Module 12: Containers &amp; GKE</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner/Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­ Foundation for GKE</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 15, you will be able to:
*   <strong>Deconstruct</strong> the architecture of a container vs. a virtual machine.
*   <strong>Visualize</strong> the Docker layer system and image caching.
*   <strong>Architect</strong> a multi-step Docker workflow from local build to Cloud Registry.
*   <strong>Deploy</strong> a functional container using Cloud Shell and Artifact Registry.</p>
<hr />
<h2>ğŸ¢ Industry Context: Containers in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Container skills are mandatory for DevOps and Platform Engineering roles. This is your gateway to Kubernetes.</p>
</blockquote>
<h3>Job Roles &amp; Container Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Containers</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Build CI/CD pipelines with containers</td>
<td>Writing Dockerfiles, optimizing images</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Standardize base images across org</td>
<td>Golden image management, security scanning</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Debug container issues in production</td>
<td>Container logs, resource limits</td>
</tr>
<tr>
<td><strong>Backend Developer</strong></td>
<td>Containerize applications</td>
<td>Local dev with Docker, multi-stage builds</td>
</tr>
</tbody>
</table>
<h3>Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Multi-Stage Builds</strong></td>
<td>Build in one image, run in slim image</td>
<td>Reduce image size, security</td>
</tr>
<tr>
<td><strong>Distroless Images</strong></td>
<td>Google's minimal runtime images</td>
<td>Production, minimal attack surface</td>
</tr>
<tr>
<td><strong>Golden Image Pipeline</strong></td>
<td>Base image â†’ Team images â†’ App images</td>
<td>Large organizations</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use Ubuntu as base image"</td>
<td>Too large, slow pulls</td>
<td>"I use slim or alpine for production"</td>
</tr>
<tr>
<td>"COPY . . at the top of Dockerfile"</td>
<td>Breaks layer caching</td>
<td>"I put frequently changed steps at the bottom"</td>
</tr>
<tr>
<td>"I run containers as root"</td>
<td>Security vulnerability</td>
<td>"I use non-root USER directive"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Containers vs. Virtual Machines</h2>
<p>Understanding the difference is critical for the ACE exam. While VMs virtualize <strong>Hardware</strong>, Containers virtualize the <strong>Operating System</strong>.</p>
<h3>The Architectural Difference</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Virtual Machine (Heavy)&quot;
        App1[App A] --&gt; Lib1[Bins/Libs]
        Lib1 --&gt; OS1[Guest OS]
        OS1 --&gt; Hypervisor[Hypervisor]
    end

    subgraph &quot;Container (Lightweight)&quot;
        App2[App B] --&gt; Lib2[Bins/Libs]
        Lib2 --&gt; Engine[Docker/Container Engine]
        Engine --&gt; HostOS[Host OS Kernel]
    end

    Hypervisor --&gt; Hardware[Physical Server]
    HostOS --&gt; Hardware
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Virtual Machines (VMs)</th>
<th style="text-align: left;">Containers</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Isolation</strong></td>
<td style="text-align: left;">Hardware-level (Hypervisor)</td>
<td style="text-align: left;">OS-level (Kernel namespaces)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Startup</strong></td>
<td style="text-align: left;">Minutes (Full OS boot)</td>
<td style="text-align: left;">Seconds (Process start)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Size</strong></td>
<td style="text-align: left;">GBs (includes kernel)</td>
<td style="text-align: left;">MBs (shared kernel)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Portability</strong></td>
<td style="text-align: left;">Hard (specific hypervisor)</td>
<td style="text-align: left;">High (Run anywhere with Docker)</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ³ 2. The Docker Lifecycle: Recipe to Reality</h2>
<p>On GCP, you rarely just run Docker; you manage the lifecycle of images.</p>
<h3>The Standard Workflow</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant D as Dockerfile
    participant I as Image
    participant R as Registry (Artifact Registry)
    participant C as Container (GKE/Cloud Run)

    D-&gt;&gt;I: docker build (The Recipe becomes the Meal)
    I-&gt;&gt;R: docker push (Store the meal in the cloud)
    R-&gt;&gt;C: Pull &amp; Run (Serve the meal to users)
</code></pre>
<blockquote>
<p>[!TIP]
<strong>ACE Pro Tip: Caching Matters</strong>
Each line in a <code>Dockerfile</code> creates a <strong>layer</strong>. Docker caches these layers. If you change a line at the bottom, Docker reuses all cached layers above it. Always put the most frequently changed lines (like <code>COPY . .</code>) at the bottom to speed up builds!</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Build. Push. Run.</h2>
<p>In this lab, we'll go beyond local Docker and prepare for GCP by using <strong>Artifact Registry</strong>.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Build a Python container and push it to Google Cloud's official storage for images.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Initialize Environment</strong>:
    <code>bash
    gcloud services enable artifactregistry.googleapis.com
    mkdir gcp-docker-lab &amp;&amp; cd gcp-docker-lab</code></p>
</li>
<li>
<p><strong>Create the Application</strong> (<code>app.py</code>):
    <code>python
    print("GCP Container is alive!")</code></p>
</li>
<li>
<p><strong>Draft the Dockerfile</strong>:
    <code>dockerfile
    # 1. Use a tiny base image
    FROM python:3.9-slim
    # 2. Set directory
    WORKDIR /app
    # 3. Copy app
    COPY app.py .
    # 4. Execute
    CMD ["python", "app.py"]</code></p>
</li>
<li>
<p><strong>Build &amp; Tag</strong>:
    <code>bash
    # Replace [PROJECT_ID] with your actual ID
    docker build -t gcr.io/[PROJECT_ID]/quickstart-image:v1 .</code></p>
</li>
<li>
<p><strong>Authenticate &amp; Push</strong>:
    <code>bash
    gcloud auth configure-docker
    docker push gcr.io/[PROJECT_ID]/quickstart-image:v1</code></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Security Trap</strong>: By default, containers share the host kernel. If a container is compromised, the host is at risk. GKE uses <strong>GKE Sandbox</strong> (based on gVisor) for extra isolation if needed.</p>
<p>[!WARNING]
<strong>Image Size</strong>: For the exam, always prefer "slim" or "alpine" base images. Smaller images pull faster (better for auto-scaling) and have a smaller attack surface.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Why are containers more efficient than VMs?</strong></p>
<ul>
<li>A. They include a dedicated OS kernel for every app.</li>
<li>B. <strong>They share the host OS kernel and virtualize at the OS level.</strong> âœ…</li>
<li>C. They run directly on hardware without any OS.</li>
<li>D. They utilize hardware-level virtualization only.</li>
</ul>
</li>
<li>
<p><strong>What GCP service is the primary successor to Container Registry (GCR)?</strong></p>
<ul>
<li>A. Cloud Storage Buckets</li>
<li>B. <strong>Artifact Registry</strong> âœ…</li>
<li>C. Cloud Build</li>
<li>D. Compute Engine Images</li>
</ul>
</li>
<li>
<p><strong>You want to speed up your Docker builds. Where should you place the command <code>COPY . .</code>?</strong></p>
<ul>
<li>A. At the very top (first line).</li>
<li>B. <strong>Near the bottom, after installing OS dependencies.</strong> âœ…</li>
<li>C. In a separate script outside the Dockerfile.</li>
<li>D. It doesn't matter; Docker builds all lines at once.</li>
</ul>
</li>
<li>
<p><strong>A command like <code>docker run -it ubuntu /bin/bash</code> does what?</strong></p>
<ul>
<li>A. Builds a new image from the Ubuntu directory.</li>
<li>B. Pushes an image to the cloud.</li>
<li>C. <strong>Starts an interactive container session from the Ubuntu image.</strong> âœ…</li>
<li>D. Deletes all running Ubuntu containers.</li>
</ul>
</li>
<li>
<p><strong>Which feature provides extra kernel isolation for containers in GKE?</strong></p>
<ul>
<li>A. Cloud Armor</li>
<li>B. VPC Service Controls</li>
<li>C. <strong>GKE Sandbox (gVisor)</strong> âœ…</li>
<li>D. Binary Authorization</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain why containers start in seconds vs minutes for VMs.', checked: false },
        { text: 'I understand that Dockerfiles build read-only images.', checked: false },
        { text: 'I know that Artifact Registry is the storage for GCP containers.', checked: false },
        { text: 'I can identify the impact of layer caching on build speed.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 15 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_16_kubernetes_arch">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 16: GKE Architecture (Control Plane &amp; Nodes)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 16, you will be able to:
*   <strong>Visualize</strong> the Kubernetes Control Plane and Worker Node interaction.
*   <strong>Explain</strong> the "Shared Responsibility" model in Google Kubernetes Engine.
*   <strong>Identify</strong> key components like the API Server, Scheduler, and Kubelet.
*   <strong>Navigate</strong> the logical boundary between Google-managed and customer-managed resources.</p>
<hr />
<h2>ğŸ¢ Industry Context: GKE in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> GKE knowledge is essential for DevOps, Platform Engineering, and SRE roles. This is where companies run production workloads.</p>
</blockquote>
<h3>Job Roles &amp; GKE Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use GKE</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Design cluster architecture</td>
<td>Node pools, Workload Identity, policies</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Deploy and scale applications</td>
<td>Deployments, Services, CI/CD integration</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Maintain cluster reliability</td>
<td>Monitoring, autoscaling, troubleshooting</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Harden cluster security</td>
<td>RBAC, network policies, Pod Security</td>
</tr>
</tbody>
</table>
<h3>Autopilot vs Standard Decision</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Autopilot</th>
<th>Standard</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Node Management</strong></td>
<td>Google</td>
<td>You</td>
</tr>
<tr>
<td><strong>Per-Pod Billing</strong></td>
<td>Yes</td>
<td>No (per-node)</td>
</tr>
<tr>
<td><strong>Customization</strong></td>
<td>Limited</td>
<td>Full control</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Teams without K8s expertise</td>
<td>Advanced teams needing control</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
<strong>Interview Tip:</strong> "When asked GKE mode, I say: Autopilot for teams that want to focus on apps, Standard for teams needing custom node configs or special hardware like GPUs."</p>
</blockquote>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I always use Standard mode"</td>
<td>Shows no cost awareness</td>
<td>"I evaluate Autopilot vs Standard based on team needs"</td>
</tr>
<tr>
<td>"I manually scale node pools"</td>
<td>Doesn't leverage auto-scaling</td>
<td>"I configure cluster autoscaler with min/max nodes"</td>
</tr>
<tr>
<td>"I don't know what Kubelet does"</td>
<td>Basic K8s knowledge gap</td>
<td>"Kubelet is the node agent that ensures containers run in pods"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. The Kubernetes "Command &amp; Control" Center</h2>
<p>A GKE cluster consists of two distinct pools of responsibility: the <strong>Control Plane</strong> (The Brain) and the <strong>Nodes</strong> (The Muscle).</p>
<h3>Architectural Blueprint</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Google-Managed Project&quot;
        CP[Control Plane]
        API[API Server] --&gt; ETCD[(etcd)]
        API --&gt; SCH[Scheduler]
        API --&gt; CM[Controller Manager]
    end

    subgraph &quot;Your Project (VPC)&quot;
        NP_STD[Node Pool: Standard]
        NP_SPOT[Node Pool: Spot/Preemptible]

        Node1[Worker Node 1]
        Node2[Worker Node 2]

        subgraph &quot;Node Detail&quot;
            KLT[Kubelet]
            KPRX[Kube-Proxy]
            CRI[Container Runtime]
            POD1[Pod A]
            POD2[Pod B]
        end
    end

    API &lt;-.-&gt; KLT
    API &lt;-.-&gt; KPRX
    NP_STD --&gt; Node1
    NP_SPOT --&gt; Node2
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Component</th>
<th style="text-align: left;">Responsibility</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>API Server</strong></td>
<td style="text-align: left;">Cluster "Front Door"</td>
<td style="text-align: left;">All <code>kubectl</code> commands talk to this.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>etcd</strong></td>
<td style="text-align: left;">Cluster State DB</td>
<td style="text-align: left;">Stores configuration. <strong>Never</strong> accessible to you in GKE.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Scheduler</strong></td>
<td style="text-align: left;">Workload Placement</td>
<td style="text-align: left;">Decides which Node has enough RAM/CPU for a Pod.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Kubelet</strong></td>
<td style="text-align: left;">Node Resident Agent</td>
<td style="text-align: left;">Reports Node health back to the API Server.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Kube-Proxy</strong></td>
<td style="text-align: left;">Networking</td>
<td style="text-align: left;">Manages IP tables/rules for Service connectivity.</td>
</tr>
</tbody>
</table>
<hr />
<hr />
<h2>ğŸŒŠ 3. Node Pools: Organizing the Muscle</h2>
<p>In GKE, you don't just add single nodes; you manage <strong>Node Pools</strong>. A pool is a group of nodes with identical configuration.</p>
<table>
<thead>
<tr>
<th>Pool Type</th>
<th>Ideal For</th>
<th>ACE Exam Key</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Standard</strong></td>
<td>Regular workloads</td>
<td>"High availability", "Reliable"</td>
</tr>
<tr>
<td><strong>Spot / Preemptible</strong></td>
<td>Batch processing, Testing</td>
<td>"Extreme cost savings (up to 80%)", "Fault tolerant workloads"</td>
</tr>
<tr>
<td><strong>Custom / GPU</strong></td>
<td>ML / Video Rendering</td>
<td>"Compute Intensive"</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!CAUTION]
<strong>Spot Nodes</strong> can be reclaimed by Google at any time with 30 seconds' notice. Never use them for non-distributed databases or stateful apps without a clear strategy.</p>
</blockquote>
<hr />
<h2>âŒ¨ï¸ 4. Kubectl Mastery: The CLI Cheatsheet</h2>
<p>The ACE exam expects you to know basic troubleshooting commands.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>When to use?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>kubectl get pods</code></td>
<td>List all pods</td>
<td>Checking status (Running, Pending, Error).</td>
</tr>
<tr>
<td><code>kubectl describe pod [NAME]</code></td>
<td>Detailed view of a pod</td>
<td>Finding WHY a pod failed (Logs/Events).</td>
</tr>
<tr>
<td><code>kubectl logs [NAME]</code></td>
<td>View app stdout</td>
<td>Debugging code errors inside the container.</td>
</tr>
<tr>
<td><code>kubectl exec -it [NAME] -- bash</code></td>
<td>Open shell inside pod</td>
<td>Manual debugging or DB connectivity tests.</td>
</tr>
<tr>
<td><code>kubectl get nodes</code></td>
<td>List worker nodes</td>
<td>Checking for "Ready" status.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Peeking Under the Hood</h2>
<p>Even though the Control Plane is managed, we can see its effects through <code>kubectl</code>.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Inspect the default system components and understand where they live.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Get Credentials</strong>:
    <code>bash
    gcloud container clusters get-credentials [CLUSTER_NAME] --zone [ZONE]</code></p>
</li>
<li>
<p><strong>List System Workloads</strong>:
    <code>bash
    # We use -n kube-system to see the internal components
    kubectl get pods -n kube-system</code>
    &gt; [!NOTE]
    &gt; Notice you see <code>kube-proxy</code> and <code>fluentbit</code> (logging), but you <strong>cannot</strong> see the API Server or etcd. That's because they run in a hidden Google-managed project!</p>
</li>
<li>
<p><strong>Inspect a Node</strong>:
    <code>bash
    kubectl describe node [NODE_NAME]</code>
    <em>Look for the "Conditions" section. This is what the </em><em>Kubelet</em><em> reports back to the brain.</em></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!WARNING]
<strong>etcd Access</strong>: A common exam trap asks how to backup the etcd database in GKE. <strong>The answer is: You don't.</strong> Google manages all etcd backups and high availability automatically.</p>
<p>[!TIP]
<strong>Version Management</strong>: GKE allows you to choose "Release Channels" (Rapid, Regular, Stable). For production, <strong>Stable</strong> is the recommended choice for maximum reliability.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which component is responsible for deciding which node a new Pod should run on?</strong></p>
<ul>
<li>A. Kubelet</li>
<li>B. API Server</li>
<li>C. <strong>Scheduler</strong> âœ…</li>
<li>D. etcd</li>
</ul>
</li>
<li>
<p><strong>In GKE, where is the Control Plane located?</strong></p>
<ul>
<li>A. On the first worker node in your VPC.</li>
<li>B. <strong>In a separate Google-managed project.</strong> âœ…</li>
<li>C. In a Cloud Storage bucket.</li>
<li>D. It runs as a container on every node.</li>
</ul>
</li>
<li>
<p><strong>What is the role of the Kubelet?</strong></p>
<ul>
<li>A. It acts as the load balancer for incoming traffic.</li>
<li>B. It stores the state of the cluster.</li>
<li>C. <strong>It is the agent that runs on each node and ensures containers are running in a Pod.</strong> âœ…</li>
<li>D. It schedules new workloads based on resource availability.</li>
</ul>
</li>
<li>
<p><strong>Why can't you see the etcd pods when running <code>kubectl get pods -n kube-system</code>?</strong></p>
<ul>
<li>A. They are hidden for security reasons.</li>
<li>B. You don't have the "Owner" role.</li>
<li>C. <strong>They run on the master nodes, which are managed by Google and not visible in your node list.</strong> âœ…</li>
<li>D. etcd is not used in GKE.</li>
</ul>
</li>
<li>
<p><strong>Which GKE release channel is recommended for production workloads?</strong></p>
<ul>
<li>A. Rapid</li>
<li>B. Regular</li>
<li>C. <strong>Stable</strong> âœ…</li>
<li>D. Extended</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between Control Plane and Worker Nodes.', checked: false },
        { text: 'I know that I do not manage etcd in GKE.', checked: false },
        { text: 'I can identify the API Server as the entry point for kubectl.', checked: false },
        { text: 'I understand the shared responsibility model.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 16 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_17_advanced_iam">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>BONUS: Advanced IAM - Workload Identity &amp; Conditions</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (Security domain is 19% of exam)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Advanced IAM Essentials)</strong><br />
<strong>Workload Identity Federation</strong> = Exchange external tokens (GitHub, AWS, Azure) for GCP access. <strong>NO JSON KEYS NEEDED!</strong> <strong>IAM Conditions</strong> = Add WHEN (time) and WHERE (IP/resource) to access control using CEL expressions. <strong>Deny Policies</strong> = Override all allow policies for hard guardrails (e.g., prevent audit log deletion). This is the gold standard for CI/CD security.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Implement</strong> Workload Identity Federation</td>
<td>Eliminate long-lived JSON keys</td>
</tr>
<tr>
<td><strong>Configure</strong> IAM Conditions</td>
<td>Context-aware access (time, IP, resource)</td>
</tr>
<tr>
<td><strong>Apply</strong> IAM Deny Policies</td>
<td>Create unbreakable guardrails</td>
</tr>
<tr>
<td><strong>Design</strong> Zero Trust patterns</td>
<td>Modern security architecture</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. The JSON Key Problem (Plain-English)</h2>
<p><strong>The Old Way:</strong> Download a JSON Service Account key, store it in your CI/CD pipeline, and hope no one leaks it.</p>
<p><strong>The Reality:</strong> 
- Developers commit keys to GitHub accidentally
- Keys get stored in plaintext in build systems
- Hackers scan GitHub for exposed keys 24/7</p>
<h3>ğŸ’¡ Real-World Analogy: House Keys</h3>
<table>
<thead>
<tr>
<th>Old Approach (JSON Keys)</th>
<th>New Approach (Workload Identity)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Giving a permanent house key to every contractor</td>
<td>Using a smart lock with temporary codes</td>
</tr>
<tr>
<td>Key can be copied infinitely</td>
<td>Code expires in hours</td>
</tr>
<tr>
<td>No audit trail</td>
<td>Every entry is logged</td>
</tr>
<tr>
<td>Lost key = change all locks</td>
<td>Revoke code instantly</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Workload Identity Federation</h2>
<h3>How It Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant GH as GitHub Actions
    participant WIF as Workload Identity Pool
    participant STS as Security Token Service
    participant SA as Service Account
    participant GCP as GCP Resources

    GH-&gt;&gt;WIF: 1. Present OIDC Token
    WIF-&gt;&gt;STS: 2. Verify token signature
    STS-&gt;&gt;SA: 3. Request impersonation
    SA-&gt;&gt;GH: 4. Return short-lived token
    GH-&gt;&gt;GCP: 5. Access resources
</code></pre>
<h3>Supported Identity Providers</h3>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AWS</strong></td>
<td>AWS workloads accessing GCP</td>
</tr>
<tr>
<td><strong>Azure AD</strong></td>
<td>Azure/Microsoft workloads</td>
</tr>
<tr>
<td><strong>GitHub Actions</strong></td>
<td>CI/CD pipelines</td>
</tr>
<tr>
<td><strong>GitLab</strong></td>
<td>CI/CD pipelines</td>
</tr>
<tr>
<td><strong>Kubernetes</strong></td>
<td>Any K8s cluster</td>
</tr>
<tr>
<td><strong>OIDC Providers</strong></td>
<td>Custom identity providers</td>
</tr>
</tbody>
</table>
<h3>Setup: GitHub Actions â†’ GCP</h3>
<pre><code class="language-bash"># 1. Create Workload Identity Pool
gcloud iam workload-identity-pools create &quot;github-pool&quot; \
    --location=&quot;global&quot; \
    --display-name=&quot;GitHub Actions Pool&quot;

# 2. Create Provider for GitHub
gcloud iam workload-identity-pools providers create-oidc &quot;github-provider&quot; \
    --location=&quot;global&quot; \
    --workload-identity-pool=&quot;github-pool&quot; \
    --issuer-uri=&quot;https://token.actions.githubusercontent.com&quot; \
    --attribute-mapping=&quot;google.subject=assertion.sub,attribute.repository=assertion.repository&quot;

# 3. Allow GitHub to impersonate Service Account
gcloud iam service-accounts add-iam-policy-binding &quot;my-sa@PROJECT.iam.gserviceaccount.com&quot; \
    --role=&quot;roles/iam.workloadIdentityUser&quot; \
    --member=&quot;principalSet://iam.googleapis.com/projects/PROJECT_NUMBER/locations/global/workloadIdentityPools/github-pool/attribute.repository/my-org/my-repo&quot;
</code></pre>
<hr />
<h2>ğŸ¯ 3. IAM Conditions (Context-Aware Access)</h2>
<p>Standard IAM: <strong>WHO</strong> can do <strong>WHAT</strong> on <strong>WHICH RESOURCE</strong>
Conditional IAM: + <strong>WHEN</strong> and <strong>WHERE</strong></p>
<h3>Condition Types</h3>
<pre><code class="language-mermaid">graph TD
    C[IAM Conditions] --&gt; T[Time-Based]
    C --&gt; R[Resource-Based]
    C --&gt; N[Network-Based]
    C --&gt; A[Attribute-Based]

    T --&gt; T1[Working hours only]
    T --&gt; T2[Expires after date]

    R --&gt; R1[Specific resource names]
    R --&gt; R2[Resource labels/tags]

    N --&gt; N1[IP address range]
    N --&gt; N2[VPC access levels]

    A --&gt; A1[Resource types]
    A --&gt; A2[Service names]

    style C fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Condition Expression Language (CEL)</h3>
<table>
<thead>
<tr>
<th>Condition</th>
<th>CEL Expression</th>
</tr>
</thead>
<tbody>
<tr>
<td>Weekdays only</td>
<td><code>request.time.getDayOfWeek() != 0 &amp;&amp; request.time.getDayOfWeek() != 6</code></td>
</tr>
<tr>
<td>Dev resources only</td>
<td><code>resource.name.startsWith("projects/my-project/zones/us-central1-a/instances/dev-")</code></td>
</tr>
<tr>
<td>From corporate IP</td>
<td><code>request.auth.accessLevels.contains("accessPolicies/123/accessLevels/corpnet")</code></td>
</tr>
<tr>
<td>Before expiry date</td>
<td><code>request.time &lt; timestamp("2024-12-31T23:59:59Z")</code></td>
</tr>
</tbody>
</table>
<h3>Apply Condition via gcloud</h3>
<pre><code class="language-bash">gcloud projects add-iam-policy-binding my-project \
    --member=&quot;user:developer@example.com&quot; \
    --role=&quot;roles/compute.instanceAdmin.v1&quot; \
    --condition=&quot;expression=resource.name.startsWith('projects/my-project/zones/us-central1-a/instances/dev-'),title=DevVMsOnly&quot;
</code></pre>
<hr />
<h2>ğŸš« 4. IAM Deny Policies (The Guardrails)</h2>
<p><strong>Standard IAM:</strong> "Allow-only" - if not granted, it's denied
<strong>Deny Policies:</strong> Override allows - "Even if you're Owner, you CANNOT do this"</p>
<h3>Use Cases for Deny Policies</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Deny Rule</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prevent anyone from disabling audit logs</td>
<td>Deny <code>logging.sinks.delete</code></td>
</tr>
<tr>
<td>Block public bucket creation</td>
<td>Deny <code>storage.buckets.setIamPolicy</code> with allUsers</td>
</tr>
<tr>
<td>Prevent project deletion</td>
<td>Deny <code>resourcemanager.projects.delete</code></td>
</tr>
<tr>
<td>Block external IP assignment</td>
<td>Deny <code>compute.instances.setMetadata</code> for external IPs</td>
</tr>
</tbody>
</table>
<h3>Create Deny Policy</h3>
<pre><code class="language-bash"># Create deny policy file
cat &gt; deny-policy.json &lt;&lt; 'EOF'
{
  &quot;displayName&quot;: &quot;Block Public Buckets&quot;,
  &quot;rules&quot;: [
    {
      &quot;denyRule&quot;: {
        &quot;deniedPrincipals&quot;: [&quot;principalSet://goog/public:all&quot;],
        &quot;deniedPermissions&quot;: [&quot;storage.buckets.setIamPolicy&quot;],
        &quot;denialCondition&quot;: {
          &quot;expression&quot;: &quot;resource.name.contains('allUsers')&quot;
        }
      }
    }
  ]
}
EOF

# Apply policy
gcloud iam policies create block-public \
    --attachment-point=&quot;cloudresourcemanager.googleapis.com/projects/my-project&quot; \
    --kind=&quot;denypolicies&quot; \
    --policy-file=deny-policy.json
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: The "Weekday-Only" Developer</h2>
<p><strong>Mission:</strong> Grant a contractor access to development VMs, but only on weekdays during business hours.</p>
<h3>Step 1: Create the Conditional Binding</h3>
<pre><code class="language-bash">gcloud projects add-iam-policy-binding my-project \
    --member=&quot;user:contractor@example.com&quot; \
    --role=&quot;roles/compute.instanceAdmin.v1&quot; \
    --condition='
      expression=resource.name.startsWith(&quot;projects/my-project/zones/us-central1-a/instances/dev-&quot;) &amp;&amp; 
        request.time.getDayOfWeek() &gt;= 1 &amp;&amp; 
        request.time.getDayOfWeek() &lt;= 5 &amp;&amp;
        request.time.getHours(&quot;America/Los_Angeles&quot;) &gt;= 9 &amp;&amp;
        request.time.getHours(&quot;America/Los_Angeles&quot;) &lt;= 17,
      title=DevVMsWeekdayHoursOnly,
      description=Access to dev VMs during weekday business hours only'
</code></pre>
<h3>Step 2: Verify</h3>
<pre><code class="language-bash"># Check current IAM policy
gcloud projects get-iam-policy my-project --format=json | jq '.bindings[] | select(.condition)'
</code></pre>
<hr />
<h2>âš ï¸ 6. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Workload Identity needs a JSON key"</td>
<td>No! It eliminates keys entirely</td>
</tr>
<tr>
<td>"Conditions work on all roles"</td>
<td>Some roles don't support conditions</td>
</tr>
<tr>
<td>"Deny policies are evaluated first"</td>
<td>No, they're evaluated with Allow policies</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Workload Identity is the gold standard</strong> for CI/CD</li>
<li><strong>Use IAM Recommender</strong> to identify unused permissions</li>
<li><strong>Deny policies are in beta</strong> - know they exist for the exam</li>
<li><strong>Conditions use CEL</strong> (Common Expression Language)</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>What does Workload Identity Federation eliminate?</strong></p>
<ul>
<li>A. Service Accounts</li>
<li>B. <strong>Long-lived JSON keys</strong> âœ…</li>
<li>C. IAM roles</li>
<li>D. Access tokens</li>
</ul>
</li>
<li>
<p><strong>Which language is used to write IAM Conditions?</strong></p>
<ul>
<li>A. Python</li>
<li>B. JavaScript</li>
<li>C. <strong>CEL (Common Expression Language)</strong> âœ…</li>
<li>D. SQL</li>
</ul>
</li>
<li>
<p><strong>You want to prevent ANYONE from deleting audit logs, even project owners. What do you use?</strong></p>
<ul>
<li>A. Conditional IAM</li>
<li>B. <strong>IAM Deny Policies</strong> âœ…</li>
<li>C. Organization Policies</li>
<li>D. VPC Service Controls</li>
</ul>
</li>
<li>
<p><strong>A developer should only access VMs labeled "env:dev". What IAM feature enables this?</strong></p>
<ul>
<li>A. Custom Roles</li>
<li>B. <strong>IAM Conditions</strong> âœ…</li>
<li>C. Service Accounts</li>
<li>D. Resource Quotas</li>
</ul>
</li>
<li>
<p><strong>Which identity providers does Workload Identity Federation support?</strong></p>
<ul>
<li>A. Only Google Workspace</li>
<li>B. Only AWS</li>
<li>C. <strong>AWS, Azure, GitHub, and any OIDC provider</strong> âœ…</li>
<li>D. Only on-premises Active Directory</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "Workload Identity Federation", "def": "Exchange external identity tokens for short-lived GCP tokens. No JSON keys needed."},
  {"term": "IAM Conditions", "def": "Context-aware access control. Add WHEN and WHERE to WHO/WHAT/WHICH."},
  {"term": "CEL", "def": "Common Expression Language. Used to write IAM condition expressions."},
  {"term": "Deny Policies", "def": "Override Allow policies. Enforce guardrails that even admins cannot bypass."},
  {"term": "OIDC", "def": "OpenID Connect. Protocol used by Workload Identity to verify external identities."},
  {"term": "Attribute-Based Access Control", "def": "ABAC. Grant access based on resource attributes/tags instead of just identity."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_17_gke_modes">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 17: GKE Modes (Standard vs. Autopilot)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 17, you will be able to:
*   <strong>Evaluate</strong> the trade-offs between GKE Standard and Autopilot.
*   <strong>Architect</strong> a cluster choice based on cost, security, and operational overhead.
*   <strong>Understand</strong> the Autopilot "Hardened" security posture.
*   <strong>Deploy</strong> a production-ready Autopilot cluster using best practices.</p>
<hr />
<h2>ğŸ§  1. Standard vs. Autopilot: The Choice</h2>
<p>The ACE exam frequently tests your ability to choose the right GKE mode for a given scenario.</p>
<h3>Decision Flowchart</h3>
<pre><code class="language-mermaid">graph TD
    Start[New GKE Project] --&gt; Q1{Need custom Node OS changes?}
    Q1 -- Yes --&gt; Standard[GKE Standard]
    Q1 -- No --&gt; Q2{Need specific GPU/TPU machine types?}
    Q2 -- Yes --&gt; Standard
    Q2 -- No --&gt; Q3{Want to minimize daily ops?}
    Q3 -- Yes --&gt; Autopilot[GKE Autopilot]
    Q3 -- No --&gt; Standard
</code></pre>
<hr />
<h2>ğŸ“‹ 2. Deep Dive Comparison</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">GKE Standard</th>
<th style="text-align: left;">GKE Autopilot</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Management</strong></td>
<td style="text-align: left;">You manage Nodes &amp; Node Pools.</td>
<td style="text-align: left;">Google manages the entire infrastructure.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Pricing</strong></td>
<td style="text-align: left;">Pay for the Compute Engine Nodes.</td>
<td style="text-align: left;">Pay for Pod resources requested.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Security</strong></td>
<td style="text-align: left;">You harden the OS yourself.</td>
<td style="text-align: left;"><strong>Hardened by default</strong> (Shielded VMs, disabled SSH).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Upgrades</strong></td>
<td style="text-align: left;">You configure maintenance windows.</td>
<td style="text-align: left;">Handled automatically by Google.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Flexibility</strong></td>
<td style="text-align: left;">Full control over Kubernetes flags.</td>
<td style="text-align: left;">Some flags/configurations are restricted.</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
<strong>ACE Pro Tip: Workload Separation</strong>
In Standard, you create <strong>Node Pools</strong> to separate different types of work (e.g., high-memory nodes for DBs). In Autopilot, you don't manage pools; you just use <strong>Taints and Tolerations</strong> or <strong>Selectors</strong>, and Google creates the hidden capacity for you.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: The Autopilot Workflow</h2>
<p>Autopilot is the recommended path for 90% of new GCP workloads. Let's see how it feels in the CLI.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Launch an Autopilot cluster and verify its unique characteristics.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Creation Command</strong>:
    <code>bash
    # Note: Autopilot clusters MUST be regional
    gcloud container clusters create-auto autopilot-prod \
        --region us-central1 \
        --project [PROJECT_ID]</code></p>
</li>
<li>
<p><strong>Verify Node Management</strong>:
    <code>bash
    kubectl get nodes</code>
    <em>Notice the machine types. Google automatically picks the best machine for your pods.</em></p>
</li>
<li>
<p><strong>Attempt Restricted Action (Security Test)</strong>:
    <code>bash
    # Try to run a privileged pod (this should fail on Autopilot)
    kubectl run secure-test --image=nginx --privileged</code>
    <em>Result:</em> Autopilot will block this because it enforces security "Guardrails" out of the box.</p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>The "Bin Packing" Trap</strong>: In <strong>Standard</strong>, if your pod uses 100MB RAM but is on a 4GB node, you pay for 4GB. In <strong>Autopilot</strong>, you only pay for the 100MB (plus a small system overhead). This is called "Pod-based billing."</p>
<p>[!WARNING]
<strong>SSH Access</strong>: You cannot SSH into the worker nodes of an Autopilot cluster. If the exam asks how to "debug a kernel issue on the node" in Autopilot, the answer is usually: "You can't; switch to Standard or use Cloud Logging."</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which GKE mode is billed based on the resources (CPU, RAM, Disk) requested by the Pods?</strong></p>
<ul>
<li>A. Standard</li>
<li>B. <strong>Autopilot</strong> âœ…</li>
<li>C. Both follow Pod-based billing.</li>
<li>D. Neither; both follow Node-based billing.</li>
</ul>
</li>
<li>
<p><strong>You need to run a legacy application that requires a specific kernel module. Which mode should you use?</strong></p>
<ul>
<li>A. Autopilot</li>
<li>B. <strong>Standard</strong> âœ…</li>
<li>C. Cloud Run</li>
<li>D. App Engine Standard</li>
</ul>
</li>
<li>
<p><strong>A team wants to 'minimize operational overhead' for their Kubernetes cluster. What is the best recommendation?</strong></p>
<ul>
<li>A. GKE Standard with Auto-scaling enabled.</li>
<li>B. <strong>GKE Autopilot</strong> âœ…</li>
<li>C. Compute Engine with manual Kubernetes installation.</li>
<li>D. GKE Standard with manual node pool management.</li>
</ul>
</li>
<li>
<p><strong>GKE Autopilot clusters are always:</strong></p>
<ul>
<li>A. Zonal for cost savings</li>
<li>B. <strong>Regional for High Availability</strong> âœ…</li>
<li>C. Private with no public IPs</li>
<li>D. Using only E2 machine types</li>
</ul>
</li>
<li>
<p><strong>What happens if you try to run a privileged container in GKE Autopilot?</strong></p>
<ul>
<li>A. It runs with warnings</li>
<li>B. It runs but costs more</li>
<li>C. <strong>It is blocked by security guardrails</strong> âœ…</li>
<li>D. It requires Owner role approval</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain why Autopilot is more cost-effective for small workloads.', checked: false },
        { text: 'I know that Autopilot clusters are regional by default.', checked: false },
        { text: 'I understand why Standard is needed for custom OS configurations.', checked: false },
        { text: 'I launched an Autopilot cluster successfully.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 17 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_18_kms_encryption">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>BONUS: Cloud KMS &amp; Data Protection</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (Encryption is a key security topic)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Understand</strong> the encryption hierarchy (Default â†’ CMEK â†’ CSEK)</li>
<li><strong>Implement</strong> Customer-Managed Encryption Keys (CMEK)</li>
<li><strong>Explain</strong> envelope encryption and why it matters</li>
<li><strong>Configure</strong> Cloud HSM and External Key Manager</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: Encryption in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Security Engineers own encryption strategy. Cloud Engineers implement it. Everyone is tested on it.</p>
</blockquote>
<h3>Job Roles &amp; Encryption Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use KMS</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Define encryption policy</td>
<td>Key hierarchy, rotation, compliance</td>
</tr>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Implement CMEK on resources</td>
<td>Bucket encryption, GKE secrets</td>
</tr>
<tr>
<td><strong>Compliance Officer</strong></td>
<td>Audit key usage</td>
<td>Access logs, key lifecycle</td>
</tr>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Encrypt sensitive data</td>
<td>Column-level encryption, tokenization</td>
</tr>
</tbody>
</table>
<h3>Compliance Requirements</h3>
<table>
<thead>
<tr>
<th>Regulation</th>
<th>Typical Requirement</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>HIPAA</strong></td>
<td>Customer-controlled keys</td>
<td>CMEK</td>
</tr>
<tr>
<td><strong>PCI-DSS</strong></td>
<td>Key rotation</td>
<td>Auto-rotation in KMS</td>
</tr>
<tr>
<td><strong>FedRAMP</strong></td>
<td>Hardware security</td>
<td>Cloud HSM</td>
</tr>
<tr>
<td><strong>Data Residency</strong></td>
<td>Keys in specific region</td>
<td>Regional keyrings</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"GCP encrypts data, so I don't need to do anything"</td>
<td>Shows no compliance awareness</td>
<td>"Default is fine, but compliance may require CMEK"</td>
</tr>
<tr>
<td>"I can recover data after destroying a key"</td>
<td>Data is permanently lost</td>
<td>"Destroying a key means crypto-shreddingâ€”data is gone forever"</td>
</tr>
<tr>
<td>"CMEK = CSEK"</td>
<td>Very different concepts</td>
<td>"CMEK stores keys in KMS; CSEK requires you to provide keys per-request"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. GCP Encryption Overview (Plain-English)</h2>
<p><strong>All data in GCP is encrypted at rest by default.</strong> You don't have to do anything.</p>
<p>But for compliance (banks, healthcare, government), you might need to prove:
- YOU control the keys
- You can revoke access anytime
- Keys never leave your control</p>
<h3>ğŸ’¡ Real-World Analogy: Safe Deposit Box</h3>
<table>
<thead>
<tr>
<th>Encryption Level</th>
<th>Analogy</th>
<th>Who Holds Key?</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Default</strong></td>
<td>Bank's vault (Google's keys)</td>
<td>Google</td>
</tr>
<tr>
<td><strong>CMEK</strong></td>
<td>Your safe inside bank's vault</td>
<td>You (in KMS)</td>
</tr>
<tr>
<td><strong>CSEK</strong></td>
<td>Your personal safe at home</td>
<td>You (on-prem)</td>
</tr>
<tr>
<td><strong>EKM</strong></td>
<td>Your safe, bank just stores it</td>
<td>You (3rd party)</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Encryption Hierarchy</h2>
<pre><code class="language-mermaid">graph TD
    subgraph Default[&quot;Default Encryption&quot;]
        D1[Google generates keys]
        D2[Google manages rotation]
        D3[You = Zero effort]
    end

    subgraph CMEK[&quot;Customer-Managed (CMEK)&quot;]
        C1[You create keys in KMS]
        C2[You control rotation]
        C3[You can disable/destroy]
    end

    subgraph CSEK[&quot;Customer-Supplied (CSEK)&quot;]
        S1[You generate keys locally]
        S2[You send key with every request]
        S3[Google never stores key]
    end

    subgraph EKM[&quot;External Key Manager&quot;]
        E1[Keys in 3rd party HSM]
        E2[Google never sees key]
        E3[Ultimate control]
    end

    Default --&gt; CMEK --&gt; CSEK --&gt; EKM

    style CMEK fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Comparison Table</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Default</th>
<th>CMEK</th>
<th>CSEK</th>
<th>EKM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Key Location</strong></td>
<td>Google</td>
<td>Cloud KMS</td>
<td>Your Server</td>
<td>3rd Party</td>
</tr>
<tr>
<td><strong>Setup Effort</strong></td>
<td>None</td>
<td>Low</td>
<td>High</td>
<td>Highest</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>Free</td>
<td>Per key operation</td>
<td>Free</td>
<td>Highest</td>
</tr>
<tr>
<td><strong>Compliance</strong></td>
<td>Basic</td>
<td>HIPAA, PCI</td>
<td>Military</td>
<td>Government</td>
</tr>
<tr>
<td><strong>Rotation</strong></td>
<td>Auto</td>
<td>Manual or Auto</td>
<td>Manual</td>
<td>Manual</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ”„ 3. Envelope Encryption</h2>
<p><strong>Problem:</strong> Encrypting 1 petabyte with a remote KMS key would be painfully slow.</p>
<p><strong>Solution:</strong> Envelope encryption - use two keys.</p>
<h3>How It Works</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant App as Application
    participant KMS as Cloud KMS
    participant Storage as Cloud Storage

    Note over App,Storage: Write Path
    App-&gt;&gt;KMS: 1. Generate DEK (Data Encryption Key)
    KMS--&gt;&gt;App: 2. Return DEK + Encrypted DEK
    App-&gt;&gt;App: 3. Encrypt data with DEK
    App-&gt;&gt;Storage: 4. Store encrypted data + encrypted DEK

    Note over App,Storage: Read Path
    Storage--&gt;&gt;App: 5. Return encrypted data + encrypted DEK
    App-&gt;&gt;KMS: 6. Decrypt the DEK
    KMS--&gt;&gt;App: 7. Return plaintext DEK
    App-&gt;&gt;App: 8. Decrypt data with DEK
</code></pre>
<h3>Key Terms</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DEK</strong></td>
<td>Data Encryption Key - encrypts the actual data (fast, local)</td>
</tr>
<tr>
<td><strong>KEK</strong></td>
<td>Key Encryption Key - encrypts the DEK (stored in KMS)</td>
</tr>
<tr>
<td><strong>Wrapped Key</strong></td>
<td>The encrypted DEK (safe to store with data)</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Why This Matters:</strong> KMS is only called twice (to wrap/unwrap DEK), not for every byte of data.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Create CMEK-Encrypted Bucket</h2>
<h3>Step 1: Create Key Ring and Key</h3>
<pre><code class="language-bash"># Create a key ring (container for keys)
gcloud kms keyrings create my-keyring \
    --location=us-central1

# Create an encryption key
gcloud kms keys create my-encryption-key \
    --keyring=my-keyring \
    --location=us-central1 \
    --purpose=encryption \
    --rotation-period=90d \
    --next-rotation-time=$(date -u -d &quot;+90 days&quot; +%Y-%m-%dT%H:%M:%SZ)
</code></pre>
<h3>Step 2: Grant Storage Access to Key</h3>
<pre><code class="language-bash"># Get the storage service account
PROJECT_NUMBER=$(gcloud projects describe $PROJECT_ID --format=&quot;value(projectNumber)&quot;)

# Grant access
gcloud kms keys add-iam-policy-binding my-encryption-key \
    --keyring=my-keyring \
    --location=us-central1 \
    --member=&quot;serviceAccount:service-${PROJECT_NUMBER}@gs-project-accounts.iam.gserviceaccount.com&quot; \
    --role=&quot;roles/cloudkms.cryptoKeyEncrypterDecrypter&quot;
</code></pre>
<h3>Step 3: Create CMEK Bucket</h3>
<pre><code class="language-bash"># Create bucket with CMEK
gcloud storage buckets create gs://my-cmek-bucket-${PROJECT_ID} \
    --location=us-central1 \
    --default-encryption-key=projects/${PROJECT_ID}/locations/us-central1/keyRings/my-keyring/cryptoKeys/my-encryption-key
</code></pre>
<h3>Step 4: Verify Encryption</h3>
<pre><code class="language-bash"># Upload a file
echo &quot;Secret data&quot; &gt; secret.txt
gcloud storage cp secret.txt gs://my-cmek-bucket-${PROJECT_ID}/

# Check encryption details
gcloud storage objects describe gs://my-cmek-bucket-${PROJECT_ID}/secret.txt --format=&quot;value(metadata.kmsKeyName)&quot;
</code></pre>
<hr />
<h2>âš¡ 5. Cloud HSM (Hardware Security Module)</h2>
<p><strong>For the most sensitive workloads</strong>, keys never leave tamper-resistant hardware.</p>
<h3>HSM Protection Levels</h3>
<table>
<thead>
<tr>
<th>Level</th>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SOFTWARE</strong></td>
<td>Software Keys</td>
<td>Keys protected by Google's secure infrastructure</td>
</tr>
<tr>
<td><strong>HSM</strong></td>
<td>Cloud HSM</td>
<td>FIPS 140-2 Level 3 certified hardware</td>
</tr>
<tr>
<td><strong>EXTERNAL</strong></td>
<td>External Key Manager</td>
<td>Keys in your own HSM (Thales, Fortanix)</td>
</tr>
</tbody>
</table>
<h3>Create HSM-Protected Key</h3>
<pre><code class="language-bash">gcloud kms keys create my-hsm-key \
    --keyring=my-keyring \
    --location=us-central1 \
    --purpose=encryption \
    --protection-level=hsm
</code></pre>
<hr />
<h2>âš ï¸ 6. Crypto-Shredding</h2>
<p><strong>What happens if you destroy a CMEK key?</strong></p>
<p>The data becomes <strong>permanently unreadable</strong>. This is called "crypto-shredding."</p>
<h3>Use Cases</h3>
<ul>
<li><strong>Data retention compliance</strong> - Destroy key after 7 years</li>
<li><strong>Customer offboarding</strong> - Customer leaves, destroy their key</li>
<li><strong>Security incident</strong> - Suspected breach, destroy all keys</li>
</ul>
<blockquote>
<p><strong>âš ï¸ WARNING:</strong> Destroying a key is irreversible. The data is gone forever.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which encryption level requires you to send the key with every API request?</strong></p>
<ul>
<li>A. Default Encryption</li>
<li>B. CMEK</li>
<li>C. <strong>CSEK (Customer-Supplied)</strong> âœ…</li>
<li>D. Cloud HSM</li>
</ul>
</li>
<li>
<p><strong>Why does GCP use envelope encryption?</strong></p>
<ul>
<li>A. To save storage space</li>
<li>B. <strong>To avoid slow remote encryption of large data</strong> âœ…</li>
<li>C. To comply with GDPR</li>
<li>D. To enable multi-region storage</li>
</ul>
</li>
<li>
<p><strong>What happens to data encrypted with a CMEK key if you destroy the key?</strong></p>
<ul>
<li>A. Data is automatically decrypted</li>
<li>B. Data moves to Archive storage</li>
<li>C. <strong>Data becomes permanently unreadable (crypto-shredded)</strong> âœ…</li>
<li>D. Google recovers the key from backup</li>
</ul>
</li>
<li>
<p><strong>Which protection level uses FIPS 140-2 Level 3 certified hardware?</strong></p>
<ul>
<li>A. SOFTWARE</li>
<li>B. <strong>HSM</strong> âœ…</li>
<li>C. EXTERNAL</li>
<li>D. DEFAULT</li>
</ul>
</li>
<li>
<p><strong>A DEK (Data Encryption Key) is encrypted by which key?</strong></p>
<ul>
<li>A. Another DEK</li>
<li>B. <strong>KEK (Key Encryption Key)</strong> âœ…</li>
<li>C. User password</li>
<li>D. Service Account key</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "CMEK", "def": "Customer-Managed Encryption Key. You create keys in Cloud KMS, Google uses them."},
  {"term": "CSEK", "def": "Customer-Supplied Encryption Key. You provide key with each request. Google never stores it."},
  {"term": "Envelope Encryption", "def": "Two-layer encryption. DEK encrypts data locally, KEK encrypts DEK in KMS."},
  {"term": "DEK", "def": "Data Encryption Key. Encrypts actual data. Fast, used locally."},
  {"term": "KEK", "def": "Key Encryption Key. Encrypts the DEK. Stored in Cloud KMS."},
  {"term": "Crypto-Shredding", "def": "Destroying encryption key to make data permanently unreadable."},
  {"term": "Cloud HSM", "def": "Hardware Security Module. FIPS 140-2 Level 3 certified tamper-resistant hardware."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_18_workloads">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 18: GKE Workloads (Deployments &amp; Services)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 18, you will be able to:
*   <strong>Deploy</strong> and scale containerized applications using Kubernetes Deployments.
*   <strong>Expose</strong> applications internally and externally using GKE Services.
*   <strong>Visualize</strong> the relationship between Pods, ReplicaSets, and Services.
*   <strong>Manage</strong> self-healing workloads and stable network endpoints.</p>
<hr />
<h2>ğŸš€ 1. Deployments: The Desired State Manager</h2>
<p>In Kubernetes, you rarely manage Pods directly. You manage <strong>Deployments</strong>. A Deployment ensures that a specific number of Pod replicas are running at all times.</p>
<h3>Deployment Hierarchy</h3>
<pre><code class="language-mermaid">graph TD
    D[Deployment: 'my-app'] --&gt; RS[ReplicaSet: 'my-app-v1']
    RS --&gt; P1[Pod 1]
    RS --&gt; P2[Pod 2]
    RS --&gt; P3[Pod 3]
</code></pre>
<blockquote>
<p>[!TIP]
<strong>ACE Pro Tip: Self-Healing</strong>
If a Node fails or a Pod crashes, the <strong>ReplicaSet</strong> (managed by your Deployment) notices the "Current State" (2 pods) doesn't match the "Desired State" (3 pods) and immediately starts a new one.</p>
</blockquote>
<hr />
<h2>ğŸ”Œ 2. Services: Stable Networking</h2>
<p>Pods are ephemeralâ€”they die and get new IP addresses. To provide a stable entry point, we use <strong>Services</strong>.</p>
<h3>Service Types Cheat Sheet</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Visibility</th>
<th style="text-align: left;">Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>ClusterIP</strong></td>
<td style="text-align: left;">Internal Only</td>
<td style="text-align: left;">Backend microservices or databases.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>NodePort</strong></td>
<td style="text-align: left;">External (Basic)</td>
<td style="text-align: left;">Opens a port (30000+) on every Node. Great for testing.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>LoadBalancer</strong></td>
<td style="text-align: left;"><strong>External (Prod)</strong></td>
<td style="text-align: left;">Provisions a Google Cloud Load Balancer with a static IP.</td>
</tr>
</tbody>
</table>
<pre><code class="language-mermaid">graph LR
    Client[Client Browser] --&gt; LB[External Load Balancer]
    LB --&gt; SVC[GKE Service: Port 80]
    SVC -- &quot;Selector: app=nginx&quot; --&gt; P1[Nginx Pod 1]
    SVC -- &quot;Selector: app=nginx&quot; --&gt; P2[Nginx Pod 2]
</code></pre>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: The "Full Stack" Exposure</h2>
<p>We will deploy an Nginx web server and expose it to the public internet using a GCP Load Balancer.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Practice the complete workflow: Create Deployment -&gt; Scale -&gt; Expose -&gt; Verify.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Create Deployment</strong>:
    <code>bash
    kubectl create deployment nginx-web --image=nginx:latest --replicas=3</code></p>
</li>
<li>
<p><strong>Scale Up</strong>:
    <code>bash
    kubectl scale deployment nginx-web --replicas=5</code></p>
</li>
<li>
<p><strong>Expose to Internet</strong>:
    <code>bash
    # This command creates a Service of type LoadBalancer
    kubectl expose deployment nginx-web --type=LoadBalancer --port=80 --target-port=80</code></p>
</li>
<li>
<p><strong>Verify &amp; Test</strong>:
    <code>bash
    # Wait until EXTERNAL-IP is assigned
    kubectl get svc nginx-web</code>
    <em>Copy the External IP into your browser. You are now hitting a Google Cloud Load Balancer!</em></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Label Selectors</strong>: A Service finds its target Pods using <strong>Labels</strong>. If your Pod is labeled <code>env=prod</code> and your service selects <code>env=dev</code>, traffic will never reach the Pod. This is a common exam troubleshooting question.</p>
<p>[!WARNING]
<strong>Pod IP Volatility</strong>: Never hardcode a Pod's IP address. Always use the <strong>Service Name</strong> (which uses internal DNS) to communicate between workloads.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which Kubernetes object is responsible for ensuring that a specific number of Pod replicas are running?</strong></p>
<ul>
<li>A. Pod</li>
<li>B. Service</li>
<li>C. <strong>ReplicaSet (via Deployment)</strong> âœ…</li>
<li>D. Kubelet</li>
</ul>
</li>
<li>
<p><strong>You want to expose a backend database so that only other microservices inside the cluster can reach it. Which Service type should you use?</strong></p>
<ul>
<li>A. NodePort</li>
<li>B. LoadBalancer</li>
<li>C. <strong>ClusterIP</strong> âœ…</li>
<li>D. ExternalName</li>
</ul>
</li>
<li>
<p><strong>What happens if a Node running a Pod in a Deployment crashes?</strong></p>
<ul>
<li>A. The Pod is lost forever.</li>
<li>B. <strong>The Deployment detects the failure and schedules a new Pod on a healthy Node.</strong> âœ…</li>
<li>C. The entire Deployment stops.</li>
<li>D. The Service IP address changes.</li>
</ul>
</li>
<li>
<p><strong>A Service uses which mechanism to decide which Pods should receive its traffic?</strong></p>
<ul>
<li>A. Pod IP ranges</li>
<li>B. <strong>Labels and Selectors</strong> âœ…</li>
<li>C. Round-robin scheduling via API Server</li>
<li>D. Node names</li>
</ul>
</li>
<li>
<p><strong>How do you update a Deployment to a new container image version without downtime?</strong></p>
<ul>
<li>A. Delete all pods first, then create new ones</li>
<li>B. <strong>Use <code>kubectl set image</code> which triggers a rolling update</strong> âœ…</li>
<li>C. Restart the entire cluster</li>
<li>D. Scale to 0 then back to desired replicas</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the hierarchy: Deployment -> ReplicaSet -> Pod.', checked: false },
        { text: 'I can differentiate between ClusterIP and LoadBalancer services.', checked: false },
        { text: 'I successfully exposed a deployment to the internet.', checked: false },
        { text: 'I know how to scale a deployment using kubectl.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 18 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_19_services">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 19: Stateful Workloads (PVs, PVCs &amp; StatefulSets)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate/Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 19, you will be able to:
*   <strong>Manage</strong> persistent data in GKE using PersistentVolumes (PV) and Claims (PVC).
*   <strong>Differentiate</strong> between Stateless (Deployments) and Stateful (StatefulSets) workloads.
*   <strong>Understand</strong> Dynamic Provisioning and Storage Classes.
*   <strong>Architect</strong> a storage solution that survives Pod restarts and Node failures.</p>
<hr />
<h2>ğŸ’¾ 1. Persistence in a Disposable World</h2>
<p>By default, data inside a container is <strong>ephemeral</strong>. If the container crashes, the data is gone. To solve this, Kubernetes uses a "Claim" system for storage.</p>
<h3>The Storage Hierarchy</h3>
<pre><code class="language-mermaid">graph TD
    SC[Storage Class: 'standard-rwo'] --&gt; PV[PersistentVolume: Physical Disk]
    PV --&gt; PVC[PersistentVolumeClaim: Logical Request]
    PVC --&gt; Pod[Your App Pod]
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Component</th>
<th style="text-align: left;">Responsibility</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>StorageClass</strong></td>
<td style="text-align: left;">The "Menu"</td>
<td style="text-align: left;">Defines the <em>type</em> of disk (SSD, Standard, etc.).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>PV</strong></td>
<td style="text-align: left;">The "Physical Disk"</td>
<td style="text-align: left;">The actual resource in GCP (Persistent Disk).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>PVC</strong></td>
<td style="text-align: left;">The "Voucher"</td>
<td style="text-align: left;">A request by a user for storage of a certain size/mode.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ›ï¸ 2. Deployments vs. StatefulSets</h2>
<p>Most apps use Deployments, but databases (MySQL, MongoDB) need <strong>StatefulSets</strong>.</p>
<h3>Critical Differences</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Deployment (Random)&quot;
        P1[web-as89f]
        P2[web-92js1]
    end

    subgraph &quot;StatefulSet (Ordered)&quot;
        S1[db-0]
        S2[db-1]
    end
</code></pre>
<ul>
<li><strong>Deployments</strong>: Pods are identical and random. If <code>web-as89f</code> dies, it's replaced by <code>web-qwer0</code>.</li>
<li><strong>StatefulSets</strong>: Pods have unique, sticky identities. If <code>db-0</code> dies, it is replaced by a new <code>db-0</code> that re-attaches to the <strong>same</strong> disk.</li>
</ul>
<blockquote>
<p>[!TIP]
<strong>ACE Pro Tip: Dynamic Provisioning</strong>
In GKE, you don't need to manually create Persistent Disks. When you create a PVC, GKE uses the <strong>StorageClass</strong> to automatically create the disk in GCP for you. This is "Dynamic Provisioning."</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Requesting a Disk</h2>
<p>We will create a PersistentVolumeClaim and see GKE provision a disk automatically.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Understand the PVC lifecycle and see the GCP Persistent Disk creation.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Define a PVC</strong> (<code>storage-claim.yaml</code>):
    <code>yaml
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: my-disk-claim
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: standard-rwo</code></p>
</li>
<li>
<p><strong>Apply the Claim</strong>:
    <code>bash
    kubectl apply -f storage-claim.yaml</code></p>
</li>
<li>
<p><strong>Verify Status</strong>:
    <code>bash
    kubectl get pvc</code>
    <em>Result: Once status is <code>Bound</code>, run the next command.</em></p>
</li>
<li>
<p><strong>Confirm in GCP</strong>:
    <code>bash
    gcloud compute disks list</code>
    <em>You will see a new 10GB disk created specifically for this Kubernetes claim!</em></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Access Modes</strong>: 
- <strong>ReadWriteOnce (RWO)</strong>: Only 1 node can mount the disk (standard).
- <strong>ReadOnlyMany (ROX)</strong>: Many nodes can read (great for shared config).
- <strong>ReadWriteMany (RWX)</strong>: Many nodes can read/write. <strong>Note:</strong> GCP Persistent Disks do NOT support RWX. You need <strong>Filestore</strong> for this.</p>
<p>[!WARNING]
<strong>StatefulSet Replicas</strong>: Never scale down a StatefulSet to zero and expect the disks to be deleted. PVCs are protected and must be deleted manually to avoid accidental data loss (and bills!).</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which Kubernetes object acts as a "request" for storage by a user?</strong></p>
<ul>
<li>A. StorageClass</li>
<li>B. PersistentVolume (PV)</li>
<li>C. <strong>PersistentVolumeClaim (PVC)</strong> âœ…</li>
<li>D. ConfigMap</li>
</ul>
</li>
<li>
<p><strong>You are deploying a database that requires a stable network identifier and a sticky disk. Which workload type should you use?</strong></p>
<ul>
<li>A. Deployment</li>
<li>B. <strong>StatefulSet</strong> âœ…</li>
<li>C. DaemonSet</li>
<li>D. ReplicaSet</li>
</ul>
</li>
<li>
<p><strong>What is the benefit of using a 'StorageClass' in GKE?</strong></p>
<ul>
<li>A. It encrypts the disk.</li>
<li>B. <strong>It enables Dynamic Provisioning, so GKE creates disks on-demand.</strong> âœ…</li>
<li>C. It allows Pods to run without a kernel.</li>
<li>D. It increases the CPU limit of the Pod.</li>
</ul>
</li>
<li>
<p><strong>A Pod in a StatefulSet named 'my-db-1' crashes. What will its replacement be named?</strong></p>
<ul>
<li>A. 'my-db-2'</li>
<li>B. 'my-db-random-id'</li>
<li>C. <strong>'my-db-1'</strong> âœ…</li>
<li>D. 'my-db-0'</li>
</ul>
</li>
<li>
<p><strong>You need multiple nodes to be able to read and write to the same shared directory simultaneously. Can you use a standard GCP Persistent Disk?</strong></p>
<ul>
<li>A. Yes, using ReadWriteMany mode.</li>
<li>B. <strong>No, standard PDs do not support ReadWriteMany. Use Google Cloud Filestore instead.</strong> âœ…</li>
<li>C. Yes, if the nodes are in the same zone.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between PV and PVC.', checked: false },
        { text: 'I can explain why databases use StatefulSets instead of Deployments.', checked: false },
        { text: 'I know that GKE handles Dynamic Provisioning automatically.', checked: false },
        { text: 'I recall that standard GCP disks only support ReadWriteOnce.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 19 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_20_backup_dr">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>BONUS: Backup &amp; Disaster Recovery</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (DR is heavily tested in scenario questions)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Backup &amp; DR Essentials)</strong><br />
<strong>RPO</strong> = How much data can you lose? <strong>RTO</strong> = How long can you be offline? Snapshots are GLOBAL (restore anywhere), INCREMENTAL (saves money), and INDEPENDENT (deleting VM keeps snapshots). DR tiers: Cold (cheap, RTO=days) â†’ Warm (RTO=hours) â†’ Hot (expensive, RTO=minutes).</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Understand</strong> RTO and RPO</td>
<td>Drives all DR architecture decisions</td>
</tr>
<tr>
<td><strong>Configure</strong> snapshot schedules</td>
<td>Automate backups without manual work</td>
</tr>
<tr>
<td><strong>Design</strong> Cold/Warm/Hot DR</td>
<td>Match cost to business requirements</td>
</tr>
<tr>
<td><strong>Implement</strong> cross-region replication</td>
<td>Survive regional outages</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Backup vs Disaster Recovery (Plain-English)</h2>
<h3>ğŸ’¡ Real-World Analogy</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Backup</strong></td>
<td>Photocopy of your passport. If you lose it, you can prove who you are.</td>
</tr>
<tr>
<td><strong>Disaster Recovery</strong></td>
<td>Second passport + suitcase + plane ticket in a safe deposit box in another country. If your house burns down, you fly there and continue your life.</td>
</tr>
</tbody>
</table>
<h3>Key Metrics</h3>
<pre><code class="language-mermaid">graph LR
    subgraph Timeline
        D[Disaster] --&gt; RPO[RPO: Data Lost]
        D --&gt; RTO[RTO: Downtime]
        RPO --&gt; |Last Backup| LB[Last Good Backup]
        RTO --&gt; |Recovery Complete| RC[Back Online]
    end

    style RPO fill:#ffebee,stroke:#f44336
    style RTO fill:#fff3e0,stroke:#ff9800
</code></pre>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Question</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RPO</strong> (Recovery Point Objective)</td>
<td>How much data can we lose?</td>
<td>"We can lose 15 minutes of work"</td>
</tr>
<tr>
<td><strong>RTO</strong> (Recovery Time Objective)</td>
<td>How long can we be offline?</td>
<td>"We must be back in 4 hours"</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> Lower RPO/RTO = Higher cost. The exam tests if you can match requirements to appropriate DR tier.</p>
</blockquote>
<hr />
<h2>ğŸ“¸ 2. GCP Backup Tools</h2>
<h3>Snapshot Types</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Scope</th>
<th>Speed</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Disk Snapshot</strong></td>
<td>Single disk</td>
<td>Fast</td>
<td>VM backup</td>
</tr>
<tr>
<td><strong>Machine Image</strong></td>
<td>Entire VM (disks + config)</td>
<td>Medium</td>
<td>Full VM clone</td>
</tr>
<tr>
<td><strong>Custom Image</strong></td>
<td>OS template</td>
<td>Fast</td>
<td>Golden image</td>
</tr>
<tr>
<td><strong>Cloud SQL Backup</strong></td>
<td>Database</td>
<td>Auto</td>
<td>Managed DB</td>
</tr>
</tbody>
</table>
<h3>Snapshot Architecture</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Source[&quot;Source Region (us-central1)&quot;]
        VM[VM Instance]
        PD[Persistent Disk]
    end

    subgraph Snapshots[&quot;Snapshots&quot;]
        S1[Snap 1&lt;br/&gt;Full: 100GB]
        S2[Snap 2&lt;br/&gt;Incremental: 5GB]
        S3[Snap 3&lt;br/&gt;Incremental: 3GB]
    end

    subgraph Storage[&quot;Multi-Region Storage&quot;]
        GCS[Cloud Storage&lt;br/&gt;Replicated globally]
    end

    subgraph Target[&quot;Target Region (europe-west1)&quot;]
        VM2[New VM]
        PD2[Restored Disk]
    end

    PD --&gt; S1 --&gt; S2 --&gt; S3
    S3 --&gt; GCS
    GCS --&gt; PD2 --&gt; VM2

    style GCS fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Key Facts About Snapshots</h3>
<ul>
<li>âœ… <strong>Incremental</strong> - Only changed blocks are stored (saves money)</li>
<li>âœ… <strong>Global</strong> - Can restore in any region</li>
<li>âœ… <strong>Independent</strong> - Deleting VM doesn't delete snapshots</li>
<li>âœ… <strong>Consistent</strong> - Application-consistent if VM is running</li>
</ul>
<hr />
<h2>ğŸ”„ 3. DR Strategy Tiers</h2>
<h3>Comparison Table</h3>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>RTO</th>
<th>RPO</th>
<th>Cost</th>
<th>Architecture</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cold</strong></td>
<td>Days</td>
<td>Hours-Days</td>
<td>ğŸ’°</td>
<td>Backups in Archive storage, no running infra</td>
</tr>
<tr>
<td><strong>Warm</strong></td>
<td>Hours</td>
<td>Minutes</td>
<td>ğŸ’°ğŸ’°</td>
<td>Database active, app servers off</td>
</tr>
<tr>
<td><strong>Hot</strong></td>
<td>Minutes</td>
<td>Seconds</td>
<td>ğŸ’°ğŸ’°ğŸ’°</td>
<td>Active-Active in multiple regions</td>
</tr>
<tr>
<td><strong>Multi-Region Active-Active</strong></td>
<td>Near-Zero</td>
<td>Near-Zero</td>
<td>ğŸ’°ğŸ’°ğŸ’°ğŸ’°</td>
<td>Everything running everywhere</td>
</tr>
</tbody>
</table>
<h3>Strategy Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[RTO Requirement?] --&gt; B{RTO &lt; 1 hour?}
    B --&gt;|Yes| C{Budget?}
    B --&gt;|No| D{RTO &lt; 1 day?}

    C --&gt;|High| HOT[Hot Standby]
    C --&gt;|Medium| WARM[Warm Standby]

    D --&gt;|Yes| WARM
    D --&gt;|No| COLD[Cold Backup]

    style HOT fill:#e8f5e9,stroke:#4caf50
    style WARM fill:#fff3e0,stroke:#ff9800
    style COLD fill:#e3f2fd,stroke:#2196f3
</code></pre>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Automated Snapshot Schedule</h2>
<h3>Step 1: Create Snapshot Schedule</h3>
<pre><code class="language-bash">gcloud compute resource-policies create snapshot-schedule daily-backup \
    --description=&quot;Daily backup at 2 AM&quot; \
    --max-retention-days=14 \
    --start-time=02:00 \
    --daily-schedule \
    --region=us-central1 \
    --storage-location=us
</code></pre>
<h3>Step 2: Attach to Disk</h3>
<pre><code class="language-bash">gcloud compute disks add-resource-policies my-disk \
    --resource-policies=daily-backup \
    --zone=us-central1-a
</code></pre>
<h3>Step 3: Verify</h3>
<pre><code class="language-bash"># List snapshots
gcloud compute snapshots list

# Check schedule
gcloud compute resource-policies describe daily-backup --region=us-central1
</code></pre>
<h3>Step 4: Restore in Different Region</h3>
<pre><code class="language-bash"># Create disk from snapshot in Europe
gcloud compute disks create recovered-disk \
    --source-snapshot=my-disk-snapshot-001 \
    --zone=europe-west1-b

# Create VM from restored disk
gcloud compute instances create recovered-vm \
    --disk=name=recovered-disk,boot=yes \
    --zone=europe-west1-b
</code></pre>
<hr />
<h2>ğŸŒ 5. Cross-Region DR Patterns</h2>
<h3>Pattern 1: Database Replication</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Primary[&quot;US (Primary)&quot;]
        CS1[Cloud SQL]
        APP1[App Server]
    end

    subgraph Secondary[&quot;EU (DR)&quot;]
        CS2[Read Replica]
        APP2[App Server&lt;br/&gt;Standby]
    end

    CS1 --&gt;|Async Replication| CS2

    style CS1 fill:#e8f5e9,stroke:#4caf50
    style CS2 fill:#fff3e0,stroke:#ff9800
</code></pre>
<h3>Pattern 2: Global Load Balancer Failover</h3>
<pre><code class="language-bash"># Configure health check
gcloud compute health-checks create http my-health-check \
    --port=80 \
    --request-path=/healthz

# Backend service with multiple regions
gcloud compute backend-services create my-global-backend \
    --global \
    --health-checks=my-health-check \
    --load-balancing-scheme=EXTERNAL
</code></pre>
<hr />
<h2>âš ï¸ 6. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Snapshots are zonal"</td>
<td>No! Snapshots are globally accessible</td>
</tr>
<tr>
<td>"Deleting VM deletes snapshots"</td>
<td>No! Snapshots are independent</td>
</tr>
<tr>
<td>"Hot standby is always best"</td>
<td>No! It's expensive and often overkill</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use snapshot schedules</strong> instead of manual snapshots</li>
<li><strong>Test your DR plan</strong> - an untested plan is no plan</li>
<li><strong>Cross-region restores</strong> are slower but possible</li>
<li><strong>Machine Images</strong> are better for full VM clones</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>What does RPO (Recovery Point Objective) measure?</strong></p>
<ul>
<li>A. Time to recover</li>
<li>B. <strong>Maximum acceptable data loss</strong> âœ…</li>
<li>C. Cost of recovery</li>
<li>D. Backup frequency</li>
</ul>
</li>
<li>
<p><strong>Where are GCP snapshots stored?</strong></p>
<ul>
<li>A. In the same zone as the disk</li>
<li>B. In the same region as the disk</li>
<li>C. <strong>In Cloud Storage (globally accessible)</strong> âœ…</li>
<li>D. On the VM's local SSD</li>
</ul>
</li>
<li>
<p><strong>Which DR strategy has the lowest cost but highest RTO?</strong></p>
<ul>
<li>A. Hot Standby</li>
<li>B. Warm Standby</li>
<li>C. <strong>Cold Backup</strong> âœ…</li>
<li>D. Active-Active</li>
</ul>
</li>
<li>
<p><strong>If you delete a VM, what happens to its snapshots?</strong></p>
<ul>
<li>A. They are automatically deleted</li>
<li>B. They expire after 30 days</li>
<li>C. <strong>They remain and are independent</strong> âœ…</li>
<li>D. They become read-only</li>
</ul>
</li>
<li>
<p><strong>You need to move a VM from Project A to Project B. What should you create?</strong></p>
<ul>
<li>A. Snapshot</li>
<li>B. <strong>Machine Image</strong> âœ…</li>
<li>C. Export to VMDK</li>
<li>D. Live migration</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "RPO", "def": "Recovery Point Objective. How much data can you afford to lose."},
  {"term": "RTO", "def": "Recovery Time Objective. How long can you be offline."},
  {"term": "Snapshot", "def": "Incremental backup of a Persistent Disk. Stored globally. Independent of VM."},
  {"term": "Machine Image", "def": "Complete VM backup including disks, metadata, and configuration."},
  {"term": "Cold DR", "def": "Lowest cost DR. Backups only, no running infrastructure. RTO = days."},
  {"term": "Hot DR", "def": "Highest cost DR. Active-Active across regions. RTO = minutes."},
  {"term": "Snapshot Schedule", "def": "Resource policy for automated daily/weekly backups with retention."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_20_config_secrets">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 20: GKE ConfigMaps &amp; Secrets</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 20, you will be able to:
*   <strong>Decouple</strong> application configuration from container images for multi-environment portability.
*   <strong>Architect</strong> secure secret management using Kubernetes Secrets and GKE's Application-layer Encryption.
*   <strong>Inject</strong> configuration data as both environment variables and mounted volume files.
*   <strong>Validate</strong> security postures using the 12-Factor App methodology.</p>
<hr />
<h2>ğŸ§  1. Decoupling Config from Code</h2>
<p>The gold standard for cloud-native apps is the <strong>12-Factor Methodology</strong>. Factor III states: <em>Store config in the environment</em>. You should use the <strong>same</strong> Docker image for Dev, Staging, and Production.</p>
<h3>The Injection Flow</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Kubernetes Store&quot;
        CM[ConfigMap: URLs, Port, Paths]
        SEC[Secret: API Keys, DB Pass]
    end

    subgraph &quot;Pod Environment&quot;
        ENV1[Env Var: $API_URL]
        ENV2[Env Var: $DB_PASS]
    end

    subgraph &quot;Pod Volume mount&quot;
        VOL[File: /etc/config/app.json]
    end

    CM -- &quot;valueFrom&quot; --&gt; ENV1
    SEC -- &quot;valueFrom&quot; --&gt; ENV2
    CM -- &quot;volumeMount&quot; --&gt; VOL
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Object</th>
<th style="text-align: left;">Data Type</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>ConfigMap</strong></td>
<td style="text-align: left;">Plain Text</td>
<td style="text-align: left;">Use for non-sensitive data. Size limit: 1MB.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Secret</strong></td>
<td style="text-align: left;">Base64 Encoded</td>
<td style="text-align: left;">Use for passwords/keys. <strong>Warning:</strong> Base64 is NOT encryption.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Hardening GKE Secrets</h2>
<p>On GKE, security goes beyond basic Kubernetes.</p>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: Encryption at Rest</strong>
By default, GKE encrypts data at rest (including Secrets in etcd). However, for high-security compliance, you can enable <strong>Application-layer Secrets Encryption</strong>. This uses Google Cloud KMS (Key Management Service) to wrap the Kubernetes secrets in an extra layer of protection.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Multi-Method Injection</h2>
<p>We will create a Secret and mount it as a file inside a container.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Practice mounting sensitive data as a volume instead of an environment variable (which is often more secure as env vars can show up in logs).</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Create a Secret</strong>:
    <code>bash
    kubectl create secret generic mysql-pass --from-literal=password=P@ssw0rd123</code></p>
</li>
<li>
<p><strong>Deploy a Pod with Volume Mount</strong> (<code>secret-pod.yaml</code>):
    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: secret-reader
    spec:
      containers:</p>
<ul>
<li>name: alpine
    image: alpine
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:<ul>
<li>name: secret-vol
  mountPath: "/etc/secrets"
  readOnly: true
  volumes:</li>
</ul>
</li>
<li>name: secret-vol
    secret:
      secretName: mysql-pass
```</li>
</ul>
</li>
<li>
<p><strong>Read the Secret from File</strong>:
    <code>bash
    kubectl exec secret-reader -- cat /etc/secrets/password</code>
    <em>Result: "P@ssw0rd123" is printed. The file exists only in the Pod's memory!</em></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!WARNING]
<strong>Base64 Confusion</strong>: Many candidates think <code>metadata: { name: my-secret }</code> means the data is encrypted. Standard Kubernetes Secrets are only <strong>Base64 encoded</strong>. Anyone with <code>get secrets</code> permissions can decode them easily. Use RBAC (Role-Based Access Control) to limit who can see secrets.</p>
<p>[!TIP]
<strong>External Integration</strong>: For enterprise-grade security, use <strong>GCP Secret Manager</strong> and sync it with GKE using the <strong>External Secrets Operator</strong> or the <strong>Secret Manager CSI Driver</strong>.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You need to provide a database connection string that is different for Dev and Prod, but not sensitive. Which object should you use?</strong></p>
<ul>
<li>A. Secret</li>
<li>B. <strong>ConfigMap</strong> âœ…</li>
<li>C. Environment Variable hardcoded in Dockerfile</li>
<li>D. PersistentVolumeClaim</li>
</ul>
</li>
<li>
<p><strong>Which statement about Kubernetes Secrets is TRUE?</strong></p>
<ul>
<li>A. They are encrypted with AES-256 by default in the cluster.</li>
<li>B. <strong>They are Base64 encoded and should be protected with RBAC.</strong> âœ…</li>
<li>C. They can store files up to 10GB in size.</li>
<li>D. They are automatically synced with your local hard drive.</li>
</ul>
</li>
<li>
<p><strong>How can you add an extra layer of security to GKE secrets to meet strict compliance requirements?</strong></p>
<ul>
<li>A. By using a ConfigMap instead.</li>
<li>B. <strong>By enabling Application-layer Secrets Encryption using Google Cloud KMS.</strong> âœ…</li>
<li>C. By password-protecting the kubectl command.</li>
<li>D. By running GKE in a private VPC only.</li>
</ul>
</li>
<li>
<p><strong>You have a ConfigMap containing 50 different property settings. What is the most efficient way to give a Pod access to all of them as files?</strong></p>
<ul>
<li>A. Use 50 <code>valueFrom</code> entries in environment variables.</li>
<li>B. <strong>Mount the ConfigMap as a Volume at a specific path.</strong> âœ…</li>
<li>C. Copy the properties into the Docker image.</li>
<li>D. Use a StatefulSet to attach a disk with the config.</li>
</ul>
</li>
<li>
<p><strong>For enterprise-grade secret management, what is the recommended integration with GKE?</strong></p>
<ul>
<li>A. Store secrets in Cloud Storage</li>
<li>B. <strong>Use GCP Secret Manager with CSI Driver</strong> âœ…</li>
<li>C. Commit secrets to Git repository</li>
<li>D. Use ConfigMaps for all secrets</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain why we decouple config from images.', checked: false },
        { text: 'I know that Secrets are only Base64 encoded by default.', checked: false },
        { text: 'I understand how to mount a Secret as a volume.', checked: false },
        { text: 'I understand the role of KMS in GKE secret protection.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 20 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_20_security_operations">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>BONUS: Security Command Center, DLP &amp; Cloud Armor</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (Security is 19% of the exam)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Navigate</strong> Security Command Center for threat detection</li>
<li><strong>Use</strong> Cloud DLP to find and redact sensitive data</li>
<li><strong>Configure</strong> Cloud Armor for DDoS and WAF protection</li>
<li><strong>Design</strong> security operations workflows</li>
</ul>
<hr />
<h2>ğŸ›¡ï¸ 1. Security Command Center (SCC)</h2>
<p><strong>SCC = Your security dashboard for the entire organization.</strong></p>
<h3>Tier Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Standard (Free)</th>
<th>Premium (Paid)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Asset Discovery</strong></td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td><strong>Security Findings</strong></td>
<td>Basic (public buckets, open firewalls)</td>
<td>âœ… Advanced</td>
</tr>
<tr>
<td><strong>Threat Detection</strong></td>
<td>âŒ</td>
<td>âœ… Cryptomining, brute force, malware</td>
</tr>
<tr>
<td><strong>Vulnerability Scanning</strong></td>
<td>âŒ</td>
<td>âœ… Web app scanning</td>
</tr>
<tr>
<td><strong>Compliance Reports</strong></td>
<td>âŒ</td>
<td>âœ… CIS, PCI-DSS, NIST</td>
</tr>
<tr>
<td><strong>Container Threat Detection</strong></td>
<td>âŒ</td>
<td>âœ… GKE runtime threats</td>
</tr>
</tbody>
</table>
<h3>SCC Architecture</h3>
<pre><code class="language-mermaid">flowchart TD
    subgraph Sources[&quot;Data Sources&quot;]
        GCE[Compute Engine]
        GCS[Cloud Storage]
        GKE[GKE Clusters]
        IAM[IAM Policies]
    end

    subgraph SCC[&quot;Security Command Center&quot;]
        AD[Asset Discovery]
        SA[Security Analytics]
        TD[Threat Detection]
        VS[Vulnerability Scanner]
    end

    subgraph Outputs[&quot;Actions&quot;]
        FN[Findings]
        AL[Alerts]
        RE[Recommendations]
    end

    Sources --&gt; SCC --&gt; Outputs

    style TD fill:#ffebee,stroke:#f44336,stroke-width:2px
    style FN fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Common Findings</h3>
<table>
<thead>
<tr>
<th>Finding</th>
<th>Severity</th>
<th>Remediation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Public bucket</td>
<td>HIGH</td>
<td>Remove allUsers/allAuthenticatedUsers</td>
</tr>
<tr>
<td>Open firewall (0.0.0.0/0 SSH)</td>
<td>CRITICAL</td>
<td>Restrict to known IPs</td>
</tr>
<tr>
<td>Cryptomining detected</td>
<td>CRITICAL</td>
<td>Stop instance, investigate</td>
</tr>
<tr>
<td>Default service account used</td>
<td>MEDIUM</td>
<td>Create custom SA with minimal permissions</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Cloud DLP (Data Loss Prevention)</h2>
<p><strong>DLP = Find, classify, and protect sensitive data automatically.</strong></p>
<h3>InfoTypes (What DLP Detects)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Financial</strong></td>
<td>Credit card, bank account</td>
</tr>
<tr>
<td><strong>PII</strong></td>
<td>SSN, passport, driver's license</td>
</tr>
<tr>
<td><strong>Healthcare</strong></td>
<td>Medical record, FDA code</td>
</tr>
<tr>
<td><strong>Credentials</strong></td>
<td>API keys, passwords</td>
</tr>
<tr>
<td><strong>Custom</strong></td>
<td>Employee IDs, internal codes</td>
</tr>
</tbody>
</table>
<h3>DLP Actions</h3>
<pre><code class="language-mermaid">flowchart LR
    D[Data] --&gt; DLP[Cloud DLP API]

    DLP --&gt; I[INSPECT&lt;br/&gt;Find sensitive data]
    DLP --&gt; R[REDACT&lt;br/&gt;Remove/mask data]
    DLP --&gt; DE[DE-IDENTIFY&lt;br/&gt;Tokenize/encrypt]

    I --&gt; |Report| FN[Findings]
    R --&gt; |Cleaned| CD[Clean Data]
    DE --&gt; |Token| TD[Tokenized Data]

    style DLP fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<h3>DLP in Data Pipelines</h3>
<pre><code class="language-bash"># Inspect text for sensitive data
gcloud dlp inspect \
    --content=&quot;My SSN is 123-45-6789 and email is john@example.com&quot; \
    --info-types=US_SOCIAL_SECURITY_NUMBER,EMAIL_ADDRESS

# Inspect a Cloud Storage bucket
gcloud dlp jobs create \
    --storage-path=&quot;gs://my-bucket/*&quot; \
    --info-types=CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER \
    --actions=publishToPubsub
</code></pre>
<hr />
<h2>ğŸ”¥ 3. Cloud Armor (WAF + DDoS Protection)</h2>
<p><strong>Cloud Armor = Protection at the edge of Google's network.</strong></p>
<h3>Protection Layers</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Internet
        AT[Attacker]
        US[Legitimate User]
    end

    subgraph Edge[&quot;Google Edge&quot;]
        CA[Cloud Armor]
    end

    subgraph Backend
        LB[Load Balancer]
        APP[Application]
    end

    AT --&gt;|Attack| CA
    US --&gt;|Request| CA
    CA --&gt;|Block| X[âŒ Blocked]
    CA --&gt;|Allow| LB --&gt; APP

    style CA fill:#ffebee,stroke:#f44336,stroke-width:2px
    style X fill:#ffcdd2,stroke:#f44336
</code></pre>
<h3>Security Policy Rules</h3>
<table>
<thead>
<tr>
<th>Rule Type</th>
<th>Example</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IP Allowlist</strong></td>
<td>Allow only 203.0.113.0/24</td>
<td>Corporate access only</td>
</tr>
<tr>
<td><strong>IP Denylist</strong></td>
<td>Block 192.0.2.0/24</td>
<td>Known bad actors</td>
</tr>
<tr>
<td><strong>Geo-blocking</strong></td>
<td><code>origin.region_code != 'US'</code></td>
<td>GDPR compliance</td>
</tr>
<tr>
<td><strong>Rate limiting</strong></td>
<td>Max 100 req/min per IP</td>
<td>Prevent abuse</td>
</tr>
<tr>
<td><strong>WAF rules</strong></td>
<td>OWASP ModSecurity CRS</td>
<td>Block SQL injection, XSS</td>
</tr>
</tbody>
</table>
<h3>Create Cloud Armor Policy</h3>
<pre><code class="language-bash"># Create security policy
gcloud compute security-policies create my-policy \
    --description=&quot;Block attackers and rate limit&quot;

# Add rule to block a country
gcloud compute security-policies rules create 1000 \
    --security-policy=my-policy \
    --expression=&quot;origin.region_code == 'XX'&quot; \
    --action=deny-403

# Add rate limiting
gcloud compute security-policies rules create 2000 \
    --security-policy=my-policy \
    --expression=&quot;true&quot; \
    --action=rate-based-ban \
    --rate-limit-threshold-count=100 \
    --rate-limit-threshold-interval-sec=60

# Attach to backend service
gcloud compute backend-services update my-backend \
    --security-policy=my-policy \
    --global
</code></pre>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: DLP Data Redaction</h2>
<h3>Step 1: Inspect Sensitive Data</h3>
<pre><code class="language-bash"># Create test file
echo &quot;Customer: John Doe, SSN: 123-45-6789, Card: 4111-1111-1111-1111&quot; &gt; sensitive.txt

# Upload to bucket
gsutil cp sensitive.txt gs://my-bucket/

# Run DLP inspection
gcloud dlp jobs create \
    --storage-path=&quot;gs://my-bucket/sensitive.txt&quot; \
    --info-types=US_SOCIAL_SECURITY_NUMBER,CREDIT_CARD_NUMBER \
    --actions=saveFindings
</code></pre>
<h3>Step 2: Create De-identification Template</h3>
<pre><code class="language-bash"># Via Console: Security &gt; DLP &gt; Templates &gt; Create
# Or via API with redaction config
cat &gt; deidentify-template.json &lt;&lt; 'EOF'
{
  &quot;deidentifyTemplate&quot;: {
    &quot;displayName&quot;: &quot;Redact PII&quot;,
    &quot;deidentifyConfig&quot;: {
      &quot;infoTypeTransformations&quot;: {
        &quot;transformations&quot;: [{
          &quot;primitiveTransformation&quot;: {
            &quot;replaceConfig&quot;: {
              &quot;newValue&quot;: {&quot;stringValue&quot;: &quot;[REDACTED]&quot;}
            }
          }
        }]
      }
    }
  }
}
EOF
</code></pre>
<hr />
<h2>âš ï¸ 5. Exam Traps &amp; Pro Tips</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"SCC Standard detects threats"</td>
<td>No! Threat detection is Premium only</td>
</tr>
<tr>
<td>"Cloud Armor protects all traffic"</td>
<td>No! Only traffic through GCLB</td>
</tr>
<tr>
<td>"DLP encrypts data"</td>
<td>No! DLP inspects/redacts; use KMS for encryption</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>SCC Premium</strong> is required for compliance reports</li>
<li><strong>Cloud Armor</strong> only works with HTTP(S) Load Balancer</li>
<li><strong>DLP</strong> can be triggered automatically via Pub/Sub + Functions</li>
<li><strong>Combine all three</strong> for defense in depth</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which service detects if your VMs are mining cryptocurrency?</strong></p>
<ul>
<li>A. Cloud DLP</li>
<li>B. Cloud Armor</li>
<li>C. <strong>Security Command Center Premium</strong> âœ…</li>
<li>D. Cloud IAM</li>
</ul>
</li>
<li>
<p><strong>You need to remove credit card numbers from data before storing in BigQuery. What do you use?</strong></p>
<ul>
<li>A. Cloud KMS</li>
<li>B. <strong>Cloud DLP</strong> âœ…</li>
<li>C. VPC Service Controls</li>
<li>D. Cloud Armor</li>
</ul>
</li>
<li>
<p><strong>Where does Cloud Armor enforce security policies?</strong></p>
<ul>
<li>A. At the VM level</li>
<li>B. In Cloud Storage</li>
<li>C. <strong>At the Global HTTP(S) Load Balancer edge</strong> âœ…</li>
<li>D. In the VPC</li>
</ul>
</li>
<li>
<p><strong>Which SCC feature is only available in the Premium tier?</strong></p>
<ul>
<li>A. Asset Discovery</li>
<li>B. Security Findings</li>
<li>C. <strong>Compliance Reports (CIS, PCI-DSS)</strong> âœ…</li>
<li>D. IAM Recommendations</li>
</ul>
</li>
<li>
<p><strong>You want to block traffic from a specific country. What do you use?</strong></p>
<ul>
<li>A. VPC Firewall</li>
<li>B. <strong>Cloud Armor geo-blocking</strong> âœ…</li>
<li>C. Cloud NAT</li>
<li>D. Identity-Aware Proxy</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "SCC", "def": "Security Command Center. Centralized security dashboard for GCP. Premium tier adds threat detection."},
  {"term": "Cloud DLP", "def": "Data Loss Prevention. Inspect, classify, and redact sensitive data like SSN and credit cards."},
  {"term": "Cloud Armor", "def": "Web Application Firewall at the edge. Protects against DDoS, SQL injection, and geo-blocks."},
  {"term": "InfoType", "def": "DLP detector category like CREDIT_CARD_NUMBER or US_SOCIAL_SECURITY_NUMBER."},
  {"term": "Event Threat Detection", "def": "SCC Premium feature that detects cryptomining, malware, and brute force attacks."},
  {"term": "WAF", "def": "Web Application Firewall. Filters malicious HTTP traffic at Layer 7."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_21_cloud_shell">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 21: Week 3 Project - The Automated Security Auditor</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes (Hands-On Project)<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (Cloud Operations &amp; CLI skills are critical)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Project Summary)</strong><br />
Build an automated security monitoring system that: (1) Detects when someone deletes a firewall rule, (2) Sends you an email alert automatically, (3) Creates an audit trail so you know WHO did it and WHEN. You'll use Cloud Logging + Log-based Metrics + Alerting Policies.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Project Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>What You'll Learn</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Shell Mastery</strong></td>
<td>Navigate and automate with gcloud CLI</td>
</tr>
<tr>
<td><strong>Log-Based Metrics</strong></td>
<td>Create custom metrics from security events</td>
</tr>
<tr>
<td><strong>Alerting Policies</strong></td>
<td>Set up real-time email/Slack notifications</td>
</tr>
<tr>
<td><strong>Incident Investigation</strong></td>
<td>Find WHO/WHEN/WHAT from audit logs</td>
</tr>
<tr>
<td><strong>Audit Trail</strong></td>
<td>Build a complete compliance-ready system</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Project Scenario (Mission Briefing)</h2>
<blockquote>
<p>[!WARNING]
<strong>Real-World Incident</strong><br />
Your security team received a complaint: someone deleted a critical firewall rule last night. Production was exposed for 3 hours. Your manager wants answers:
- <strong>WHO</strong> made the change?
- <strong>WHEN</strong> did it happen?
- <strong>HOW</strong> do we prevent silent deletions in the future?</p>
</blockquote>
<p><strong>Your Mission:</strong> Build an automated security auditor that detects suspicious GCP activities and alerts your team in real-time â€” before damage is done.</p>
<h3>ğŸ—ï¸ Solution Architecture</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Events[&quot;Security Events&quot;]
        FW[ğŸ”¥ Firewall Deleted]
        SA[ğŸ”‘ SA Key Created]
        VM[ğŸ’» VM Deleted]
    end

    subgraph Logging[&quot;Cloud Logging&quot;]
        AL[Audit Logs]
        LBM[Log-Based Metrics]
    end

    subgraph Alerting[&quot;Cloud Monitoring&quot;]
        AP[Alerting Policy]
        NC[Notification Channel]
    end

    subgraph Notify[&quot;Notifications&quot;]
        EM[ğŸ“§ Email]
        SL[ğŸ’¬ Slack]
        PS[ğŸ“± PagerDuty]
    end

    Events --&gt; AL --&gt; LBM --&gt; AP --&gt; NC --&gt; Notify

    style LBM fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style AP fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<hr />
<h2>ğŸ”§ 2. Cloud Shell Power User Cheatsheet</h2>
<h3>Essential gcloud Commands</h3>
<table>
<thead>
<tr>
<th>Task</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Set project</strong></td>
<td><code>gcloud config set project PROJECT_ID</code></td>
</tr>
<tr>
<td><strong>List projects</strong></td>
<td><code>gcloud projects list</code></td>
</tr>
<tr>
<td><strong>Current config</strong></td>
<td><code>gcloud config list</code></td>
</tr>
<tr>
<td><strong>Authenticate</strong></td>
<td><code>gcloud auth login</code></td>
</tr>
<tr>
<td><strong>Get access token</strong></td>
<td><code>gcloud auth print-access-token</code></td>
</tr>
</tbody>
</table>
<h3>Compute Commands</h3>
<pre><code class="language-bash"># List all VMs
gcloud compute instances list

# Create a VM
gcloud compute instances create my-vm \
    --zone=us-central1-a \
    --machine-type=e2-micro

# SSH into VM
gcloud compute ssh my-vm --zone=us-central1-a

# Delete VM
gcloud compute instances delete my-vm --zone=us-central1-a
</code></pre>
<h3>Firewall Commands</h3>
<pre><code class="language-bash"># List firewall rules
gcloud compute firewall-rules list

# Create firewall rule
gcloud compute firewall-rules create allow-ssh \
    --direction=INGRESS \
    --priority=1000 \
    --network=default \
    --action=ALLOW \
    --rules=tcp:22 \
    --source-ranges=0.0.0.0/0

# Delete firewall rule
gcloud compute firewall-rules delete allow-ssh
</code></pre>
<h3>Logging Commands</h3>
<pre><code class="language-bash"># Read recent logs
gcloud logging read &quot;resource.type=gce_instance&quot; --limit=10

# Read with time filter
gcloud logging read &quot;timestamp&gt;=\&quot;2024-01-01T00:00:00Z\&quot;&quot; --limit=50

# Read firewall deletions
gcloud logging read 'protoPayload.methodName=&quot;v1.compute.firewalls.delete&quot;' --limit=5
</code></pre>
<hr />
<h2>ğŸ› ï¸ 3. Lab Part 1: Generate &amp; Investigate an Incident</h2>
<h3>Step 1: Create Evidence (Simulate the Incident)</h3>
<pre><code class="language-bash"># Create a &quot;suspicious&quot; firewall rule
gcloud compute firewall-rules create allow-bad-traffic \
    --direction=INGRESS \
    --priority=1000 \
    --network=default \
    --action=ALLOW \
    --rules=tcp:666 \
    --source-ranges=0.0.0.0/0

# Wait 30 seconds for logs to propagate
sleep 30

# Now delete it (this is what we'll detect!)
gcloud compute firewall-rules delete allow-bad-traffic --quiet
</code></pre>
<h3>Step 2: Hunt in Log Explorer</h3>
<pre><code class="language-bash"># Open in browser or use CLI
# Filter for firewall deletions
gcloud logging read '
  resource.type=&quot;gce_firewall_rule&quot; AND
  protoPayload.methodName=&quot;v1.compute.firewalls.delete&quot;
' --format=&quot;json&quot; --limit=5
</code></pre>
<h3>Step 3: Extract the Culprit</h3>
<p>Look for these key fields in the log entry:</p>
<pre><code class="language-json">{
  &quot;protoPayload&quot;: {
    &quot;authenticationInfo&quot;: {
      &quot;principalEmail&quot;: &quot;your-email@domain.com&quot;  // WHO
    },
    &quot;methodName&quot;: &quot;v1.compute.firewalls.delete&quot;,  // WHAT
    &quot;resourceName&quot;: &quot;projects/PROJECT/global/firewalls/allow-bad-traffic&quot;  // WHICH
  },
  &quot;timestamp&quot;: &quot;2024-01-15T10:30:00.000Z&quot;  // WHEN
}
</code></pre>
<hr />
<h2>ğŸ› ï¸ 4. Lab Part 2: Create Log-Based Metrics</h2>
<h3>Via Console</h3>
<ol>
<li>Go to <strong>Logging</strong> &gt; <strong>Log Explorer</strong></li>
<li>Enter filter:
   <code>resource.type="gce_firewall_rule"
   protoPayload.methodName="v1.compute.firewalls.delete"</code></li>
<li>Click <strong>Actions</strong> &gt; <strong>Create Metric</strong></li>
<li>Name: <code>firewall-deletions</code></li>
<li>Type: Counter</li>
<li>Click <strong>Create Metric</strong></li>
</ol>
<h3>Via gcloud</h3>
<pre><code class="language-bash">gcloud logging metrics create firewall-deletions \
    --description=&quot;Counts firewall rule deletions&quot; \
    --log-filter='
      resource.type=&quot;gce_firewall_rule&quot; AND
      protoPayload.methodName=&quot;v1.compute.firewalls.delete&quot;
    '
</code></pre>
<h3>Verify Metric Exists</h3>
<pre><code class="language-bash">gcloud logging metrics list
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Lab Part 3: Create Alerting Policy</h2>
<h3>Via Console</h3>
<ol>
<li>Go to <strong>Monitoring</strong> &gt; <strong>Alerting</strong> &gt; <strong>Create Policy</strong></li>
<li><strong>Condition:</strong></li>
<li>Resource type: <code>logging.googleapis.com/user/firewall-deletions</code></li>
<li>Threshold: <code>&gt; 0</code></li>
<li>Duration: <code>1 minute</code></li>
<li><strong>Notifications:</strong> Add email channel</li>
<li><strong>Name:</strong> "Critical: Firewall Deletion Detected"</li>
<li>Click <strong>Create Policy</strong></li>
</ol>
<h3>Via gcloud</h3>
<pre><code class="language-bash"># Create notification channel first
gcloud alpha monitoring channels create \
    --display-name=&quot;Security Team Email&quot; \
    --type=email \
    --channel-labels=email_address=security@company.com

# Get channel ID
CHANNEL_ID=$(gcloud alpha monitoring channels list --format=&quot;value(name)&quot; | head -1)

# Create alerting policy
gcloud alpha monitoring policies create \
    --display-name=&quot;Firewall Deletion Alert&quot; \
    --condition-display-name=&quot;Firewall deleted&quot; \
    --condition-filter='metric.type=&quot;logging.googleapis.com/user/firewall-deletions&quot;' \
    --condition-threshold-value=0 \
    --condition-threshold-comparison=COMPARISON_GT \
    --notification-channels=$CHANNEL_ID
</code></pre>
<hr />
<h2>ğŸ› ï¸ 6. Lab Part 4: Test the Full Pipeline</h2>
<pre><code class="language-bash"># Create and delete another firewall rule
gcloud compute firewall-rules create test-alert \
    --direction=INGRESS \
    --network=default \
    --action=ALLOW \
    --rules=tcp:9999 \
    --source-ranges=0.0.0.0/0

# Delete it to trigger the alert
gcloud compute firewall-rules delete test-alert --quiet

# Check your email in ~5 minutes!
</code></pre>
<hr />
<h2>âš ï¸ 7. Pro Tips &amp; Best Practices</h2>
<h3>Security Monitoring Best Practices</h3>
<table>
<thead>
<tr>
<th>Event</th>
<th>Log Filter</th>
<th>Why Monitor</th>
</tr>
</thead>
<tbody>
<tr>
<td>Firewall deletions</td>
<td><code>v1.compute.firewalls.delete</code></td>
<td>Network security holes</td>
</tr>
<tr>
<td>SA key creation</td>
<td><code>google.iam.admin.v1.CreateServiceAccountKey</code></td>
<td>Credential theft</td>
</tr>
<tr>
<td>IAM changes</td>
<td><code>SetIamPolicy</code></td>
<td>Privilege escalation</td>
</tr>
<tr>
<td>VPC creation</td>
<td><code>v1.compute.networks.insert</code></td>
<td>Unauthorized networks</td>
</tr>
<tr>
<td>Bucket made public</td>
<td><code>storage.setIamPermissions</code></td>
<td>Data exposure</td>
</tr>
</tbody>
</table>
<h3>Automation Tips</h3>
<pre><code class="language-bash"># Create alias for common filters
alias firewall-audit='gcloud logging read &quot;protoPayload.methodName:firewalls&quot; --limit=20'

# Save as script
cat &lt;&lt; 'EOF' &gt; ~/security-audit.sh
#!/bin/bash
echo &quot;=== Recent Security Events ===&quot;
gcloud logging read &quot;
  protoPayload.methodName:delete OR
  protoPayload.methodName:SetIamPolicy
&quot; --limit=50 --format=&quot;table(timestamp,protoPayload.methodName,protoPayload.authenticationInfo.principalEmail)&quot;
EOF
chmod +x ~/security-audit.sh
</code></pre>
<hr />
<h2>ğŸ¯ 8. ACE Exam Focus</h2>
<h3>Key Concepts</h3>
<table>
<thead>
<tr>
<th>Topic</th>
<th>What to Know</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Shell</strong></td>
<td>5GB persistent home dir, pre-authenticated, 60-min timeout</td>
</tr>
<tr>
<td><strong>Log-based Metrics</strong></td>
<td>Count or distribution from log entries</td>
</tr>
<tr>
<td><strong>Audit Logs</strong></td>
<td>Admin Activity (always on), Data Access (must enable)</td>
</tr>
<tr>
<td><strong>Alerting</strong></td>
<td>Metric + Threshold + Duration + Notification Channel</td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>Audit logs â‰  all logs</strong> - Data Access logs must be enabled</li>
<li>âš ï¸ <strong>Cloud Shell times out</strong> after 60 minutes of inactivity</li>
<li>âš ï¸ <strong>Log-based metrics are delayed</strong> - not real-time</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 9. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which gcloud command reads Cloud Logging entries for a specific resource type?</strong></p>
<ul>
<li>A. <code>gcloud compute logs list</code></li>
<li>B. <strong><code>gcloud logging read 'resource.type="gce_instance"'</code></strong> âœ…</li>
<li>C. <code>gcloud monitoring logs filter</code></li>
<li>D. <code>gcloud audit logs query</code></li>
</ul>
</li>
<li>
<p><strong>You want to track how many times a specific API is called per hour. What should you create?</strong></p>
<ul>
<li>A. An Uptime Check</li>
<li>B. <strong>A Log-based Metric</strong> âœ…</li>
<li>C. A Cloud Function</li>
<li>D. A Dashboard</li>
</ul>
</li>
<li>
<p><strong>Which field in a Cloud Logging entry reveals WHO performed an action?</strong></p>
<ul>
<li>A. <code>resource.labels</code></li>
<li>B. <code>timestamp</code></li>
<li>C. <strong><code>protoPayload.authenticationInfo.principalEmail</code></strong> âœ…</li>
<li>D. <code>severity</code></li>
</ul>
</li>
<li>
<p><strong>What is the persistent storage size available in Cloud Shell?</strong></p>
<ul>
<li>A. 1 GB</li>
<li>B. <strong>5 GB</strong> âœ…</li>
<li>C. 10 GB</li>
<li>D. Unlimited</li>
</ul>
</li>
<li>
<p><strong>Which type of Audit Log is always enabled and cannot be disabled?</strong></p>
<ul>
<li>A. Data Access Logs</li>
<li>B. <strong>Admin Activity Logs</strong> âœ…</li>
<li>C. System Event Logs</li>
<li>D. Policy Denied Logs</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Project Checklist</h2>
<ul>
<li>[ ] Create and delete a test firewall rule</li>
<li>[ ] Find the deletion event in Log Explorer</li>
<li>[ ] Identify WHO/WHEN/WHAT from the log entry</li>
<li>[ ] Create <code>firewall-deletions</code> log-based metric</li>
<li>[ ] Set up alerting policy with email notification</li>
<li>[ ] Verify alert triggers on test deletion</li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 22: Cloud Operations (Logging &amp; Monitoring)</strong>
*   Deep dive into Cloud Monitoring
*   Custom dashboards
*   SLOs and Error Budgets</p>
<!-- FLASHCARDS
[
  {"term": "Cloud Shell", "def": "Browser-based CLI with 5GB persistent storage. Pre-authenticated with gcloud. Times out after 60 min."},
  {"term": "Log-based Metric", "def": "Custom metric created from log entries. Can be counter or distribution type."},
  {"term": "Audit Logs", "def": "Record of admin actions. Admin Activity is always on; Data Access must be enabled."},
  {"term": "Alerting Policy", "def": "Metric condition + threshold + notification channel. Triggers when condition is met."},
  {"term": "principalEmail", "def": "Field in audit logs that identifies WHO performed an action."},
  {"term": "gcloud logging read", "def": "CLI command to query Cloud Logging. Supports filters and time ranges."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_21_containers_intro">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Day 21: Containers 101 - Before GKE</h1>
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/containers">Containers Concepts</a> | <a href="https://cloud.google.com/artifact-registry/docs">Artifact Registry</a></p>
</blockquote>
<h2>Learning Objectives</h2>
<p>By the end of this day, you should be able to:
- Understand containers vs VMs and when to use each
- Build, tag, and push Docker images
- Use Artifact Registry for container storage
- Apply container security best practices</p>
<hr />
<h2>1ï¸âƒ£ What is a Container? ğŸ“¦</h2>
<h3>VMs vs Containers</h3>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;Virtual Machines&quot;
        HW1[ğŸ–¥ï¸ Hardware]
        HV1[Hypervisor]
        VM1[Guest OS 1]
        VM2[Guest OS 2]
        App1[App A]
        App2[App B]

        HW1 --&gt; HV1
        HV1 --&gt; VM1 &amp; VM2
        VM1 --&gt; App1
        VM2 --&gt; App2
    end

    subgraph &quot;Containers&quot;
        HW2[ğŸ–¥ï¸ Hardware]
        OS2[Host OS]
        Docker[ğŸ³ Container Runtime]
        Con1[Container A]
        Con2[Container B]
        Con3[Container C]

        HW2 --&gt; OS2 --&gt; Docker
        Docker --&gt; Con1 &amp; Con2 &amp; Con3
    end
</code></pre>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Virtual Machine</th>
<th>Container</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Isolation</strong></td>
<td>Full OS per VM</td>
<td>Shared kernel</td>
</tr>
<tr>
<td><strong>Size</strong></td>
<td>GBs (includes OS)</td>
<td>MBs (app + deps only)</td>
</tr>
<tr>
<td><strong>Boot Time</strong></td>
<td>Minutes</td>
<td>Milliseconds</td>
</tr>
<tr>
<td><strong>Portability</strong></td>
<td>Limited</td>
<td>"Works everywhere"</td>
</tr>
<tr>
<td><strong>Overhead</strong></td>
<td>High</td>
<td>Low</td>
</tr>
</tbody>
</table>
<h3>The "Shipping Container" Analogy ğŸš¢</h3>
<p>Think of shipping containers:
- <strong>Before containers</strong>: Goods loaded loosely, different for every ship
- <strong>After containers</strong>: Standardized boxes, fit any ship, train, or truck</p>
<p><strong>Software containers</strong> = Code + dependencies in a standardized package that runs anywhere.</p>
<hr />
<h2>2ï¸âƒ£ Docker Fundamentals ğŸ³</h2>
<h3>Core Concepts</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Dockerfile</strong></td>
<td>Instructions to build an image</td>
<td>Recipe ğŸ“</td>
</tr>
<tr>
<td><strong>Image</strong></td>
<td>Built artifact, immutable</td>
<td>Cake ğŸ‚</td>
</tr>
<tr>
<td><strong>Container</strong></td>
<td>Running instance of an image</td>
<td>Slice being eaten ğŸ°</td>
</tr>
<tr>
<td><strong>Registry</strong></td>
<td>Storage for images</td>
<td>Bakery warehouse ğŸ­</td>
</tr>
<tr>
<td><strong>Tag</strong></td>
<td>Version label for images</td>
<td>"v1.0", "latest"</td>
</tr>
</tbody>
</table>
<h3>Image Layers</h3>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;Docker Image Layers&quot;
        L1[ğŸ“¦ Base: python:3.11-slim]
        L2[ğŸ“¦ WORKDIR /app]
        L3[ğŸ“¦ COPY requirements.txt]
        L4[ğŸ“¦ RUN pip install]
        L5[ğŸ“¦ COPY . .]
        L6[ğŸ“¦ CMD python app.py]
    end

    L1 --&gt; L2 --&gt; L3 --&gt; L4 --&gt; L5 --&gt; L6

    Note1[Each layer is cached!&lt;br&gt;Change code = only L5 &amp; L6 rebuild]
</code></pre>
<hr />
<h2>3ï¸âƒ£ Hands-On Lab: Build Your First Container ğŸ› ï¸</h2>
<h3>Step 1: Create Application Files</h3>
<pre><code class="language-bash"># Create project directory
mkdir my-container &amp;&amp; cd my-container
</code></pre>
<p><strong>app.py:</strong></p>
<pre><code class="language-python">from flask import Flask
import os

app = Flask(__name__)

@app.route('/')
def hello():
    return f&quot;Hello from Container! Host: {os.uname().nodename}&quot;

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
</code></pre>
<p><strong>requirements.txt:</strong></p>
<pre><code class="language-text">flask==2.3.2
gunicorn==21.2.0
</code></pre>
<h3>Step 2: Write Dockerfile</h3>
<pre><code class="language-dockerfile"># Use official Python runtime as base
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Copy requirements first (layer caching)
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Run as non-root user (security!)
RUN useradd -m appuser
USER appuser

# Expose port
EXPOSE 8080

# Start command
CMD [&quot;gunicorn&quot;, &quot;--bind&quot;, &quot;0.0.0.0:8080&quot;, &quot;app:app&quot;]
</code></pre>
<h3>Step 3: Build &amp; Run Locally</h3>
<pre><code class="language-bash"># Build the image
docker build -t my-flask-app:v1 .

# Run container
docker run -p 8080:8080 my-flask-app:v1

# Test it
curl http://localhost:8080
</code></pre>
<h3>Step 4: Push to Artifact Registry</h3>
<pre><code class="language-bash"># Configure Docker for Artifact Registry
gcloud auth configure-docker us-central1-docker.pkg.dev

# Tag for Artifact Registry
docker tag my-flask-app:v1 \
    us-central1-docker.pkg.dev/PROJECT_ID/my-repo/flask-app:v1

# Push
docker push us-central1-docker.pkg.dev/PROJECT_ID/my-repo/flask-app:v1
</code></pre>
<hr />
<h2>4ï¸âƒ£ Artifact Registry vs Container Registry</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Container Registry (gcr.io)</th>
<th>Artifact Registry</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Status</strong></td>
<td>Legacy</td>
<td>Recommended âœ…</td>
</tr>
<tr>
<td><strong>Formats</strong></td>
<td>Docker only</td>
<td>Docker, Maven, npm, Python, etc.</td>
</tr>
<tr>
<td><strong>Security</strong></td>
<td>Basic</td>
<td>Fine-grained IAM, VPC-SC</td>
</tr>
<tr>
<td><strong>Regional</strong></td>
<td>Multi-region only</td>
<td>Regional OR multi-region</td>
</tr>
<tr>
<td><strong>Pricing</strong></td>
<td>Storage only</td>
<td>Storage + egress</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash"># Create Artifact Registry repository
gcloud artifacts repositories create my-repo \
    --repository-format=docker \
    --location=us-central1 \
    --description=&quot;My container images&quot;
</code></pre>
<hr />
<h2>5ï¸âƒ£ Multi-Stage Builds (Smaller Images)</h2>
<pre><code class="language-dockerfile"># Stage 1: Build
FROM golang:1.21 AS builder
WORKDIR /app
COPY . .
RUN CGO_ENABLED=0 go build -o myapp

# Stage 2: Runtime (tiny!)
FROM alpine:3.18
COPY --from=builder /app/myapp /myapp
CMD [&quot;/myapp&quot;]
</code></pre>
<p><strong>Result</strong>: 
- Without multi-stage: ~800 MB (includes Go compiler)
- With multi-stage: ~15 MB (just the binary)</p>
<hr />
<h2>6ï¸âƒ£ Container Security Best Practices ğŸ”’</h2>
<table>
<thead>
<tr>
<th>Practice</th>
<th>Why</th>
<th>How</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Run as non-root</strong></td>
<td>Limits damage if compromised</td>
<td><code>USER appuser</code> in Dockerfile</td>
</tr>
<tr>
<td><strong>Use minimal base images</strong></td>
<td>Fewer vulnerabilities</td>
<td><code>alpine</code>, <code>distroless</code></td>
</tr>
<tr>
<td><strong>Scan for vulnerabilities</strong></td>
<td>Catch issues early</td>
<td>Artifact Registry scanning</td>
</tr>
<tr>
<td><strong>Pin versions</strong></td>
<td>Reproducible builds</td>
<td><code>python:3.11.4</code> not <code>python:latest</code></td>
</tr>
<tr>
<td><strong>No secrets in images</strong></td>
<td>Prevent leaks</td>
<td>Use Secret Manager</td>
</tr>
</tbody>
</table>
<pre><code class="language-bash"># Enable vulnerability scanning
gcloud artifacts repositories update my-repo \
    --location=us-central1 \
    --vulnerability-scanning=STANDARD
</code></pre>
<hr />
<h2>7ï¸âƒ£ Key Docker Commands (Exam)</h2>
<pre><code class="language-bash"># Build
docker build -t NAME:TAG .

# Run
docker run -p HOST:CONTAINER IMAGE

# List images
docker images

# List running containers
docker ps

# Stop container
docker stop CONTAINER_ID

# Push to registry
docker push REGISTRY/IMAGE:TAG

# Pull from registry
docker pull REGISTRY/IMAGE:TAG
</code></pre>
<hr />
<h2>8ï¸âƒ£ Exam Scenarios &amp; Traps ğŸš¨</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Store container images securely"</td>
<td><strong>Artifact Registry</strong></td>
</tr>
<tr>
<td>"Reduce image size"</td>
<td><strong>Multi-stage builds</strong></td>
</tr>
<tr>
<td>"Run containers without managing servers"</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>"Orchestrate many containers"</td>
<td><strong>GKE</strong></td>
</tr>
<tr>
<td>"Need to build images from source"</td>
<td><strong>Cloud Build</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!WARNING]
<strong>Trap</strong>: Container Registry (gcr.io) is legacy. New projects should use <strong>Artifact Registry</strong>.</p>
<p>[!TIP]
<strong>Security</strong>: Always run containers as non-root and scan images for vulnerabilities.</p>
</blockquote>
<hr />
<h2>9ï¸âƒ£ Cheat Sheet</h2>
<pre><code class="language-text">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CONTAINERS CHEAT SHEET                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DOCKER BASICS:                                          â”‚
â”‚ docker build -t NAME:TAG .        # Build image         â”‚
â”‚ docker run -p 8080:8080 IMAGE     # Run container      â”‚
â”‚ docker push REGISTRY/IMAGE:TAG    # Push to registry   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ARTIFACT REGISTRY:                                      â”‚
â”‚ gcloud artifacts repositories create REPO               â”‚
â”‚ gcloud auth configure-docker REGION-docker.pkg.dev     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BEST PRACTICES:                                         â”‚
â”‚ - Use non-root USER                                    â”‚
â”‚ - Pin image versions                                   â”‚
â”‚ - Multi-stage builds for smaller images               â”‚
â”‚ - Scan images for vulnerabilities                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<hr />
<h2>ğŸ”Ÿ Checkpoint Quiz</h2>
<ol>
<li><strong>Which file defines how to build a Docker image?</strong></li>
<li>A) build.yaml</li>
<li>B) Dockerfile âœ…</li>
<li>C) container.json</li>
<li>
<p>D) image.yml</p>
</li>
<li>
<p><strong>What's the recommended registry for new GCP projects?</strong></p>
</li>
<li>A) Docker Hub</li>
<li>B) Container Registry (gcr.io)</li>
<li>C) Artifact Registry âœ…</li>
<li>
<p>D) GitHub Container Registry</p>
</li>
<li>
<p><strong>How do you reduce container image size?</strong></p>
</li>
<li>A) Use larger base images</li>
<li>B) Multi-stage builds âœ…</li>
<li>C) Add more layers</li>
<li>
<p>D) Include build tools in final image</p>
</li>
<li>
<p><strong>Container security: Which user should run your app?</strong></p>
</li>
<li>A) root</li>
<li>B) admin</li>
<li>C) Non-root user âœ…</li>
<li>
<p>D) docker</p>
</li>
<li>
<p><strong>True or False: Containers share the host OS kernel.</strong></p>
</li>
<li>Answer: <strong>True</strong> (Unlike VMs which have their own kernel)</li>
</ol>
<hr />
<!-- FLASHCARDS
[
  {"term": "Container", "def": "Lightweight, isolated environment for running applications."},
  {"term": "Dockerfile", "def": "Text file with instructions to build a Docker image."},
  {"term": "Image", "def": "Immutable, layered artifact containing app and dependencies."},
  {"term": "Artifact Registry", "def": "GCP's recommended registry for containers and packages."},
  {"term": "Multi-Stage Build", "def": "Dockerfile technique to create smaller final images."},
  {"term": "Non-root User", "def": "Security practice to limit container privileges."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_21_final_architecture">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>BONUS: Architecture Thinking - Putting It All Together</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ Very High (Scenario questions dominate the exam)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Apply</strong> architectural thinking to exam scenarios</li>
<li><strong>Match</strong> business requirements to GCP services</li>
<li><strong>Use</strong> elimination strategies for complex questions</li>
<li><strong>Recognize</strong> common architecture patterns</li>
</ul>
<hr />
<h2>ğŸ§  1. The Architecture Mindset</h2>
<p><strong>ACE Exam â‰  "What is a VM?"</strong>
<strong>ACE Exam = "Given these requirements, which services should you use?"</strong></p>
<h3>The Translation Game</h3>
<table>
<thead>
<tr>
<th>When They Say...</th>
<th>They Mean...</th>
<th>Answer Pattern</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Fault-tolerant web app"</td>
<td>Auto-healing, multi-zone</td>
<td>MIG or Cloud Run</td>
</tr>
<tr>
<td>"Store relational data"</td>
<td>SQL, transactions</td>
<td>Cloud SQL or Spanner</td>
</tr>
<tr>
<td>"Store images/videos"</td>
<td>Unstructured, large files</td>
<td>Cloud Storage</td>
</tr>
<tr>
<td>"Cheap/cost-effective"</td>
<td>Minimize spend</td>
<td>Preemptible, smaller types</td>
</tr>
<tr>
<td>"Global users"</td>
<td>Low latency worldwide</td>
<td>Global LB, multi-region</td>
</tr>
<tr>
<td>"Compliance required"</td>
<td>HIPAA, PCI, SOC2</td>
<td>CMEK, VPC-SC, Regions</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Common Architecture Patterns</h2>
<h3>Pattern 1: Scalable Web Application</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Users[&quot;Users&quot;]
        U1[ğŸŒ Global Users]
    end

    subgraph Edge[&quot;Edge&quot;]
        GLB[Global HTTP(S) LB]
        CDN[Cloud CDN]
        CA[Cloud Armor]
    end

    subgraph Compute[&quot;Compute&quot;]
        MIG1[MIG: us-central1]
        MIG2[MIG: europe-west1]
    end

    subgraph Data[&quot;Data&quot;]
        SQL[Cloud SQL HA]
        GCS[Cloud Storage]
        MC[Memorystore]
    end

    Users --&gt; GLB
    GLB --&gt; CDN --&gt; CA
    CA --&gt; MIG1 &amp; MIG2
    MIG1 &amp; MIG2 --&gt; SQL &amp; GCS &amp; MC

    style GLB fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<p><strong>Use When:</strong> "High availability", "global reach", "auto-scaling"</p>
<hr />
<h3>Pattern 2: Serverless API Backend</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Client
        APP[Mobile/Web App]
    end

    subgraph API[&quot;API Layer&quot;]
        AG[API Gateway]
        CR[Cloud Run]
    end

    subgraph Services[&quot;Backend&quot;]
        FS[Firestore]
        PS[Pub/Sub]
        CF[Cloud Functions]
    end

    APP --&gt; AG --&gt; CR
    CR --&gt; FS
    CR --&gt; PS --&gt; CF

    style CR fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<p><strong>Use When:</strong> "No infrastructure management", "pay per request", "variable traffic"</p>
<hr />
<h3>Pattern 3: Data Analytics Pipeline</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Ingest[&quot;Ingestion&quot;]
        IOT[IoT Devices]
        LOG[App Logs]
    end

    subgraph Stream[&quot;Streaming&quot;]
        PS[Pub/Sub]
        DF[Dataflow]
    end

    subgraph Store[&quot;Storage&quot;]
        BQ[BigQuery]
        GCS[Cloud Storage]
    end

    subgraph Analyze[&quot;Analysis&quot;]
        DS[Data Studio]
        ML[Vertex AI]
    end

    IOT &amp; LOG --&gt; PS --&gt; DF --&gt; BQ &amp; GCS --&gt; DS &amp; ML

    style BQ fill:#fff3e0,stroke:#ff9800,stroke-width:2px
</code></pre>
<p><strong>Use When:</strong> "Real-time analytics", "process petabytes", "ML insights"</p>
<hr />
<h3>Pattern 4: Secure Enterprise (Compliance)</h3>
<pre><code class="language-mermaid">flowchart TD
    subgraph OnPrem[&quot;On-Premises&quot;]
        DC[Data Center]
    end

    subgraph GCP[&quot;GCP (VPC)&quot;]
        subgraph Private[&quot;Private Subnet&quot;]
            GKE[GKE Private]
            SQL[Cloud SQL Private]
        end
        VPNSC[VPC Service Controls]
    end

    DC --&gt;|VPN/Interconnect| GCP
    VPNSC --&gt; Private

    style VPNSC fill:#ffebee,stroke:#f44336,stroke-width:2px
</code></pre>
<p><strong>Use When:</strong> "No public IPs", "regulatory compliance", "hybrid cloud"</p>
<hr />
<h2>ğŸ¯ 3. The Elimination Strategy</h2>
<h3>Step-by-Step Process</h3>
<pre><code class="language-mermaid">flowchart TD
    Q[Read Question] --&gt; R1[Step 1: Eliminate Fake Services]
    R1 --&gt; R2[Step 2: Eliminate Wrong Scope]
    R2 --&gt; R3[Step 3: Eliminate Wrong Type]
    R3 --&gt; R4[Step 4: Choose Best Match]

    R1 -.-&gt; E1[&quot;'Google Relational Store' = FAKE&quot;]
    R2 -.-&gt; E2[&quot;'Global DB' but answer is Cloud SQL = WRONG&quot;]
    R3 -.-&gt; E3[&quot;'Unstructured' but answer is BigQuery = WRONG&quot;]
</code></pre>
<h3>Quick Reference: Scope Matching</h3>
<table>
<thead>
<tr>
<th>Scope</th>
<th>Correct Services</th>
<th>Wrong Services</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Global</strong></td>
<td>Spanner, Global LB, Cloud CDN</td>
<td>Cloud SQL, Regional LB</td>
</tr>
<tr>
<td><strong>Regional</strong></td>
<td>Cloud SQL, Cloud Run, MIG</td>
<td>Cloud Spanner</td>
</tr>
<tr>
<td><strong>Zonal</strong></td>
<td>Compute Engine, Persistent Disk</td>
<td>Regional resources</td>
</tr>
</tbody>
</table>
<h3>Quick Reference: Data Type Matching</h3>
<table>
<thead>
<tr>
<th>Data Type</th>
<th>Correct Services</th>
<th>Wrong Services</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Relational</strong></td>
<td>Cloud SQL, Spanner</td>
<td>Bigtable, Firestore</td>
</tr>
<tr>
<td><strong>Key-Value</strong></td>
<td>Firestore, Memorystore</td>
<td>Cloud SQL</td>
</tr>
<tr>
<td><strong>Time-Series</strong></td>
<td>Bigtable</td>
<td>Cloud SQL, Spanner</td>
</tr>
<tr>
<td><strong>Analytics</strong></td>
<td>BigQuery</td>
<td>Cloud SQL</td>
</tr>
<tr>
<td><strong>Unstructured</strong></td>
<td>Cloud Storage</td>
<td>BigQuery</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 4. Scenario Practice</h2>
<h3>Scenario 1</h3>
<blockquote>
<p>"A gaming company needs to store player scores with sub-millisecond reads. Global users. Writes happen frequently."</p>
</blockquote>
<p><strong>Analysis:</strong>
- Sub-millisecond reads â†’ Fast storage
- Global â†’ All regions
- Frequent writes â†’ High throughput</p>
<p><strong>Answer:</strong> <strong>Bigtable</strong> (wide-column, global, low latency)</p>
<hr />
<h3>Scenario 2</h3>
<blockquote>
<p>"A startup wants to run a Python web app. They have no DevOps team and unpredictable traffic."</p>
</blockquote>
<p><strong>Analysis:</strong>
- No DevOps â†’ Managed/Serverless
- Python web app â†’ Container or PaaS
- Unpredictable traffic â†’ Auto-scaling</p>
<p><strong>Answer:</strong> <strong>Cloud Run</strong> (serverless, scales to zero, no infra management)</p>
<hr />
<h3>Scenario 3</h3>
<blockquote>
<p>"A bank needs to store transaction records for 7 years. Data must be encrypted with keys they control."</p>
</blockquote>
<p><strong>Analysis:</strong>
- 7 years â†’ Archive/Coldline storage
- Bank â†’ Compliance requirement
- Keys they control â†’ CMEK</p>
<p><strong>Answer:</strong> <strong>Cloud Storage (Archive) + CMEK</strong></p>
<hr />
<h2>âš ï¸ 5. Exam Traps</h2>
<h3>âŒ Common Mistakes</h3>
<table>
<thead>
<tr>
<th>Trap</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Cloud SQL is global"</td>
<td>No! Cloud SQL is regional (use Spanner for global)</td>
</tr>
<tr>
<td>"BigQuery stores files"</td>
<td>No! BigQuery is for analytics, use GCS for files</td>
</tr>
<tr>
<td>"App Engine is containers"</td>
<td>No! App Engine is PaaS, Cloud Run is containers</td>
</tr>
<tr>
<td>"Firestore is SQL"</td>
<td>No! Firestore is NoSQL document DB</td>
</tr>
</tbody>
</table>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>A customer needs a fault-tolerant web app that auto-scales based on traffic. What should they use?</strong></p>
<ul>
<li>A. Single Compute Engine VM</li>
<li>B. <strong>Managed Instance Group with autoscaling</strong> âœ…</li>
<li>C. Cloud Functions</li>
<li>D. Cloud SQL</li>
</ul>
</li>
<li>
<p><strong>You need to store 1 petabyte of sensor logs and query them with SQL. What's the best option?</strong></p>
<ul>
<li>A. Cloud SQL</li>
<li>B. Firestore</li>
<li>C. <strong>BigQuery</strong> âœ…</li>
<li>D. Cloud Storage</li>
</ul>
</li>
<li>
<p><strong>A company needs global, ACID-compliant transactions. Which database should they use?</strong></p>
<ul>
<li>A. Cloud SQL</li>
<li>B. Firestore</li>
<li>C. <strong>Cloud Spanner</strong> âœ…</li>
<li>D. Bigtable</li>
</ul>
</li>
<li>
<p><strong>You need to run a script every night at 2 AM. What's the simplest solution?</strong></p>
<ul>
<li>A. Compute Engine cron job</li>
<li>B. <strong>Cloud Scheduler + Cloud Functions</strong> âœ…</li>
<li>C. Always-on Cloud Run service</li>
<li>D. GKE CronJob</li>
</ul>
</li>
<li>
<p><strong>A marketing team wants a cheap static website. What should they use?</strong></p>
<ul>
<li>A. App Engine Standard</li>
<li>B. Compute Engine</li>
<li>C. <strong>Cloud Storage (static website) + Cloud CDN</strong> âœ…</li>
<li>D. Cloud Run</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "Architecture Thinking", "def": "Matching business requirements to GCP service capabilities."},
  {"term": "Elimination Strategy", "def": "Remove fake services, wrong scope, and wrong type to find the answer."},
  {"term": "MIG", "def": "Managed Instance Group. Auto-scaling, auto-healing group of VMs."},
  {"term": "Serverless", "def": "No infrastructure management. Pay per request. Cloud Run, Functions."},
  {"term": "Best Practice", "def": "Use managed services over DIY. Choose the narrowest capability that fits."},
  {"term": "Fault Tolerance", "def": "System continues operating despite failures. Use multi-zone/region."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_21_week_3_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 21: Week 3 Review &amp; Kubernetes Deep Dive</h1>
<p><strong>Level:</strong> Review / Milestone<br />
<strong>Milestone:</strong> ğŸ Week 3 Complete! (Kubernetes Mastered)</p>
<hr />
<h2>ğŸ” 1. Week 3 Visual Recap</h2>
<p>Kubernetes is the most complex topic in the ACE exam. Let's look at how all the pieces we learned fit together in a single production architecture.</p>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;External Access&quot;
        User[User Browser] --&gt; ING[Ingress: /api]
        ING --&gt; SVC[LoadBalancer Service]
    end

    subgraph &quot;The Application&quot;
        SVC --&gt; P1[Frontend Pod]
        SVC --&gt; P2[Frontend Pod]
    end

    subgraph &quot;The Secrets &amp; Config&quot;
        CM[ConfigMap: Theme] -.-&gt; P1
        SEC[Secret: API Key] -.-&gt; P1
    end

    subgraph &quot;The Backend (Stateful)&quot;
        P1 --&gt; BSVC[ClusterIP Service]
        BSVC --&gt; STS[StatefulSet: db-0]
        STS --&gt; PVC[PersistentVolumeClaim]
        PVC --&gt; PD[GCP Persistent Disk]
    end
</code></pre>
<hr />
<h2>ğŸ¯ 2. ACE Exam: High-Frequency Scenarios</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Scenario</th>
<th style="text-align: left;">Recommended Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>"Minimize management overhead for GKE"</strong></td>
<td style="text-align: left;"><strong>Autopilot Mode</strong>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Running a database that needs fixed disk storage"</strong></td>
<td style="text-align: left;"><strong>StatefulSet</strong> + Persistent Volume.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Injecting non-sensitive environment variables"</strong></td>
<td style="text-align: left;"><strong>ConfigMap</strong>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Exposing an HTTP app with path-based routing (/v1, /v2)"</strong></td>
<td style="text-align: left;"><strong>Ingress</strong>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Ensuring specific hardware (GPUs) is used"</strong></td>
<td style="text-align: left;"><strong>GKE Standard</strong> + Node Pools.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§ª 3. Hands-On Review Lab: The "Full Stack" Blueprint</h2>
<p>In this review lab, we unify everything into one cohesive deployment.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Deploy a web application, provide it with a config, and expose it to the internet.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Configure Environment</strong>:
    <code>bash
    kubectl create configmap web-config --from-literal=ENVIRONMENT=production</code></p>
</li>
<li>
<p><strong>Deploy Application</strong> (<code>review-app.yaml</code>):
    <code>yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: review-web
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: review-web
      template:
        metadata:
          labels:
            app: review-web
        spec:
          containers:
          - name: nginx
            image: nginx:latest
            env:
            - name: APP_ENV
              valueFrom:
                configMapKeyRef:
                  name: web-config
                  key: ENVIRONMENT</code></p>
</li>
<li>
<p><strong>Expose via LoadBalancer</strong>:
    <code>bash
    kubectl expose deployment review-web --type=LoadBalancer --port=80</code></p>
</li>
<li>
<p><strong>Verification</strong>: 
    <code>kubectl get services</code> -&gt; Click the External IP.</p>
</li>
</ol>
<hr />
<h2>ğŸ“ 4. Week 3 Mock Exam (ACE Standards)</h2>
<ol>
<li>
<p><strong>A team needs to deploy 50 different microservices, each requiring its own external IP address for HTTP traffic. What is the most COST-EFFECTIVE way to handle this in GKE?</strong></p>
<ul>
<li>A. Create 50 Services of type LoadBalancer.</li>
<li>B. <strong>Create 50 ClusterIP Services and one Ingress object with routing rules.</strong> âœ…</li>
<li>C. Use NodePort services for all 50 apps.</li>
<li>D. Create 50 separate GKE clusters.</li>
</ul>
</li>
<li>
<p><strong>You are migrating a legacy license-server that is hardcoded to look for a host with the specific name 'lic-srv-01'. Which Kubernetes object ensures the pod always gets this specific hostname?</strong></p>
<ul>
<li>A. Deployment</li>
<li>B. <strong>StatefulSet</strong> âœ…</li>
<li>C. DaemonSet</li>
<li>D. ReplicaSet</li>
</ul>
</li>
<li>
<p><strong>A developer wants to SSH into the GKE worker nodes to debug a kernel crash. Which GKE mode must the cluster be using?</strong></p>
<ul>
<li>A. Autopilot</li>
<li>B. <strong>Standard</strong> âœ…</li>
<li>C. Serverless</li>
<li>D. Cloud Run</li>
</ul>
</li>
<li>
<p><strong>You need to ensure that your GKE cluster can automatically scale up when there are no more resources for new pods, and scale down when nodes are underutilized. Which feature must you enable?</strong></p>
<ul>
<li>A. Horizontal Pod Autoscaler (HPA)</li>
<li>B. <strong>Cluster Autoscaler</strong> âœ…</li>
<li>C. Vertical Pod Autoscaler (VPA)</li>
<li>D. Cloud Load Balancer</li>
</ul>
</li>
<li>
<p><strong>True or False: In GKE Autopilot, you pay for the number of nodes in the 'Google-managed' project.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False (You pay for the CPU/RAM requested by your Pods)</strong> âœ…</li>
</ul>
</li>
</ol>
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain the relationship between a Deployment and a Service.', checked: false },
        { text: 'I know when to choose Autopilot vs Standard.', checked: false },
        { text: 'I understand why Ingress is better than individual LoadBalancers.', checked: false },
        { text: 'I completed the Week 3 final review lab.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Week 3 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_22_cloud_ops">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Module 13: Cloud Operations</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 22, you will be able to:
*   <strong>Differentiate</strong> between Cloud Monitoring (Metrics) and Cloud Logging (Audit/Text).
*   <strong>Visualize</strong> the flow of logs using Sinks and Exports.
*   <strong>Architect</strong> alerting policies for proactive incident response.
*   <strong>Install</strong> and configure the Ops Agent for deep resource visibility.</p>
<hr />
<h2>ğŸ¢ Industry Context: Observability in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> SRE and DevOps roles are DEFINED by observability skills. This section is career-critical.</p>
</blockquote>
<h3>Job Roles &amp; Observability Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Ops Suite</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SRE</strong></td>
<td>Define SLIs/SLOs, incident response</td>
<td>Dashboards, alerting, postmortems</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Pipeline monitoring, logging</td>
<td>Log sinks, build metrics</td>
</tr>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Infrastructure health</td>
<td>VM monitoring, uptime checks</td>
</tr>
<tr>
<td><strong>Security Engineer</strong></td>
<td>Audit logging, compliance</td>
<td>Log exports to BigQuery for analysis</td>
</tr>
</tbody>
</table>
<h3>Production Observability Stack</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Purpose</th>
<th>Storage Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Monitoring</strong></td>
<td>Metrics, dashboards, alerts</td>
<td>6 weeks (free tier)</td>
</tr>
<tr>
<td><strong>Cloud Logging</strong></td>
<td>Logs, audit trails</td>
<td>30 days default</td>
</tr>
<tr>
<td><strong>Log Sink â†’ BigQuery</strong></td>
<td>Long-term analysis</td>
<td>Years (you pay)</td>
</tr>
<tr>
<td><strong>Log Sink â†’ GCS</strong></td>
<td>Compliance archive</td>
<td>Years (cheapest)</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use logging for everything"</td>
<td>Costs add up, hard to query</td>
<td>"I use log-based metrics for alerting, sinks for storage"</td>
</tr>
<tr>
<td>"I don't set up alerts"</td>
<td>Reactive, not proactive</td>
<td>"I create alerting policies for SLO violations"</td>
</tr>
<tr>
<td>"Ops Agent is optional"</td>
<td>Missing RAM/disk visibility</td>
<td>"I always install Ops Agent for full OS metrics"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. The Operations Ecosystem</h2>
<p>The <strong>Google Cloud Operations Suite</strong> (formerly Stackdriver) is your centralized observability platform. It is split into three core pillars: <strong>Health</strong> (Monitoring), <strong>Traceability</strong> (Logging), and <strong>Intelligence</strong> (Error Reporting/Trace/Profiler).</p>
<h3>The Observability Pipeline</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Data Sources&quot;
        VM[GCE VMs]
        GKE[GKE Clusters]
        LB[Load Balancers]
    end

    subgraph &quot;Processing Room&quot;
        LOGS[Cloud Logging: Text/Events]
        METRICS[Cloud Monitoring: Numbers/Charts]
    end

    subgraph &quot;Action Center&quot;
        DASH[Dashboards]
        ALERTS[Alerting Policies]
        SINKS[Log Sinks: BQ/GCS/PubSub]
    end

    VM --&gt; LOGS
    VM --&gt; METRICS
    GKE --&gt; LOGS
    GKE --&gt; METRICS
    LB --&gt; LOGS
    LB --&gt; METRICS

    LOGS --&gt; SINKS
    LOGS --&gt; DASH
    METRICS --&gt; DASH
    METRICS --&gt; ALERTS
</code></pre>
<hr />
<h2>ğŸ“Š 2. Monitoring vs. Logging: The Great Divide</h2>
<p>Understanding the distinction is vital for the ACE exam.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Cloud Monitoring</th>
<th style="text-align: left;">Cloud Logging</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Data Type</strong></td>
<td style="text-align: left;"><strong>Metrics</strong> (Numeric/Timeseries)</td>
<td style="text-align: left;"><strong>Entries</strong> (Text/JSON/Events)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Question</strong></td>
<td style="text-align: left;">"Is the CPU high?"</td>
<td style="text-align: left;">"What exactly failed?"</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Retention</strong></td>
<td style="text-align: left;">6 weeks (basic)</td>
<td style="text-align: left;">30 days (standard)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Action</strong></td>
<td style="text-align: left;">Threshold-based Alerting</td>
<td style="text-align: left;">Log-based Metrics &amp; Sinks</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› Error Reporting, Trace &amp; Profiler</h2>
<p>The Operations Suite includes specialized tools beyond basic Monitoring and Logging. Understanding when to use each is critical for exam scenarios.</p>
<h3>Observability Tools Comparison</h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Purpose</th>
<th>Use When...</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Logging</strong></td>
<td>All logs (structured or unstructured)</td>
<td>"Show me all requests in the last hour"</td>
</tr>
<tr>
<td><strong>Error Reporting</strong></td>
<td>Crashes, exceptions, stack traces</td>
<td>"Group similar application errors"</td>
</tr>
<tr>
<td><strong>Cloud Trace</strong></td>
<td>Request latency across services</td>
<td>"Why is this API slow?"</td>
</tr>
<tr>
<td><strong>Cloud Profiler</strong></td>
<td>CPU/memory usage in production</td>
<td>"Where is my code spending time?"</td>
</tr>
</tbody>
</table>
<h3>Error Reporting Deep Dive</h3>
<p><strong>What It Does:</strong> Automatically aggregates, counts, and alerts on application exceptions (stack traces).</p>
<pre><code class="language-mermaid">flowchart LR
    subgraph &quot;Application Crashes&quot;
        E1[NullPointerException]
        E2[NullPointerException]
        E3[TimeoutException]
    end

    subgraph &quot;Error Reporting&quot;
        ER[Groups + Counts]
    end

    subgraph &quot;Output&quot;
        G1[&quot;NullPointer: 2 occurrences&quot;]
        G2[&quot;Timeout: 1 occurrence&quot;]
    end

    E1 --&gt; ER
    E2 --&gt; ER
    E3 --&gt; ER
    ER --&gt; G1
    ER --&gt; G2
</code></pre>
<h3>Why NOT Just Use Cloud Logging?</h3>
<table>
<thead>
<tr>
<th>If You Need...</th>
<th>Why Logging Falls Short</th>
<th>Use Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>Group similar errors</td>
<td>Logging shows individual entries</td>
<td><strong>Error Reporting</strong></td>
</tr>
<tr>
<td>See request flow across services</td>
<td>Logging doesn't correlate requests</td>
<td><strong>Cloud Trace</strong></td>
</tr>
<tr>
<td>Find slow code in production</td>
<td>Logging doesn't profile CPU</td>
<td><strong>Cloud Profiler</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If the question mentions "stack traces", "group similar errors", or "exception aggregation", the answer is <strong>Error Reporting</strong>.</p>
</blockquote>
<h2>ğŸ› ï¸ 3. Hands-On Lab: The "Zero Visibility" Fix</h2>
<p>By default, GCP cannot see your VM's <strong>Memory (RAM)</strong> or <strong>Disk Usage</strong>. This is because the Hypervisor only sees the outside "box" (CPU/Network).</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Install the <strong>Ops Agent</strong> to gain internal OS visibility and create an Uptime Check.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Initialize the VM</strong>:
    <code>bash
    gcloud compute instances create monitor-node --zone=us-central1-a</code></p>
</li>
<li>
<p><strong>Deploy the Ops Agent (Internal Vision)</strong>:
    SSH into the instance and run the one-liner:
    <code>bash
    curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
    sudo bash add-google-cloud-ops-agent-repo.sh --also-install</code></p>
</li>
<li>
<p><strong>Verify Metrics</strong>:
    Go to <strong>Monitoring &gt; Dashboards &gt; VM Instances</strong>.
    &gt; [!TIP]
    &gt; Notice that <code>agent.googleapis.com/memory/percent_used</code> now has data. Without the agent, this graph would be blank!</p>
</li>
<li>
<p><strong>Create a Global Uptime Check</strong>:</p>
<ul>
<li>Target: Your VM's External IP.</li>
<li>Path: <code>/</code></li>
<li>Checkers: Global (US, Europe, Asia).
<em>This tests if your app is reachable globally.</em></li>
</ul>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: Log Sinks</strong>
If you need to keep logs for 7 years (compliance), standard Cloud Logging is too expensive. You must create a <strong>Log Sink</strong> to export logs to <strong>Cloud Storage (GCS)</strong> for long-term archival or <strong>BigQuery</strong> for analysis.</p>
<p>[!WARNING]
<strong>Workspace Boundary</strong>: Monitoring data exists within a <strong>Scoping Project</strong>. You can add multiple projects to one Scoping Project to see all your VMs in a single dashboard!</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>A company needs to analyze log data from the last 2 years using SQL. Where should they export their logs?</strong></p>
<ul>
<li>A. Cloud Storage</li>
<li>B. <strong>BigQuery</strong> âœ…</li>
<li>C. Cloud Monitoring Dashboard</li>
<li>D. Pub/Sub</li>
</ul>
</li>
<li>
<p><strong>Why is the 'Ops Agent' necessary for monitoring disk space utilization on a Compute Engine VM?</strong></p>
<ul>
<li>A. To encrypt the disk.</li>
<li>B. <strong>The hypervisor cannot see the file system structure inside the Guest OS.</strong> âœ…</li>
<li>C. To improve disk performance.</li>
<li>D. To enable auto-scaling.</li>
</ul>
</li>
<li>
<p><strong>You want an SMS notification when 'DATABASE_CONNECTION_REFUSED' appears in logs. What is the best approach?</strong></p>
<ul>
<li>A. Check the Logs Explorer every hour.</li>
<li>B. <strong>Create a Log-based Metric and then an Alerting Policy.</strong> âœ…</li>
<li>C. Create an Uptime Check.</li>
<li>D. Export logs to Cloud Storage.</li>
</ul>
</li>
<li>
<p><strong>What is the default retention period for standard logs in Cloud Logging?</strong></p>
<ul>
<li>A. 7 days</li>
<li>B. <strong>30 days</strong> âœ…</li>
<li>C. 1 year</li>
<li>D. Permanently</li>
</ul>
</li>
<li>
<p><strong>What does an Uptime Check monitor?</strong></p>
<ul>
<li>A. RAM usage on a VM</li>
<li>B. <strong>Whether a URL or service is reachable</strong> âœ…</li>
<li>C. Disk space utilization</li>
<li>D. CPU temperature</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand that Monitoring is for numbers and Logging is for text.', checked: false },
        { text: 'I know that Log Sinks are used for long-term storage.', checked: false },
        { text: 'I successfully installed the Ops Agent on a VM.', checked: false },
        { text: 'I understand what a Scoping Project is.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 22 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_22_final_exams">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Day 22: The 45-Day Final Mock Exam</h1>
<blockquote>
<p><strong>Objective</strong>: Test your knowledge with exam-style questions and develop test-taking strategies.</p>
</blockquote>
<hr />
<h2>ğŸ§  Exam Day Strategy</h2>
<h3>The 3-Pass Method</h3>
<pre><code class="language-mermaid">graph LR
    P1[ğŸƒ Pass 1&lt;br&gt;Easy Questions] --&gt; P2[ğŸš¶ Pass 2&lt;br&gt;Medium Questions] --&gt; P3[ğŸ” Pass 3&lt;br&gt;Hard Questions]

    P1 --&gt;|&quot;Flag &amp; Skip&quot;| Hard1[Hard Q]
    P2 --&gt;|&quot;Flag &amp; Skip&quot;| Hard2[Very Hard Q]
</code></pre>
<ol>
<li><strong>Pass 1 (Speed)</strong>: Answer all questions you know instantly. Flag and skip the rest.</li>
<li><strong>Pass 2 (Think)</strong>: Return to flagged questions. Eliminate wrong answers.</li>
<li><strong>Pass 3 (Guess Smart)</strong>: For remaining, use elimination. Never leave blank.</li>
</ol>
<h3>Key Strategies</h3>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>How to Apply</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Read the End First</strong></td>
<td>What are they asking? "Minimize cost?" "High availability?"</td>
</tr>
<tr>
<td><strong>Eliminate 2 Answers</strong></td>
<td>Usually 2 are obviously wrong</td>
</tr>
<tr>
<td><strong>Choose "Google Way"</strong></td>
<td>Managed service &gt; DIY almost always</td>
</tr>
<tr>
<td><strong>Keyword Mapping</strong></td>
<td>Match keywords to services (see below)</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¯ Keyword Cheat Sheet</h2>
<table>
<thead>
<tr>
<th>Keywords</th>
<th>Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Global + Relational + Strong consistency"</td>
<td><strong>Spanner</strong></td>
</tr>
<tr>
<td>"Analytics + SQL + Petabytes"</td>
<td><strong>BigQuery</strong></td>
</tr>
<tr>
<td>"Serverless containers"</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>"Managed Kubernetes"</td>
<td><strong>GKE</strong></td>
</tr>
<tr>
<td>"Private connection + High bandwidth"</td>
<td><strong>Dedicated Interconnect</strong></td>
</tr>
<tr>
<td>"Over internet + Encrypted"</td>
<td><strong>Cloud VPN</strong></td>
</tr>
<tr>
<td>"Streaming + Real-time"</td>
<td><strong>Pub/Sub + Dataflow</strong></td>
</tr>
<tr>
<td>"Least privilege IAM"</td>
<td><strong>Custom roles</strong></td>
</tr>
<tr>
<td>"Auto-scaling VMs"</td>
<td><strong>Managed Instance Groups</strong></td>
</tr>
<tr>
<td>"Static website"</td>
<td><strong>Cloud Storage + Load Balancer</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ Sample Exam Questions</h2>
<h3>Section 1: Compute (Questions 1-5)</h3>
<p><strong>Q1.</strong> Your application requires VMs that can be preempted to save costs but need at least 24 hours of guaranteed runtime. Which option should you choose?</p>
<ul>
<li>A) Preemptible VMs</li>
<li>B) Spot VMs</li>
<li>C) Standard VMs with Committed Use Discount âœ…</li>
<li>D) Sole-tenant nodes</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Preemptible/Spot VMs can be terminated anytime. For guaranteed runtime, use standard VMs. CUD saves up to 57%.</p>
</blockquote>
<hr />
<p><strong>Q2.</strong> You need to run a stateless web application that auto-scales based on traffic. What should you use?</p>
<ul>
<li>A) Single Compute Engine VM</li>
<li>B) Managed Instance Group with autoscaler âœ…</li>
<li>C) Unmanaged Instance Group</li>
<li>D) Cloud Functions</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: MIGs with autoscaling handle stateless web apps. Cloud Functions is for event-driven, not sustained web traffic.</p>
</blockquote>
<hr />
<p><strong>Q3.</strong> Your company wants to run containers without managing the underlying infrastructure. They need auto-scaling to zero. Best option?</p>
<ul>
<li>A) GKE Standard</li>
<li>B) GKE Autopilot</li>
<li>C) Cloud Run âœ…</li>
<li>D) Compute Engine with Docker</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Cloud Run is serverless and scales to zero. GKE requires cluster management.</p>
</blockquote>
<hr />
<p><strong>Q4.</strong> You're running batch processing jobs that can tolerate interruptions. How do you minimize costs?</p>
<ul>
<li>A) Use preemptible/Spot VMs âœ…</li>
<li>B) Use committed use discounts</li>
<li>C) Use sustained use discounts</li>
<li>D) Use premium machine types</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Spot VMs are 60-91% cheaper and perfect for fault-tolerant batch jobs.</p>
</blockquote>
<hr />
<p><strong>Q5.</strong> An application needs dedicated physical servers for licensing compliance. What do you use?</p>
<ul>
<li>A) Standard VMs</li>
<li>B) Preemptible VMs</li>
<li>C) Sole-tenant nodes âœ…</li>
<li>D) Cloud Run</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Sole-tenant nodes provide dedicated physical servers for compliance/licensing.</p>
</blockquote>
<hr />
<h3>Section 2: Networking (Questions 6-10)</h3>
<p><strong>Q6.</strong> You need to connect your on-premises data center to GCP with a 50 Gbps dedicated private connection. Best option?</p>
<ul>
<li>A) Cloud VPN</li>
<li>B) Partner Interconnect</li>
<li>C) Dedicated Interconnect âœ…</li>
<li>D) Direct Peering</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Dedicated Interconnect provides 10-200 Gbps private connections.</p>
</blockquote>
<hr />
<p><strong>Q7.</strong> Your application serves users globally and needs to minimize latency. Which load balancer?</p>
<ul>
<li>A) Regional External TCP Load Balancer</li>
<li>B) Global External HTTP(S) Load Balancer âœ…</li>
<li>C) Internal TCP Load Balancer</li>
<li>D) Network Load Balancer</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Global HTTP(S) LB uses anycast IP and routes to nearest healthy backend.</p>
</blockquote>
<hr />
<p><strong>Q8.</strong> You want VMs in different VPCs to communicate without using public IPs. What do you configure?</p>
<ul>
<li>A) Cloud NAT</li>
<li>B) VPC Peering âœ…</li>
<li>C) Cloud VPN</li>
<li>D) Shared VPC</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: VPC Peering connects VPCs privately. Cloud NAT is for egress. Shared VPC is for multi-project.</p>
</blockquote>
<hr />
<p><strong>Q9.</strong> Your web servers need to make outbound API calls but shouldn't have public IPs. Solution?</p>
<ul>
<li>A) VPC Peering</li>
<li>B) Cloud NAT âœ…</li>
<li>C) Cloud VPN</li>
<li>D) External IP</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Cloud NAT provides outbound internet access for VMs without public IPs.</p>
</blockquote>
<hr />
<p><strong>Q10.</strong> Users report slow performance. Your static assets are served from US but most users are in Asia. Quick fix?</p>
<ul>
<li>A) Move buckets to Asia</li>
<li>B) Enable Cloud CDN âœ…</li>
<li>C) Use larger VMs</li>
<li>D) Increase bandwidth</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Cloud CDN caches content at edge locations globally, serving Asian users faster.</p>
</blockquote>
<hr />
<h3>Section 3: Storage &amp; Databases (Questions 11-15)</h3>
<p><strong>Q11.</strong> Your app needs a relational database with automatic failover and up to 64TB storage. Best choice?</p>
<ul>
<li>A) Cloud SQL âœ…</li>
<li>B) Cloud Spanner</li>
<li>C) BigQuery</li>
<li>D) Firestore</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Cloud SQL supports MySQL/PostgreSQL with HA and up to 64TB storage.</p>
</blockquote>
<hr />
<p><strong>Q12.</strong> You need a globally distributed, strongly consistent relational database. Which service?</p>
<ul>
<li>A) Cloud SQL</li>
<li>B) Cloud Spanner âœ…</li>
<li>C) Firestore</li>
<li>D) Bigtable</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Spanner is the only globally distributed, strongly consistent relational database.</p>
</blockquote>
<hr />
<p><strong>Q13.</strong> Store infrequently accessed data for at least 365 days at lowest cost. Which storage class?</p>
<ul>
<li>A) Standard</li>
<li>B) Nearline</li>
<li>C) Coldline</li>
<li>D) Archive âœ…</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Archive is cheapest for data accessed &lt; once/year with 365-day minimum.</p>
</blockquote>
<hr />
<p><strong>Q14.</strong> Your analytics team needs to run SQL queries on petabytes of log data. Best service?</p>
<ul>
<li>A) Cloud SQL</li>
<li>B) Cloud Spanner</li>
<li>C) BigQuery âœ…</li>
<li>D) Firestore</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: BigQuery is designed for petabyte-scale analytics with SQL.</p>
</blockquote>
<hr />
<p><strong>Q15.</strong> IoT devices send millions of small messages per second. You need low-latency reads/writes. Which database?</p>
<ul>
<li>A) Cloud SQL</li>
<li>B) Firestore</li>
<li>C) Bigtable âœ…</li>
<li>D) BigQuery</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Bigtable is designed for high-throughput, low-latency reads/writes at scale.</p>
</blockquote>
<hr />
<h3>Section 4: Security &amp; IAM (Questions 16-20)</h3>
<p><strong>Q16.</strong> A developer needs to read Cloud Storage objects but not delete them. Best approach?</p>
<ul>
<li>A) Grant roles/storage.admin</li>
<li>B) Grant roles/storage.objectViewer âœ…</li>
<li>C) Grant roles/owner</li>
<li>D) Create a custom role with all permissions</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: objectViewer allows read access without delete. Follow least privilege.</p>
</blockquote>
<hr />
<p><strong>Q17.</strong> Your application running on a VM needs to access Cloud Storage. Best practice?</p>
<ul>
<li>A) Store service account key on VM</li>
<li>B) Use default Compute Engine service account with necessary roles âœ…</li>
<li>C) Use your personal credentials</li>
<li>D) Create a user account for the VM</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Use attached service accounts, not keys. Keys can leak.</p>
</blockquote>
<hr />
<p><strong>Q18.</strong> You need to encrypt data with your own keys stored in GCP. Which service?</p>
<ul>
<li>A) Cloud KMS âœ…</li>
<li>B) Cloud HSM</li>
<li>C) Secret Manager</li>
<li>D) Cloud IAM</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Cloud KMS manages customer-managed encryption keys (CMEK).</p>
</blockquote>
<hr />
<p><strong>Q19.</strong> An auditor needs to view all IAM policies but not modify them. Which role?</p>
<ul>
<li>A) roles/viewer</li>
<li>B) roles/iam.securityReviewer âœ…</li>
<li>C) roles/iam.securityAdmin</li>
<li>D) roles/owner</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: securityReviewer can view policies. Viewer is too broad. Admin can modify.</p>
</blockquote>
<hr />
<p><strong>Q20.</strong> Store database passwords securely for Cloud Run applications. Best service?</p>
<ul>
<li>A) Cloud KMS</li>
<li>B) Environment variables</li>
<li>C) Secret Manager âœ…</li>
<li>D) Cloud Storage</li>
</ul>
<blockquote>
<p><strong>Explanation</strong>: Secret Manager stores, manages, and rotates secrets. Cloud Run integrates natively.</p>
</blockquote>
<hr />
<h2>ğŸ† Scoring Guide</h2>
<table>
<thead>
<tr>
<th>Score</th>
<th>Level</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td>18-20</td>
<td>ğŸ† Expert</td>
<td>Ready for exam!</td>
</tr>
<tr>
<td>14-17</td>
<td>âœ… Proficient</td>
<td>Review weak areas</td>
</tr>
<tr>
<td>10-13</td>
<td>ğŸ“– Learning</td>
<td>Study more, retake</td>
</tr>
<tr>
<td>0-9</td>
<td>ğŸ”„ Beginning</td>
<td>Review all content</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ Graduation Checklist</h2>
<p>Before taking the real exam, ensure you can:</p>
<ul>
<li>[ ] Create and manage VMs, MIGs, and autoscaling</li>
<li>[ ] Configure VPCs, subnets, firewall rules</li>
<li>[ ] Deploy applications to Cloud Run and GKE</li>
<li>[ ] Choose the right database for different scenarios</li>
<li>[ ] Implement IAM best practices (least privilege)</li>
<li>[ ] Use Cloud Monitoring and Logging</li>
<li>[ ] Estimate costs with the Pricing Calculator</li>
</ul>
<hr />
<h2>âš¡ Next Steps</h2>
<ol>
<li><strong>Book your exam</strong>: <a href="https://cloud.google.com/certification">Google Cloud Certification</a></li>
<li><strong>Practice more</strong>: <a href="https://cloud.google.com/certification/practice-exam/cloud-engineer">Official Practice Exam</a></li>
<li><strong>Build projects</strong>: Apply what you learned!</li>
</ol>
<blockquote>
<p>"The Cloud is just a tool. <strong>You</strong> are the builder."</p>
</blockquote>
<hr />
<!-- FLASHCARDS
[
  {"term": "Elimination Strategy", "def": "Remove 2 obviously wrong answers first."},
  {"term": "Keyword Mapping", "def": "Global + Relational = Spanner. Analytics + SQL = BigQuery."},
  {"term": "Managed over DIY", "def": "Always prefer Managed Services (Cloud SQL) over DIY (VM)."},
  {"term": "Least Privilege", "def": "Always give the minimum permission needed."},
  {"term": "Cost vs Speed", "def": "Know when the exam asks for Cheapest vs Fastest."},
  {"term": "3-Pass Method", "def": "Easy first, medium second, hard last with elimination."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_23_cloud_functions">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Day 23: Cloud Functions &amp; Eventarc</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 23, you will be able to:
*   <strong>Architect</strong> event-driven solutions using the "Trigger -&gt; Action" pattern.
*   <strong>Differentiate</strong> between 1st Gen and 2nd Gen Cloud Functions (Architecture &amp; Limits).
*   <strong>Implement</strong> Eventarc to unify events from 100+ Google Cloud sources.
*   <strong>Deploy</strong> a serverless function with environment variables and trigger filters.</p>
<hr />
<h2>ğŸ¢ Industry Context: Serverless in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Serverless is critical for Backend Developers and DevOps. It's the fastest path from code to production.</p>
</blockquote>
<h3>Job Roles &amp; Serverless Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Functions</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Backend Developer</strong></td>
<td>Build event-driven APIs</td>
<td>Writing functions, Eventarc triggers</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Automation and glue code</td>
<td>CI/CD triggers, cleanup automation</td>
</tr>
<tr>
<td><strong>Data Engineer</strong></td>
<td>ETL triggers and processing</td>
<td>File upload â†’ transform â†’ BigQuery</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Alerting and remediation</td>
<td>Auto-remediation on incidents</td>
</tr>
</tbody>
</table>
<h3>Cloud Run vs Cloud Functions Decision</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Cloud Functions</th>
<th>Cloud Run</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Best For</strong></td>
<td>Event-driven, simple logic</td>
<td>Complex apps, containers</td>
</tr>
<tr>
<td><strong>Cold Starts</strong></td>
<td>Higher</td>
<td>Lower (with min-instances)</td>
</tr>
<tr>
<td><strong>Concurrency</strong></td>
<td>1000 (2nd Gen)</td>
<td>1000</td>
</tr>
<tr>
<td><strong>Container Control</strong></td>
<td>None (Google builds)</td>
<td>Full (your Dockerfile)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
<strong>Interview Tip:</strong> "For simple event triggers, I use Cloud Functions. For APIs or complex apps, I use Cloud Run. Both are serverless, but Cloud Run gives me more control."</p>
</blockquote>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use 1st Gen Functions for everything"</td>
<td>Missing 2nd Gen benefits</td>
<td>"I use 2nd Gen for longer timeouts and higher concurrency"</td>
</tr>
<tr>
<td>"Cold starts are acceptable"</td>
<td>Shows no production awareness</td>
<td>"I set min-instances=1 for latency-sensitive functions"</td>
</tr>
<tr>
<td>"I put secrets in environment variables"</td>
<td>Security issue</td>
<td>"I use Secret Manager with Cloud Functions integration"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. The Serverless "Rube Goldberg" Machine</h2>
<p>Cloud Functions are designed for <strong>Glue Code</strong>. They connect disparate services without requiring you to manage a single server, container, or runtime environment.</p>
<h3>Event-Driven Flow</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;The Trigger&quot;
        GCS[Cloud Storage: Upload]
        PUB[Pub/Sub: Message]
        AUD[Audit Log: VM Created]
    end

    subgraph &quot;The Glue&quot;
        EA[Eventarc / Trigger]
    end

    subgraph &quot;The Action&quot;
        CF[Cloud Function]
        DB[Update Firestore]
    end

    GCS --&gt; EA
    PUB --&gt; EA
    AUD --&gt; EA
    EA --&gt; CF
    CF --&gt; DB
</code></pre>
<hr />
<h2>âš¡ 2. 1st Gen vs. 2nd Gen: The Shift to Cloud Run</h2>
<p>Cloud Functions 2nd Gen is actually powered by <strong>Cloud Run</strong> under the hood, giving it massive performance and flexibility gains.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">1st Generation</th>
<th style="text-align: left;">2nd Generation (ACE Choice)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Max Timeout</strong></td>
<td style="text-align: left;">9 Minutes</td>
<td style="text-align: left;"><strong>60 Minutes</strong> (HTTP)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Concurrency</strong></td>
<td style="text-align: left;">1 request per instance</td>
<td style="text-align: left;"><strong>1000+ requests per instance</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Max Memory</strong></td>
<td style="text-align: left;">8 GB</td>
<td style="text-align: left;"><strong>16 GB+</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Triggers</strong></td>
<td style="text-align: left;">Limited (PubSub/GCS)</td>
<td style="text-align: left;"><strong>Eventarc (100+ Event Types)</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Traffic Splitting</strong></td>
<td style="text-align: left;">Not natively supported</td>
<td style="text-align: left;"><strong>Supported (Blue/Green)</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: The "Auto-Log" Trigger</h2>
<p>We will create a function that automatically logs metadata whenever a file is uploaded to a specific bucket.</p>
<h3>ğŸ§ª Lab Objective</h3>
<p>Deploy a 2nd Gen Python function and use Eventarc to bridge Cloud Storage events to it.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Prepare the Storage Bucket</strong>:
    <code>bash
    export BUCKET_NAME="my-event-bucket-${PROJECT_ID}"
    gcloud storage buckets create gs://$BUCKET_NAME --location=us-central1</code></p>
</li>
<li>
<p><strong>Define the Logic</strong> (<code>main.py</code>):
    ```python
    import functions_framework</p>
<p>@functions_framework.cloud_event
def monitor_gcs(cloud_event):
    data = cloud_event.data
    name = data["name"]
    bucket = data["bucket"]
    print(f"File {name} detected in bucket {bucket}!")
```</p>
</li>
<li>
<p><strong>Deploy as 2nd Gen</strong>:
    <code>bash
    gcloud functions deploy cloud-visual-logs \
      --gen2 \
      --runtime=python310 \
      --region=us-central1 \
      --source=. \
      --entry-point=monitor_gcs \
      --trigger-event-filters="type=google.cloud.storage.object.v1.finalized" \
      --trigger-event-filters="bucket=$BUCKET_NAME"</code></p>
</li>
<li>
<p><strong>Test &amp; Audit</strong>:
    Upload a dummy file and check the logs in the <strong>Cloud Logging</strong> console or via CLI:
    <code>bash
    gcloud functions logs read cloud-visual-logs --gen2 --region=us-central1</code></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: The 9-Minute Wall</strong>
If an exam question asks you to process a large file that takes <strong>15 minutes</strong> to complete, Cloud Functions <strong>1st Gen</strong> is the WRONG answer. You must use <strong>2nd Gen</strong> or <strong>Cloud Run</strong>.</p>
<p>[!TIP]
<strong>Cold Starts</strong>: To eliminate "Cold Start" latency for production-critical functions, set <code>--min-instances 1</code>. This keeps one instance always warm and ready (but you'll pay for it!).</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which technology powers Cloud Functions 2nd Gen, allowing for high concurrency and longer timeouts?</strong></p>
<ul>
<li>A. App Engine</li>
<li>B. <strong>Cloud Run</strong> âœ…</li>
<li>C. Compute Engine</li>
<li>D. Cloud Build</li>
</ul>
</li>
<li>
<p><strong>You need to trigger a function whenever a new BigQuery dataset is created. Which service unifies these events for Cloud Functions?</strong></p>
<ul>
<li>A. Cloud Scheduler</li>
<li>B. <strong>Eventarc</strong> âœ…</li>
<li>C. Pub/Sub</li>
<li>D. Cloud Tasks</li>
</ul>
</li>
<li>
<p><strong>An application requirement states that a function must handle 100 concurrent requests within a single instance to reduce costs. Which version should you use?</strong></p>
<ul>
<li>A. Cloud Functions 1st Gen</li>
<li>B. <strong>Cloud Functions 2nd Gen</strong> âœ…</li>
<li>C. Cloud Functions legacy</li>
<li>D. Local Docker container</li>
</ul>
</li>
<li>
<p><strong>What is the primary use case for Cloud Functions in a Google Cloud architecture?</strong></p>
<ul>
<li>A. Hosting a complex, high-traffic web application.</li>
<li>B. <strong>Acting as 'Glue Code' to respond to cloud events.</strong> âœ…</li>
<li>C. Storing large amounts of unstructured data.</li>
<li>D. Running long-term stateful databases.</li>
</ul>
</li>
<li>
<p><strong>How can you eliminate cold start latency for production-critical functions?</strong></p>
<ul>
<li>A. Use 1st Gen instead of 2nd Gen</li>
<li>B. <strong>Set min-instances to 1 to keep an instance warm</strong> âœ…</li>
<li>C. Increase the memory allocation</li>
<li>D. Deploy to multiple regions</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand why 2nd Gen is superior for long-running tasks.', checked: false },
        { text: 'I can explain the role of Eventarc as an event broker.', checked: false },
        { text: 'I know how to deploy a function with specific event filters.', checked: false },
        { text: 'I understand the trade-off of using min-instances.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 23 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_23_cloud_spanner_bigtable">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>BONUS: Cloud Spanner &amp; Bigtable Deep Dive</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­ Medium (Database selection questions)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Understand</strong> globally distributed database architecture</li>
<li><strong>Compare</strong> Spanner vs Bigtable vs Cloud SQL use cases</li>
<li><strong>Apply</strong> CAP theorem to database selection</li>
<li><strong>Design</strong> schemas for each database type</li>
</ul>
<hr />
<h2>ğŸ§  1. The Database Selection Problem</h2>
<p><strong>Which database do I use?</strong> This is one of the most common GCP architecture questions.</p>
<h3>ğŸ’¡ Real-World Analogy: Storage Facilities</h3>
<table>
<thead>
<tr>
<th>Database</th>
<th>Analogy</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud SQL</strong></td>
<td>Personal safe deposit box</td>
<td>Structured data, transactions</td>
</tr>
<tr>
<td><strong>Spanner</strong></td>
<td>Global bank network</td>
<td>Global scale + ACID transactions</td>
</tr>
<tr>
<td><strong>Bigtable</strong></td>
<td>Giant warehouse with shelves</td>
<td>High-throughput, time-series</td>
</tr>
<tr>
<td><strong>Firestore</strong></td>
<td>Filing cabinet</td>
<td>Mobile/web app data</td>
</tr>
<tr>
<td><strong>BigQuery</strong></td>
<td>Library archives</td>
<td>Analytics, historical queries</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸŒ 2. Cloud Spanner: The Global Database</h2>
<h3>What Makes Spanner Special?</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Traditional SQL&quot;
        T1[Transactions] --&gt; T2[ACID]
        T2 --&gt; T3[Single Region]
    end

    subgraph &quot;Traditional NoSQL&quot;
        N1[Scale] --&gt; N2[Global]
        N2 --&gt; N3[Eventually Consistent]
    end

    subgraph &quot;Cloud Spanner&quot;
        S1[Transactions + ACID] --&gt; S2[Global Scale]
        S2 --&gt; S3[Strong Consistency]
        S3 --&gt; S4[99.999% SLA]
    end

    style S4 fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>TrueTime: The Secret Sauce</h3>
<p>Spanner uses <strong>atomic clocks + GPS</strong> in every data center to synchronize time globally within microseconds. This enables:
- Global strong consistency
- Lock-free reads
- Serializable transactions across continents</p>
<h3>When to Use Spanner</h3>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Why Spanner</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global financial systems</td>
<td>ACID across regions, zero data loss</td>
</tr>
<tr>
<td>Gaming leaderboards</td>
<td>Low latency worldwide</td>
</tr>
<tr>
<td>Inventory management</td>
<td>Consistent stock counts globally</td>
</tr>
<tr>
<td>Healthcare records</td>
<td>Compliance + availability</td>
</tr>
</tbody>
</table>
<h3>Spanner Pricing Considerations</h3>
<ul>
<li><strong>Minimum:</strong> 1 node (~$0.90/hour)</li>
<li><strong>Not for:</strong> Small projects, dev/test (use Cloud SQL instead)</li>
<li><strong>Sweet spot:</strong> 10TB+ data, global users</li>
</ul>
<hr />
<h2>ğŸ“Š 3. Bigtable: The Wide-Column Workhorse</h2>
<h3>Architecture Overview</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Clients
        C1[IoT Devices]
        C2[Analytics]
        C3[ML Pipelines]
    end

    subgraph Bigtable[&quot;Bigtable Cluster&quot;]
        N1[Node 1]
        N2[Node 2]
        N3[Node N]
    end

    subgraph Storage[&quot;Colossus (Google Storage)&quot;]
        T1[Tablet 1]
        T2[Tablet 2]
        T3[Tablet N]
    end

    Clients --&gt; Bigtable --&gt; Storage

    style Bigtable fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<h3>Key Characteristics</h3>
<ul>
<li><strong>Schema:</strong> Row key + Column families + Timestamps</li>
<li><strong>Scale:</strong> Petabytes, millions of ops/sec</li>
<li><strong>Latency:</strong> Single-digit milliseconds</li>
<li><strong>No:</strong> Joins, secondary indexes, SQL</li>
</ul>
<h3>When to Use Bigtable</h3>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Why Bigtable</th>
</tr>
</thead>
<tbody>
<tr>
<td>Time-series data</td>
<td>IoT sensors, stock prices</td>
</tr>
<tr>
<td>User analytics</td>
<td>Clickstream, session data</td>
</tr>
<tr>
<td>ML feature store</td>
<td>Fast lookups for training</td>
</tr>
<tr>
<td>Graph data</td>
<td>Social connections</td>
</tr>
</tbody>
</table>
<h3>Row Key Design (Critical!)</h3>
<pre><code># GOOD: Reverse timestamp for recent-first queries
rowKey = &quot;user#123#20240115120000&quot;

# BAD: Sequential timestamps (hotspotting)
rowKey = &quot;20240115120000#user#123&quot;

# GOOD: Salted prefix for distribution
rowKey = &quot;a#user#123#20240115&quot;  # where 'a' = hash(user_id) % 10
</code></pre>
<hr />
<h2>4. CAP Theorem &amp; GCP Databases</h2>
<h3>The CAP Trade-off</h3>
<pre><code class="language-mermaid">graph TD
    C[Consistency] --- A[Availability]
    A --- P[Partition Tolerance]
    P --- C

    CS[Cloud SQL] --&gt; CA[CA: Consistency + Availability]
    BT[Bigtable] --&gt; AP[AP: Availability + Partition]
    SP[Spanner] --&gt; CP[CP: Consistency + Partition&lt;br&gt;+ External Consistency!]

    style SP fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Database Selection Matrix</h3>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Cloud SQL</th>
<th>Spanner</th>
<th>Bigtable</th>
<th>Firestore</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ACID transactions</strong></td>
<td>âœ…</td>
<td>âœ…</td>
<td>âŒ</td>
<td>âœ… (limited)</td>
</tr>
<tr>
<td><strong>Global scale</strong></td>
<td>âŒ</td>
<td>âœ…</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td><strong>SQL support</strong></td>
<td>âœ…</td>
<td>âœ…</td>
<td>âŒ</td>
<td>âŒ</td>
</tr>
<tr>
<td><strong>Sub-ms latency</strong></td>
<td>âš¡</td>
<td>âš¡</td>
<td>âš¡âš¡</td>
<td>âš¡</td>
</tr>
<tr>
<td><strong>Petabyte scale</strong></td>
<td>âŒ</td>
<td>âœ…</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>ğŸ’°</td>
<td>ğŸ’°ğŸ’°ğŸ’°</td>
<td>ğŸ’°ğŸ’°</td>
<td>ğŸ’°</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 5. Quick Lab: Query Both Databases</h2>
<h3>Spanner Query (SQL)</h3>
<pre><code class="language-sql">-- Spanner uses standard SQL
SELECT 
    user_id, 
    username,
    created_at
FROM Users
WHERE region = 'us-central1'
ORDER BY created_at DESC
LIMIT 100;
</code></pre>
<h3>Bigtable Query (HBase CLI)</h3>
<pre><code class="language-bash"># Bigtable uses HBase shell or client libraries
# Scan recent rows for a user
scan 'user_events', {
    ROWPREFIXFILTER =&gt; 'user#123#',
    LIMIT =&gt; 100,
    REVERSED =&gt; true
}
</code></pre>
<h3>Bigtable with Python</h3>
<pre><code class="language-python">from google.cloud import bigtable

client = bigtable.Client(project='my-project', admin=True)
instance = client.instance('my-instance')
table = instance.table('user_events')

# Read rows
rows = table.read_rows(row_set=row_set, limit=100)
for row in rows:
    print(row.row_key, row.cells)
</code></pre>
<hr />
<h2>âš ï¸ 6. Common Pitfalls</h2>
<h3>Spanner Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Impact</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using for small data</td>
<td>Expensive overkill</td>
<td>Use Cloud SQL</td>
</tr>
<tr>
<td>Poor interleaving</td>
<td>Slow joins</td>
<td>Design parent-child tables</td>
</tr>
<tr>
<td>No indexes</td>
<td>Full scans</td>
<td>Create secondary indexes</td>
</tr>
</tbody>
</table>
<h3>Bigtable Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Impact</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sequential row keys</td>
<td>Hotspotting</td>
<td>Reverse/salt row keys</td>
</tr>
<tr>
<td>Too many column families</td>
<td>Slow reads</td>
<td>Keep &lt;10 families</td>
</tr>
<tr>
<td>Using for small data</td>
<td>Min 3 nodes = $$</td>
<td>Use Firestore instead</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¯ 7. ACE Exam Focus</h2>
<h3>Quick Decision Guide</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Global, ACID, SQL"</td>
<td><strong>Spanner</strong></td>
</tr>
<tr>
<td>"IoT time-series, millions writes/sec"</td>
<td><strong>Bigtable</strong></td>
</tr>
<tr>
<td>"MySQL compatibility needed"</td>
<td><strong>Cloud SQL</strong></td>
</tr>
<tr>
<td>"Mobile app, offline sync"</td>
<td><strong>Firestore</strong></td>
</tr>
<tr>
<td>"Analytics, petabyte queries"</td>
<td><strong>BigQuery</strong></td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>Spanner is expensive</strong> - minimum cost ~$650/month</li>
<li>âš ï¸ <strong>Bigtable has no SQL</strong> - HBase API only</li>
<li>âš ï¸ <strong>Bigtable minimum is 1 node</strong> production, scales to thousands</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which GCP database provides global ACID transactions with SQL support?</strong></p>
<ul>
<li>A. Bigtable</li>
<li>B. Firestore</li>
<li>C. <strong>Cloud Spanner</strong> âœ…</li>
<li>D. Cloud SQL</li>
</ul>
</li>
<li>
<p><strong>What type of data model does Bigtable use?</strong></p>
<ul>
<li>A. Relational (tables with joins)</li>
<li>B. Document (JSON)</li>
<li>C. <strong>Wide-column (row key + column families)</strong> âœ…</li>
<li>D. Graph</li>
</ul>
</li>
<li>
<p><strong>You're building an IoT platform that ingests millions of sensor readings per second. Which database is best?</strong></p>
<ul>
<li>A. Cloud SQL</li>
<li>B. Firestore</li>
<li>C. <strong>Bigtable</strong> âœ…</li>
<li>D. Cloud Spanner</li>
</ul>
</li>
<li>
<p><strong>What technology does Cloud Spanner use to achieve global consistency?</strong></p>
<ul>
<li>A. Two-phase commit</li>
<li>B. Paxos consensus</li>
<li>C. <strong>TrueTime (atomic clocks + GPS)</strong> âœ…</li>
<li>D. Vector clocks</li>
</ul>
</li>
<li>
<p><strong>Which is a critical Bigtable row key design mistake?</strong></p>
<ul>
<li>A. Using composite keys</li>
<li>B. <strong>Using sequential timestamps as prefix</strong> âœ…</li>
<li>C. Including user IDs</li>
<li>D. Using reverse timestamps</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud Spanner", "def": "Globally distributed, horizontally scalable SQL database with ACID transactions. Uses TrueTime for consistency."},
  {"term": "Bigtable", "def": "Wide-column NoSQL database for high-throughput workloads. Great for time-series and IoT data."},
  {"term": "TrueTime", "def": "Google's globally synchronized clock using atomic clocks and GPS. Enables Spanner's consistency."},
  {"term": "Hotspotting", "def": "When writes concentrate on few nodes due to sequential keys. Avoid by salting row keys."},
  {"term": "CAP Theorem", "def": "Distributed systems can only guarantee 2 of 3: Consistency, Availability, Partition tolerance."},
  {"term": "Wide-column", "def": "Data model with row keys, column families, and billions of columns. Used by Bigtable and HBase."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_23_iam_advanced">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 23: IAM Advanced (Service Accounts)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 23, learners will be able to:
*   <strong>Define</strong> a Service Account (SA).
*   <strong>Differentiate</strong> between User Accounts and Service Accounts.
*   <strong>Troubleshoot</strong> "Permission Denied" errors using the Policy Troubleshooter.</p>
<hr />
<h2>ğŸ§  1. What Is a Service Account?</h2>
<p>We talked about <strong>You</strong> (User) accessing GCP in Day 6.
But how does <strong>Your App</strong> (running on a VM) access a Bucket?
Apps don't have Gmail addresses. They don't have passwords.</p>
<p><strong>Solution:</strong> <strong>Service Account (SA)</strong>.
*   An Identity for a machine.
*   Email looks like: <code>my-app@project-id.iam.gserviceaccount.com</code>.
*   You grant Roles to the SA, just like a User.</p>
<hr />
<h2>ğŸ« 2. Real-World Analogy: The VIP Staff Pass</h2>
<ul>
<li><strong>User Account</strong> = <strong>Driver's License</strong>. Identifies a specific human (Bob).</li>
<li><strong>Service Account</strong> = <strong>"STAFF" Badge</strong>. <ul>
<li>Whoever wears the badge (VM, Cloud Function) gets access to the Staff Room (Bucket).</li>
<li>The badge doesn't care <em>which human</em> started the VM. It only cares that the VM has the badge.</li>
</ul>
</li>
</ul>
<hr />
<h2>ğŸ”‘ 3. Keys vs Managed Identity</h2>
<p>Two ways to "wear" the badge:
1.  <strong>Attached (Managed):</strong> You attach the SA to the VM when creating it.
    *   <strong>Secure.</strong> Google rotates the keys automatically.
    *   <em>Recommended.</em>
2.  <strong>Keys (JSON file):</strong> You download a <code>.json</code> key file.
    *   <strong>Dangerous!</strong> If you leak this on GitHub, hackers are instantly YOU.
    *   <em>Avoid unless absolutely necessary (e.g., On-prem server).</em></p>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Service Account Access</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Create a VM that <em>cannot</em> access Storage, then fix it.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Create Bucket:</strong> <code>gsutil mb gs://my-secret-bucket-[RANDOM]</code></li>
<li><strong>Create VM (Default SA):</strong><ul>
<li>Create a standard VM. (It uses the <em>Compute Engine Default SA</em>).</li>
<li>SSH into it.</li>
<li>Run <code>gsutil ls gs://my-secret-bucket...</code> -&gt; <strong>Success</strong>.</li>
<li><em>Why?</em> The Default SA is too powerful (Editor role).</li>
</ul>
</li>
<li><strong>Create Custom SA:</strong><ul>
<li>IAM &gt; Service Accounts &gt; Create.</li>
<li>Name: <code>restricted-sa</code>. Do <strong>NOT</strong> grant any roles yet.</li>
</ul>
</li>
<li><strong>Create VM (Restricted):</strong><ul>
<li>Create VM. In <strong>Identity and API Access</strong>, select <code>restricted-sa</code>.</li>
<li>SSH into it.</li>
<li>Run <code>gsutil ls ...</code> -&gt; <strong>AccessDeniedException</strong>.</li>
</ul>
</li>
<li><strong>Fix it:</strong><ul>
<li>Go to Console &gt; Storage &gt; Bucket.</li>
<li>Grant <code>Storage Object Viewer</code> to <code>restricted-sa@...</code>.</li>
<li>Try SSH command again. -&gt; <strong>Success!</strong></li>
</ul>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Quick Knowledge Check (Quiz)</h2>
<ol>
<li>
<p><strong>What is a Service Account?</strong></p>
<ul>
<li>A. A Gmail account for admins.</li>
<li>B. <strong>A special account representing a non-human application/machine.</strong> âœ…</li>
<li>C. A billing account.</li>
</ul>
</li>
<li>
<p><strong>Which practice is recommended for granting access to a VM running on GCP?</strong></p>
<ul>
<li>A. Download a JSON key and upload it to the VM.</li>
<li>B. <strong>Attach the Service Account to the VM (Managed Identity).</strong> âœ…</li>
<li>C. Hardcode your username/password.</li>
</ul>
</li>
<li>
<p><strong>You accidentally uploaded a Service Account JSON key to a public GitHub repo. What should you do?</strong></p>
<ul>
<li>A. Delete the repo.</li>
<li>B. <strong>Revoke/Delete the key immediately in console.</strong> âœ…</li>
<li>C. Hope no one sees it.</li>
</ul>
</li>
<li>
<p><strong>Your colleague gets a "403 Permission Denied" error. Which tool helps identify the missing role?</strong></p>
<ul>
<li>A. Cloud Debugger</li>
<li>B. <strong>Policy Troubleshooter</strong> âœ…</li>
<li>C. Cloud Trace</li>
</ul>
</li>
<li>
<p><strong>The "Compute Engine Default Service Account" has which role by default?</strong></p>
<ul>
<li>A. Viewer</li>
<li>B. <strong>Editor (Very broad!)</strong> âœ…</li>
<li>C. Owner</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I know what a Service Account is.', checked: false },
        { text: 'I created a custom SA with limited permissions.', checked: false },
        { text: 'I successfully swapped a VMs identity.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 23 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_24_bigquery_data_warehousing">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Module 14: BigQuery Analytics</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/bigquery/docs">BigQuery Documentation</a></p>
</blockquote>
<h2>Learning Objectives</h2>
<p>By the end of this day, you should be able to:
- Understand BigQuery's serverless architecture and when to use it
- Create datasets, tables, and run SQL queries
- Implement partitioning and clustering for cost optimization
- Load data from Cloud Storage and other sources</p>
<hr />
<h2>ğŸ¢ Industry Context: BigQuery in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> BigQuery is THE interview topic for Data Engineers. Cost optimization questions are guaranteed.</p>
</blockquote>
<h3>Job Roles &amp; BigQuery Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use BigQuery</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Build data pipelines</td>
<td>ETL, partitioning, scheduling</td>
</tr>
<tr>
<td><strong>Data Analyst</strong></td>
<td>Query and analyze</td>
<td>SQL, dashboards, reporting</td>
</tr>
<tr>
<td><strong>FinOps Analyst</strong></td>
<td>Optimize costs</td>
<td>Slot usage, query patterns</td>
</tr>
<tr>
<td><strong>ML Engineer</strong></td>
<td>Feature engineering</td>
<td>BigQuery ML, training data</td>
</tr>
</tbody>
</table>
<h3>Cost Optimization Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Savings</th>
<th>Implementation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Partitioning</strong></td>
<td>90%+</td>
<td>Filter by partition column</td>
</tr>
<tr>
<td><strong>Clustering</strong></td>
<td>50-80%</td>
<td>Sort by frequently filtered columns</td>
</tr>
<tr>
<td><strong>SELECT specific columns</strong></td>
<td>50%+</td>
<td>Avoid SELECT *</td>
</tr>
<tr>
<td><strong>Slot-based pricing</strong></td>
<td>Predictable</td>
<td>Switch at &gt; $10k/month</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I use SELECT * for convenience"</td>
<td>Wastes money scanning all columns</td>
<td>"I always select only needed columns"</td>
</tr>
<tr>
<td>"BigQuery is for everything"</td>
<td>Not for OLTP</td>
<td>"BigQuery for analytics; Cloud SQL for transactions"</td>
</tr>
<tr>
<td>"I don't partition tables"</td>
<td>Full scans are expensive</td>
<td>"I partition by date for time-based queries"</td>
</tr>
</tbody>
</table>
<h3>ğŸ” Role Lens: What Each Role Focuses On</h3>
<blockquote>
<p><strong>ğŸ”µ Data Engineer:</strong> Master partitioning, clustering, and Dataflow integration. Know how to optimize ETL costs.</p>
<p><strong>ğŸŸ¢ Data Analyst:</strong> Focus on SQL proficiency, scheduled queries, and dashboard integration with Looker.</p>
<p><strong>ğŸŸ  FinOps Analyst:</strong> Understand slot pricing vs on-demand, identify expensive queries from INFORMATION_SCHEMA.</p>
<p><strong>ğŸ”´ ML Engineer:</strong> Know BigQuery ML syntax, feature engineering techniques, and export to Vertex AI.</p>
</blockquote>
<hr />
<h2>1ï¸âƒ£ What is BigQuery? ğŸ›ï¸</h2>
<p><strong>BigQuery</strong> is Google's fully-managed, serverless data warehouse designed for large-scale analytics. Think of it as a <strong>massive library</strong> where:
- You don't manage the building (infrastructure)
- You just ask questions (SQL queries)
- You pay only for the books you read (data scanned)</p>
<h3>Architecture Overview</h3>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;BigQuery Architecture&quot;
        Client[ğŸ‘¤ User/Application]
        BQ[ğŸ”· BigQuery API]

        subgraph &quot;Dremel Engine&quot;
            Root[Root Server]
            Mix1[Mixer 1]
            Mix2[Mixer 2]
            Leaf1[Leaf 1]
            Leaf2[Leaf 2]
            Leaf3[Leaf 3]
            Leaf4[Leaf 4]
        end

        subgraph &quot;Colossus Storage&quot;
            Col1[(Column 1)]
            Col2[(Column 2)]
            Col3[(Column 3)]
        end
    end

    Client --&gt; BQ
    BQ --&gt; Root
    Root --&gt; Mix1 &amp; Mix2
    Mix1 --&gt; Leaf1 &amp; Leaf2
    Mix2 --&gt; Leaf3 &amp; Leaf4
    Leaf1 &amp; Leaf2 &amp; Leaf3 &amp; Leaf4 --&gt; Col1 &amp; Col2 &amp; Col3
</code></pre>
<h3>Key Concepts</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
<th>Analogy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Dataset</strong></td>
<td>Container for tables</td>
<td>A folder in your library</td>
</tr>
<tr>
<td><strong>Table</strong></td>
<td>Structured data storage</td>
<td>A book with chapters</td>
</tr>
<tr>
<td><strong>View</strong></td>
<td>Virtual table from a query</td>
<td>A bookmark to specific pages</td>
</tr>
<tr>
<td><strong>Partitioned Table</strong></td>
<td>Table split by date/integer</td>
<td>Books organized by year</td>
</tr>
<tr>
<td><strong>Clustered Table</strong></td>
<td>Data sorted within partitions</td>
<td>Alphabetized chapters</td>
</tr>
</tbody>
</table>
<hr />
<h2>2ï¸âƒ£ Real-World Analogy: The Infinite Library ğŸ“š</h2>
<p>Imagine a library with <strong>infinite shelves</strong> and <strong>1000 librarians</strong>:
- You ask: "Find all books about 'Cloud' published in 2024"
- All 1000 librarians search simultaneously (parallel processing)
- They only look at the 2024 section (partitioning)
- Within 2024, books are alphabetized (clustering)
- You pay per page they read, not per librarian</p>
<p><strong>That's BigQuery</strong> - massively parallel, column-oriented, pay-per-query.</p>
<hr />
<h2>3ï¸âƒ£ BigQuery Pricing ğŸ’°</h2>
<table>
<thead>
<tr>
<th>Pricing Model</th>
<th>How It Works</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>On-Demand</strong></td>
<td>$5 per TB scanned</td>
<td>Occasional queries</td>
</tr>
<tr>
<td><strong>Flat-Rate</strong></td>
<td>$2,000+/month for slots</td>
<td>Heavy, predictable usage</td>
</tr>
<tr>
<td><strong>Storage</strong></td>
<td>$0.02/GB/month (active)</td>
<td>All data</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!TIP]
<strong>Cost Optimization</strong>: Use <code>SELECT specific_columns</code> instead of <code>SELECT *</code>. You pay for data scanned!</p>
</blockquote>
<hr />
<h2>4ï¸âƒ£ Hands-On Lab: Your First BigQuery Analysis ğŸ› ï¸</h2>
<h3>Step 1: Create a Dataset</h3>
<pre><code class="language-bash"># In Cloud Shell
bq mk --dataset --location=US my_dataset
</code></pre>
<h3>Step 2: Query Public Data (Free!)</h3>
<pre><code class="language-sql">-- Query GitHub public dataset
SELECT 
  repo_name,
  COUNT(*) as commit_count
FROM `bigquery-public-data.github_repos.commits`
WHERE 
  author.date &gt; '2024-01-01'
GROUP BY repo_name
ORDER BY commit_count DESC
LIMIT 10;
</code></pre>
<h3>Step 3: Create a Partitioned Table</h3>
<pre><code class="language-sql">CREATE TABLE my_dataset.sales_partitioned
PARTITION BY DATE(sale_date)
CLUSTER BY region, product_id
AS
SELECT 
  order_id,
  sale_date,
  region,
  product_id,
  amount
FROM my_dataset.raw_sales;
</code></pre>
<h3>Step 4: Load Data from Cloud Storage</h3>
<pre><code class="language-bash">bq load \
  --source_format=CSV \
  --skip_leading_rows=1 \
  my_dataset.customers \
  gs://my-bucket/customers.csv \
  name:STRING,email:STRING,signup_date:DATE
</code></pre>
<hr />
<h2>5ï¸âƒ£ Partitioning vs Clustering</h2>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Without Optimization&quot;
        A[Full Table Scan ğŸ’¸]
    end

    subgraph &quot;With Partitioning&quot;
        B[Scan Only 2024 Partition âœ…]
    end

    subgraph &quot;With Clustering&quot;
        C[Scan Only 'US' Region âœ…âœ…]
    end

    A --&gt;|100 TB scanned| Cost1[$500]
    B --&gt;|10 TB scanned| Cost2[$50]
    C --&gt;|1 TB scanned| Cost3[$5]
</code></pre>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Partitioning</th>
<th>Clustering</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>What</strong></td>
<td>Divides table into segments</td>
<td>Sorts data within partitions</td>
</tr>
<tr>
<td><strong>By</strong></td>
<td>Date, timestamp, or integer</td>
<td>Up to 4 columns</td>
</tr>
<tr>
<td><strong>Benefit</strong></td>
<td>Reduces data scanned</td>
<td>Further reduces data scanned</td>
</tr>
<tr>
<td><strong>Limit</strong></td>
<td>4,000 partitions</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<hr />
<h2>6ï¸âƒ£ Exam Scenarios &amp; Traps ğŸš¨</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Analyze petabytes of log data with SQL"</td>
<td><strong>BigQuery</strong></td>
</tr>
<tr>
<td>"Need ACID transactions on relational data"</td>
<td><strong>Cloud SQL</strong> or <strong>Spanner</strong> (NOT BigQuery)</td>
</tr>
<tr>
<td>"Real-time streaming analytics"</td>
<td><strong>BigQuery Streaming Insert</strong> + <strong>Dataflow</strong></td>
</tr>
<tr>
<td>"Reduce query costs for date-based queries"</td>
<td><strong>Partition by date</strong></td>
</tr>
<tr>
<td>"Query runs slow on large table"</td>
<td>Check if table is <strong>partitioned/clustered</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!CAUTION]
<strong>Trap</strong>: BigQuery is NOT for OLTP (transactional workloads). Use Cloud SQL or Spanner for that!</p>
</blockquote>
<hr />
<h2>7ï¸âƒ£ Cheat Sheet</h2>
<pre><code class="language-text">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIGQUERY CHEAT SHEET                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bq mk --dataset DATASET           # Create dataset     â”‚
â”‚ bq ls                              # List datasets      â”‚
â”‚ bq query &quot;SELECT...&quot;              # Run query          â”‚
â”‚ bq load DATASET.TABLE FILE        # Load data          â”‚
â”‚ bq extract DATASET.TABLE gs://... # Export data        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PARTITION BY DATE(col)            # Date partitioning  â”‚
â”‚ CLUSTER BY col1, col2             # Clustering         â”‚
â”‚ SELECT * EXCEPT(col)              # Exclude columns    â”‚
â”‚ APPROX_COUNT_DISTINCT(col)        # Fast distinct      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<hr />
<h2>8ï¸âƒ£ Checkpoint Quiz</h2>
<ol>
<li><strong>What is the primary pricing model for BigQuery on-demand?</strong></li>
<li>A) Per hour of query execution</li>
<li>B) Per TB of data scanned âœ…</li>
<li>C) Per row returned</li>
<li>
<p>D) Flat monthly fee</p>
</li>
<li>
<p><strong>Which feature reduces costs for queries filtering by date?</strong></p>
</li>
<li>A) Views</li>
<li>B) Clustering</li>
<li>C) Partitioning âœ…</li>
<li>
<p>D) Caching</p>
</li>
<li>
<p><strong>You need to analyze 10 years of sales data occasionally. Which pricing?</strong></p>
</li>
<li>A) Flat-rate</li>
<li>B) On-demand âœ…</li>
<li>C) Free tier</li>
<li>
<p>D) Committed use</p>
</li>
<li>
<p><strong>BigQuery is best suited for:</strong></p>
</li>
<li>A) High-frequency transactional writes</li>
<li>B) Large-scale analytical queries âœ…</li>
<li>C) Document storage</li>
<li>
<p>D) Real-time gaming leaderboards</p>
</li>
<li>
<p><strong>True or False: You can cluster a table by up to 10 columns.</strong></p>
</li>
<li>Answer: <strong>False</strong> (Maximum is 4 columns)</li>
</ol>
<hr />
<!-- FLASHCARDS
[
  {"term": "BigQuery", "def": "Serverless, petabyte-scale data warehouse for analytics."},
  {"term": "Partitioning", "def": "Dividing a table by date/integer to reduce scan costs."},
  {"term": "Clustering", "def": "Sorting data within partitions by up to 4 columns."},
  {"term": "Dremel", "def": "BigQuery's query engine that enables parallel processing."},
  {"term": "On-Demand Pricing", "def": "$5 per TB of data scanned by queries."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_24_functions_eventarc">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 9 min read</div>
<h1>Day 23: Cloud Functions &amp; Event-Driven Architecture</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­ Medium (Serverless compute is a core exam topic)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Understand</strong> Cloud Functions Gen 1 vs Gen 2 differences</li>
<li><strong>Design</strong> event-driven architectures using Eventarc</li>
<li><strong>Deploy</strong> functions triggered by HTTP, Pub/Sub, and Cloud Storage</li>
<li><strong>Compare</strong> Cloud Functions vs Cloud Run for serverless workloads</li>
<li><strong>Implement</strong> best practices for function performance and security</li>
</ul>
<hr />
<h2>ğŸ§  1. What Are Cloud Functions? (Plain-English)</h2>
<p><strong>Cloud Functions = Code that runs when something happens.</strong></p>
<p>Think of it like a <strong>motion-sensor light</strong>: you don't leave it on 24/7. It only turns on when someone walks by. Similarly, Cloud Functions only run (and charge you) when triggered.</p>
<h3>ğŸ’¡ Real-World Analogy: The Automatic Door</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Traditional Server</th>
<th>Cloud Functions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Setup</strong></td>
<td>Hire a doorman 24/7</td>
<td>Install motion sensor</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>Pay salary even when no visitors</td>
<td>Pay only when door opens</td>
</tr>
<tr>
<td><strong>Scaling</strong></td>
<td>One doorman = bottleneck</td>
<td>Unlimited parallel triggers</td>
</tr>
<tr>
<td><strong>Maintenance</strong></td>
<td>You manage the doorman</td>
<td>Google manages everything</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Key Insight:</strong> You write the code, Google handles servers, scaling, and patching.</p>
</blockquote>
<hr />
<h2>ğŸ”„ 2. Gen 1 vs Gen 2: The Evolution</h2>
<p>Cloud Functions Gen 2 is a <strong>major upgrade</strong> built on Cloud Run infrastructure.</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Gen 1</th>
<th>Gen 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Max Timeout</strong></td>
<td>9 minutes</td>
<td><strong>60 minutes</strong></td>
</tr>
<tr>
<td><strong>Max Memory</strong></td>
<td>8 GB</td>
<td><strong>32 GB</strong></td>
</tr>
<tr>
<td><strong>Concurrency</strong></td>
<td>1 request/instance</td>
<td><strong>Up to 1000 requests/instance</strong></td>
</tr>
<tr>
<td><strong>Cold Start</strong></td>
<td>Slower</td>
<td><strong>Faster</strong> (Runs on Cloud Run)</td>
</tr>
<tr>
<td><strong>Traffic Splitting</strong></td>
<td>âŒ No</td>
<td>âœ… Yes (Canary deployments)</td>
</tr>
<tr>
<td><strong>Eventarc Support</strong></td>
<td>Limited</td>
<td><strong>Full</strong> (90+ event sources)</td>
</tr>
<tr>
<td><strong>Pricing</strong></td>
<td>Per invocation</td>
<td>Per invocation + Cloud Run pricing</td>
</tr>
</tbody>
</table>
<h3>Architecture Comparison</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Gen 1&quot;
        T1[Trigger] --&gt; F1[Function Instance]
        F1 --&gt; |1 request| R1[Response]
    end

    subgraph &quot;Gen 2 (Built on Cloud Run)&quot;
        T2[Trigger] --&gt; CR[Cloud Run Service]
        CR --&gt; |Concurrent| F2a[Request 1]
        CR --&gt; |Requests| F2b[Request 2]
        CR --&gt; F2c[Request N]
    end

    style CR fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> If a question mentions "long-running function" (&gt;9 min) or "concurrent requests" â†’ <strong>Gen 2</strong> is the answer.</p>
</blockquote>
<hr />
<h2>ğŸ”— 3. Eventarc: The Universal Event Router</h2>
<p><strong>Eventarc = The nervous system of your cloud.</strong></p>
<p>It connects events from 90+ sources to any target that can receive HTTP requests.</p>
<h3>Event Flow Architecture</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Sources[&quot;Event Sources&quot;]
        GCS[Cloud Storage]
        PS[Pub/Sub]
        AL[Audit Logs]
        FB[Firebase]
        SC[Scheduler]
    end

    subgraph Eventarc[&quot;Eventarc&quot;]
        TR[Trigger Rules]
    end

    subgraph Targets[&quot;Targets&quot;]
        CF[Cloud Functions]
        CR[Cloud Run]
        WF[Workflows]
        GKE[GKE Services]
    end

    Sources --&gt; TR
    TR --&gt; Targets

    style TR fill:#fff3e0,stroke:#ff9800,stroke-width:2px
</code></pre>
<h3>Common Eventarc Triggers</h3>
<table>
<thead>
<tr>
<th>Event Source</th>
<th>Example Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Storage</strong></td>
<td>Image uploaded â†’ Resize &amp; thumbnail</td>
</tr>
<tr>
<td><strong>Pub/Sub</strong></td>
<td>Message received â†’ Process order</td>
</tr>
<tr>
<td><strong>Audit Logs</strong></td>
<td>VM created â†’ Send Slack notification</td>
</tr>
<tr>
<td><strong>Cloud Scheduler</strong></td>
<td>Every 5 min â†’ Run cleanup job</td>
</tr>
<tr>
<td><strong>Firestore</strong></td>
<td>Document updated â†’ Sync to BigQuery</td>
</tr>
</tbody>
</table>
<hr />
<h2>4. Trigger Types Deep Dive</h2>
<h3>HTTP Triggers (Synchronous)</h3>
<pre><code class="language-bash"># Deploy HTTP function
gcloud functions deploy hello-http \
    --gen2 \
    --runtime python311 \
    --trigger-http \
    --allow-unauthenticated \
    --region us-central1
</code></pre>
<p><strong>Use When:</strong> You need a REST API endpoint, webhook, or direct invocation.</p>
<h3>Event Triggers (Asynchronous)</h3>
<pre><code class="language-bash"># Deploy function triggered by Cloud Storage
gcloud functions deploy process-image \
    --gen2 \
    --runtime python311 \
    --trigger-event-filters=&quot;type=google.cloud.storage.object.v1.finalized&quot; \
    --trigger-event-filters=&quot;bucket=my-bucket&quot; \
    --region us-central1
</code></pre>
<p><strong>Use When:</strong> Background processing, file processing, data pipelines.</p>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Build an Image Processor</h2>
<p><strong>Mission:</strong> Create an automatic image thumbnail generator.</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant U as User
    participant GCS as Cloud Storage
    participant EA as Eventarc
    participant CF as Cloud Function
    participant OUT as Output Bucket

    U-&gt;&gt;GCS: Upload image.jpg
    GCS-&gt;&gt;EA: Object finalized event
    EA-&gt;&gt;CF: Trigger function
    CF-&gt;&gt;CF: Resize image
    CF-&gt;&gt;OUT: Save thumbnail.jpg
    OUT--&gt;&gt;U: Ready!
</code></pre>
<h3>Step 1: Create Buckets</h3>
<pre><code class="language-bash"># Source bucket (uploads go here)
gcloud storage buckets create gs://PROJECT_ID-uploads --location=us-central1

# Output bucket (thumbnails go here)
gcloud storage buckets create gs://PROJECT_ID-thumbnails --location=us-central1
</code></pre>
<h3>Step 2: Create the Function</h3>
<p>Create <code>main.py</code>:</p>
<pre><code class="language-python">from google.cloud import storage
from PIL import Image
import io
import functions_framework

@functions_framework.cloud_event
def generate_thumbnail(cloud_event):
    &quot;&quot;&quot;Triggered by Cloud Storage finalize event.&quot;&quot;&quot;
    data = cloud_event.data
    bucket_name = data[&quot;bucket&quot;]
    file_name = data[&quot;name&quot;]

    # Skip if already a thumbnail
    if file_name.startswith(&quot;thumb_&quot;):
        return

    # Download, resize, upload
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(file_name)

    image_data = blob.download_as_bytes()
    image = Image.open(io.BytesIO(image_data))
    image.thumbnail((128, 128))

    # Save to output bucket
    output_bucket = storage_client.bucket(f&quot;{bucket_name.split('-')[0]}-thumbnails&quot;)
    output_blob = output_bucket.blob(f&quot;thumb_{file_name}&quot;)

    buffer = io.BytesIO()
    image.save(buffer, format='JPEG')
    output_blob.upload_from_string(buffer.getvalue(), content_type='image/jpeg')

    print(f&quot;Thumbnail created: thumb_{file_name}&quot;)
</code></pre>
<h3>Step 3: Deploy</h3>
<pre><code class="language-bash">gcloud functions deploy generate-thumbnail \
    --gen2 \
    --runtime python311 \
    --trigger-event-filters=&quot;type=google.cloud.storage.object.v1.finalized&quot; \
    --trigger-event-filters=&quot;bucket=PROJECT_ID-uploads&quot; \
    --region us-central1 \
    --source .
</code></pre>
<h3>Step 4: Test</h3>
<pre><code class="language-bash"># Upload a test image
gcloud storage cp test-image.jpg gs://PROJECT_ID-uploads/

# Check the output bucket
gcloud storage ls gs://PROJECT_ID-thumbnails/
</code></pre>
<hr />
<h2>âš ï¸ 6. Common Pitfalls &amp; Pro Tips</h2>
<h3>âŒ Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Infinite loops</td>
<td>Function triggers itself</td>
<td>Check file prefix/suffix before processing</td>
</tr>
<tr>
<td>Cold starts</td>
<td>Slow first request</td>
<td>Use min instances or Gen 2</td>
</tr>
<tr>
<td>Timeout errors</td>
<td>Function runs too long</td>
<td>Increase timeout or use Cloud Run Jobs</td>
</tr>
<tr>
<td>Missing permissions</td>
<td>Function can't access resources</td>
<td>Grant service account proper IAM roles</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use <code>--min-instances=1</code></strong> for production to eliminate cold starts</li>
<li><strong>Set <code>--memory=256MB</code></strong> minimum for Python/Node (128MB is too small)</li>
<li><strong>Use Secrets Manager</strong> instead of environment variables for API keys</li>
<li><strong>Enable Cloud Trace</strong> for debugging distributed systems</li>
</ul>
<hr />
<h2>ğŸ¯ 7. ACE Exam Focus</h2>
<h3>Decision Tree: When to Use What?</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Need Serverless Compute?] --&gt; B{Container Required?}
    B --&gt;|Yes| CR[Cloud Run]
    B --&gt;|No| C{Long Running?&gt;9min}
    C --&gt;|Yes| CR
    C --&gt;|No| D{Need Concurrency?}
    D --&gt;|Yes| CF2[Cloud Functions Gen 2]
    D --&gt;|No| E{Simple Event Handler?}
    E --&gt;|Yes| CF1[Cloud Functions Gen 1]
    E --&gt;|No| CF2

    style CF2 fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style CR fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>Gen 1 max timeout is 9 minutes</strong> (not 15!)</li>
<li>âš ï¸ <strong>Gen 2 is built on Cloud Run</strong> (know this for architecture questions)</li>
<li>âš ï¸ <strong>Eventarc uses CloudEvents format</strong> (standardized, portable)</li>
</ul>
<hr />
<h2>ğŸ” Cloud Functions vs Cloud Run: The ACE Exam Classic</h2>
<p>This comparison is one of the <strong>most common exam questions</strong>. Both are serverless, but they solve different problems.</p>
<h3>When to Use Which</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Cloud Functions</th>
<th>Cloud Run</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Unit of deployment</strong></td>
<td>Single function</td>
<td>Container (any language/framework)</td>
</tr>
<tr>
<td><strong>Max timeout</strong></td>
<td>9 min (Gen 1), 60 min (Gen 2)</td>
<td>60 min</td>
</tr>
<tr>
<td><strong>Concurrency</strong></td>
<td>1 request/instance (Gen 1)</td>
<td>Up to 1000 requests/instance</td>
</tr>
<tr>
<td><strong>WebSocket support</strong></td>
<td>âŒ No</td>
<td>âœ… Yes</td>
</tr>
<tr>
<td><strong>Custom binaries</strong></td>
<td>Limited</td>
<td>âœ… Any executable</td>
</tr>
<tr>
<td><strong>Startup time</strong></td>
<td>Faster (simpler)</td>
<td>Slightly slower (container)</td>
</tr>
<tr>
<td><strong>Best for</strong></td>
<td>Event glue, lightweight handlers</td>
<td>APIs, microservices, existing containers</td>
</tr>
</tbody>
</table>
<h3>Why NOT Cloud Functions?</h3>
<table>
<thead>
<tr>
<th>If You Need...</th>
<th>Why Functions Fails</th>
<th>Use Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>WebSocket connections</td>
<td>Not supported</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>Custom OS packages</td>
<td>Limited runtime</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>Long-running jobs (&gt;60 min)</td>
<td>Timeout limit</td>
<td><strong>Cloud Run Jobs</strong> or <strong>Batch</strong></td>
</tr>
<tr>
<td>Multi-file applications</td>
<td>Designed for single function</td>
<td><strong>Cloud Run</strong> or <strong>App Engine</strong></td>
</tr>
</tbody>
</table>
<h3>Why NOT Cloud Run?</h3>
<table>
<thead>
<tr>
<th>If You Need...</th>
<th>Why Run is Overkill</th>
<th>Use Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple event handler (20 lines)</td>
<td>Container overhead</td>
<td><strong>Cloud Functions</strong></td>
</tr>
<tr>
<td>Fastest cold start possible</td>
<td>Container loading slower</td>
<td><strong>Cloud Functions Gen 2</strong></td>
</tr>
<tr>
<td>No Docker knowledge</td>
<td>Requires Dockerfile</td>
<td><strong>Cloud Functions</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> 
- "Lightweight event handler triggered by Pub/Sub" â†’ <strong>Cloud Functions</strong>
- "Containerized REST API microservice" â†’ <strong>Cloud Run</strong>
- "Need to run legacy binary with custom dependencies" â†’ <strong>Cloud Run</strong></p>
</blockquote>
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>What is the maximum execution timeout for Cloud Functions Gen 2?</strong></p>
<ul>
<li>A. 9 minutes</li>
<li>B. 15 minutes</li>
<li>C. <strong>60 minutes</strong> âœ…</li>
<li>D. Unlimited</li>
</ul>
</li>
<li>
<p><strong>Cloud Functions Gen 2 is built on top of which service?</strong></p>
<ul>
<li>A. App Engine</li>
<li>B. Compute Engine</li>
<li>C. <strong>Cloud Run</strong> âœ…</li>
<li>D. Kubernetes Engine</li>
</ul>
</li>
<li>
<p><strong>Which component routes events from sources to targets in GCP?</strong></p>
<ul>
<li>A. Cloud Scheduler</li>
<li>B. Pub/Sub</li>
<li>C. <strong>Eventarc</strong> âœ…</li>
<li>D. Cloud Tasks</li>
</ul>
</li>
<li>
<p><strong>You need a function that processes 500 concurrent requests. Which should you use?</strong></p>
<ul>
<li>A. Cloud Functions Gen 1</li>
<li>B. <strong>Cloud Functions Gen 2</strong> âœ…</li>
<li>C. App Engine Standard</li>
<li>D. Compute Engine</li>
</ul>
</li>
<li>
<p><strong>What event format does Eventarc use for standardization?</strong></p>
<ul>
<li>A. JSON-RPC</li>
<li>B. Protocol Buffers</li>
<li>C. <strong>CloudEvents</strong> âœ…</li>
<li>D. Apache Avro</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 23 Checklist</h2>
<ul>
<li>[ ] Understand Gen 1 vs Gen 2 differences</li>
<li>[ ] Deploy an HTTP-triggered function</li>
<li>[ ] Deploy an event-triggered function</li>
<li>[ ] Complete the image processor lab</li>
<li>[ ] Pass the quiz with 80%+</li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 24: Advanced IAM &amp; Identity Governance</strong>
*   Service Account best practices
*   Workload Identity Federation
*   IAM Conditions and Deny Policies</p>
<!-- FLASHCARDS
[
  {"term": "Cloud Functions", "def": "Serverless FaaS (Function as a Service). Upload code, Google runs it on demand."},
  {"term": "Gen 2", "def": "Latest Cloud Functions version. Built on Cloud Run. 60min timeout, concurrent requests."},
  {"term": "Eventarc", "def": "Universal event router. Connects 90+ GCP sources to any HTTP target."},
  {"term": "CloudEvents", "def": "Standardized event format used by Eventarc. Portable across cloud providers."},
  {"term": "Cold Start", "def": "Delay when a new function instance must be created. Mitigate with min-instances."},
  {"term": "Trigger", "def": "The event that causes a function to execute (HTTP, Pub/Sub, Storage, etc)."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_24_network_security">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 24: Network Security (Firewalls &amp; IAP)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 24, you will be able to:
*   <strong>Configure</strong> stateful VPC firewall rules with granular priorities and targets.
*   <strong>Implement</strong> Identity-Aware Proxy (IAP) to secure SSH/RDP access without public IPs.
*   <strong>Understand</strong> Cloud Armor's role in L7 filtering and DDoS mitigation.
*   <strong>Audit</strong> network traffic using Firewall Insights and Log Analysis.</p>
<hr />
<h2>ğŸ›¡ï¸ 1. VPC Firewall Rules: The Perimeter</h2>
<p>GCP Firewalls are <strong>stateful</strong> (if you allow ingress, egress is automatically allowed for that session) and distributed (enforced at each VM, not at a single bottleneck).</p>
<h3>Rule Evaluation Order</h3>
<pre><code class="language-mermaid">graph TD
    P1[Rule Priority: 1 - Highest] --&gt; P2[Rule Priority: 2 ...]
    P2 --&gt; P3[Rule Priority: 1000 - Default]
    P3 --&gt; P4[Rule Priority: 65535 - Lowest]

    subgraph &quot;Implicit Rules&quot;
        P4 --&gt; ID[Implicit Deny Ingress]
        P4 --&gt; IA[Implicit Allow Egress]
    end
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Element</th>
<th style="text-align: left;">Property</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Priority</strong></td>
<td style="text-align: left;">0 - 65535</td>
<td style="text-align: left;"><strong>Lower number wins</strong>. A rule with priority 100 overrides priority 500.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Targets</strong></td>
<td style="text-align: left;">Tags / Service Accounts</td>
<td style="text-align: left;">Best practice: Use <strong>Service Accounts</strong> for dynamic security.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Source</strong></td>
<td style="text-align: left;">IP Ranges / Tags</td>
<td style="text-align: left;">Use <code>0.0.0.0/0</code> only for public web traffic (Port 80/443).</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ° 2. Identity-Aware Proxy (IAP)</h2>
<p>IAP changes the security paradigm from "Network-based" to "Identity-based." Instead of opening a firewall port to the whole internet, you only open it to Google's specialized proxy service.</p>
<h3>The IAP Tunneling Flow</h3>
<pre><code class="language-mermaid">graph LR
    User[Admin] --&gt;|HTTPS/Auth| IAP[Google IAP Service]
    IAP --&gt;|Port 22 Tunnel| VM[Private VM]

    subgraph &quot;Firewall Protection&quot;
        FW[Allow 35.235.240.0/20]
    end

    FW -.-&gt; VM
</code></pre>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: The Magic Range</strong>
To enable IAP for SSH/RDP, you MUST allow ingress from the IP range <strong><code>35.235.240.0/20</code></strong> on Port 22 (SSH) or 3389 (RDP). This is a common exam question!</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: The "Fortress" VM</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Access a VM that has <strong>no external IP</strong> and is blocked from the general internet, using only IAP.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Create a Stealth VM</strong>:
    <code>bash
    gcloud compute instances create stealth-box \
      --network=default \
      --no-address \
      --zone=us-central1-a</code></p>
</li>
<li>
<p><strong>Verify Inaccessibility</strong>:
    Try to SSH. It will timeout because there is no path from your computer to a private IP.</p>
</li>
<li>
<p><strong>Deploy the "Secret Tunnel" Rule</strong>:
    <code>bash
    gcloud compute firewall-rules create allow-ssh-iap \
      --direction=INGRESS \
      --priority=1000 \
      --network=default \
      --action=ALLOW \
      --rules=tcp:22 \
      --source-ranges=35.235.240.0/20</code></p>
</li>
<li>
<p><strong>Execute the Tunnel</strong>:
    <code>bash
    gcloud compute ssh stealth-box --tunnel-through-iap --zone=us-central1-a</code>
    <em>Result: Successful login! The VM remains invisible to the public internet.</em></p>
</li>
</ol>
<hr />
<h2>ğŸ›¡ï¸ 4. Beyond Firewalls: Cloud Armor</h2>
<p>While firewalls handle Layer 4 (IP/Port), <strong>Cloud Armor</strong> handles Layer 7 (HTTP/S).</p>
<ul>
<li><strong>WAF (Web Application Firewall)</strong>: Blocks SQL Injection and Cross-Site Scripting (XSS).</li>
<li><strong>DDoS Protection</strong>: Automatically mitigates massive flooding attacks.</li>
<li><strong>Adaptive Protection</strong>: Uses ML to detect anomalies in traffic patterns.</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>A developer created a firewall rule with priority 500 to DENY traffic, and another rule with priority 200 to ALLOW that same traffic. What will happen?</strong></p>
<ul>
<li>A. Traffic is denied because Deny always wins.</li>
<li>B. <strong>Traffic is allowed because priority 200 is evaluated first.</strong> âœ…</li>
<li>C. Both rules are ignored.</li>
<li>D. GCP will throw an error for conflicting rules.</li>
</ul>
</li>
<li>
<p><strong>Which IP range must be allowed in your firewall to enable Identity-Aware Proxy (IAP) for administrative access?</strong></p>
<ul>
<li>A. 0.0.0.0/0</li>
<li>B. <strong>35.235.240.0/20</strong> âœ…</li>
<li>C. 10.0.0.0/8</li>
<li>D. 192.168.1.0/24</li>
</ul>
</li>
<li>
<p><strong>What is the default action for any INGRESS traffic that doesn't match a specific firewall rule?</strong></p>
<ul>
<li>A. Allow</li>
<li>B. <strong>Deny</strong> âœ…</li>
<li>C. Log and Allow</li>
<li>D. Forward to the admin</li>
</ul>
</li>
<li>
<p><strong>You want to protect your globally exposed application from SQL injection attacks. Which service should you use?</strong></p>
<ul>
<li>A. VPC Firewall Rules</li>
<li>B. <strong>Cloud Armor</strong> âœ…</li>
<li>C. Cloud NAT</li>
<li>D. IAM Conditions</li>
</ul>
</li>
<li>
<p><strong>True or False: GCP Firewall Rules are stateful.</strong></p>
<ul>
<li>A. <strong>True</strong> âœ…</li>
<li>B. False</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain the priority system (0-65535).', checked: false },
        { text: 'I know the IAP source range by heart.', checked: false },
        { text: 'I understand the difference between Firewall Rules (L4) and Cloud Armor (L7).', checked: false },
        { text: 'I successfully SSHed into a VM with no public IP.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 24 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_25_cloud_armor">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 25: Cloud Armor &amp; Data Security</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 25, you will be able to:
*   <strong>Protect</strong> web applications at the edge using Cloud Armor Security Policies.
*   <strong>Configure</strong> WAF rules to detect and block SQL injection and Cross-Site Scripting (XSS).
*   <strong>Differentiate</strong> between Default Encryption, Customer-Managed Keys (CMEK), and Customer-Supplied Keys (CSEK).
*   <strong>Implement</strong> geo-blocking and rate limiting to mitigate automated attacks.</p>
<hr />
<h2>ğŸ›¡ï¸ 1. Cloud Armor: The Edge Shield</h2>
<p>Cloud Armor works in tandem with the <strong>Global HTTP(S) Load Balancer</strong> to provide a multi-layer defense. It stops malicious traffic at the Google edge, before it even enters your VPC.</p>
<h3>The Defense-in-Depth Pipeline</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Public Internet&quot;
        User[User]
        Bot[Botnet/Hacker]
    end

    subgraph &quot;Google Edge&quot;
        LB[Global Load Balancer]
        CA[Cloud Armor WAF]
    end

    subgraph &quot;Your Project&quot;
        BE[Backend Service]
        VM[GCE Instances]
    end

    User --&gt; LB
    Bot --&gt; LB
    LB &lt;--&gt; CA
    CA -- &quot;Filtered&quot; --&gt; BE
    BE --&gt; VM
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Rule Type</th>
<th style="text-align: left;">Use Case</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>IP-based</strong></td>
<td style="text-align: left;">Block/Allow specific CIDRs.</td>
<td style="text-align: left;">Simplest form of filtering.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Geo-based</strong></td>
<td style="text-align: left;">Block countries for compliance/risk.</td>
<td style="text-align: left;">Uses Google's global IP-to-location map.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Expression-based</strong></td>
<td style="text-align: left;">Block SQLi, XSS, specific headers.</td>
<td style="text-align: left;">Uses predefined "WAF" rules.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Rate Limiting</strong></td>
<td style="text-align: left;">Prevent DDoS by throttling IPs.</td>
<td style="text-align: left;">Enforces a max RPS (Requests Per Second).</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Protecting Data at Rest</h2>
<p>Google encrypts all data at rest by default. However, for many compliance standards, you need more control over the <strong>Keys</strong>.</p>
<h3>The Key Management Spectrum</h3>
<ol>
<li><strong>Default Encryption</strong>: Google manage the keys. No effort, zero cost.</li>
<li><strong>CMEK (Customer-Managed)</strong>: You create a key in <strong>Cloud KMS</strong>. You control rotation and can disable the key at any time.</li>
<li><strong>CSEK (Customer-Supplied)</strong>: You provide the raw key for every disk/bucket operation. Google doesn't store it. If you lose it, the data is gone forever.</li>
</ol>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: Crypto-shredding</strong>
If you need to instantly and irreversibly destroy large amounts of data, the fastest way is to <strong>delete the CMEK key</strong> in Cloud KMS. This renders all encrypted chunks unreadable immediately.</p>
</blockquote>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Defeating SQL Injection</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Deploy a Cloud Armor policy that uses a predefined rule to block common SQL injection patterns.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Initialize the Policy</strong>:
    <code>bash
    gcloud compute security-policies create waf-policy-sql \
        --description "WAF policy with SQLi protection"</code></p>
</li>
<li>
<p><strong>Add Predefined SQLi Rule</strong>:
    We use the priority system where 1000 is for our custom rule.
    <code>bash
    gcloud compute security-policies rules create 1000 \
        --security-policy waf-policy-sql \
        --expression "evaluatePredefinedExpr('sqli-v33-stable')" \
        --action "deny-403" \
        --description "Deny SQL Injection attempts"</code></p>
</li>
<li>
<p><strong>Attach to Backend</strong>:
    Attach this policy to an existing Global Load Balancer backend.
    <code>bash
    gcloud compute backend-services update my-web-backend \
        --security-policy waf-policy-sql \
        --global</code></p>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 4. Knowledge Check</h2>
<ol>
<li>
<p><strong>You need to ensure that your web application is only accessible from users in the United Kingdom for legal compliance. Which service should you use?</strong></p>
<ul>
<li>A. VPC Firewall Rules</li>
<li>B. <strong>Cloud Armor Security Policy (Geo-blocking)</strong> âœ…</li>
<li>C. IAM Conditions</li>
<li>D. Cloud CDN</li>
</ul>
</li>
<li>
<p><strong>What is the most secure key management option where Google never stores the raw key on persistent storage?</strong></p>
<ul>
<li>A. Default Google-managed encryption</li>
<li>B. Cloud KMS (CMEK)</li>
<li>C. <strong>Customer-Supplied Encryption Keys (CSEK)</strong> âœ…</li>
<li>D. IAM Service Accounts</li>
</ul>
</li>
<li>
<p><strong>Which Google Cloud service provides protection against Distributed Denial of Service (DDoS) attacks at the global edge?</strong></p>
<ul>
<li>A. Cloud NAT</li>
<li>B. <strong>Cloud Armor</strong> âœ…</li>
<li>C. Cloud Router</li>
<li>D. VPC Peering</li>
</ul>
</li>
<li>
<p><strong>How is Cloud Armor billed in the standard tier?</strong></p>
<ul>
<li>A. Per CPU hour.</li>
<li>B. <strong>Per security policy and per incoming request.</strong> âœ…</li>
<li>C. Per number of VMs protected.</li>
<li>D. It is a free service included with all projects.</li>
</ul>
</li>
<li>
<p><strong>You want to implement 'Crypto-shredding' for an old project. What is the correct procedure?</strong></p>
<ul>
<li>A. Format the hard drives.</li>
<li>B. <strong>Delete the Customer-Managed Key (CMEK) associated with the data.</strong> âœ…</li>
<li>C. Change the project billing account.</li>
<li>D. Move the data to Coldline storage.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand that Cloud Armor lives at the Global Load Balancer edge.', checked: false },
        { text: 'I can differentiate between CMEK and CSEK.', checked: false },
        { text: 'I know how to block traffic based on Geography.', checked: false },
        { text: 'I know what predefined WAF rules are (SQLi/XSS).', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 25 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_25_data_security">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 3 min read</div>
<h1>Day 25: Data Security (Encryption &amp; KMS)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­ Medium</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 25, learners will be able to:
*   <strong>Explain</strong> how GCP encrypts data by default.
*   <strong>Differentiate</strong> between Google-Managed Keys vs CMEK.
*   <strong>Create</strong> a Key in Cloud KMS.</p>
<hr />
<h2>ğŸ§  1. Encryption Everywhere</h2>
<p>Good News: <strong>Google encrypts ALL data at rest and in transit by default.</strong>
You don't need to click a button for this. It just happens.</p>
<p>However, some industries (Banking, Healthcare) have a rule:
<em>"Google cannot own the keys. WE must own the keys."</em></p>
<hr />
<h2>ğŸ”‘ 2. Key Management Types</h2>
<ol>
<li><strong>Google-Managed Keys (Default):</strong> Google creates the key, rotates it, and manages it. You do nothing. (99% of use cases).</li>
<li><strong>Customer-Managed Encryption Keys (CMEK):</strong> <strong>You</strong> create the key in <strong>Cloud KMS</strong>. You manage rotation. You can <strong>destroy</strong> the key (making the data unreadable, even to Google).</li>
<li><strong>Customer-Supplied Encryption Keys (CSEK):</strong> You bring your own raw key bytes from on-prem. Google never stores the key. (Rare/Extreme).</li>
</ol>
<hr />
<h2>âœ‰ï¸ 3. Real-World Analogy: The Secret Envelope</h2>
<ul>
<li><strong>Google-Managed:</strong> You put your letter in a safe. Google holds the key to the safe. They promise to keep it locked.</li>
<li><strong>CMEK (KMS):</strong> You put your letter in a safe. <strong>You hold the key</strong>. Google guards the safe, but they can't open it unless you give permission. If you melt the key, the safe is locked forever.</li>
</ul>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Create a Crypto Key</h2>
<p><strong>ğŸ§ª Lab Objective:</strong> Create a KeyRing and Key in KMS.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Open Console:</strong> Go to <strong>Security &gt; Key Management</strong>.</li>
<li><strong>Create Key Ring:</strong><ul>
<li>Name: <code>my-keyring</code>.</li>
<li>Location: <code>us-central1</code>.</li>
</ul>
</li>
<li><strong>Create Key:</strong><ul>
<li>Name: <code>my-crypto-key</code>.</li>
<li>Protection Level: Software.</li>
<li>Rotation: 90 days (Best practice).</li>
</ul>
</li>
<li><strong>Use it:</strong><ul>
<li>Go to <strong>Cloud Storage</strong>. Create a Bucket.</li>
<li>Under <strong>Encryption</strong>, verify you can select "Customer-managed key" and pick the one you just made.</li>
<li><em>Result:</em> Now, if you revoke permission to that key, the bucket becomes inaccessible.</li>
</ul>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Quick Knowledge Check (Quiz)</h2>
<ol>
<li>
<p><strong>What is the default encryption state for data stored in GCP?</strong></p>
<ul>
<li>A. Unencrypted.</li>
<li>B. <strong>Encrypted at Rest and in Transit.</strong> âœ…</li>
<li>C. Encrypted only if you pay.</li>
</ul>
</li>
<li>
<p><strong>You work for a bank. Regulation says you must be able to revoke Google's ability to decrypt data at any time. What do you use?</strong></p>
<ul>
<li>A. Default Encryption</li>
<li>B. <strong>CMEK (Cloud KMS)</strong> âœ…</li>
<li>C. HTTPS</li>
</ul>
</li>
<li>
<p><strong>What happens if you accidentally delete/destroy a CMEK key?</strong></p>
<ul>
<li>A. Google can restore it.</li>
<li>B. <strong>The data encrypted with that key is lost forever (Crypto-shredding).</strong> âœ…</li>
<li>C. Nothing, data is fine.</li>
</ul>
</li>
<li>
<p><strong>Which services allow you to use CMEK?</strong></p>
<ul>
<li>A. Cloud Storage</li>
<li>B. Cloud SQL</li>
<li>C. Compute Engine (Disks)</li>
<li>D. <strong>All of the above</strong> âœ…</li>
</ul>
</li>
<li>
<p><strong>Which service scans your data for sensitive info like Credit Card numbers?</strong></p>
<ul>
<li>A. Cloud Armor</li>
<li>B. <strong>Cloud DLP (Data Loss Prevention)</strong> âœ…</li>
<li>C. IAM</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the default encryption.', checked: false },
        { text: 'I created a KMS KeyRing and Key.', checked: false },
        { text: 'I know the risk of destroying a key.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 25 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_25_pub_sub_data_pipelines">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Day 25: Pub/Sub &amp; Data Pipelines</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Event-driven architecture is heavily tested)</p>
<blockquote>
<p><strong>Official Doc Reference</strong>: <a href="https://cloud.google.com/pubsub/docs">Pub/Sub Documentation</a></p>
</blockquote>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Pub/Sub in 30 Seconds)</strong><br />
Pub/Sub = Asynchronous messaging between services. Publishers send to <strong>Topics</strong>, subscribers receive from <strong>Subscriptions</strong>. <strong>Pull</strong> = subscriber requests messages (batch processing). <strong>Push</strong> = Pub/Sub sends to HTTPS endpoint (Cloud Functions). Message size limit: 10MB. Delivery: <strong>At-least-once</strong> (design for duplicates!). Combine with <strong>Dataflow</strong> for real-time processing.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Understand</strong> publish-subscribe architecture</td>
<td>Foundation of event-driven systems</td>
</tr>
<tr>
<td><strong>Create</strong> topics and subscriptions</td>
<td>Core hands-on skill</td>
</tr>
<tr>
<td><strong>Choose</strong> Push vs Pull delivery</td>
<td>Right tool for each scenario</td>
</tr>
<tr>
<td><strong>Build</strong> data pipelines with Dataflow</td>
<td>Real-time streaming pattern</td>
</tr>
</tbody>
</table>
<h2>1ï¸âƒ£ What is Pub/Sub? ğŸ“¬</h2>
<p><strong>Pub/Sub</strong> (Publish/Subscribe) is Google's fully-managed messaging service that enables <strong>asynchronous communication</strong> between services. Think of it as a <strong>post office</strong>:</p>
<ul>
<li><strong>Publishers</strong> drop letters (messages) in the mailbox (topic)</li>
<li>The post office (Pub/Sub) holds them reliably</li>
<li><strong>Subscribers</strong> pick up their mail from their PO Box (subscription)</li>
</ul>
<h3>Why Use Pub/Sub?</h3>
<table>
<thead>
<tr>
<th>Problem</th>
<th>Pub/Sub Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Services tightly coupled</td>
<td>Decouples senders from receivers</td>
</tr>
<tr>
<td>Data loss during spikes</td>
<td>Buffers messages, guarantees delivery</td>
</tr>
<tr>
<td>Scaling bottlenecks</td>
<td>Handles millions of messages/second</td>
</tr>
<tr>
<td>Complex integrations</td>
<td>Event-driven, loosely coupled architecture</td>
</tr>
</tbody>
</table>
<hr />
<h2>2ï¸âƒ£ Architecture Overview</h2>
<pre><code class="language-mermaid">graph LR
    subgraph Publishers
        P1[ğŸ­ IoT Sensors]
        P2[ğŸŒ Web App]
        P3[ğŸ“± Mobile App]
    end

    subgraph &quot;Pub/Sub&quot;
        T1[ğŸ“¨ Topic: orders]
        S1[ğŸ“¥ Sub: analytics]
        S2[ğŸ“¥ Sub: warehouse]
        S3[ğŸ“¥ Sub: notifications]
    end

    subgraph Subscribers
        A1[ğŸ“Š BigQuery]
        A2[ğŸ¢ Inventory System]
        A3[ğŸ“§ Email Service]
    end

    P1 &amp; P2 &amp; P3 --&gt; T1
    T1 --&gt; S1 &amp; S2 &amp; S3
    S1 --&gt; A1
    S2 --&gt; A2
    S3 --&gt; A3
</code></pre>
<h3>Key Concepts</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
<th>ACE Exam Key</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Topic</strong></td>
<td>Named flow for messages</td>
<td>"Communication Channel"</td>
</tr>
<tr>
<td><strong>Subscription</strong></td>
<td>How messages are pulled/pushed</td>
<td>"Destination"</td>
</tr>
<tr>
<td><strong>Message</strong></td>
<td>Payload + Attributes</td>
<td>Max size: 10MB</td>
</tr>
<tr>
<td><strong>Acknowledgment (Ack)</strong></td>
<td>"I got it, don't resend"</td>
<td>Ack Deadline: 10-600s</td>
</tr>
<tr>
<td><strong>Dead Letter Topic</strong></td>
<td>Store unprocessable messages</td>
<td>"Troubleshooting poison pills"</td>
</tr>
<tr>
<td><strong>Snapshot/Seek</strong></td>
<td><strong>Replay</strong> messages from the past</td>
<td>"Bug recovery", "Retesting"</td>
</tr>
</tbody>
</table>
<hr />
<h2>3ï¸âƒ£ Push vs Pull Delivery</h2>
<pre><code class="language-mermaid">graph TB
    subgraph &quot;PULL (Subscriber initiates)&quot;
        Topic1[ğŸ“¨ Topic] --&gt; Sub1[ğŸ“¥ Subscription]
        Sub1 -.-&gt;|&quot;1. Pull request&quot;| Worker1[âš™ï¸ Worker]
        Worker1 -.-&gt;|&quot;2. Messages&quot;| Sub1
        Worker1 -.-&gt;|&quot;3. Ack&quot;| Sub1
    end

    subgraph &quot;PUSH (Pub/Sub initiates)&quot;
        Topic2[ğŸ“¨ Topic] --&gt; Sub2[ğŸ“¥ Subscription]
        Sub2 --&gt;|&quot;HTTP POST&quot;| Endpoint[ğŸŒ HTTPS Endpoint]
        Endpoint --&gt;|&quot;200 OK = Ack&quot;| Sub2
    end
</code></pre>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Pull</th>
<th>Push</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Who initiates</strong></td>
<td>Subscriber</td>
<td>Pub/Sub</td>
</tr>
<tr>
<td><strong>Best for</strong></td>
<td>Large volume, batch processing</td>
<td>Webhooks, Cloud Functions</td>
</tr>
<tr>
<td><strong>Scaling</strong></td>
<td>You manage workers</td>
<td>Auto-scales to endpoint</td>
</tr>
<tr>
<td><strong>Endpoint needed</strong></td>
<td>No</td>
<td>Yes (HTTPS)</td>
</tr>
<tr>
<td><strong>Example</strong></td>
<td>Dataflow pipeline</td>
<td>Cloud Run, Cloud Functions</td>
</tr>
</tbody>
</table>
<hr />
<hr />
<h2>4ï¸âƒ£ Advanced Features (The Best-in-Market Edge)</h2>
<h3>ğŸ¯ Exactly-Once Delivery</h3>
<p>Pub/Sub now supports <strong>Exactly-once delivery</strong> for a specific subscription. This prevents duplicates <em>before</em> they reach your code.</p>
<blockquote>
<p><strong>Note:</strong> Requires a 7-day retention period.</p>
</blockquote>
<h3>ğŸ” Filtering</h3>
<p>Don't waste money! You can filter messages at the <strong>subscription</strong> level so the subscriber only receives what it needs (e.g., <code>attributes.priority = "high"</code>).</p>
<h3>ğŸ“ Schemas (Registry)</h3>
<p>Enforce data quality using <strong>Protocol Buffers</strong> or <strong>Avro</strong>. If a publisher sends a message that doesn't match the schema, Pub/Sub rejects it.</p>
<hr />
<h2>5ï¸âƒ£ Hands-On Lab: Build an Event Pipeline ğŸ› ï¸</h2>
<h3>Step 1: Create a Topic</h3>
<pre><code class="language-bash"># Create a topic for order events
gcloud pubsub topics create orders

# Verify
gcloud pubsub topics list
</code></pre>
<h3>Step 2: Create Subscriptions</h3>
<pre><code class="language-bash"># Pull subscription for analytics
gcloud pubsub subscriptions create analytics-sub \
    --topic=orders \
    --ack-deadline=60

# Push subscription to Cloud Function (example)
gcloud pubsub subscriptions create notify-sub \
    --topic=orders \
    --push-endpoint=https://my-function-url.run.app
</code></pre>
<h3>Step 3: Publish Messages</h3>
<pre><code class="language-bash"># Publish a single message
gcloud pubsub topics publish orders \
    --message='{&quot;order_id&quot;: &quot;12345&quot;, &quot;amount&quot;: 99.99}'

# Publish with attributes
gcloud pubsub topics publish orders \
    --message='{&quot;order_id&quot;: &quot;12346&quot;, &quot;amount&quot;: 150.00}' \
    --attribute='priority=high,region=us-west'
</code></pre>
<h3>Step 4: Pull Messages</h3>
<pre><code class="language-bash"># Pull and acknowledge messages
gcloud pubsub subscriptions pull analytics-sub --auto-ack --limit=10
</code></pre>
<h3>Step 5: Python Example</h3>
<pre><code class="language-python">from google.cloud import pubsub_v1

# Publisher
publisher = pubsub_v1.PublisherClient()
topic_path = publisher.topic_path('my-project', 'orders')

data = '{&quot;order_id&quot;: &quot;12347&quot;, &quot;amount&quot;: 200.00}'
future = publisher.publish(topic_path, data.encode('utf-8'))
print(f&quot;Published message ID: {future.result()}&quot;)

# Subscriber (Pull)
subscriber = pubsub_v1.SubscriberClient()
subscription_path = subscriber.subscription_path('my-project', 'analytics-sub')

def callback(message):
    print(f&quot;Received: {message.data}&quot;)
    message.ack()

subscriber.subscribe(subscription_path, callback=callback)
</code></pre>
<hr />
<h2>6ï¸âƒ£ Pub/Sub + Dataflow Pipeline</h2>
<pre><code class="language-mermaid">graph LR
    IoT[ğŸŒ¡ï¸ IoT Sensors] --&gt;|Stream| Topic[ğŸ“¨ Pub/Sub Topic]
    Topic --&gt; Dataflow[âš¡ Dataflow]
    Dataflow --&gt;|Transform| BQ[(ğŸ“Š BigQuery)]
    Dataflow --&gt;|Alert| Alert[ğŸš¨ Alert System]
</code></pre>
<p><strong>Common Pattern</strong>: Real-time data ingestion
1. <strong>Pub/Sub</strong> receives streaming events
2. <strong>Dataflow</strong> processes in real-time (filter, aggregate, enrich)
3. <strong>BigQuery</strong> stores for analytics</p>
<hr />
<h2>7ï¸âƒ£ Exam Scenarios &amp; Traps ğŸš¨</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Decouple microservices"</td>
<td><strong>Pub/Sub</strong></td>
</tr>
<tr>
<td>"Process events in real-time"</td>
<td><strong>Pub/Sub + Dataflow</strong></td>
</tr>
<tr>
<td>"IoT device sends data to cloud"</td>
<td><strong>Pub/Sub as ingestion</strong></td>
</tr>
<tr>
<td>"Need exactly-once processing"</td>
<td><strong>Dataflow</strong> (Pub/Sub is at-least-once)</td>
</tr>
<tr>
<td>"Trigger Cloud Function on event"</td>
<td><strong>Push subscription</strong></td>
</tr>
<tr>
<td>"Batch process messages hourly"</td>
<td><strong>Pull subscription</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!CAUTION]
<strong>Trap</strong>: Pub/Sub guarantees <strong>at-least-once</strong> delivery. Messages may be delivered multiple times. Design subscribers to be idempotent!</p>
<p>[!TIP]
<strong>Exam Watch</strong>: "Global, scalable, asynchronous messaging" = Pub/Sub. "Managed Kafka" = Confluent Cloud or self-managed.</p>
</blockquote>
<hr />
<h2>8ï¸âƒ£ Cheat Sheet</h2>
<pre><code class="language-text">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PUB/SUB CHEAT SHEET                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gcloud pubsub topics create TOPIC        # Create topic â”‚
â”‚ gcloud pubsub topics publish TOPIC --message=&quot;...&quot;     â”‚
â”‚ gcloud pubsub subscriptions create SUB --topic=TOPIC   â”‚
â”‚ gcloud pubsub subscriptions pull SUB --auto-ack        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Message size limit:        10 MB                       â”‚
â”‚ Message retention:         7 days (default)            â”‚
â”‚ Ack deadline:              10-600 seconds              â”‚
â”‚ Delivery guarantee:        At-least-once               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<hr />
<h2>9ï¸âƒ£ Checkpoint Quiz</h2>
<ol>
<li><strong>What is the maximum message size in Pub/Sub?</strong></li>
<li>A) 1 MB</li>
<li>B) 10 MB âœ…</li>
<li>C) 100 MB</li>
<li>
<p>D) Unlimited</p>
</li>
<li>
<p><strong>Which delivery method should you use with Cloud Functions?</strong></p>
</li>
<li>A) Pull</li>
<li>B) Push âœ…</li>
<li>C) Streaming</li>
<li>
<p>D) Batch</p>
</li>
<li>
<p><strong>Pub/Sub provides which delivery guarantee?</strong></p>
</li>
<li>A) Exactly-once</li>
<li>B) At-most-once</li>
<li>C) At-least-once âœ…</li>
<li>
<p>D) Best-effort</p>
</li>
<li>
<p><strong>What happens to unacknowledged messages?</strong></p>
</li>
<li>A) Deleted immediately</li>
<li>B) Redelivered to subscriber âœ…</li>
<li>C) Sent to publisher</li>
<li>
<p>D) Stored in BigQuery</p>
</li>
<li>
<p><strong>You need to process streaming IoT data in real-time. Which combination?</strong></p>
</li>
<li>A) Cloud Storage + BigQuery</li>
<li>B) Pub/Sub + Dataflow âœ…</li>
<li>C) Cloud SQL + Cloud Functions</li>
<li>D) Compute Engine + Pub/Sub</li>
</ol>
<hr />
<!-- FLASHCARDS
[
  {"term": "Topic", "def": "Named channel where publishers send messages."},
  {"term": "Subscription", "def": "Entity representing a message stream from a topic."},
  {"term": "Push Delivery", "def": "Pub/Sub sends messages to an HTTPS endpoint."},
  {"term": "Pull Delivery", "def": "Subscriber requests messages from Pub/Sub."},
  {"term": "At-Least-Once", "def": "Guarantee that messages are delivered, but may arrive more than once."},
  {"term": "Dead Letter Topic", "def": "Destination for messages that can't be processed after max retries."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_26_billing_management">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 26: Resource Management &amp; Billing</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Beginner/Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 26, you will be able to:
*   <strong>Navigate</strong> the Google Cloud resource hierarchy (Org, Folders, Projects).
*   <strong>Architect</strong> a cost-control strategy using Budgets, Alerts, and Quotas.
*   <strong>Analyze</strong> complex spending patterns using Billing Exports to BigQuery.
*   <strong>Implement</strong> labels for granular cost tracking and filtering.</p>
<hr />
<h2>ğŸ—ï¸ 1. The Resource Hierarchy</h2>
<p>In Google Cloud, resources aren't just floating in space. They follow a strict hierarchy that dictates how permissions and billing are inherited.</p>
<pre><code class="language-mermaid">graph TD
    ORG[Organization: 'company.com'] --&gt; F1[Folder: Production]
    ORG --&gt; F2[Folder: Development]

    F1 --&gt; P1[Project: Primary App]
    F2 --&gt; P2[Project: Sandbox]
    F2 --&gt; P3[Project: Testing]

    P1 --&gt; R1[VMs, Buckets, DBs]
    P2 --&gt; R2[Trial VM]
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Level</th>
<th style="text-align: left;">Key Responsibility</th>
<th style="text-align: left;">ACE Exam Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Organization</strong></td>
<td style="text-align: left;">Root node.</td>
<td style="text-align: left;">Requires a verified Google Workspace domain.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Folder</strong></td>
<td style="text-align: left;">Grouping (per dept, per env).</td>
<td style="text-align: left;">Used to apply bulk IAM policies.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Project</strong></td>
<td style="text-align: left;">The boundary for resources.</td>
<td style="text-align: left;">Every project <strong>must</strong> be linked to a Billing Account.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Label</strong></td>
<td style="text-align: left;">Key-Value pairs on resources.</td>
<td style="text-align: left;">Best for categorizing costs (e.g. <code>team:data</code>).</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š 2. Budgets vs. Quotas: The Safestop</h2>
<p>It is a common mistake to think Budgets stop your spending. They don't. Only <strong>Quotas</strong> actually halt resource creation.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Budgets &amp; Alerts</th>
<th style="text-align: left;">Quotas</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Goal</strong></td>
<td style="text-align: left;">Cost Awareness</td>
<td style="text-align: left;">Safety &amp; Capacity</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Action</strong></td>
<td style="text-align: left;">Sends an email/notification.</td>
<td style="text-align: left;">Blocks the <code>Create</code> operation.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Stops Spend?</strong></td>
<td style="text-align: left;"><strong>NO</strong>. Resources keep running.</td>
<td style="text-align: left;"><strong>YES</strong>. Prevents new spend.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Increase?</strong></td>
<td style="text-align: left;">You set the limit yourself.</td>
<td style="text-align: left;">You must request from Google.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: Cost Safety Net</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Set up a multi-threshold budget and understand where to find your current Quota usage.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Create a Budget</strong>:</p>
<ul>
<li>Go to <strong>Billing &gt; Budgets &amp; alerts</strong>.</li>
<li>Set Monthy Budget: <strong>$10.00</strong>.</li>
<li>Set Thresholds:<ul>
<li>50% (Email Admins)</li>
<li>90% (Email Admins + PubSub Notification)</li>
<li>100% (Email Admins)</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Inspect Quotas</strong>:</p>
<ul>
<li>Go to <strong>IAM &amp; Admin &gt; Quotas</strong>.</li>
<li>Filter by: <strong>Service: Compute Engine API</strong>.</li>
<li>Metric: <strong>CPUs (all regions)</strong>.</li>
<li><em>Observation:</em> Note your current limit (usually 8 or 32 for new accounts). If you try to create 100 VMs, this is where it would be blocked!</li>
</ul>
</li>
<li>
<p><strong>Label a Resource</strong>:
    <code>bash
    gcloud compute instances add-labels monitor-node \
      --labels="env=dev,owner=learner" \
      --zone=us-central1-a</code>
    <em>Now, your next billing report allows you to filter specifically for <code>env=dev</code> costs.</em></p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: BigQuery Export</strong>
If you need to "Visualize billing data over the last 12 months with custom charts," the first step is always <strong>exporting the billing data to BigQuery</strong>. Standard console reports only show limited history.</p>
<p>[!WARNING]
<strong>Billing Account Permissions</strong>: To link a project to a billing account, you must have the <strong>Billing Account User</strong> role on the <em>Billing Account</em>, and <strong>Project Creator/Owner</strong> on the <em>Project</em>.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You want to receive an automated notification when your monthly spend reaches $500, but you do NOT want your services to stop. What should you configure?</strong></p>
<ul>
<li>A. A hard Quota limit.</li>
<li>B. <strong>A Billing Budget and Alert.</strong> âœ…</li>
<li>C. An IAM Policy.</li>
<li>D. A Firewall Rule.</li>
</ul>
</li>
<li>
<p><strong>You are unable to create a new Compute Engine instance in the <code>us-east1</code> region because you have 'exceeded account limits.' How do you resolve this?</strong></p>
<ul>
<li>A. Increase your Billing Budget.</li>
<li>B. <strong>Request a Quota increase in the Console.</strong> âœ…</li>
<li>C. Change your credit card.</li>
<li>D. Delete your project and start over.</li>
</ul>
</li>
<li>
<p><strong>Which level of the resource hierarchy is best suited for applying a single IAM policy that affects all production projects simultaneously?</strong></p>
<ul>
<li>A. Project level</li>
<li>B. <strong>Folder level ('Production' folder)</strong> âœ…</li>
<li>C. Resource level</li>
<li>D. Label level</li>
</ul>
</li>
<li>
<p><strong>What is the primary benefit of exporting billing data to BigQuery?</strong></p>
<ul>
<li>A. It makes the bill cheaper.</li>
<li>B. <strong>It allows for complex SQL analysis and long-term data retention.</strong> âœ…</li>
<li>C. It automatically pays the bill using credits.</li>
<li>D. It encrypts the billing data.</li>
</ul>
</li>
<li>
<p><strong>You need to track exactly how much the 'Marketing' team is spending on Cloud Storage vs the 'Engineering' team within the same project. What should you use?</strong></p>
<ul>
<li>A. Folders</li>
<li>B. <strong>Labels (e.g., team=marketing, team=eng)</strong> âœ…</li>
<li>C. Different Billing Accounts</li>
<li>D. Different VPCs</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can draw the Org -> Folder -> Project hierarchy.', checked: false },
        { text: 'I understand that Budgets do not stop services.', checked: false },
        { text: 'I know the difference between Billing Account Admin and User.', checked: false },
        { text: 'I understand how to use Labels for cost tracking.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 26 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_26_infrastructure_as_code_terraform">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 9 min read</div>
<h1>Module 15: Terraform IaC</h1>
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<blockquote>
<p><strong>ğŸ¯ Objectives:</strong>
*   Master core concepts
*   Build hands-on resources
*   Pass the ACE exam scenarios</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸ“š Concepts</th>
<th>ğŸ§ª Lab</th>
<th>ğŸ“ Quiz</th>
<th>ğŸ’¼ Interview</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#concepts">Jump to Theory</a></td>
<td><a href="#hands-on-lab">Jump to Lab</a></td>
<td><a href="#knowledge-check">Jump to Quiz</a></td>
<td><a href="#interview-questions">Jump to Interview</a></td>
</tr>
</tbody>
</table>
<hr />
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­ Medium (IaC concepts appear in automation questions)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Understand</strong> Infrastructure as Code (IaC) principles</li>
<li><strong>Compare</strong> Terraform vs Deployment Manager vs Pulumi</li>
<li><strong>Write</strong> basic Terraform configurations for GCP</li>
<li><strong>Execute</strong> the Terraform workflow: init â†’ plan â†’ apply</li>
<li><strong>Manage</strong> state files and workspaces</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: IaC in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Terraform is THE most valuable skill for Cloud Engineers and DevOps. It's on every job description.</p>
</blockquote>
<h3>Job Roles &amp; IaC Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use IaC</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Engineer</strong></td>
<td>Provision infrastructure</td>
<td>Writing modules, managing state</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Automate everything</td>
<td>CI/CD + Terraform pipelines</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Create standardized modules</td>
<td>Module development, governance</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Infrastructure reliability</td>
<td>Drift detection, rollback</td>
</tr>
</tbody>
</table>
<h3>Production IaC Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Monorepo</strong></td>
<td>All IaC in one repo</td>
<td>Small teams, simpler governance</td>
</tr>
<tr>
<td><strong>Module Registry</strong></td>
<td>Shared modules + consuming repos</td>
<td>Large organizations</td>
</tr>
<tr>
<td><strong>GitOps</strong></td>
<td>Terraform + CI/CD auto-apply</td>
<td>Mature DevOps teams</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I commit state files to git"</td>
<td>Security disaster (contains secrets)</td>
<td>"I use remote state in GCS with versioning"</td>
</tr>
<tr>
<td>"I run terraform apply without plan"</td>
<td>Dangerous, unexpected changes</td>
<td>"I always review terraform plan first"</td>
</tr>
<tr>
<td>"I hardcode everything"</td>
<td>Not reusable</td>
<td>"I use variables and modules"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What Is Infrastructure as Code? (Plain-English)</h2>
<p><strong>IaC = Write code to create infrastructure instead of clicking buttons.</strong></p>
<p>Think of it like a <strong>recipe vs cooking by memory</strong>: A recipe is repeatable, shareable, and version-controlled. Cooking by memory leads to inconsistent results.</p>
<h3>ğŸ’¡ Real-World Analogy: IKEA Instructions</h3>
<table>
<thead>
<tr>
<th>Manual Setup</th>
<th>Infrastructure as Code</th>
</tr>
</thead>
<tbody>
<tr>
<td>Build furniture from memory</td>
<td>Follow IKEA instruction manual</td>
</tr>
<tr>
<td>Different every time</td>
<td>Identical every time</td>
</tr>
<tr>
<td>Hard to replicate</td>
<td>Easy to share and repeat</td>
</tr>
<tr>
<td>No rollback</td>
<td>Version control (git)</td>
</tr>
<tr>
<td>"Works on my machine"</td>
<td>Works everywhere</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ”„ 2. IaC Tools Comparison</h2>
<h3>GCP IaC Options</h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Type</th>
<th>Language</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Terraform</strong></td>
<td>Multi-cloud</td>
<td>HCL</td>
<td>Most popular, large community</td>
</tr>
<tr>
<td><strong>Deployment Manager</strong></td>
<td>GCP-native</td>
<td>YAML/Jinja2</td>
<td>Pure GCP, no external tools</td>
</tr>
<tr>
<td><strong>Pulumi</strong></td>
<td>Multi-cloud</td>
<td>Python/TS/Go</td>
<td>Developers who prefer real languages</td>
</tr>
<tr>
<td><strong>Config Connector</strong></td>
<td>Kubernetes-native</td>
<td>YAML</td>
<td>GKE-centric environments</td>
</tr>
</tbody>
</table>
<h3>Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Choose IaC Tool] --&gt; B{Multi-cloud?}
    B --&gt;|Yes| C{Prefer Real Languages?}
    B --&gt;|No| D[Deployment Manager]

    C --&gt;|Yes| E[Pulumi]
    C --&gt;|No| F[Terraform]

    style F fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style D fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> For the exam, know that <strong>Terraform is the most common</strong> choice for multi-cloud, and <strong>Deployment Manager is GCP-native</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ“ 3. Terraform Core Concepts</h2>
<h3>The Terraform Workflow</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Write[&quot;1. Write&quot;]
        TF[main.tf]
        VAR[variables.tf]
        OUT[outputs.tf]
    end

    subgraph Commands[&quot;2. Commands&quot;]
        INIT[terraform init]
        PLAN[terraform plan]
        APPLY[terraform apply]
    end

    subgraph State[&quot;3. State&quot;]
        STATE[terraform.tfstate]
        REMOTE[Remote Backend&lt;br&gt;GCS Bucket]
    end

    Write --&gt; INIT --&gt; PLAN --&gt; APPLY --&gt; STATE
    STATE --&gt; REMOTE

    style PLAN fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    style APPLY fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Key Terms</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Provider</strong></td>
<td>Plugin that talks to cloud APIs (google, aws, azure)</td>
</tr>
<tr>
<td><strong>Resource</strong></td>
<td>Infrastructure object to create (VM, bucket, network)</td>
</tr>
<tr>
<td><strong>State</strong></td>
<td>Terraform's record of what exists (terraform.tfstate)</td>
</tr>
<tr>
<td><strong>Plan</strong></td>
<td>Preview of changes before applying</td>
</tr>
<tr>
<td><strong>Module</strong></td>
<td>Reusable group of resources</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Deploy Your First VM</h2>
<h3>Step 1: Project Setup</h3>
<pre><code class="language-bash"># Create project directory
mkdir terraform-gcp-demo &amp;&amp; cd terraform-gcp-demo

# Create main configuration file
touch main.tf variables.tf outputs.tf
</code></pre>
<h3>Step 2: Configure Provider (main.tf)</h3>
<pre><code class="language-hcl"># main.tf

terraform {
  required_providers {
    google = {
      source  = &quot;hashicorp/google&quot;
      version = &quot;~&gt; 5.0&quot;
    }
  }
}

provider &quot;google&quot; {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}

# Create a VPC network
resource &quot;google_compute_network&quot; &quot;vpc&quot; {
  name                    = &quot;terraform-vpc&quot;
  auto_create_subnetworks = false
}

# Create a subnet
resource &quot;google_compute_subnetwork&quot; &quot;subnet&quot; {
  name          = &quot;terraform-subnet&quot;
  ip_cidr_range = &quot;10.0.1.0/24&quot;
  region        = var.region
  network       = google_compute_network.vpc.id
}

# Create a VM instance
resource &quot;google_compute_instance&quot; &quot;vm&quot; {
  name         = &quot;terraform-vm&quot;
  machine_type = &quot;e2-micro&quot;
  zone         = var.zone

  boot_disk {
    initialize_params {
      image = &quot;debian-cloud/debian-11&quot;
    }
  }

  network_interface {
    subnetwork = google_compute_subnetwork.subnet.id
    access_config {
      # Ephemeral public IP
    }
  }

  tags = [&quot;web&quot;, &quot;terraform-managed&quot;]

  labels = {
    environment = &quot;dev&quot;
    managed_by  = &quot;terraform&quot;
  }
}

# Create firewall rule
resource &quot;google_compute_firewall&quot; &quot;allow_ssh&quot; {
  name    = &quot;terraform-allow-ssh&quot;
  network = google_compute_network.vpc.name

  allow {
    protocol = &quot;tcp&quot;
    ports    = [&quot;22&quot;]
  }

  source_ranges = [&quot;0.0.0.0/0&quot;]
  target_tags   = [&quot;web&quot;]
}
</code></pre>
<h3>Step 3: Define Variables (variables.tf)</h3>
<pre><code class="language-hcl"># variables.tf

variable &quot;project_id&quot; {
  description = &quot;GCP Project ID&quot;
  type        = string
}

variable &quot;region&quot; {
  description = &quot;GCP Region&quot;
  type        = string
  default     = &quot;us-central1&quot;
}

variable &quot;zone&quot; {
  description = &quot;GCP Zone&quot;
  type        = string
  default     = &quot;us-central1-a&quot;
}
</code></pre>
<h3>Step 4: Define Outputs (outputs.tf)</h3>
<pre><code class="language-hcl"># outputs.tf

output &quot;vm_external_ip&quot; {
  description = &quot;External IP of the VM&quot;
  value       = google_compute_instance.vm.network_interface[0].access_config[0].nat_ip
}

output &quot;vpc_name&quot; {
  description = &quot;Name of the VPC&quot;
  value       = google_compute_network.vpc.name
}
</code></pre>
<h3>Step 5: Execute Terraform</h3>
<pre><code class="language-bash"># Initialize (download provider plugins)
terraform init

# Preview changes
terraform plan -var=&quot;project_id=YOUR_PROJECT_ID&quot;

# Apply changes (creates resources)
terraform apply -var=&quot;project_id=YOUR_PROJECT_ID&quot;

# Verify in console
gcloud compute instances list
</code></pre>
<h3>Step 6: Cleanup</h3>
<pre><code class="language-bash"># Destroy all resources
terraform destroy -var=&quot;project_id=YOUR_PROJECT_ID&quot;
</code></pre>
<hr />
<h2>ğŸ” 5. Remote State Management</h2>
<h3>Why Remote State?</h3>
<ul>
<li><strong>Collaboration:</strong> Team members share state</li>
<li><strong>Locking:</strong> Prevents concurrent modifications</li>
<li><strong>Security:</strong> State contains sensitive data</li>
</ul>
<h3>Configure GCS Backend</h3>
<pre><code class="language-hcl"># backend.tf

terraform {
  backend &quot;gcs&quot; {
    bucket = &quot;my-terraform-state-bucket&quot;
    prefix = &quot;terraform/state&quot;
  }
}
</code></pre>
<pre><code class="language-bash"># Create state bucket first
gcloud storage buckets create gs://my-terraform-state-bucket \
    --location=us-central1 \
    --uniform-bucket-level-access

# Re-initialize to migrate state
terraform init -migrate-state
</code></pre>
<hr />
<h2>âš ï¸ 6. Common Pitfalls &amp; Pro Tips</h2>
<h3>âŒ Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Committing state files</td>
<td>Exposes secrets</td>
<td>Use remote backend, add to .gitignore</td>
</tr>
<tr>
<td>No state locking</td>
<td>Concurrent runs corrupt state</td>
<td>Use GCS backend (has locking)</td>
</tr>
<tr>
<td>Hardcoding values</td>
<td>Not reusable</td>
<td>Use variables for everything</td>
</tr>
<tr>
<td>Ignoring plan output</td>
<td>Unexpected changes</td>
<td>Always review <code>terraform plan</code></td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use <code>terraform fmt</code></strong> to auto-format code</li>
<li><strong>Use <code>terraform validate</code></strong> before plan</li>
<li><strong>Tag resources</strong> with <code>managed_by = "terraform"</code> label</li>
<li><strong>Use modules</strong> for reusable patterns</li>
<li><strong>Store state in GCS</strong> with versioning enabled</li>
</ul>
<hr />
<h2>ğŸ¯ 7. ACE Exam Focus</h2>
<h3>Terraform vs Deployment Manager</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Terraform</th>
<th>Deployment Manager</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multi-cloud</td>
<td>âœ… Yes</td>
<td>âŒ GCP only</td>
</tr>
<tr>
<td>Language</td>
<td>HCL</td>
<td>YAML/Jinja2/Python</td>
</tr>
<tr>
<td>State management</td>
<td>External (GCS)</td>
<td>Managed by GCP</td>
</tr>
<tr>
<td>Community</td>
<td>Huge</td>
<td>Smaller</td>
</tr>
<tr>
<td>Exam relevance</td>
<td>High</td>
<td>Medium</td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>State files contain secrets</strong> - never commit to git</li>
<li>âš ï¸ <strong><code>terraform plan</code> doesn't make changes</strong> - only shows preview</li>
<li>âš ï¸ <strong>Deployment Manager uses "configurations" and "deployments"</strong></li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>What command shows a preview of Terraform changes without applying them?</strong></p>
<ul>
<li>A. <code>terraform init</code></li>
<li>B. <strong><code>terraform plan</code></strong> âœ…</li>
<li>C. <code>terraform apply --dry-run</code></li>
<li>D. <code>terraform preview</code></li>
</ul>
</li>
<li>
<p><strong>Where should Terraform state files be stored for team collaboration?</strong></p>
<ul>
<li>A. Local filesystem</li>
<li>B. GitHub repository</li>
<li>C. <strong>Remote backend (GCS bucket)</strong> âœ…</li>
<li>D. Terraform Cloud only</li>
</ul>
</li>
<li>
<p><strong>Which GCP-native IaC tool uses YAML and Jinja2 templates?</strong></p>
<ul>
<li>A. Terraform</li>
<li>B. <strong>Deployment Manager</strong> âœ…</li>
<li>C. Pulumi</li>
<li>D. Config Connector</li>
</ul>
</li>
<li>
<p><strong>What does <code>terraform init</code> do?</strong></p>
<ul>
<li>A. Creates infrastructure</li>
<li>B. Destroys resources</li>
<li>C. <strong>Downloads provider plugins and initializes backend</strong> âœ…</li>
<li>D. Shows resource state</li>
</ul>
</li>
<li>
<p><strong>Why should you never commit terraform.tfstate to version control?</strong></p>
<ul>
<li>A. It's too large</li>
<li>B. <strong>It contains sensitive data like passwords</strong> âœ…</li>
<li>C. It changes too frequently</li>
<li>D. Git doesn't support binary files</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 27 Checklist</h2>
<ul>
<li>[ ] Understand IaC principles</li>
<li>[ ] Write a basic Terraform config</li>
<li>[ ] Execute init â†’ plan â†’ apply workflow</li>
<li>[ ] Configure remote state in GCS</li>
<li>[ ] Destroy resources with <code>terraform destroy</code></li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 28: Week 4 Review</strong>
*   Consolidate Security &amp; IaC knowledge
*   Practice scenario-based questions</p>
<!-- FLASHCARDS
[
  {"term": "Infrastructure as Code", "def": "Managing infrastructure through code files instead of manual processes. Enables version control and repeatability."},
  {"term": "Terraform", "def": "Popular multi-cloud IaC tool using HCL language. Provider-based architecture."},
  {"term": "terraform plan", "def": "Command that shows what changes Terraform will make WITHOUT actually making them."},
  {"term": "terraform.tfstate", "def": "State file tracking what resources Terraform manages. Contains sensitive data."},
  {"term": "Remote Backend", "def": "Storage location for state files. GCS bucket for GCP. Enables team collaboration."},
  {"term": "Deployment Manager", "def": "GCP-native IaC tool. Uses YAML/Jinja2. State managed by Google."}
]
-->
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_27_cloud_build">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 27: Cloud Build &amp; CI/CD Pipelines</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 27, you will be able to:
*   <strong>Define</strong> the stages of a Continuous Integration and Continuous Deployment (CI/CD) pipeline.
*   <strong>Construct</strong> a multi-step <code>cloudbuild.yaml</code> file using community and custom builders.
*   <strong>Automate</strong> deployments using Git triggers and environment variables.
*   <strong>Architect</strong> private build pipelines using Cloud Build Private Pools.</p>
<hr />
<h2>ğŸ—ï¸ 1. The Serverless Build Factory</h2>
<p>Cloud Build is Google Cloud's serverless CI/CD platform. It abstracts away the management of build servers (like Jenkins) and scales automatically based on your workload.</p>
<h3>The CI/CD Lifecycle</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;The Trigger&quot;
        GIT[GitHub / Cloud Source Repo]
    end

    subgraph &quot;Cloud Build (The Factory)&quot;
        STEP1[Step 1: Test]
        STEP2[Step 2: Build]
        STEP3[Step 3: Scan]
    end

    subgraph &quot;Artifact Storage&quot;
        AR[Artifact Registry]
    end

    subgraph &quot;Deployment&quot;
        CR[Cloud Run / GKE]
    end

    GIT --&gt;|Push Event| STEP1
    STEP1 --&gt; STEP2
    STEP2 --&gt; STEP3
    STEP3 --&gt; AR
    AR --&gt; CR
</code></pre>
<hr />
<h2>ğŸ› ï¸ 2. Anatomy of <code>cloudbuild.yaml</code></h2>
<p>The <code>cloudbuild.yaml</code> file is where you define your "Recipes." Each step runs inside a Docker container.</p>
<pre><code class="language-yaml">steps:
# 1. Run Unit Tests (using Python)
- name: 'python:3.9-slim'
  entrypoint: 'python'
  args: ['-m', 'pytest']

# 2. Build the Docker Image
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:v1', '.']

# 3. Push to Artifact Registry
- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:v1']

images:
- 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:v1'
</code></pre>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On Lab: The "Auto-Build" Workflow</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Submit a manual build to Cloud Build and verify the artifact in Artifact Registry.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Prepare Artifact Registry</strong>:
    Cloud Build needs a destination.
    <code>bash
    gcloud artifacts repositories create my-repo \
      --repository-format=docker \
      --location=us-central1</code></p>
</li>
<li>
<p><strong>Create a Sample App</strong>:
    <code>bash
    echo "FROM nginx:alpine" &gt; Dockerfile
    echo "&lt;h1&gt;V1 Deployed via Cloud Build&lt;/h1&gt;" &gt; index.html
    echo "COPY index.html /usr/share/nginx/html/index.html" &gt;&gt; Dockerfile</code></p>
</li>
<li>
<p><strong>Submit the Build</strong>:
    <code>bash
    gcloud builds submit --tag us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/web-app:v1 .</code></p>
</li>
<li>
<p><strong>Verify History</strong>:
    Go to <strong>Cloud Build &gt; History</strong>. You'll see the logs streaming in real-time. If it's green, your image is ready for deployment to Cloud Run or GKE!</p>
</li>
</ol>
<hr />
<h2>âš ï¸ 4. Exam Traps &amp; Best Practices</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: The Service Account</strong>
Cloud Build uses a default service account (<code>[PROJECT_NUMBER]@cloudbuild.gserviceaccount.com</code>). If your build fails to deploy to GKE or Cloud Run, you usually need to grant that service account the <strong>Cloud Run Admin</strong> or <strong>Kubernetes Engine Developer</strong> role.</p>
<p>[!TIP]
<strong>Private VPC Access</strong>: If you need Cloud Build to access assets inside a Private VPC (like a private database), you must use <strong>Cloud Build Private Pools</strong> and set up <strong>VPC Peering</strong>. Standard Cloud Build has no path to private internal IPs.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which file is the primary configuration for defining build steps in Cloud Build?</strong></p>
<ul>
<li>A. Dockerfile</li>
<li>B. <strong>cloudbuild.yaml</strong> âœ…</li>
<li>C. app.yaml</li>
<li>D. build.sh</li>
</ul>
</li>
<li>
<p><strong>Your build process needs to access a private SQL database that has no public IP address. Which Cloud Build feature do you need?</strong></p>
<ul>
<li>A. Cloud Build Public API</li>
<li>B. <strong>Cloud Build Private Pools</strong> âœ…</li>
<li>C. Cloud NAT</li>
<li>D. Cloud VPN</li>
</ul>
</li>
<li>
<p><strong>What is the default behavior of Cloud Build after a successful build step that generates an image?</strong></p>
<ul>
<li>A. It deletes the image.</li>
<li>B. It deploys it to production.</li>
<li>C. <strong>It can automatically push the image to a registry if specified in the 'images' field.</strong> âœ…</li>
<li>D. It emails the developer the raw binary.</li>
</ul>
</li>
<li>
<p><strong>A developer pushes code to a GitHub repository, but the Cloud Build trigger doesn't fire. What is the most likely cause?</strong></p>
<ul>
<li>A. GitHub is too slow.</li>
<li>B. <strong>The Cloud Build Service Account lacks permissions or the trigger filter doesn't match the branch.</strong> âœ…</li>
<li>C. Cloud Build only works with Google Source Repositories.</li>
<li>D. You can only trigger 1 build per day.</li>
</ul>
</li>
<li>
<p><strong>True or False: Each step in a Cloud Build configuration runs in its own isolated Docker container.</strong></p>
<ul>
<li>A. <strong>True</strong> âœ…</li>
<li>B. False</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between CI and CD.', checked: false },
        { text: 'I can identify the stages of a cloudbuild.yaml file.', checked: false },
        { text: 'I know how to resolve permission errors by checking the Cloud Build Service Account.', checked: false },
        { text: 'I understand when to use Private Pools for internal VPC access.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 27 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_27_cloud_build_ci_cd">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>BONUS: Cloud Build CI/CD Pipelines</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­ Medium (DevOps &amp; Automation questions)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Understand</strong> CI/CD principles and Cloud Build architecture</li>
<li><strong>Write</strong> cloudbuild.yaml configuration files</li>
<li><strong>Configure</strong> triggers for automated builds</li>
<li><strong>Implement</strong> deployment pipelines to GKE and Cloud Run</li>
</ul>
<hr />
<h2>ğŸ¢ Industry Context: CI/CD in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> CI/CD skills are non-negotiable for DevOps roles. Cloud Build is Google's native answer.</p>
</blockquote>
<h3>Job Roles &amp; CI/CD Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use CI/CD</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>Build and maintain pipelines</td>
<td>Writing cloudbuild.yaml, managing triggers</td>
</tr>
<tr>
<td><strong>Platform Engineer</strong></td>
<td>Standardize deployment patterns</td>
<td>Templates, private pools</td>
</tr>
<tr>
<td><strong>Backend Developer</strong></td>
<td>Ship code to production</td>
<td>Trigger builds, review logs</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Deployment safety</td>
<td>Rollback configs, canary analysis</td>
</tr>
</tbody>
</table>
<h3>Production CI/CD Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Build + Push + Deploy</strong></td>
<td>All in one pipeline</td>
<td>Simple apps</td>
</tr>
<tr>
<td><strong>Build + Store, Deploy Separately</strong></td>
<td>Cloud Build + Cloud Deploy</td>
<td>GKE with approvals</td>
</tr>
<tr>
<td><strong>Multi-environment</strong></td>
<td>Dev â†’ Staging â†’ Prod triggers</td>
<td>Enterprise deployments</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I deploy directly from my laptop"</td>
<td>No audit trail, not reproducible</td>
<td>"I use CI/CD pipelines for all deployments"</td>
</tr>
<tr>
<td>"I hardcode secrets in cloudbuild.yaml"</td>
<td>Security vulnerability</td>
<td>"I use Secret Manager integration"</td>
</tr>
<tr>
<td>"I don't test before deployment"</td>
<td>Broken production</td>
<td>"I include test steps in my pipeline"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. What Is CI/CD? (Plain-English)</h2>
<p><strong>CI/CD = Automate the boring stuff between "git push" and "live in production".</strong></p>
<h3>Why Does This Matter for Cloud Engineers?</h3>
<p>Manual deployments are slow, error-prone, and don't scale. As a Cloud Engineer, you'll be expected to automate deployments so developers can push code safely and quickly. The ACE exam tests your ability to configure these pipelines.</p>
<h3>ğŸ’¡ Real-World Analogy: Pizza Delivery</h3>
<table>
<thead>
<tr>
<th>Manual Deployment</th>
<th>CI/CD Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cook makes pizza by hand</td>
<td>Automated pizza-making machine</td>
</tr>
<tr>
<td>Driver manually finds address</td>
<td>GPS-optimized route</td>
</tr>
<tr>
<td>Quality check at random</td>
<td>Every pizza inspected</td>
</tr>
<tr>
<td>60 min delivery</td>
<td>15 min delivery</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2. Cloud Build Architecture</h2>
<pre><code class="language-mermaid">flowchart LR
    subgraph Trigger[&quot;Triggers&quot;]
        GH[GitHub Push]
        CR[Cloud Repo]
        PB[Pub/Sub]
        MN[Manual]
    end

    subgraph Build[&quot;Cloud Build&quot;]
        CB[Build Steps]
        AR[Artifact Registry]
    end

    subgraph Deploy[&quot;Targets&quot;]
        GKE[GKE Cluster]
        RUN[Cloud Run]
        GAE[App Engine]
        GCE[Compute Engine]
    end

    Trigger --&gt; CB --&gt; AR --&gt; Deploy

    style CB fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Key Components</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Trigger</strong></td>
<td>What starts the build (push, PR, schedule)</td>
</tr>
<tr>
<td><strong>cloudbuild.yaml</strong></td>
<td>Pipeline definition</td>
</tr>
<tr>
<td><strong>Build Step</strong></td>
<td>Single action (build, test, push)</td>
</tr>
<tr>
<td><strong>Artifact Registry</strong></td>
<td>Store container images</td>
</tr>
<tr>
<td><strong>Substitutions</strong></td>
<td>Variables like <code>$PROJECT_ID</code></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 3. Hands-On: Build &amp; Deploy Pipeline</h2>
<h3>Sample cloudbuild.yaml</h3>
<pre><code class="language-yaml"># cloudbuild.yaml
steps:
  # Step 1: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/$PROJECT_ID/my-app:$SHORT_SHA', '.']

  # Step 2: Push to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/my-app:$SHORT_SHA']

  # Step 3: Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'my-app'
      - '--image=gcr.io/$PROJECT_ID/my-app:$SHORT_SHA'
      - '--region=us-central1'
      - '--platform=managed'

images:
  - 'gcr.io/$PROJECT_ID/my-app:$SHORT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY
</code></pre>
<h3>Create Trigger</h3>
<pre><code class="language-bash">gcloud builds triggers create github \
    --name=&quot;deploy-on-push&quot; \
    --repo-name=&quot;my-repo&quot; \
    --repo-owner=&quot;my-org&quot; \
    --branch-pattern=&quot;^main$&quot; \
    --build-config=&quot;cloudbuild.yaml&quot;
</code></pre>
<hr />
<h2>ğŸ¯ 4. ACE Exam Focus</h2>
<h3>Cloud Build vs Other Tools</h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cloud Build</strong></td>
<td>GCP-native CI/CD, container builds</td>
</tr>
<tr>
<td><strong>Cloud Deploy</strong></td>
<td>Managed CD for GKE</td>
</tr>
<tr>
<td><strong>Jenkins</strong></td>
<td>Complex, self-managed pipelines</td>
</tr>
<tr>
<td><strong>GitHub Actions</strong></td>
<td>GitHub-centric workflows</td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>Cloud Build runs in containers</strong> - each step is isolated</li>
<li>âš ï¸ <strong>Substitutions</strong> use <code>$VAR</code> syntax</li>
<li>âš ï¸ <strong>Private pools</strong> for builds in VPC</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>What file defines Cloud Build pipeline steps?</strong></p>
<ul>
<li>A. Dockerfile</li>
<li>B. <strong>cloudbuild.yaml</strong> âœ…</li>
<li>C. pipeline.json</li>
<li>D. buildspec.yml</li>
</ul>
</li>
<li>
<p><strong>Which built-in substitution contains the short commit SHA?</strong></p>
<ul>
<li>A. <code>$COMMIT_ID</code></li>
<li>B. <code>$GIT_SHA</code></li>
<li>C. <strong><code>$SHORT_SHA</code></strong> âœ…</li>
<li>D. <code>$REVISION</code></li>
</ul>
</li>
<li>
<p><strong>You need to build containers inside a private VPC. What should you use?</strong></p>
<ul>
<li>A. Public workers</li>
<li>B. <strong>Private pools</strong> âœ…</li>
<li>C. Compute Engine</li>
<li>D. Cloud Run jobs</li>
</ul>
</li>
<li>
<p><strong>What triggers a Cloud Build automatically?</strong></p>
<ul>
<li>A. <strong>GitHub push event</strong> âœ…</li>
<li>B. Console refresh</li>
<li>C. API Gateway</li>
<li>D. Cloud Scheduler only</li>
</ul>
</li>
<li>
<p><strong>Where are built Docker images typically stored?</strong></p>
<ul>
<li>A. Cloud Storage</li>
<li>B. <strong>Artifact Registry</strong> âœ…</li>
<li>C. Compute Engine</li>
<li>D. Secret Manager</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<!-- FLASHCARDS
[
  {"term": "Cloud Build", "def": "GCP-native CI/CD service. Runs build steps in containers. Integrates with GitHub/GitLab."},
  {"term": "cloudbuild.yaml", "def": "Configuration file defining build steps, images, and substitutions."},
  {"term": "Trigger", "def": "Event that starts a build (push, PR, schedule, manual)."},
  {"term": "Private Pool", "def": "Build workers inside your VPC. For security-sensitive builds."},
  {"term": "Artifact Registry", "def": "Managed storage for container images and packages. Successor to Container Registry."},
  {"term": "$SHORT_SHA", "def": "Built-in substitution for first 7 characters of commit SHA."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_27_iac">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 3 min read</div>
<h1>Day 27: Infrastructure as Code (Terraform)</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­ Low (But growing)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 27, learners will be able to:
*   <strong>Define</strong> IaC (Infrastructure as Code).
*   <strong>Compare</strong> Imperative (gcloud) vs Declarative (Terraform).
*   <strong>Read</strong> a basic Terraform file.</p>
<hr />
<h2>ğŸ§  1. Why Code?</h2>
<p>Clicking in the Console is fun for Day 1.
It is a nightmare for Day 100.
*   "Did Bob enable the firewall? Or was it Alice?"
*   "We need to create the exact same environment in Europe. Do we click 500 times again?"</p>
<p><strong>Solution:</strong> <strong>Infrastructure as Code (IaC)</strong>.
You write a text file describing your infra. You run a tool. The tool builds it.</p>
<hr />
<h2>ğŸ¡ 2. Real-World Analogy: The Blueprint</h2>
<ul>
<li><strong>Console/gcloud</strong> = <strong>Building a house by shouting.</strong><ul>
<li>"Put a brick there! Wait, move it left!"</li>
<li>Hard to replicate.</li>
</ul>
</li>
<li><strong>Terraform</strong> = <strong>The Blueprint</strong>.<ul>
<li>You give the contractor a drawing.</li>
<li>It shows <em>exactly</em> what the final house should look like.</li>
<li>You can give the same blueprint to another contractor to build a clone.</li>
</ul>
</li>
</ul>
<hr />
<h2>âš”ï¸ 3. Imperative vs Declarative</h2>
<ul>
<li><strong>Imperative (gcloud / Script):</strong> "Step 1: Create VM. Step 2: Add Disk."<ul>
<li><em>Problem:</em> If you run it twice, you get 2 VMs (or an error).</li>
</ul>
</li>
<li><strong>Declarative (Terraform):</strong> "I want 1 VM to exist."<ul>
<li><em>Benefit:</em> If you run it twice, Terraform says "It already exists. Nothing to do." (Idempotent).</li>
</ul>
</li>
</ul>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Read Terraform</h2>
<p><em>Note: We won't install Terraform today (it takes too long), but we will analyze the code.</em></p>
<p><strong>main.tf:</strong></p>
<pre><code class="language-hcl">resource &quot;google_compute_instance&quot; &quot;default&quot; {
  name         = &quot;my-vm&quot;
  machine_type = &quot;e2-medium&quot;
  zone         = &quot;us-central1-a&quot;

  boot_disk {
    initialize_params {
      image = &quot;debian-cloud/debian-11&quot;
    }
  }

  network_interface {
    network = &quot;default&quot;
  }
}
</code></pre>
<ul>
<li><strong>resource:</strong> What we are creating.</li>
<li><strong>google_compute_instance:</strong> The GCP resource type.</li>
<li><strong>"default":</strong> The local name in code.</li>
<li><strong>properties:</strong> The inputs (name, zone).</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Quick Knowledge Check (Quiz)</h2>
<ol>
<li>
<p><strong>What is the main benefit of Infrastructure as Code?</strong></p>
<ul>
<li>A. It's faster to write once.</li>
<li>B. <strong>Reproducibility and Version Control (Git).</strong> âœ…</li>
<li>C. It requires knowing Python.</li>
</ul>
</li>
<li>
<p><strong>Which Google Cloud native tool is similar to Terraform?</strong></p>
<ul>
<li>A. Cloud Build</li>
<li>B. <strong>Deployment Manager</strong> âœ…</li>
<li>C. Cloud Spanner</li>
</ul>
</li>
<li>
<p><strong>Terraform is:</strong></p>
<ul>
<li>A. Imperative (Step-by-step).</li>
<li>B. <strong>Declarative (End-state description).</strong> âœ…</li>
</ul>
</li>
<li>
<p><strong>If you run a Terraform apply command twice, what happens?</strong></p>
<ul>
<li>A. It duplicates resources.</li>
<li>B. <strong>It does nothing the second time (Idempotent), because the state matches.</strong> âœ…</li>
<li>C. It deletes resources.</li>
</ul>
</li>
<li>
<p><strong>Where do you store your Terraform files?</strong></p>
<ul>
<li>A. In a bucket.</li>
<li>B. <strong>In a Version Control System (like GitHub).</strong> âœ…</li>
<li>C. On a USB drive.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand why clicking in the console is bad for Prod.', checked: false },
        { text: 'I know the difference between Imperative and Declarative.', checked: false },
        { text: 'I can identify a Resource in a Terraform file.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 27 Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_28_week_4_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 28: Week 4 Review &amp; Deep Dive</h1>
<p><strong>Level:</strong> Review<br />
<strong>Milestone:</strong> ğŸ Week 4 Complete! (Ops &amp; Security)</p>
<hr />
<h2>ğŸ” 1. Week 4 Visual Recap</h2>
<p>This week moved from "Building" to "Operating." You learned how to monitor health, secure the perimeter, and manage the organization's resources.</p>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Operations Hub (Day 22-23)&quot;
        MON[Cloud Monitoring]
        LOG[Cloud Logging]
        FUN[Cloud Functions]
    end

    subgraph &quot;Security Perimeter (Day 24-25)&quot;
        IAP[Identity-Aware Proxy]
        FW[Firewall Rules]
        ARM[Cloud Armor]
    end

    subgraph &quot;Governance (Day 26-27)&quot;
        BIL[Billing &amp; Budgets]
        BLD[Cloud Build CI/CD]
    end

    MON -.-&gt;|Alert| FUN
    FW --&gt; IAP
    ARM --&gt; FW
    BLD --&gt;|Audit| LOG
</code></pre>
<hr />
<h2>ğŸ¯ 2. High-Frequency Exam Scenarios</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Scenario</th>
<th style="text-align: left;">Recommended Solution</th>
<th style="text-align: left;">ACE Key Concept</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>"Monitor RAM on a VM"</strong></td>
<td style="text-align: left;">Install <strong>Ops Agent</strong>.</td>
<td style="text-align: left;">Hypervisor Visibility Gap.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Secure SSH without Public IP"</strong></td>
<td style="text-align: left;">Use <strong>IAP Tunneling</strong>.</td>
<td style="text-align: left;">Identity-based Access.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Retain logs for 7 years"</strong></td>
<td style="text-align: left;">Create a <strong>Log Sink</strong> to GCS.</td>
<td style="text-align: left;">Compliance Archiving.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Stop DDoS / SQL Injection"</strong></td>
<td style="text-align: left;">Attach <strong>Cloud Armor</strong> to GLB.</td>
<td style="text-align: left;">Edge-based WAF.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Predict future costs via SQL"</strong></td>
<td style="text-align: left;">Enable <strong>BigQuery Billing Export</strong>.</td>
<td style="text-align: left;">Cost Analysis.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"Deploying to Private GKE"</strong></td>
<td style="text-align: left;">Use <strong>Cloud Build Private Pools</strong>.</td>
<td style="text-align: left;">VPC Peering.</td>
</tr>
</tbody>
</table>
<hr />
<h2>âš ï¸ 3. Pro Troubleshooting Strategy</h2>
<h3>The "Least Privilege" Flowchart</h3>
<p>When a build or service fails with a <code>403 Forbidden</code> error:
1.  <strong>Identify the Project Number</strong> of your project.
2.  <strong>Locate the Service Account</strong>: It usually follows the pattern <code>[PROJECT_NUMBER]@cloudbuild.gserviceaccount.com</code> (for Cloud Build) or <code>[PROJECT_NUMBER]-compute@developer.gserviceaccount.com</code> (for GCE).
3.  <strong>Grant the Minimal Role</strong>: Don't give <code>Owner</code>. If it's a deployment, give <code>Cloud Run Admin</code> or <code>Kubernetes Engine Developer</code>.</p>
<hr />
<h2>ğŸ§ª 4. Batch 2 Hands-On Review</h2>
<p><strong>Project: The Zero-Trust Bridge</strong></p>
<ol>
<li><strong>Isolation</strong>: Create a VM with no public IP.</li>
<li><strong>Tunneling</strong>: Allow IAP range (<code>35.235.240.0/20</code>) on Port 22.</li>
<li><strong>Observability</strong>: Install Ops Agent and verify that Memory metrics appear in the Dashboard.</li>
<li><strong>Audit</strong>: Export the SSH login logs to a specific BigQuery table using a Log Sink.</li>
</ol>
<hr />
<h2>ğŸ† 5. Week 4 Mock Exam (ACE Alignment)</h2>
<ol>
<li>
<p><strong>You need to ensure that your application's memory usage is being tracked in Cloud Monitoring. After viewing the dashboard, you see 'No Data' for the 'memory/percent_used' metric. What is the first corrective action?</strong></p>
<ul>
<li>A. Increase the VM machine type.</li>
<li>B. <strong>Install the Ops Agent on the VM.</strong> âœ…</li>
<li>C. Enable the Cloud Monitoring API.</li>
<li>D. Create an Uptime Check.</li>
</ul>
</li>
<li>
<p><strong>A security policy requires that all SSH logins to Compute Engine instances must be authenticated via IAM and occur without exposing Port 22 to the public internet. Which feature should you implement?</strong></p>
<ul>
<li>A. Cloud VPN</li>
<li>B. VPC Peering</li>
<li>C. <strong>Identity-Aware Proxy (IAP) Tunneling.</strong> âœ…</li>
<li>D. Cloud Armor</li>
</ul>
</li>
<li>
<p><strong>You are managing a multi-project organization. You want to see the total spending of all projects combined into a single, searchable SQL database for the last 6 months. What is the most efficient method?</strong></p>
<ul>
<li>A. Download CSVs from each project and merge them.</li>
<li>B. <strong>Configure a Billing Export to BigQuery at the Billing Account level.</strong> âœ…</li>
<li>C. Use the Cloud Operations Dashboard.</li>
<li>D. Create a Log Sink to Cloud Storage.</li>
</ul>
</li>
<li>
<p><strong>A Cloud Build pipeline fails to deploy a new container to Cloud Run. The error message is 'Permission denied'. Cloud Build is using the default service account. How do you fix this?</strong></p>
<ul>
<li>A. Give the developer the 'Owner' role.</li>
<li>B. <strong>Grant the Cloud Build service account the 'Cloud Run Admin' role.</strong> âœ…</li>
<li>C. Open the Cloud Run service to 'allUsers'.</li>
<li>D. Disable the Cloud Run API and re-enable it.</li>
</ul>
</li>
<li>
<p><strong>Which Google Cloud service should be used to block incoming traffic to a specific web application based on the user's geographic location (e.g., blocking all traffic from outside the US)?</strong></p>
<ul>
<li>A. VPC Firewall Rules</li>
<li>B. <strong>Cloud Armor.</strong> âœ…</li>
<li>C. Cloud NAT</li>
<li>D. Identity-Aware Proxy</li>
</ul>
</li>
</ol>
<hr />
<h2>ğŸš€ 6. Next Steps: Week 5</h2>
<p>Congratulations on completing the <strong>Core Infrastructure &amp; Operations</strong> track! </p>
<p>Next week, we level up to <strong>Week 5: Advanced Architecting</strong>, where we dive into:
- Hybrid Connectivity (VPN/Interconnect Deep Dive).
- Data Analytics Pipelines (BigQuery, Pub/Sub, Dataflow).
- Database Migrations &amp; Modernization.</p>
<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_29_architect_case_studies">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 29: Architect Case Studies (Thinking Like a Pro)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (The "Synthesis" Day)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 29, you will be able to:
*   <strong>Deconstruct</strong> complex business requirements into GCP service components.
*   <strong>Apply</strong> architectural patterns for global scale, high availability, and strict compliance.
*   <strong>Evaluate</strong> trade-offs between different compute and storage options in real-world scenarios.
*   <strong>Select</strong> the correct database and messaging patterns for specific workload types (IoT, Payments, Analytics).</p>
<hr />
<h2>ğŸ—ï¸ 1. Scenario A: The "Uber" Clone (Global Real-Time)</h2>
<p><strong>Requirement:</strong>
*   Global scale with drivers/riders across 3 continents.
*   Real-time location tracking (Driver updates lat/long every 5s).
*   Strongly consistent payment processing (No double-charging).
*   Predictive analytics for surge pricing.</p>
<h3>The Architecture</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Global Edge&quot;
        LB[Global External LB + Cloud CDN]
    end

    subgraph &quot;Compute Tier (GKE)&quot;
        MS[Matchmaking Microservices]
        PAY[Payment Microservices]
    end

    subgraph &quot;Streaming Tier&quot;
        PS[Cloud Pub/Sub]
        DF[Cloud Dataflow]
    end

    subgraph &quot;Storage Tier&quot;
        BT[&quot;Cloud Bigtable (Location Hist)&quot;]
        SPAN[&quot;Cloud Spanner (Payments)&quot;]
        BQ[&quot;BigQuery (Surge Analytics)&quot;]
    end

    LB --&gt; MS
    MS --&gt; PS
    PS --&gt; DF
    DF --&gt; BT
    DF --&gt; BQ
    MS --&gt; SPAN
</code></pre>
<p><strong>Why these choices?</strong>
*   <strong>Cloud Spanner:</strong> The only choice for global SQL consistency across regions for payments.
*   <strong>Bigtable:</strong> Optimized for the millions of low-latency writes required for driver GPS pings.
*   <strong>Dataflow:</strong> Processes the stream from Pub/Sub to calculated surge pricing in real-time.</p>
<hr />
<h2>ğŸ¬ 2. Scenario B: The "Netflix" Clone (High Bandwidth)</h2>
<p><strong>Requirement:</strong>
*   Petabytes of video content stored and distributed globally.
*   Personalized recommendations using ML models.
*   Zero buffering for users worldwide.</p>
<h3>The Content Delivery Pipeline</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Storage &amp; Processing&quot;
        GCS[Cloud Storage Objects]
        TC[Transcoding Jobs]
    end

    subgraph &quot;Edge Distribution&quot;
        CDN[Cloud CDN]
        LB[Global Load Balancer]
    end

    subgraph &quot;Intelligence&quot;
        BQ[BigQuery Watch History]
        VX[Vertex AI Model]
    end

    GCS --&gt; TC --&gt; GCS
    GCS --&gt; CDN
    CDN --&gt; User[End User]
    User --&gt; BQ --&gt; VX --&gt; User
</code></pre>
<p><strong>Why these choices?</strong>
*   <strong>Cloud CDN + GCS:</strong> Massive egress at the edge reduces latency and cost.
*   <strong>Vertex AI:</strong> Seamlessly integrates with BigQuery data to serve one-to-one recommendations.</p>
<hr />
<h2>ğŸ¦ 3. Scenario C: The "Regulated Bank" (Zero Trust)</h2>
<p><strong>Requirement:</strong>
*   Absolute network isolation (No egress to the internet).
*   7-year audit log retention for compliance.
*   Encryption keys managed by the bank (CMEK).</p>
<h3>The Zero-Trust Architecture</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;On-Premises&quot;
        HQ[Bank HQ]
    end

    subgraph &quot;GCP Network (Shared VPC)&quot;
        IC[Cloud Interconnect]
        VPN[Cloud VPN Backup]
    end

    subgraph &quot;Service Perimeter&quot;
        VPC_SC[VPC Service Controls]
        CMEK[Cloud KMS / Keys]
    end

    subgraph &quot;Resources&quot;
        SQL[Cloud SQL Private]
        LOG[Log Sink -&gt; Archive GCS]
    end

    HQ --- IC
    IC --- VPC_SC
    VPC_SC --- SQL
    SQL --- CMEK
    SQL --&gt; LOG
</code></pre>
<hr />
<h2>ğŸ§  4. The "Decision Matrix" (Cheat Sheet)</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">If you need...</th>
<th style="text-align: left;">Your Primary Choice</th>
<th style="text-align: left;">The "Why"</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Global SQL / ACID</strong></td>
<td style="text-align: left;"><strong>Cloud Spanner</strong></td>
<td style="text-align: left;">Consistency across continents.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>High Throughput NoSQL</strong></td>
<td style="text-align: left;"><strong>Cloud Bigtable</strong></td>
<td style="text-align: left;">Low latency, massive write scale.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Analytical Warehouse</strong></td>
<td style="text-align: left;"><strong>BigQuery</strong></td>
<td style="text-align: left;">Serverless, petabyte-scale SQL.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Private Internal GCE</strong></td>
<td style="text-align: left;"><strong>IAP + Private Access</strong></td>
<td style="text-align: left;">SECURE admin access.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Event-Driven Glue</strong></td>
<td style="text-align: left;"><strong>Cloud Functions</strong></td>
<td style="text-align: left;">Short-lived snippets.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Hybrid Connection</strong></td>
<td style="text-align: left;"><strong>Interconnect</strong></td>
<td style="text-align: left;">Low latency, high bandwidth (&gt;10Gb).</td>
</tr>
</tbody>
</table>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You are designing a global inventory system that requires strong consistency for stock levels across Asia and the US. Which database should you use?</strong></p>
<ul>
<li>A. Cloud SQL with read replicas.</li>
<li>B. <strong>Cloud Spanner.</strong> âœ…</li>
<li>C. Cloud Bigtable.</li>
<li>D. BigQuery.</li>
</ul>
</li>
<li>
<p><strong>A media company needs to serve video content to millions of global users with minimum latency. Which combination of services is most effective?</strong></p>
<ul>
<li>A. Compute Engine + VPC Peering.</li>
<li>B. <strong>Cloud Storage + Cloud CDN.</strong> âœ…</li>
<li>C. Cloud SQL + Cloud Armor.</li>
<li>D. Cloud Build + GKE.</li>
</ul>
</li>
<li>
<p><strong>A bank requires that its data be encrypted with keys that they can rotate and disable at any time. Which management option should you recommend?</strong></p>
<ul>
<li>A. Default Google-managed encryption.</li>
<li>B. <strong>Customer-Managed Encryption Keys (CMEK) via Cloud KMS.</strong> âœ…</li>
<li>C. Customer-Supplied Encryption Keys (CSEK).</li>
<li>D. IAM Role: Owner.</li>
</ul>
</li>
<li>
<p><strong>You need to process 1 million IoT sensor events per second and store them for long-term analytical trends. What is the best pipeline?</strong></p>
<ul>
<li>A. Pub/Sub -&gt; Cloud SQL.</li>
<li>B. <strong>Pub/Sub -&gt; Dataflow -&gt; Bigtable (Real-time) + BigQuery (Long-term).</strong> âœ…</li>
<li>C. Cloud Storage -&gt; App Engine.</li>
<li>D. Deployment Manager -&gt; Compute Engine.</li>
</ul>
</li>
<li>
<p><strong>A company wants to connect their data center to GCP with a dedicated, physical 10Gbps connection that does not use the public internet. What is this called?</strong></p>
<ul>
<li>A. Cloud VPN.</li>
<li>B. <strong>Dedicated Interconnect.</strong> âœ…</li>
<li>C. Partner Interconnect.</li>
<li>D. VPC Peering.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can map business requirements to specific GCP products.', checked: false },
        { text: 'I understand when to choose Cloud Spanner over Cloud SQL.', checked: false },
        { text: 'I know the basic anatomy of a data streaming pipeline (Pub/Sub -> Dataflow).', checked: false },
        { text: 'I understand the role of VPC Service Controls in data security.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" width="24" height="24" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 29 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_30_bigquery">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>Day 30: BigQuery &amp; Data Warehousing</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (BigQuery Cost-Saving Essentials)</strong><br />
BigQuery = Serverless data warehouse. Charged $5 per TB scanned. <strong>LIMIT does NOT reduce cost</strong> (data is scanned before limiting). Use <strong>Partitioning</strong> (skip whole files) and <strong>Clustering</strong> (sort within partitions) to reduce scans. <strong>Colossus</strong> = storage, <strong>Dremel</strong> = compute. Always check the <strong>Query Validator</strong> before running expensive queries.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explain</strong> serverless architecture</td>
<td>Understand Colossus vs Dremel</td>
</tr>
<tr>
<td><strong>Execute</strong> queries on public datasets</td>
<td>Hands-on skill</td>
</tr>
<tr>
<td><strong>Optimize</strong> with Partitioning/Clustering</td>
<td>Save money on queries</td>
</tr>
<tr>
<td><strong>Differentiate</strong> pricing models</td>
<td>On-Demand vs Capacity (Slots)</td>
</tr>
<tr>
<td><strong>Implement</strong> data ingestion</td>
<td>Streaming vs Batch</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 1. Architecture: The Power of Separation</h2>
<p>BigQuery is not a traditional database. Its performance comes from the total separation of <strong>Compute</strong> and <strong>Storage</strong>, connected by a high-speed "Jupiter" network.</p>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Dremel (Compute Tier)&quot;
        S1[Slot 1]
        S2[Slot 2]
        S3[Slot 3]
    end

    subgraph &quot;Jupiter Network (Petabit/s)&quot;
        N[High-Speed Fabric]
    end

    subgraph &quot;Colossus (Storage Tier)&quot;
        C1[(Columnar File 1)]
        C2[(Columnar File 2)]
        C3[(Columnar File 3)]
    end

    S1 &lt;--&gt; N
    S2 &lt;--&gt; N
    S3 &lt;--&gt; N
    N &lt;--&gt; C1
    N &lt;--&gt; C2
    N &lt;--&gt; C3
</code></pre>
<ul>
<li><strong>Colossus (Storage):</strong> Stores data in <strong>Capacitor</strong> (columnar) format. Because it's columnar, BigQuery only reads the specific columns your query requests, drastically reducing I/O.</li>
<li><strong>Dremel (Compute):</strong> A massive distributed query engine that compiles your SQL into an execution tree across thousands of "slots" (CPUs).</li>
</ul>
<hr />
<h2>ğŸ’° 2. Cost Management: Avoid the "Bill Shock"</h2>
<p>BigQuery charges for two things: <strong>Storage</strong> (very cheap) and <strong>Analysis</strong> (can be expensive).</p>
<h3>Pricing Models</h3>
<ol>
<li><strong>On-Demand:</strong> $5 per TB scanned. Great for unpredictable workloads.</li>
<li><strong>Edition Pricing (Slots):</strong> You buy capacity (Autoscaling slots). Best for large enterprises with steady workloads.</li>
</ol>
<h3>ğŸ›¡ï¸ Guardrails</h3>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: The Validator</strong>
Before you hit "Run", always check the <strong>Query Validator</strong> in the bottom right of the BigQuery UI. It tells you exactly how many gigabytes or terabytes will be processed. <strong><code>LIMIT 10</code> does NOT reduce cost!</strong> It filters the results <em>after</em> the scan is complete.</p>
</blockquote>
<hr />
<table>
<thead>
<tr>
<th style="text-align: left;">Technique</th>
<th style="text-align: left;">How it Works</th>
<th style="text-align: left;">Analogy</th>
<th style="text-align: left;">Cost Benefit</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Partitioning</strong></td>
<td style="text-align: left;">Divides by Date/Integer</td>
<td style="text-align: left;">Bookshelf sections</td>
<td style="text-align: left;">ğŸš€ Huge (Skips whole files)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Clustering</strong></td>
<td style="text-align: left;">Sorts within partition</td>
<td style="text-align: left;">Alphabetical sorting</td>
<td style="text-align: left;">ğŸ“ˆ Good (Sorts data for faster scan)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!IMPORTANT]
<strong>Constraint:</strong> You can have up to 4,000 partitions per table. If your data is more granular, use <strong>Clustering</strong> alongside Partitioning.</p>
</blockquote>
<hr />
<h2>ğŸ”¬ 4. Advanced BigQuery (The "Market Best" Edge)</h2>
<h3>ğŸ¤– BigQuery ML (SQL + AI)</h3>
<p>You don't need Python to build ML models. You can do it in SQL!</p>
<pre><code class="language-sql">CREATE MODEL `my_dataset.my_model`
OPTIONS(model_type='linear_reg') AS
SELECT label, feature1, feature2 FROM `my_table`;
</code></pre>
<h3>ğŸ›¡ï¸ Data Governance &amp; Security</h3>
<ul>
<li><strong>Column-Level Security:</strong> Restrict access to specific columns (e.g., PII like <code>ssn</code>) using Policy Tags.</li>
<li><strong>Data Masking:</strong> Show only the last 4 digits of a credit card to certain users.</li>
<li><strong>Authorized Views:</strong> Share query results with others without giving them access to the underlying table.</li>
</ul>
<h3>ğŸŒ BigQuery Omni</h3>
<p>Query data residing in <strong>AWS S3</strong> or <strong>Azure Blob Storage</strong> directly from the BigQuery UI without moving the data.</p>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Querying the Planet</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Query a 100GB+ public dataset using partitioning logic to keep costs zero.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Open BigQuery Console</strong>: Search for "Public Datasets".</li>
<li><strong>Explore</strong>: Find <code>bigquery-public-data.ghcn_d</code> (Global Historical Climatology Network).</li>
<li><strong>Run an Inefficient Query</strong> (DO NOT actually run, just look at the validator):
    <code>sql
    SELECT id, date, element, value 
    FROM `bigquery-public-data.ghcn_d.ghcnd_2024` 
    -- This scans the whole year! (e.g., 80 GB)</code></li>
<li><strong>Run an Optimized Query</strong>:
    <code>sql
    SELECT id, element, value 
    FROM `bigquery-public-data.ghcn_d.ghcnd_2024` 
    WHERE date = '2024-06-01'
    -- If partitioned by date, this scans &lt; 1 GB.</code></li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You are charged $5,000 for a single query. What is the most likely reason?</strong></p>
<ul>
<li>A. You used too many <code>JOIN</code> statements.</li>
<li>B. <strong>The query scanned a massive amount of data on a non-partitioned table.</strong> âœ…</li>
<li>C. You forgot to use <code>LIMIT 10</code>.</li>
<li>D. You streamed the data into the table.</li>
</ul>
</li>
<li>
<p><strong>A company wants a set, predictable monthly bill for their BigQuery usage. Which pricing model should they choose?</strong></p>
<ul>
<li>A. On-Demand Pricing.</li>
<li>B. <strong>Capacity Pricing (Slots).</strong> âœ…</li>
<li>C. Flat-rate Storage.</li>
<li>D. Bigtable Tiers.</li>
</ul>
</li>
<li>
<p><strong>Which architectural component of BigQuery is responsible for storing data in a columnar format?</strong></p>
<ul>
<li>A. Dremel.</li>
<li>B. <strong>Colossus.</strong> âœ…</li>
<li>C. Borg.</li>
<li>D. BigTable.</li>
</ul>
</li>
<li>
<p><strong>You need to stream real-time events into BigQuery for immediate analysis. Is it possible?</strong></p>
<ul>
<li>A. No, BigQuery only supports batch loading.</li>
<li>B. <strong>Yes, using the Streaming API (via Dataflow or direct API calls).</strong> âœ…</li>
<li>C. Yes, but only for tables smaller than 10GB.</li>
<li>D. Yes, by using Cloud SQL as a proxy.</li>
</ul>
</li>
<li>
<p><strong>True or False: Using 'SELECT *' is generally considered a best practice in BigQuery to ensure all data is cached.</strong></p>
<ul>
<li>A. True.</li>
<li>B. <strong>False. Only select the columns you need to save on bytes scanned.</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand that Compute and Storage are separate in BigQuery.', checked: false },
        { text: 'I know how to use the Query Validator to estimate costs.', checked: false },
        { text: 'I can explain why LIMIT does not save money on scanning costs.', checked: false },
        { text: 'I understand the performance benefits of Clustering.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 30 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_30_final_exam_readiness">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 30: Final Exam Readiness - The Complete Strategy Guide</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> All Levels<br />
<strong>Purpose:</strong> Exam preparation and strategy</p>
<hr />
<h2>ğŸ The Final Stretch</h2>
<p>You've completed 29 days of intense study. You built VPCs, deployed Kubernetes clusters, optimized BigQuery tables, and secured IAM policies. <strong>You are ready.</strong></p>
<hr />
<h2>ğŸ† 1. The "Golden Rules" of GCP Exams</h2>
<h3>Rule #1: Business Constraints Dictate Answers</h3>
<p>Google exams test <strong>architectural thinking</strong>, not command memorization.</p>
<table>
<thead>
<tr>
<th>Question Pattern</th>
<th>Look For</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Store data with sub-ms latency"</td>
<td>Low latency requirement</td>
<td>Memorystore (Redis)</td>
</tr>
<tr>
<td>"Query with SQL"</td>
<td>SQL requirement</td>
<td>Cloud SQL or Spanner</td>
</tr>
<tr>
<td>"Store cheaply for 7 years"</td>
<td>Long retention</td>
<td>Archive Storage</td>
</tr>
<tr>
<td>"Global users, ACID transactions"</td>
<td>Global + consistency</td>
<td>Cloud Spanner</td>
</tr>
<tr>
<td>"Process petabytes of data"</td>
<td>Big data analytics</td>
<td>BigQuery</td>
</tr>
</tbody>
</table>
<h3>Rule #2: The 50/50 Elimination</h3>
<p>Usually 2 answers are obviously wrong. Identify them first to double your odds.</p>
<h3>Rule #3: Watch for "Minimal Effort" Keywords</h3>
<p>When you see "minimum operational overhead" or "least administrative effort":
- Prefer <strong>managed services</strong> over self-managed
- Prefer <strong>serverless</strong> over provisioned
- Prefer <strong>Autopilot</strong> over Standard GKE</p>
<hr />
<h2>ğŸ“‹ 2. Top 10 "Must Know" Topics</h2>
<p>If you have 24 hours before the exam, focus on these:</p>
<h3>Compute Services Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Need Compute?] --&gt; B{Containers?}
    B --&gt;|No| C{Need Control?}
    B --&gt;|Yes| D{Kubernetes?}

    C --&gt;|Full Control| CE[Compute Engine]
    C --&gt;|Just Code| E{Scaling Needs?}

    D --&gt;|Yes| GKE[GKE]
    D --&gt;|No| CR[Cloud Run]

    E --&gt;|Auto| F{HTTP?}
    E --&gt;|Manual| CE

    F --&gt;|Yes| AE[App Engine]
    F --&gt;|Event| CF[Cloud Functions]

    style GKE fill:#e8f5e9,stroke:#4caf50
    style CR fill:#e3f2fd,stroke:#2196f3
</code></pre>
<h3>Quick Reference Table</h3>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Key Facts</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IAM</strong></td>
<td>Identity â†’ Role â†’ Resource. Least privilege. Service accounts for apps.</td>
</tr>
<tr>
<td><strong>VPC</strong></td>
<td>VPCs are global, Subnets are regional. Firewall rules are stateful.</td>
</tr>
<tr>
<td><strong>Compute</strong></td>
<td>CE (VMs) &lt; App Engine (PaaS) &lt; Cloud Run (containers) &lt; Functions (events)</td>
</tr>
<tr>
<td><strong>Storage Classes</strong></td>
<td>Standard â†’ Nearline (30d) â†’ Coldline (90d) â†’ Archive (365d)</td>
</tr>
<tr>
<td><strong>Databases</strong></td>
<td>SQL (Cloud SQL), Global (Spanner), NoSQL (Bigtable), Analytics (BigQuery)</td>
</tr>
<tr>
<td><strong>Load Balancing</strong></td>
<td>HTTP(S) is global, Network LB is regional.</td>
</tr>
<tr>
<td><strong>Interconnect</strong></td>
<td>VPN (cheap, encrypted) vs Dedicated (fast, not encrypted by default)</td>
</tr>
<tr>
<td><strong>GKE</strong></td>
<td>Autopilot (Google manages nodes) vs Standard (you manage)</td>
</tr>
<tr>
<td><strong>Ops Suite</strong></td>
<td>Logging (what happened) vs Monitoring (how it's doing) vs Trace (latency)</td>
</tr>
<tr>
<td><strong>Billing</strong></td>
<td>SUDs (auto), CUDs (committed), Spot VMs (cheapest, interruptible)</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  3. Exam Day Strategy</h2>
<h3>Time Management</h3>
<table>
<thead>
<tr>
<th>Action</th>
<th>When</th>
</tr>
</thead>
<tbody>
<tr>
<td>First pass</td>
<td>0-60 min: Answer confident questions</td>
</tr>
<tr>
<td>Mark &amp; skip</td>
<td>If &gt;60 sec: Mark for review, move on</td>
</tr>
<tr>
<td>Second pass</td>
<td>60-90 min: Return to marked questions</td>
</tr>
<tr>
<td>Final review</td>
<td>90-120 min: Double-check flagged answers</td>
</tr>
</tbody>
</table>
<h3>Question Analysis Framework</h3>
<pre><code>1. Read the LAST sentence first (what are they asking?)
2. Identify the CONSTRAINT (cost? latency? compliance?)
3. Eliminate 2 obviously wrong answers
4. Choose between remaining 2 based on constraint
</code></pre>
<h3>Red Flags in Wrong Answers</h3>
<ul>
<li>âŒ "Create your own..." (usually too much effort)</li>
<li>âŒ "Use third-party..." (usually unnecessary)</li>
<li>âŒ "Modify source code..." (usually not needed)</li>
<li>âŒ "Install on VMs..." (usually a managed service exists)</li>
</ul>
<hr />
<h2>ğŸ“Š 4. ACE Exam Domain Weight</h2>
<pre><code class="language-mermaid">pie title ACE Exam Domain Distribution
    &quot;Setting up cloud projects&quot; : 17
    &quot;Planning &amp; configuring compute&quot; : 17
    &quot;Planning &amp; configuring data solutions&quot; : 14
    &quot;Planning &amp; configuring networking&quot; : 14
    &quot;Implementing security&quot; : 19
    &quot;Monitoring &amp; logging&quot; : 11
    &quot;General troubleshooting&quot; : 8
</code></pre>
<h3>Domain-Specific Tips</h3>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Focus Areas</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Security (19%)</strong></td>
<td>IAM, service accounts, VPC firewalls, Cloud Armor</td>
</tr>
<tr>
<td><strong>Compute (17%)</strong></td>
<td>When to use CE vs GKE vs Cloud Run</td>
</tr>
<tr>
<td><strong>Projects (17%)</strong></td>
<td>Hierarchy, billing, quotas, labels</td>
</tr>
<tr>
<td><strong>Data (14%)</strong></td>
<td>Database selection, BigQuery optimization</td>
</tr>
<tr>
<td><strong>Networking (14%)</strong></td>
<td>VPCs, subnets, load balancing, VPN</td>
</tr>
<tr>
<td><strong>Monitoring (11%)</strong></td>
<td>Logging, alerting, dashboards</td>
</tr>
</tbody>
</table>
<hr />
<h2>âœ… 5. Final Revision Checklist (Print This!)</h2>
<h3>The 7-Day Exam Sprint</h3>
<table>
<thead>
<tr>
<th>Day</th>
<th>Focus Area</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Day 7</strong></td>
<td>Weak spots</td>
<td>Take practice exam, note lowest-scoring domains</td>
</tr>
<tr>
<td><strong>Day 6</strong></td>
<td>Compute</td>
<td>Review GKE vs Cloud Run vs App Engine decision tree</td>
</tr>
<tr>
<td><strong>Day 5</strong></td>
<td>Networking</td>
<td>VPC, subnets, firewalls, load balancing types</td>
</tr>
<tr>
<td><strong>Day 4</strong></td>
<td>Security</td>
<td>IAM, service accounts, least privilege, Cloud KMS</td>
</tr>
<tr>
<td><strong>Day 3</strong></td>
<td>Data</td>
<td>Database selection (SQL vs NoSQL vs Analytics)</td>
</tr>
<tr>
<td><strong>Day 2</strong></td>
<td>Operations</td>
<td>Logging vs Monitoring vs Trace vs Error Reporting</td>
</tr>
<tr>
<td><strong>Day 1</strong></td>
<td>Strategy</td>
<td>Review this guide, Top 10 topics, get good sleep</td>
</tr>
</tbody>
</table>
<h3>"Last Hour" Quick Review Topics</h3>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Must Remember</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VPCs</strong></td>
<td>Global resource. Subnets are regional.</td>
</tr>
<tr>
<td><strong>Firewalls</strong></td>
<td>Ingress blocked by default. Egress allowed. Stateful.</td>
</tr>
<tr>
<td><strong>IAM</strong></td>
<td>Principal â†’ Role â†’ Resource. Never use Basic roles in production.</td>
</tr>
<tr>
<td><strong>Storage Classes</strong></td>
<td>Standard â†’ Nearline (30d) â†’ Coldline (90d) â†’ Archive (365d)</td>
</tr>
<tr>
<td><strong>Load Balancers</strong></td>
<td>HTTP(S) = Global. Network = Regional.</td>
</tr>
<tr>
<td><strong>GKE</strong></td>
<td>Autopilot = Google manages nodes. Standard = You manage.</td>
</tr>
<tr>
<td><strong>Health Checks</strong></td>
<td>Must allow <code>130.211.0.0/22</code> and <code>35.191.0.0/16</code> in firewall</td>
</tr>
<tr>
<td><strong>Spot VMs</strong></td>
<td>Cheapest compute. Can be interrupted. Good for batch jobs.</td>
</tr>
</tbody>
</table>
<h3>Mock Exam Readiness Scorecard</h3>
<p>Before taking the real exam, you should score <strong>80%+</strong> on practice exams consistently.</p>
<table>
<thead>
<tr>
<th>Readiness Level</th>
<th>Score Range</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td>ğŸ”´ Not Ready</td>
<td>0-60%</td>
<td>Review fundamentals, do more labs</td>
</tr>
<tr>
<td>ğŸŸ¡ Almost Ready</td>
<td>60-75%</td>
<td>Focus on weak domains</td>
</tr>
<tr>
<td>ğŸŸ¢ Ready</td>
<td>75-85%</td>
<td>Light review, schedule exam</td>
</tr>
<tr>
<td>â­ Confident</td>
<td>85%+</td>
<td>Trust yourself, take the exam!</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¯ 6. Quick Decision Cheatsheet</h2>
<table>
<thead>
<tr>
<th>When They Say...</th>
<th>Answer Is Usually...</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Minimum cost"</td>
<td>Preemptible/Spot VMs, smaller machine types</td>
</tr>
<tr>
<td>"High availability"</td>
<td>Multi-zone, regional resources</td>
</tr>
<tr>
<td>"Disaster recovery"</td>
<td>Multi-region, cross-region replication</td>
</tr>
<tr>
<td>"Real-time analytics"</td>
<td>BigQuery streaming, Pub/Sub + Dataflow</td>
</tr>
<tr>
<td>"Batch processing"</td>
<td>Dataproc, Batch, Cloud Functions</td>
</tr>
<tr>
<td>"Mobile/web backend"</td>
<td>Firebase, Firestore, Cloud Run</td>
</tr>
<tr>
<td>"API management"</td>
<td>Cloud Endpoints, API Gateway</td>
</tr>
<tr>
<td>"Sensitive data"</td>
<td>VPC Service Controls, DLP, KMS</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸš€ 7. You Are Ready!</h2>
<p>Take a deep breath. You didn't just read about the cloudâ€”<strong>you built it</strong>.</p>
<h3>Final Words of Wisdom</h3>
<ul>
<li>Trust your preparation</li>
<li>Don't second-guess too much</li>
<li>If unsure, go with "managed" over "manual"</li>
<li>Remember: 70% to pass, not 100%</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ Final Readiness Quiz</h2>
<ol>
<li>
<p><strong>A question asks for "minimum operational overhead." What approach should you prefer?</strong></p>
<ul>
<li>A. Install on Compute Engine VMs</li>
<li>B. <strong>Use a managed GCP service</strong> âœ…</li>
<li>C. Build a custom solution</li>
<li>D. Use third-party tools</li>
</ul>
</li>
<li>
<p><strong>When you see "global users with ACID transactions," which database is the answer?</strong></p>
<ul>
<li>A. Cloud SQL</li>
<li>B. Bigtable</li>
<li>C. <strong>Cloud Spanner</strong> âœ…</li>
<li>D. Firestore</li>
</ul>
</li>
<li>
<p><strong>What's the best strategy when a question takes more than 60 seconds?</strong></p>
<ul>
<li>A. Keep thinking until solved</li>
<li>B. <strong>Mark for review and move on</strong> âœ…</li>
<li>C. Guess randomly</li>
<li>D. Skip permanently</li>
</ul>
</li>
<li>
<p><strong>Which exam domain has the highest weight (19%)?</strong></p>
<ul>
<li>A. Compute resources</li>
<li>B. <strong>Security</strong> âœ…</li>
<li>C. Networking</li>
<li>D. Data solutions</li>
</ul>
</li>
<li>
<p><strong>The question says "cost-effective" and "fault-tolerant batch job." What's likely the answer?</strong></p>
<ul>
<li>A. Standard VMs with SSD</li>
<li>B. <strong>Spot/Preemptible VMs</strong> âœ…</li>
<li>C. Bare Metal Solution</li>
<li>D. Cloud SQL</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h3>Good Luck! ğŸ€</h3>
<p>You've put in the work. Now go show them what you know.</p>
<!-- FLASHCARDS
[
  {"term": "50/50 Rule", "def": "Eliminate 2 obviously wrong answers first to double your odds on tough questions."},
  {"term": "Business Constraint", "def": "The key requirement in a question (cost, latency, compliance) that dictates the answer."},
  {"term": "Managed Service", "def": "Always prefer managed GCP services over DIY when asked for 'minimum effort'."},
  {"term": "Mark for Review", "def": "If a question takes >60 seconds, flag it and return later."},
  {"term": "Security Domain", "def": "Largest exam domain at 19%. Focus on IAM, firewalls, service accounts."},
  {"term": "Pass Threshold", "def": "70% to pass. You don't need to be perfect."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_31_pubsub">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 31: Pub/Sub &amp; Asynchronous Messaging</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 31, you will be able to:
*   <strong>Design</strong> decoupled architectures using the Publisher-Subscriber pattern.
*   <strong>Differentiate</strong> between Push and Pull delivery mechanisms.
*   <strong>Implement</strong> reliability patterns like Dead Letter Queues (DLQ) and Exponential Backoff.
*   <strong>Configure</strong> message ordering and understand Exactly-Once delivery.</p>
<hr />
<h2>ğŸ¢ Industry Context: Messaging in Production</h2>
<blockquote>
<p>[!NOTE]
<strong>Role Lens:</strong> Event-driven architecture is core to modern systems. Data Engineers and Backend Developers use Pub/Sub daily.</p>
</blockquote>
<h3>Job Roles &amp; Pub/Sub Usage</h3>
<table>
<thead>
<tr>
<th>Role</th>
<th>How They Use Pub/Sub</th>
<th>Day-to-Day Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Engineer</strong></td>
<td>Event streaming, data pipelines</td>
<td>Topics, subscriptions, Dataflow integration</td>
</tr>
<tr>
<td><strong>Backend Developer</strong></td>
<td>Async processing, webhooks</td>
<td>Pub/Sub triggers, DLQ handling</td>
</tr>
<tr>
<td><strong>DevOps Engineer</strong></td>
<td>System notifications</td>
<td>Alerting, CI/CD events</td>
</tr>
<tr>
<td><strong>SRE</strong></td>
<td>Decoupling for resilience</td>
<td>Message retention, monitoring</td>
</tr>
</tbody>
</table>
<h3>Production Patterns</h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Architecture</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Fan-Out</strong></td>
<td>1 topic â†’ multiple subscriptions</td>
<td>Multiple consumers need same events</td>
</tr>
<tr>
<td><strong>Event-Driven</strong></td>
<td>Pub/Sub â†’ Cloud Function</td>
<td>Serverless processing</td>
</tr>
<tr>
<td><strong>Buffering</strong></td>
<td>Pub/Sub as shock absorber</td>
<td>Protect backend from traffic spikes</td>
</tr>
</tbody>
</table>
<h3>âŒ Interview Mistakes to Avoid</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Why It's Bad</th>
<th>What to Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I always use Push subscriptions"</td>
<td>Not always appropriate</td>
<td>"I choose Push for webhooks, Pull for batch processing"</td>
</tr>
<tr>
<td>"I don't configure DLQ"</td>
<td>Poison messages crash workers</td>
<td>"I always set up Dead Letter Queue for failed messages"</td>
</tr>
<tr>
<td>"Messages are processed exactly once by default"</td>
<td>Default is at-least-once</td>
<td>"Default is at-least-once; I enable exactly-once when needed"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 1. Why Decouple? The Silent Hero</h2>
<p>In a synchronous system, a failure in the database crashes the frontend. In an <strong>asynchronous</strong> system, Pub/Sub acts as a persistent buffer, absorbing spikes and ensuring no data is lost during downstream outages.</p>
<h3>Messaging Lifecycle</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Producer&quot;
        App[Web App]
        IoT[IoT Device]
    end

    subgraph &quot;Pub/Sub Service&quot;
        Topic{Topic: 'orders'}
        Sub[Subscription]
    end

    subgraph &quot;Consumers&quot;
        Worker[Inventory Worker]
        CF[Cloud Function]
    end

    App --&gt; Topic
    IoT --&gt; Topic
    Topic --&gt; Sub
    Sub -- &quot;PULL&quot; --&gt; Worker
    Sub -- &quot;PUSH&quot; --&gt; CF
</code></pre>
<hr />
<h2>ğŸ› ï¸ 2. Core Patterns: Push vs. Pull</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;"><strong>Pull</strong> (Standard)</th>
<th style="text-align: left;"><strong>Push</strong> (Webhooks)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>How it works</strong></td>
<td style="text-align: left;">Subscriber asks BQ: "Any messages?"</td>
<td style="text-align: left;">Pub/Sub sends HTTP POST to your app.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Best for</strong></td>
<td style="text-align: left;">High-throughput batch processing.</td>
<td style="text-align: left;">Low-latency, event-driven (Cloud Run/Functions).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Scaling</strong></td>
<td style="text-align: left;">You control the rate (throttling).</td>
<td style="text-align: left;">Pub/Sub scales as fast as your endpoint allows.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Network</strong></td>
<td style="text-align: left;">Behind firewall (outbound only).</td>
<td style="text-align: left;">Requires a public endpoint or IAP.</td>
</tr>
</tbody>
</table>
<h3>Push vs Pull: The ACE Exam Classic</h3>
<p>This comparison appears frequently on the exam. Memorize these selection criteria:</p>
<table>
<thead>
<tr>
<th>If You Need...</th>
<th>Use Pull</th>
<th>Use Push</th>
</tr>
</thead>
<tbody>
<tr>
<td>Webhook integration</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
<tr>
<td>Batch processing worker</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td>Cloud Functions trigger</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
<tr>
<td>VM behind firewall (no public IP)</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td>Control message rate</td>
<td>âœ…</td>
<td>âŒ</td>
</tr>
<tr>
<td>Real-time response</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
</tbody>
</table>
<h3>Why NOT Push?</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Problem with Push</th>
<th>Use Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>No public endpoint</td>
<td>Pub/Sub can't reach you</td>
<td><strong>Pull</strong></td>
</tr>
<tr>
<td>Need throttling</td>
<td>Push sends as fast as possible</td>
<td><strong>Pull</strong> with rate control</td>
</tr>
<tr>
<td>Behind corporate firewall</td>
<td>Inbound blocked</td>
<td><strong>Pull</strong> (outbound only)</td>
</tr>
</tbody>
</table>
<h3>Why NOT Pull?</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Problem with Pull</th>
<th>Use Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>Need instant response</td>
<td>Polling delay</td>
<td><strong>Push</strong></td>
</tr>
<tr>
<td>Triggering Cloud Functions</td>
<td>Functions expect HTTP</td>
<td><strong>Push</strong> (via Eventarc)</td>
</tr>
<tr>
<td>Simple webhook integration</td>
<td>Extra code to poll</td>
<td><strong>Push</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> 
- "Webhook" or "HTTPS endpoint" â†’ <strong>Push subscription</strong>
- "Batch worker", "rate control", or "no public IP" â†’ <strong>Pull subscription</strong></p>
</blockquote>
<h2>ğŸ›¡ï¸ 3. Reliability &amp; "The Graveyard"</h2>
<p>Redundant delivery is part of the job. You must handle failures gracefully.</p>
<ol>
<li><strong>Dead Letter Queues (DLQ):</strong> If a message fails to be acknowledged (NACKed) after $N$ attempts, it is moved to a separate topic. This prevents "poison messages" from crashing your workers in a loop.</li>
<li><strong>Exactly-Once Delivery:</strong> A premium feature that suppresses duplicates at the regional level, ensuring your code doesn't process the same order twice.</li>
<li><strong>Ack Deadline:</strong> The amount of time Pub/Sub waits for a "success" signal before redelivering the message.</li>
</ol>
<hr />
<h2>ğŸ§ª 4. Hands-On Lab: Building a Reliable Pipeline</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Create a topic, a pull subscription with a DLQ, and test message lifecycle.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Initialize Topics</strong>:
    <code>bash
    # Create the main topic and the graveyard
    gcloud pubsub topics create order-processing
    gcloud pubsub topics create order-dead-letter</code></p>
</li>
<li>
<p><strong>Create Subscription with DLQ</strong>:
    <code>bash
    gcloud pubsub subscriptions create order-sub \
        --topic=order-processing \
        --dead-letter-topic=order-dead-letter \
        --max-delivery-attempts=5 \
        --ack-deadline=30</code></p>
</li>
<li>
<p><strong>Publish a Trial Message</strong>:
    <code>bash
    gcloud pubsub topics publish order-processing --message='{"id": 123, "item": "Cloud-Guru-Shirt"}'</code></p>
</li>
<li>
<p><strong>Pull and Acknowledge</strong>:
    <code>bash
    gcloud pubsub subscriptions pull order-sub --auto-ack</code></p>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Your application processes payments. You need to ensure that even if the network fails, an order is never processed twice. Which Pub/Sub feature is most helpful?</strong></p>
<ul>
<li>A. Message Storage.</li>
<li>B. <strong>Exactly-Once Delivery.</strong> âœ…</li>
<li>C. Push Subscriptions.</li>
<li>D. Cloud Logging.</li>
</ul>
</li>
<li>
<p><strong>A specific message keeps causing your subscriber to crash. After 5 retries, you want to stop processing it and move it aside for review. What should you configure?</strong></p>
<ul>
<li>A. An Uptime Check.</li>
<li>B. <strong>A Dead Letter Queue (DLQ).</strong> âœ…</li>
<li>C. A Larger Timeout.</li>
<li>D. A different Region.</li>
</ul>
</li>
<li>
<p><strong>What is the default delivery guarantee of Cloud Pub/Sub?</strong></p>
<ul>
<li>A. Exactly-Once.</li>
<li>B. <strong>At-Least-Once.</strong> âœ…</li>
<li>C. Best-Effort (No guarantee).</li>
<li>D. Synchronous.</li>
</ul>
</li>
<li>
<p><strong>You want to trigger a Cloud Function every time a new image is uploaded to a bucket. What is the most decoupled way to do this?</strong></p>
<ul>
<li>A. Use a Cron job.</li>
<li>B. <strong>Use Pub/Sub Notifications for Cloud Storage.</strong> âœ…</li>
<li>C. Hardcode the function call in the frontend.</li>
<li>D. Use Cloud Interconnect.</li>
</ul>
</li>
<li>
<p><strong>True or False: Pub/Sub topics are regional resources and data cannot be sent from one region to a topic in another.</strong></p>
<ul>
<li>A. True.</li>
<li>B. <strong>False. Pub/Sub is a Global service with regional endpoints for performance.</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the Publish-Subscribe model.', checked: false },
        { text: 'I can explain the difference between Push and Pull.', checked: false },
        { text: 'I know when to use a Dead Letter Queue.', checked: false },
        { text: 'I understand the impact of Ack Deadlines on redelivery.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 31 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_32_dataflow_dataproc">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 32: Dataflow &amp; Dataproc (Massive Scale ETL)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate/Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 32, you will be able to:
*   <strong>Select</strong> between Dataflow and Dataproc based on workload source and legacy requirements.
*   <strong>Architect</strong> an ETL pipeline using Apache Beam for unified batch and stream processing.
*   <strong>Manage</strong> Big Data clusters using Dataproc's ephemeral infrastructure.
*   <strong>Implement</strong> reliability concepts like Windowing and Watermarks in streaming pipelines.</p>
<hr />
<h2>ğŸ—ï¸ 1. The Big Data Choice (Memorize This)</h2>
<p>The ACE exam frequently tests your ability to choose the right processing engine. The decision usually boils down to <strong>Scale vs. Legacy</strong>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;"><strong>Dataflow</strong></th>
<th style="text-align: left;"><strong>Dataproc</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Model</strong></td>
<td style="text-align: left;">Serverless / NoOps</td>
<td style="text-align: left;">Managed Hadoop/Spark Clusters</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Programming</strong></td>
<td style="text-align: left;">Apache Beam (Unified)</td>
<td style="text-align: left;">Spark, Hive, Pig, Flink</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Ideal Use Case</strong></td>
<td style="text-align: left;">New, Green-field development</td>
<td style="text-align: left;">Moving existing Spark/Hadoop to GCP</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Streaming</strong></td>
<td style="text-align: left;">Native and Powerful</td>
<td style="text-align: left;">Spark Streaming (Micro-batch)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Autoscaling</strong></td>
<td style="text-align: left;"><strong>Vertical</strong> (RAM/CPU) + Horizontal</td>
<td style="text-align: left;">Horizontal only</td>
</tr>
</tbody>
</table>
<h3>The "New vs. Old" Flowchart</h3>
<pre><code class="language-mermaid">graph TD
    Start[Need to process Big Data?] --&gt; Spark{Have existing Spark jobs?}
    Spark -- &quot;YES&quot; --&gt; DP[Dataproc: Managed Hadoop]
    Spark -- &quot;NO&quot; --&gt; Serverless{Want to manage VMs?}
    Serverless -- &quot;YES&quot; --&gt; DP
    Serverless -- &quot;NO&quot; --&gt; DF[Dataflow: Serverless ETL]
</code></pre>
<hr />
<h2>ğŸš€ 2. Dataflow: The Beam Advantage</h2>
<p>Dataflow runs <strong>Apache Beam</strong>. The "Beam" name comes from <strong>B</strong>atch + str<strong>EAM</strong>, meaning you write one piece of code that handles both history and real-time data.</p>
<h3>Key Streaming Concepts</h3>
<ul>
<li><strong>Windowing:</strong> Slicing a continuous stream into chunks (e.g., "Sum clicks every 60 seconds").</li>
<li><strong>Watermarks:</strong> The system's "notion of time." It allows Dataflow to handle <strong>Late Data</strong> (e.g., a phone that was offline for 10 minutes then sends a burst of data).</li>
<li><strong>Dataflow Prime:</strong> A newer version that uses <strong>Vertical Autoscaling</strong> to dynamically add RAM/CPU to workers when they hit "Out of Memory" errors.</li>
</ul>
<hr />
<h2>ğŸ˜ 3. Dataproc: The Cloud-Native Hadoop</h2>
<p>Dataproc is for when you want the power of the Open Source ecosystem (Spark/Hadoop) without the pain of managing hardware.</p>
<blockquote>
<p>[!TIP]
<strong>FinOps Pro Tip: Ephemeral Clusters</strong>
Never leave a Dataproc cluster running 24/7. Use the "Job-scoped" cluster pattern: Spin up -&gt; Run Spark Job -&gt; Self-Delete. This ensures you only pay for the exact compute time of the processing.</p>
</blockquote>
<hr />
<h2>ğŸ§ª 4. Hands-On Lab: Google-Scale Processing</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Run a serverless Dataflow job to process a 100MB+ dataset from Cloud Storage into BigQuery.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Open Dataflow Console</strong>: Click "Create Job from Template."</li>
<li><strong>Select Template</strong>: "Text Files on Cloud Storage to BigQuery."</li>
<li><strong>Configure Parameters</strong>:<ul>
<li><strong>Input GCS File</strong>: <code>gs://cloud-samples-data/weather/weather.csv</code></li>
<li><strong>Output Table</strong>: <code>your_project:your_dataset.weather_results</code></li>
<li><strong>Temporary Location</strong>: <code>gs://your-bucket/temp/</code></li>
</ul>
</li>
<li><strong>Execute</strong>: Click <strong>Run Job</strong>.</li>
<li><strong>Monitor</strong>: Switch to the <strong>Execution Graph</strong> view. Note how Dataflow automatically partitions the work across multiple workers.</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You have a team of developers who are experts in Apache Spark. They need to move their 50 existing processing jobs to GCP with minimal code changes. What should you recommend?</strong></p>
<ul>
<li>A. <strong>Cloud Dataproc.</strong> âœ…</li>
<li>B. Cloud Dataflow.</li>
<li>C. Compute Engine with manual installs.</li>
<li>D. BigQuery ML.</li>
</ul>
</li>
<li>
<p><strong>Which Dataflow feature allows the system to handle data that arrives late due to network latency on mobile devices?</strong></p>
<ul>
<li>A. Windowing.</li>
<li>B. <strong>Watermarks.</strong> âœ…</li>
<li>C. PCollections.</li>
<li>D. Cloud Pub/Sub.</li>
</ul>
</li>
<li>
<p><strong>What is the primary benefit of Dataflow being 'Serverless'?</strong></p>
<ul>
<li>A. It's free.</li>
<li>B. It doesn't use VMs.</li>
<li>C. <strong>You don't need to manage clusters, patching, or scaling workers manually.</strong> âœ…</li>
<li>D. It only works for Batch data.</li>
</ul>
</li>
<li>
<p><strong>A company wants to reduce costs for their Dataproc workloads. What is the most effective strategy?</strong></p>
<ul>
<li>A. Run clusters 24/7.</li>
<li>B. <strong>Use Ephemeral Clusters (Create -&gt; Run -&gt; Delete).</strong> âœ…</li>
<li>C. Use only 1 node clusters.</li>
<li>D. Disable Cloud Logging.</li>
</ul>
</li>
<li>
<p><strong>True or False: Apache Beam allows you to use the same code logic for both batch and streaming data processing.</strong></p>
<ul>
<li>A. <strong>True.</strong> âœ…</li>
<li>B. False.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can differentiate between Dataflow (Beam) and Dataproc (Hadoop/Spark).', checked: false },
        { text: 'I understand what Watermarks are in a streaming context.', checked: false },
        { text: 'I know that Dataproc clusters should be ephemeral to save cost.', checked: false },
        { text: 'I understand the concept of unified batch and stream processing.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 32 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_33_hybrid_connectivity">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 33: Hybrid Connectivity (VPN &amp; Interconnect)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 31, you will be able to:
*   <strong>Design</strong> secure bridges between On-Premises data centers and Google Cloud.
*   <strong>Evaluate</strong> the trade-offs between Cloud VPN, Partner Interconnect, and Dedicated Interconnect.
*   <strong>Configure</strong> High-Availability (HA) VPN with BGP dynamic routing.
*   <strong>Identify</strong> use cases for Direct Peering and Carrier Peering.</p>
<hr />
<h2>ğŸ—ï¸ 1. The Global Connectivity Spectrum</h2>
<p>Bridging an on-premises network to GCP requires choosing between the <strong>Public Internet</strong> (VPN) and <strong>Private Fiber</strong> (Interconnect).</p>
<h3>Connectivity Selection Model</h3>
<pre><code class="language-mermaid">graph TD
    Start[Choose Connection] --&gt; Speed{Need &gt; 3 Gbps?}
    Speed -- &quot;NO&quot; --&gt; VPN[HA Cloud VPN: Secure IPsec over Internet]
    Speed -- &quot;YES&quot; --&gt; Fiber[Cloud Interconnect: Private Fiber]

    Fiber --&gt; Router{Own a Router in a Google Colocation?}
    Router -- &quot;YES&quot; --&gt; Ded[Dedicated Interconnect: 10/100 Gbps Physical Link]
    Router -- &quot;NO&quot; --&gt; Part[Partner Interconnect: Connect via ISP / Partner]
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Bandwidth</th>
<th style="text-align: left;">Typical SLA</th>
<th style="text-align: left;">ACE Exam Target</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>HA VPN</strong></td>
<td style="text-align: left;">Up to 3 Gbps</td>
<td style="text-align: left;">99.99%</td>
<td style="text-align: left;">Budget-friendly, encrypted, quick setup.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Partner Interconnect</strong></td>
<td style="text-align: left;">50Mbps - 10Gbps</td>
<td style="text-align: left;">99.99%</td>
<td style="text-align: left;">No physical facility presence, flexible speed.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Dedicated Interconnect</strong></td>
<td style="text-align: left;">10Gbps - 200Gbps</td>
<td style="text-align: left;">99.99%</td>
<td style="text-align: left;">Highest volume, lowest latency, physical fiber.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ›¡ï¸ 2. Cloud VPN: The Secure Tunnel</h2>
<p>Cloud VPN uses <strong>IPsec</strong> to create an encrypted tunnel over the public internet.</p>
<ul>
<li><strong>HA VPN (Recommended):</strong> Uses two external IP addresses and two tunnels from different Google edge devices. Requires <strong>Cloud Router</strong> and <strong>BGP</strong> (Border Gateway Protocol) for dynamic routing.</li>
<li><strong>Security:</strong> Traffic is encrypted at the source (On-prem) and decrypted at the destination (VPC).</li>
</ul>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: The BGP Rule</strong>
HA VPN <em>requires</em> <strong>Cloud Router</strong>. You cannot use static routing and achieve the 99.99% SLA. Cloud Router exchanges IP ranges automatically using BGP.</p>
</blockquote>
<hr />
<h2>ğŸš„ 3. Cloud Interconnect: The Private Wire</h2>
<p>Interconnect provides a private, physical connection that does not traverse the public internet.</p>
<ul>
<li><strong>Dedicated Interconnect:</strong> You physically connect your router to Google's router in a colocation facility.</li>
<li><strong>Partner Interconnect:</strong> You connect to a partner (like Equinix or AT&amp;T), and they connect you to Google.</li>
<li><strong>Direct Peering:</strong> Connecting to Google's public IP range (not for VPC trafficâ€”mostly for GWS/YouTube).</li>
</ul>
<blockquote>
<p>[!WARNING]
<strong>Encryption Note:</strong> Cloud Interconnect is <strong>NOT</strong> encrypted by default. It is a private wire. If your compliance requires encryption over fiber, you must use <strong>MACsec</strong> (for Dedicated) or layer an <strong>HA VPN over Interconnect</strong>.</p>
</blockquote>
<hr />
<h2>ğŸ§ª 4. Hands-On Lab: Simulating a Hybrid Bridge</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Configure a virtual "On-Prem" to "Cloud" bridge using two VPCs and HA VPN.</p>
<h3>âœ… Steps</h3>
<ol>
<li>
<p><strong>Prepare Networks</strong>:</p>
<ul>
<li>Create VPC <code>on-prem-network</code> (Subnet: <code>10.1.0.0/24</code>).</li>
<li>Create VPC <code>gcp-network</code> (Subnet: <code>192.168.1.0/24</code>).</li>
</ul>
</li>
<li>
<p><strong>Create HA VPN Gateway</strong>:</p>
<ul>
<li>Initialize the gateway in <code>gcp-network</code>. Note the two interface IPs Google provides.</li>
</ul>
</li>
<li>
<p><strong>Configure Cloud Router</strong>:</p>
<ul>
<li>Create a Cloud Router in each VPC.</li>
<li>Assign an <strong>ASN</strong> (Autonomous System Number). Use <code>64512</code> for GCP and <code>64513</code> for "On-Prem".</li>
</ul>
</li>
<li>
<p><strong>Establish BGP Sessions</strong>:</p>
<ul>
<li>Configure the tunnels to "talk." Once BGP status is green, you will see the <code>10.1.0.0/24</code> route appear in your <code>gcp-network</code> routing table automatically.</li>
</ul>
</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>A company needs to transfer 50TB of data every night from their data center to BigQuery. They require a 99.99% SLA and consistent sub-10ms latency. What should they use?</strong></p>
<ul>
<li>A. Cloud VPN.</li>
<li>B. <strong>Dedicated Interconnect.</strong> âœ…</li>
<li>C. VPC Peering.</li>
<li>D. Cloud Storage Transfer Service over Internet.</li>
</ul>
</li>
<li>
<p><strong>You are setting up an HA VPN. How many tunnels are required to meet the 99.99% SLA?</strong></p>
<ul>
<li>A. 1.</li>
<li>B. <strong>2 (from two different Google edge interfaces).</strong> âœ…</li>
<li>C. 4.</li>
<li>D. No tunnels, just an IP address.</li>
</ul>
</li>
<li>
<p><strong>Which routing protocol is mandatory when configuring Cloud Router for an HA VPN?</strong></p>
<ul>
<li>A. OSPF.</li>
<li>B. <strong>BGP.</strong> âœ…</li>
<li>C. RIP.</li>
<li>D. Static local routes.</li>
</ul>
</li>
<li>
<p><strong>True or False: Dedicated Interconnect traffic is encrypted by default using IPsec.</strong></p>
<ul>
<li>A. True.</li>
<li>B. <strong>False. It is a private line, but unencrypted unless MACsec or VPN-over-Interconnect is added.</strong> âœ…</li>
</ul>
</li>
<li>
<p><strong>Your company does not have a router in a Google Colocation facility but wants a private connection. Which service should you choose?</strong></p>
<ul>
<li>A. Dedicated Interconnect.</li>
<li>B. <strong>Partner Interconnect.</strong> âœ…</li>
<li>C. Classic VPN.</li>
<li>D. Cloud NAT.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand when to choose VPN over Interconnect.', checked: false },
        { text: 'I know that HA VPN requires Cloud Router and BGP.', checked: false },
        { text: 'I can explain the difference between Dedicated and Partner Interconnect.', checked: false },
        { text: 'I understand that Interconnect is private but NOT encrypted by default.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 33 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_34_db_migration">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 34: Database Migration Strategies</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 34, you will be able to:
*   <strong>Execute</strong> zero-downtime migrations using Database Migration Service (DMS).
*   <strong>Plan</strong> heterogeneous migrations (e.g., Oracle to PostgreSQL) using Schema Conversion tools.
*   <strong>Automate</strong> data ingestion into BigQuery using the Data Transfer Service.
*   <strong>Differentiate</strong> between Homogeneous and Heterogeneous migration paths.</p>
<hr />
<h2>ğŸšš 1. The Migration Continuum</h2>
<p>Moving a database is not a simple "copy-paste." It requires careful planning of the source, destination, and the "Change Data Capture" (CDC) method.</p>
<h3>Migration Decision Matrix</h3>
<pre><code class="language-mermaid">graph TD
    Start[Database Migration?] --&gt; Engine{Same Engine?}
    Engine -- &quot;YES&quot; --&gt; DMS[DMS: Serverless Lift &amp; Shift]
    Engine -- &quot;NO&quot; --&gt; Tool{Engine Change?}

    Tool -- &quot;Oracle to Postgre&quot; --&gt; SCT[Schema Conversion Tool + DMS]
    Tool -- &quot;Data Warehouse&quot; --&gt; BQDT[BigQuery Data Transfer Service]
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Examples</th>
<th style="text-align: left;">Best Tool</th>
<th style="text-align: left;">Complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Homogeneous</strong></td>
<td style="text-align: left;">MySQL to Cloud SQL (MySQL)</td>
<td style="text-align: left;"><strong>DMS</strong></td>
<td style="text-align: left;">ğŸŸ¢ Low</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Heterogeneous</strong></td>
<td style="text-align: left;">SQL Server to PostgreSQL</td>
<td style="text-align: left;"><strong>SCT + DMS</strong></td>
<td style="text-align: left;">ğŸ”´ High</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Data Warehouse</strong></td>
<td style="text-align: left;">Teradata/S3 to BigQuery</td>
<td style="text-align: left;"><strong>BQ Data Transfer</strong></td>
<td style="text-align: left;">ğŸŸ¡ Medium</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ› ï¸ 2. Database Migration Service (DMS)</h2>
<p>DMS is Googleâ€™s serverless tool for moving data into <strong>Cloud SQL</strong> and <strong>AlloyDB</strong>.</p>
<ul>
<li><strong>Serverless Logic:</strong> Google manages the migration instances; you only pay for the target database.</li>
<li><strong>Continuous Sync:</strong> Uses source logs (like MySQL binary logs) to replicate every single write in real-time.</li>
<li><strong>Cutover:</strong> Once the destination reflects the source, you perform a brief "cutover" (changing the app connection string), resulting in seconds of downtime instead of hours.</li>
</ul>
<blockquote>
<p>[!IMPORTANT]
<strong>ACE Exam Alert: Connectivity</strong>
For DMS to work with an on-premises database, you must establish a path. The exam favorite is the <strong>Reverse SSH Tunnel</strong>â€”it's secure and doesn't require complex corporate firewall changes.</p>
</blockquote>
<hr />
<h2>ğŸ“¦ 3. BigQuery Data Transfer Service</h2>
<p>If your goal is <strong>Analytics</strong>, you don't need DMS. You need the Data Transfer Service.</p>
<ul>
<li><strong>Managed Connectors:</strong> Built-in support for Google Ads, YouTube Analytics, AWS S3, and Azure Blob Storage.</li>
<li><strong>Scheduling:</strong> Set it to run every hour, day, or week.</li>
<li><strong>Serverless:</strong> No code needed. Just point-and-click configuration in the console.</li>
</ul>
<hr />
<h2>ğŸ§ª 4. Hands-On Lab: AWS to GCP Migration</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Configure a migration job that mocks moving an Amazon RDS (MySQL) instance to Cloud SQL.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Initialize DMS</strong>: Go to <strong>Database Migration</strong> &gt; <strong>Migration Jobs</strong> &gt; <strong>Create Job</strong>.</li>
<li><strong>Define Source</strong>:<ul>
<li>Set Source Type to <strong>Amazon RDS for MySQL</strong>.</li>
<li>Enter the "RDS Endpoint" and credential details.</li>
</ul>
</li>
<li><strong>Define Destination</strong>:<ul>
<li>Create a new Cloud SQL (MySQL) instance as the target.</li>
</ul>
</li>
<li><strong>Connectivity Method</strong>:<ul>
<li>Choose <strong>VPC Peering</strong> (if connecting from another VPC) or <strong>IP Allowlist</strong>.</li>
</ul>
</li>
<li><strong>Validation</strong>: Click <strong>Verify</strong>. DMS will check if it can read the source bins logs.</li>
<li><strong>Execute</strong>: Start the migration. Monitor the "Full Dump" vs. "Incremental" phases.</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You need to migrate a 500GB production PostgreSQL database from On-Premises to AlloyDB. You can only afford 30 seconds of downtime. What is the best strategy?</strong></p>
<ul>
<li>A. Export to SQL dump, upload to GCS, import to AlloyDB.</li>
<li>B. <strong>Use Database Migration Service (DMS) with continuous replication.</strong> âœ…</li>
<li>C. Use gsutil cp to move the data files.</li>
<li>D. Manual SQL copy-paste.</li>
</ul>
</li>
<li>
<p><strong>Which tool should you use to automatically import daily sales data from Amazon S3 into BigQuery for analysis?</strong></p>
<ul>
<li>A. Cloud Dataflow.</li>
<li>B. <strong>BigQuery Data Transfer Service.</strong> âœ…</li>
<li>C. Cloud Pub/Sub.</li>
<li>D. VPC Peering.</li>
</ul>
</li>
<li>
<p><strong>You want to migrate an Oracle database to Cloud SQL for PostgreSQL. Why can't you use DMS by itself?</strong></p>
<ul>
<li>A. DMS is only for small databases.</li>
<li>B. <strong>Oracle and PostgreSQL use different schemas and dialects; you need a Schema Conversion Tool first.</strong> âœ…</li>
<li>C. Google doesn't support PostgreSQL.</li>
<li>D. Oracle only works on-premises.</li>
</ul>
</li>
<li>
<p><strong>What is a common connectivity method used by DMS to securely connect to an on-premises database through a firewall?</strong></p>
<ul>
<li>A. Public Internet.</li>
<li>B. <strong>Reverse SSH Tunnel.</strong> âœ…</li>
<li>C. ICMP Pings.</li>
<li>D. FTP.</li>
</ul>
</li>
<li>
<p><strong>True or False: BigQuery Data Transfer Service requires you to write custom Python scripts to move data from YouTube Analytics.</strong></p>
<ul>
<li>A. True.</li>
<li>B. <strong>False. It is a managed, configuration-based service.</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between Homogeneous and Heterogeneous migration.', checked: false },
        { text: 'I know how DMS uses replication logs for zero-downtime migrations.', checked: false },
        { text: 'I understand when to use BigQuery Data Transfer over DMS.', checked: false },
        { text: 'I know the importance of Schema Conversion for different DB engines.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 34 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_34_vertex_ai">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 34: Database Modernization &amp; AI/ML Integration</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate to Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­ Medium (Migration &amp; AI basics appear in scenario questions)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (AI/ML &amp; Migration Quick Reference)</strong><br />
<strong>AutoML</strong> = No-code ML (upload data, get model). <strong>Custom Training</strong> = Bring your own TensorFlow/PyTorch. <strong>Database Migration Service (DMS)</strong> = Minimal-downtime migrations to Cloud SQL. <strong>Feature Store</strong> = Share reusable ML features. For exam: "Build model without coding" = AutoML, "Migrate MySQL" = DMS.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… Skill</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Understand</strong> Vertex AI platform</td>
<td>Unified ML platform for all skill levels</td>
</tr>
<tr>
<td><strong>Compare</strong> AutoML vs Custom Training</td>
<td>Pick the right approach for the team</td>
</tr>
<tr>
<td><strong>Design</strong> database migration strategies</td>
<td>Move legacy DBs to GCP</td>
</tr>
<tr>
<td><strong>Apply</strong> modernization best practices</td>
<td>Avoid common migration pitfalls</td>
</tr>
<tr>
<td><strong>Identify</strong> the right AI/ML service</td>
<td>Match service to use case</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. Vertex AI: The Unified ML Platform (Plain-English)</h2>
<p><strong>Vertex AI = One-stop shop for all ML needs.</strong></p>
<p>Think of it like a <strong>car factory</strong>: You can either buy a pre-built car (AutoML) or bring your own design and use their manufacturing equipment (Custom Training).</p>
<h3>ğŸ’¡ Real-World Analogy: Restaurant Kitchen</h3>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Restaurant Analogy</th>
<th>Vertex AI Equivalent</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>No ML Experience</strong></td>
<td>Order from menu</td>
<td>AutoML (data in, model out)</td>
</tr>
<tr>
<td><strong>Some Experience</strong></td>
<td>Customize existing dish</td>
<td>AutoML with tuning</td>
</tr>
<tr>
<td><strong>Expert Chef</strong></td>
<td>Create your own recipe</td>
<td>Custom Training (TensorFlow/PyTorch)</td>
</tr>
<tr>
<td><strong>Restaurant Chain</strong></td>
<td>Standardized recipes everywhere</td>
<td>Feature Store + Model Registry</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ¤– 2. AutoML vs Custom Training</h2>
<h3>Decision Matrix</h3>
<table>
<thead>
<tr>
<th>Factor</th>
<th>AutoML</th>
<th>Custom Training</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Coding Required</strong></td>
<td>âŒ No code</td>
<td>âœ… Python/TensorFlow/PyTorch</td>
</tr>
<tr>
<td><strong>Time to First Model</strong></td>
<td>Hours</td>
<td>Days to Weeks</td>
</tr>
<tr>
<td><strong>Data Required</strong></td>
<td>Minimum samples</td>
<td>Large datasets</td>
</tr>
<tr>
<td><strong>Customization</strong></td>
<td>Limited</td>
<td>Full control</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>Higher per prediction</td>
<td>Lower at scale</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>POCs, business users</td>
<td>Production ML teams</td>
</tr>
</tbody>
</table>
<h3>Supported Data Types</h3>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;AutoML Services&quot;
        AT[AutoML Tables] --&gt; |Structured Data| CSV[CSV/BigQuery]
        AI[AutoML Image] --&gt; |Images| IMG[JPG/PNG]
        AV[AutoML Video] --&gt; |Videos| VID[MP4]
        AN[AutoML NLP] --&gt; |Text| TXT[Documents]
    end

    style AT fill:#e8f5e9,stroke:#4caf50
    style AI fill:#e3f2fd,stroke:#2196f3
    style AV fill:#fce4ec,stroke:#e91e63
    style AN fill:#fff3e0,stroke:#ff9800
</code></pre>
<hr />
<h2>ğŸ”„ 3. Vertex AI Components</h2>
<h3>The ML Lifecycle in Vertex AI</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Data[&quot;1. Data Prep&quot;]
        FS[Feature Store]
        DS[Datasets]
    end

    subgraph Train[&quot;2. Training&quot;]
        AM[AutoML]
        CT[Custom Training]
        HP[Hyperparameter Tuning]
    end

    subgraph Deploy[&quot;3. Deployment&quot;]
        MR[Model Registry]
        EP[Endpoints]
        BP[Batch Predictions]
    end

    subgraph Monitor[&quot;4. Monitoring&quot;]
        MM[Model Monitoring]
        EX[Explainability]
    end

    Data --&gt; Train --&gt; Deploy --&gt; Monitor
    Monitor -.-&gt;|Retrain| Train

    style FS fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style EP fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<h3>Key Components Explained</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Purpose</th>
<th>ACE Exam Relevance</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Feature Store</strong></td>
<td>Share ML features across teams</td>
<td>"Reuse features" questions</td>
</tr>
<tr>
<td><strong>Workbench</strong></td>
<td>Managed Jupyter notebooks</td>
<td>"Data scientist environment"</td>
</tr>
<tr>
<td><strong>Pipelines</strong></td>
<td>Orchestrate ML workflows</td>
<td>Similar to Cloud Composer</td>
</tr>
<tr>
<td><strong>Model Registry</strong></td>
<td>Version control for models</td>
<td>"Model governance"</td>
</tr>
<tr>
<td><strong>Endpoints</strong></td>
<td>Real-time predictions</td>
<td>"Low latency inference"</td>
</tr>
<tr>
<td><strong>Batch Predictions</strong></td>
<td>Large-scale offline scoring</td>
<td>"Process millions of records"</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š 4. Database Modernization Strategies</h2>
<h3>Migration Approaches</h3>
<pre><code class="language-mermaid">graph TD
    subgraph Source[&quot;On-Premises&quot;]
        ORA[Oracle]
        SQL[SQL Server]
        MY[MySQL]
        PG[PostgreSQL]
    end

    subgraph Target[&quot;GCP&quot;]
        CS[Cloud SQL]
        SP[Cloud Spanner]
        BQ[BigQuery]
        FS2[Firestore]
    end

    subgraph Tools[&quot;Migration Tools&quot;]
        DMS[Database Migration Service]
        DF[Dataflow]
        DS2[Datastream]
    end

    Source --&gt; Tools --&gt; Target

    style DMS fill:#fff3e0,stroke:#ff9800,stroke-width:2px
</code></pre>
<h3>Database Migration Service (DMS)</h3>
<p><strong>DMS = Managed, minimal-downtime migrations.</strong></p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Supported Sources</strong></td>
<td>MySQL, PostgreSQL, SQL Server, Oracle</td>
</tr>
<tr>
<td><strong>Supported Targets</strong></td>
<td>Cloud SQL, AlloyDB</td>
</tr>
<tr>
<td><strong>Migration Type</strong></td>
<td>Continuous replication (near-zero downtime)</td>
</tr>
<tr>
<td><strong>Security</strong></td>
<td>Private IP, Cloud KMS encryption</td>
</tr>
</tbody>
</table>
<h3>Migration Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[What's your source DB?] --&gt; B{Relational?}
    B --&gt;|Yes| C{Need Global Scale?}
    B --&gt;|No| D{Document Store?}

    C --&gt;|Yes| SP[Cloud Spanner]
    C --&gt;|No| E{MySQL/PostgreSQL?}

    E --&gt;|Yes| CS[Cloud SQL]
    E --&gt;|SQL Server/Oracle| AS[AlloyDB or Bare Metal]

    D --&gt;|Yes| FS[Firestore]
    D --&gt;|Wide Column| BT[Bigtable]

    style SP fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style CS fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Train an AutoML Model</h2>
<p><strong>Mission:</strong> Build a customer churn prediction model without writing code.</p>
<h3>Step 1: Prepare Data</h3>
<pre><code class="language-bash"># Download sample dataset
curl -O https://storage.googleapis.com/cloud-samples-data/ai-platform/census/adult.csv

# Upload to Cloud Storage
gsutil cp adult.csv gs://YOUR_BUCKET/data/
</code></pre>
<h3>Step 2: Create Dataset in Vertex AI</h3>
<ol>
<li>Go to <strong>Vertex AI</strong> &gt; <strong>Datasets</strong></li>
<li>Click <strong>Create Dataset</strong></li>
<li>Select <strong>Tabular</strong> &gt; <strong>Regression/Classification</strong></li>
<li>Import from Cloud Storage: <code>gs://YOUR_BUCKET/data/adult.csv</code></li>
</ol>
<h3>Step 3: Train AutoML Model</h3>
<ol>
<li>Go to <strong>Training</strong> &gt; <strong>Train New Model</strong></li>
<li>Select your dataset</li>
<li>Choose target column: <code>income</code> (&gt;50K or &lt;=50K)</li>
<li>Set training budget: <strong>1 node hour</strong> (for testing)</li>
<li>Click <strong>Start Training</strong></li>
</ol>
<h3>Step 4: Deploy &amp; Predict</h3>
<pre><code class="language-bash"># Get predictions using REST API
curl -X POST \
  -H &quot;Authorization: Bearer $(gcloud auth print-access-token)&quot; \
  -H &quot;Content-Type: application/json&quot; \
  &quot;https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/endpoints/ENDPOINT_ID:predict&quot; \
  -d '{
    &quot;instances&quot;: [
      {&quot;age&quot;: 35, &quot;workclass&quot;: &quot;Private&quot;, &quot;education&quot;: &quot;Bachelors&quot;}
    ]
  }'
</code></pre>
<hr />
<h2>âš ï¸ 6. Common Pitfalls &amp; Pro Tips</h2>
<h3>âŒ Migration Mistakes</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Big-bang migration</td>
<td>High risk, long downtime</td>
<td>Use phased approach with DMS</td>
</tr>
<tr>
<td>Ignoring schema differences</td>
<td>Oracle â†’ PostgreSQL issues</td>
<td>Run schema conversion first</td>
</tr>
<tr>
<td>No testing environment</td>
<td>Production surprises</td>
<td>Always create staging replica</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Use Datastream</strong> for change data capture (CDC) to BigQuery</li>
<li><strong>Feature Store</strong> prevents recomputing the same features</li>
<li><strong>AutoML is expensive</strong> for high-volume predictionsâ€”consider exporting to TensorFlow Lite</li>
<li><strong>Monitor model drift</strong> with Vertex AI Model Monitoring</li>
</ul>
<hr />
<h2>ğŸ¯ 7. ACE Exam Focus</h2>
<h3>Service Selection Matrix</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Best Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Build ML model without coding"</td>
<td><strong>AutoML</strong></td>
</tr>
<tr>
<td>"Train custom TensorFlow model"</td>
<td><strong>Custom Training</strong></td>
</tr>
<tr>
<td>"Migrate MySQL with minimal downtime"</td>
<td><strong>Database Migration Service</strong></td>
</tr>
<tr>
<td>"Share features between ML teams"</td>
<td><strong>Feature Store</strong></td>
</tr>
<tr>
<td>"Real-time predictions at scale"</td>
<td><strong>Vertex AI Endpoints</strong></td>
</tr>
<tr>
<td>"Batch process millions of records"</td>
<td><strong>Batch Predictions</strong></td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>AutoML â‰  Free</strong>: Training costs node-hours</li>
<li>âš ï¸ <strong>DMS only supports certain databases</strong>: Check compatibility</li>
<li>âš ï¸ <strong>Feature Store is for ML features</strong>, not general caching</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 8. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which Vertex AI feature allows business users to build ML models without coding?</strong></p>
<ul>
<li>A. Custom Training</li>
<li>B. <strong>AutoML</strong> âœ…</li>
<li>C. Feature Store</li>
<li>D. Workbench</li>
</ul>
</li>
<li>
<p><strong>What is the purpose of Vertex AI Feature Store?</strong></p>
<ul>
<li>A. Store training datasets</li>
<li>B. <strong>Share reusable ML features across teams</strong> âœ…</li>
<li>C. Deploy models to production</li>
<li>D. Monitor model performance</li>
</ul>
</li>
<li>
<p><strong>Which service provides minimal-downtime database migration to Cloud SQL?</strong></p>
<ul>
<li>A. Dataflow</li>
<li>B. Transfer Service</li>
<li>C. <strong>Database Migration Service</strong> âœ…</li>
<li>D. Cloud Composer</li>
</ul>
</li>
<li>
<p><strong>You need to migrate an Oracle database to GCP with the least operational overhead. What should you use?</strong></p>
<ul>
<li>A. Lift and shift to Compute Engine</li>
<li>B. <strong>AlloyDB or Bare Metal Solution</strong> âœ…</li>
<li>C. Cloud Spanner</li>
<li>D. Firestore</li>
</ul>
</li>
<li>
<p><strong>Which Vertex AI component is used for real-time, low-latency predictions?</strong></p>
<ul>
<li>A. Batch Predictions</li>
<li>B. Pipelines</li>
<li>C. <strong>Endpoints</strong> âœ…</li>
<li>D. Workbench</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 34 Checklist</h2>
<ul>
<li>[ ] Understand AutoML vs Custom Training trade-offs</li>
<li>[ ] Know Vertex AI component purposes</li>
<li>[ ] Understand database migration options</li>
<li>[ ] Complete the AutoML hands-on lab</li>
<li>[ ] Pass the quiz with 80%+</li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 35: Week 5 Review</strong>
*   Consolidate Data &amp; Hybrid knowledge
*   Practice scenario-based questions
*   Review migration patterns</p>
<!-- FLASHCARDS
[
  {"term": "Vertex AI", "def": "Unified ML platform. Combines AutoML, Custom Training, and MLOps tools."},
  {"term": "AutoML", "def": "No-code ML. Upload data, get a trained model. Best for POCs and business users."},
  {"term": "Custom Training", "def": "Bring your own code (TensorFlow/PyTorch). Full control over model architecture."},
  {"term": "Feature Store", "def": "Centralized repository for ML features. Prevents duplicate feature engineering."},
  {"term": "Database Migration Service", "def": "Managed service for near-zero downtime database migrations to Cloud SQL."},
  {"term": "Endpoints", "def": "Managed infrastructure for real-time model predictions. Auto-scales based on traffic."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_35_week_5_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 35: Week 5 Review &amp; Mock Exam</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes<br />
<strong>Level:</strong> Comprehensive<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ High-Frequency Synthesis</p>
<hr />
<h2>ğŸ¯ Week 5 Mastery Objective</h2>
<p>Week 5 shifted the focus from individual services to <strong>System Architecture</strong>. You learned how to bridge physical data centers to the cloud, how to process petabytes of data serverlessly, and how to migrate legacy databases with zero downtime.</p>
<hr />
<h2>ğŸ—ï¸ 1. The Global Architecture Recap</h2>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;External World&quot;
        User[Public User]
        HQ[On-Premises HQ]
    end

    subgraph &quot;GCP Edge / Connectivity&quot;
        GLB[Global Load Balancer]
        VPN[HA Cloud VPN]
        IC[Cloud Interconnect]
    end

    subgraph &quot;Processing Tier&quot;
        DF[Cloud Dataflow]
        PS[Cloud Pub/Sub]
    end

    subgraph &quot;Persistence Tier&quot;
        SPAN[Cloud Spanner]
        BT[Cloud Bigtable]
        BQ[BigQuery]
    end

    User --&gt; GLB
    HQ --- VPN
    HQ --- IC
    GLB --&gt; PS
    PS --&gt; DF
    DF --&gt; SPAN
    DF --&gt; BT
    DF --&gt; BQ
</code></pre>
<hr />
<h2>ğŸ§  2. The Professional Decision Matrix</h2>
<p>If you face these requirements in the exam, choose these services:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Requirement</th>
<th style="text-align: left;">Choose This</th>
<th style="text-align: left;">Key Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Global SQL consistency</strong></td>
<td style="text-align: left;"><strong>Cloud Spanner</strong></td>
<td style="text-align: left;">The only GCP database with regional/global synchronous replication.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Millisecond latency IoT writes</strong></td>
<td style="text-align: left;"><strong>Bigtable</strong></td>
<td style="text-align: left;">Designed for sustained high-throughput write workloads.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Hadoop/Spark Expert Team</strong></td>
<td style="text-align: left;"><strong>Dataproc</strong></td>
<td style="text-align: left;">Leverage existing scripts (SaaS model) rather than rewriting in Beam.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>"At Least Once" Messaging</strong></td>
<td style="text-align: left;"><strong>Pub/Sub</strong></td>
<td style="text-align: left;">Global bus for decoupling systems.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>50TB Migration (No Fiber)</strong></td>
<td style="text-align: left;"><strong>Transfer Appliance</strong></td>
<td style="text-align: left;">Physical shipping is faster than low-bandwidth internet uploads.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>PostgreSQL with 99.99% HA</strong></td>
<td style="text-align: left;"><strong>Cloud SQL / AlloyDB</strong></td>
<td style="text-align: left;">Managed PostgreSQL with automatic failover and replicas.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ 3. Week 5 Mock Exam (ACE Alignment)</h2>
<ol>
<li>
<p><strong>A logistics company needs to track 500,000 trucks in real-time. Each truck sends an update every 5 seconds. The data must be available for real-time dashboards and long-term history. What is the recommended architecture?</strong></p>
<ul>
<li>A. Cloud SQL for all data.</li>
<li>B. <strong>Pub/Sub (Ingest) -&gt; Dataflow (Process) -&gt; Bigtable (Real-time) + BigQuery (History).</strong> âœ…</li>
<li>C. App Engine -&gt; Cloud Storage.</li>
<li>D. Compute Engine -&gt; Local SSD.</li>
</ul>
</li>
<li>
<p><strong>You need to connect an on-premises data center to GCP with a 10Gbps connection that MUST be encrypted for regulatory compliance. You choose Dedicated Interconnect. What additional step is required?</strong></p>
<ul>
<li>A. Interconnect is encrypted by default.</li>
<li>B. <strong>Configure MACsec or an HA VPN tunnel over the physical Interconnect line.</strong> âœ…</li>
<li>C. Use Cloud Armor.</li>
<li>D. Enable VPC Service Controls.</li>
</ul>
</li>
<li>
<p><strong>Which BigQuery pricing model allows for automatic scaling of processing power based on workload, ensuring a predictable budget?</strong></p>
<ul>
<li>A. On-Demand Pricing.</li>
<li>B. <strong>Edition Pricing (Capacity/Slots).</strong> âœ…</li>
<li>C. Flat-rate Storage.</li>
<li>D. BigTable Reserved Units.</li>
</ul>
</li>
<li>
<p><strong>You are migrating 20 MySQL databases to Google Cloud. You want a tool that manages the replication and allows for a 'one-click' cutover with minimal downtime. Which service should you use?</strong></p>
<ul>
<li>A. Storage Transfer Service.</li>
<li>B. <strong>Database Migration Service (DMS).</strong> âœ…</li>
<li>C. gsutil rsync.</li>
<li>D. Compute Engine Snapshots.</li>
</ul>
</li>
<li>
<p><strong>What is the primary difference between Dataflow and Dataproc?</strong></p>
<ul>
<li>A. Dataflow is for VMs, Dataproc is for containers.</li>
<li>B. <strong>Dataflow is serverless/NoOps; Dataproc provides managed Hadoop/Spark clusters.</strong> âœ…</li>
<li>C. Dataflow only handles batch data.</li>
<li>D. Dataproc is only for small datasets.</li>
</ul>
</li>
</ol>
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between Spanner, Bigtable, and BigQuery.', checked: false },
        { text: 'I can explain why Decoupling (Pub/Sub) increases system reliability.', checked: false },
        { text: 'I know when to use Transfer Appliance vs. Online Transfer.', checked: false },
        { text: 'I am comfortable with the Hybrid Connectivity selection model.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Week 5 Readiness Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_36_sre_ops">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 5 min read</div>
<h1>Day 36: SRE Principles &amp; Cloud Operations</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 36, you will be able to:
*   <strong>Define</strong> Site Reliability Engineering (SRE) and its core difference from traditional Ops.
*   <strong>Design</strong> observability frameworks using SLIs, SLOs, and SLAs.
*   <strong>Manage</strong> the Error Budget to balance innovation and stability.
*   <strong>Identify</strong> and eliminate "Toil" through engineering automation.</p>
<hr />
<h2>ğŸ—ï¸ 1. SRE: Engineering for Reliability</h2>
<p><strong>Site Reliability Engineering (SRE)</strong> is what happens when you ask a software engineer to design an operations function. Google pioneered SRE to replace a "toss it over the wall" culture with shared responsibility and automation.</p>
<h3>Core Tenets</h3>
<ul>
<li><strong>Embracing Risk:</strong> 100% uptime is the wrong target. It's too expensive and stops you from deploying new features.</li>
<li><strong>Toil Reduction:</strong> SREs should spend no more than 50% of their time on manual tasks. The other 50% must be spent on developing automation code.</li>
<li><strong>Monitoring:</strong> Moving from "Is it up?" to "How happy are the users?"</li>
</ul>
<hr />
<h2>ğŸ“Š 2. The Golden Triangle (SLI vs. SLO vs. SLA)</h2>
<p>To measure happiness, you need a common language between business and engineering.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Term</th>
<th style="text-align: left;">Concept</th>
<th style="text-align: left;">The Question</th>
<th style="text-align: left;">Audience</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>SLI</strong></td>
<td style="text-align: left;"><strong>Indicator</strong></td>
<td style="text-align: left;"><em>What is the metric?</em></td>
<td style="text-align: left;">Engineers</td>
<td style="text-align: left;">99th Percentile Latency.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SLO</strong></td>
<td style="text-align: left;"><strong>Objective</strong></td>
<td style="text-align: left;"><em>What is the target?</em></td>
<td style="text-align: left;">Team</td>
<td style="text-align: left;">Latency &lt; 200ms for 99% of requests.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SLA</strong></td>
<td style="text-align: left;"><strong>Agreement</strong></td>
<td style="text-align: left;"><em>What is the penalty?</em></td>
<td style="text-align: left;">Customers</td>
<td style="text-align: left;">"We pay you back if SLO is missed."</td>
</tr>
</tbody>
</table>
<h3>ğŸ› ï¸ The Process Flow</h3>
<pre><code class="language-mermaid">graph LR
    subgraph &quot;Measurement&quot;
        Metrics[Cloud Monitoring] --&gt; SLI[Indicator: Metrics]
    end

    subgraph &quot;Governance&quot;
        SLI --&gt; SLO[Objective: The Goal]
        SLO --&gt; EB[Error Budget: The Risk Buffer]
    end

    subgraph &quot;Decision&quot;
        EB --&gt;|Positive| Update[Ship Fast]
        EB --&gt;|Negative| Freeze[Focus on Stability]
    end
</code></pre>
<hr />
<h2>ğŸ“‰ 3. The Error Budget: Your License to Move</h2>
<p><strong>Error Budget</strong> = $100\% - \text{SLO}$.</p>
<p>If your SLO is 99.9%, your error budget is 0.1% of "unhappiness" per month.
*   <strong>Spending the Budget:</strong> Planned downtime, buggy releases, and experiments "spend" this budget.
*   <strong>Running Out:</strong> If you hit 0% error budget, feature releases <strong>must stop</strong>. The team pivots 100% to stability until the budget refills.</p>
<hr />
<h2>ğŸ› ï¸ 4. Hands-On Lab: Set an SLO ğŸ“Š</h2>
<h3>ğŸ§ª Lab Objective</h3>
<p>Configure a custom SLO for an App Engine or GKE service in Cloud Monitoring to monitor burn rate.</p>
<h3>âœ… Steps</h3>
<ol>
<li><strong>Open Cloud Monitoring</strong>: Navigate to <strong>Services</strong>.</li>
<li><strong>Define Service</strong>: Select an existing service (e.g., your App Engine frontend).</li>
<li><strong>Create SLO</strong>:<ul>
<li><strong>SLI Type</strong>: Availability (Request count).</li>
<li><strong>Performance Goal</strong>: 99.9%.</li>
<li><strong>Compliance Period</strong>: Rolling 28 days.</li>
</ul>
</li>
<li><strong>Configure Alert</strong>: Set a "Burn Rate" alert. This alerts you if your current failure rate will exhaust your entire error budget before the 28 days are up.</li>
<li><strong>Visualize</strong>: Check the dashboard to see your "Error Budget Remaining" percentage.</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You have a request-based service. You define an SLI as the ratio of successful requests to total requests. You set a target of 99.9%. What is this target called?</strong></p>
<ul>
<li>A. SLI.</li>
<li>B. <strong>SLO.</strong> âœ…</li>
<li>C. SLA.</li>
<li>D. Toil.</li>
</ul>
</li>
<li>
<p><strong>Your team has exhausted its 'Error Budget' for the current monthly window. According to SRE best practices, what should happen?</strong></p>
<ul>
<li>A. Increase the SLO to 100%.</li>
<li>B. <strong>Implement a feature freeze and focus 100% on system reliability.</strong> âœ…</li>
<li>C. Ignore the budget and keep deploying to stay competitive.</li>
<li>D. Delete the monitoring metrics.</li>
</ul>
</li>
<li>
<p><strong>Which term refers to manual, repetitive, tactical work that scales linearly with the number of users?</strong></p>
<ul>
<li>A. Engineering.</li>
<li>B. <strong>Toil.</strong> âœ…</li>
<li>C. Innovation.</li>
<li>D. Latency.</li>
</ul>
</li>
<li>
<p><strong>A legal contract states that a Cloud Service Provider will credit a customer 10% of their bill if service availability falls below 99.5%. What is this document?</strong></p>
<ul>
<li>A. SLI.</li>
<li>B. SLO.</li>
<li>C. <strong>SLA.</strong> âœ…</li>
<li>D. SRE handbook.</li>
</ul>
</li>
<li>
<p><strong>True or False: The primary goal of SRE is to achieve 100% uptime for all services at all times.</strong></p>
<ul>
<li>A. True.</li>
<li>B. <strong>False. 100% is too expensive and prevents innovation; SRE aims for a balance using Error Budgets.</strong> âœ…</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between SLI, SLO, and SLA.', checked: false },
        { text: 'I can explain how an Error Budget governs release velocity.', checked: false },
        { text: 'I know how to identify Toil in a production environment.', checked: false },
        { text: 'I know how to set an SLO in Google Cloud Monitoring.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 36 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_37_finops">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 37: FinOps &amp; Cost Optimization (Thinking Like a CFO)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Intermediate-Advanced<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­ High (Crucial for Resource Management)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 37, you will be able to:
*   <strong>Differentiate</strong> between SUDs, CUDs, and Spot VMs.
*   <strong>Implement</strong> resource labels for granular billing attribution.
*   <strong>Design</strong> cost-alerting workflows using Budgets and Cloud Functions.
*   <strong>Analyze</strong> historical spend using BigQuery billing exports.</p>
<hr />
<h2>ğŸ—ï¸ 1. The FinOps Lifecycle</h2>
<p>FinOps isn't just "saving money"; it's about the <strong>value</strong> of every dollar spent. Google Cloud follows the three-phase lifecycle:</p>
<pre><code class="language-mermaid">graph LR
    A[&quot;Inform (Visibility)&quot;] --&gt; B[&quot;Optimize (Savings)&quot;]
    B --&gt; C[&quot;Operate (Alignment)&quot;]
    C --&gt; A
    style A fill:#e0f2fe,stroke:#0369a1
    style B fill:#fdf9c3,stroke:#a16207
    style C fill:#dcfce7,stroke:#15803d
</code></pre>
<ol>
<li><strong>Inform:</strong> Tagging resources, setting budgets, and visualizing spend in Looker Studio.</li>
<li><strong>Optimize:</strong> Rightsizing VMs, deleting orphaned disks, and purchasing CUDs.</li>
<li><strong>Operate:</strong> Automating cost-saving (e.g., stopping dev environments at night).</li>
</ol>
<hr />
<h2>ğŸ’° 2. Discount Models: The Holy Trinity</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;"><strong>Sustained Use (SUD)</strong></th>
<th style="text-align: left;"><strong>Committed Use (CUD)</strong></th>
<th style="text-align: left;"><strong>Spot VMs</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Mechanic</strong></td>
<td style="text-align: left;"><strong>Automatic</strong>. Discount kicks in after 25% monthly usage.</td>
<td style="text-align: left;"><strong>Contractual</strong>. 1 or 3-year commitment.</td>
<td style="text-align: left;"><strong>Insecure</strong>. Google can reclaim capacity anytime.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Max Savings</strong></td>
<td style="text-align: left;">~30%</td>
<td style="text-align: left;">~70%</td>
<td style="text-align: left;"><strong>~91%</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Best For</strong></td>
<td style="text-align: left;">Spiky/Unpredictable workloads.</td>
<td style="text-align: left;">Stable, 24/7 Production Databases.</td>
<td style="text-align: left;">Batch jobs, CI/CD, Stateless GKE nodes.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Exam Trap</strong></td>
<td style="text-align: left;">You don't "buy" SUDs. They just happen.</td>
<td style="text-align: left;">You pay for the <strong>commitment</strong>, even if VMs are off.</td>
<td style="text-align: left;">Must handle <strong>30-second termination</strong> notice.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ·ï¸ 3. Labels vs. Tags (ACE Must Know!)</h2>
<p>This is one of the most common points of confusion in the exam.</p>
<ul>
<li><strong>Labels (Billing):</strong> Key-value pairs (e.g., <code>dept:marketing</code>) used for <strong>cost allocation</strong>. They show up in the billing export.</li>
<li><strong>Network Tags (Traffic):</strong> Strings (e.g., <code>http-server</code>) used for <strong>firewall rules</strong> and routing. They have <strong>nothing</strong> to do with billing.</li>
</ul>
<hr />
<h2>ğŸš¨ 4. The "Safety Net": Budgets &amp; Automation</h2>
<p><strong>The Fact:</strong> Budgets <strong>DO NOT</strong> stop your resources by default. They only send notifications.</p>
<h3>Pro Architecture: Automatic Shutdown</h3>
<p>To automatically stop a project when it hits 100% budget:
1.  <strong>Budget Alert</strong> sends a message to a <strong>Pub/Sub Topic</strong>.
2.  <strong>Cloud Function</strong> is triggered by that topic.
3.  The Function uses the <strong>Cloud Resource Manager API</strong> to disable billing or the <strong>Compute API</strong> to stop VMs.</p>
<hr />
<h2>ğŸ“Š 5. Analyzing Spend with BigQuery</h2>
<p>For any enterprise GCP setup, <strong>Billing Export to BigQuery</strong> is mandatory on Day 1.</p>
<pre><code class="language-sql">-- Example: Get cost by Label (Team)
SELECT
  labels.value as team,
  SUM(cost) as total_cost
FROM `my-project.billing_dataset.gcp_billing_export`
LEFT JOIN UNNEST(labels) as labels ON labels.key = 'team'
GROUP BY 1
ORDER BY 2 DESC;
</code></pre>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Knowledge Check</h2>
<ol>
<li>
<p><strong>A team needs to run a rendering job that can be interrupted and resumed. They want the lowest possible cost. Which compute option is best?</strong></p>
<ul>
<li>A. E2 instance with 3-year CUD.</li>
<li>B. <strong>Spot VM.</strong> âœ… (Up to 91% discount for fault-tolerant tasks).</li>
<li>C. Standard VM with SUD.</li>
<li>D. Cloud Functions.</li>
</ul>
</li>
<li>
<p><strong>True or False: A Budget Alert set at 100% will automatically stop all running Compute Engine instances in a project to prevent further charges.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False.</strong> âœ… (Budgets only alert; automation requires Pub/Sub + Cloud Functions).</li>
</ul>
</li>
<li>
<p><strong>You need to track which department is responsible for specific costs in a shared GCP project. What should you use?</strong></p>
<ul>
<li>A. Network Tags.</li>
<li>B. <strong>Resource Labels.</strong> âœ… (Labels are for metadata and billing).</li>
<li>C. IAM Roles.</li>
<li>D. Project Descriptions.</li>
</ul>
</li>
<li>
<p><strong>You have a database server that must run 24/7 for the next 2 years. Which discount model provides the highest guaranteed savings?</strong></p>
<ul>
<li>A. Sustained Use Discount (SUD).</li>
<li>B. <strong>Committed Use Discount (CUD).</strong> âœ… (Best for long-term stable workloads).</li>
<li>C. Spot VMs.</li>
<li>D. Free Tier.</li>
</ul>
</li>
<li>
<p><strong>Where can you view a visual dashboard of your GCP spending trends without writing custom code?</strong></p>
<ul>
<li>A. Cloud Shell.</li>
<li>B. <strong>Cloud Billing Reports (Console).</strong> âœ… (Standard visual tool).</li>
<li>C. Secret Manager.</li>
<li>D. Deployment Manager.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between Labels and Network Tags.', checked: false },
        { text: 'I know how to enable Billing Export to BigQuery.', checked: false },
        { text: 'I can explain why Budgets don\'t stop resources by default.', checked: false },
        { text: 'I know when to recommend Spot VMs over CUDs.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 37 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_38_network_capstone">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 38: Network Capstone (The "Black Hole" Subnet)</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes<br />
<strong>Level:</strong> Advanced (Scenario-Based)<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Hands-on Troubleshooting)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (What You'll Fix)</strong><br />
A VM is completely isolated â€” no internet in, no internet out, can't even ping. You'll diagnose the problem systematically: check for missing Cloud NAT (outbound), missing firewall rules (inbound), and missing network tags. By the end, you'll have a bulletproof troubleshooting mindset for the ACE exam.</p>
</blockquote>
<hr />
<h2>ğŸ•µï¸â€â™‚ï¸ The Scenario: "Nothing Works!"</h2>
<p>A junior developer has provisioned a "secure" custom VPC environment. However, the application server is completely isolated.</p>
<table>
<thead>
<tr>
<th>ğŸš¨ Problem</th>
<th>What's Broken</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Inbound</strong></td>
<td>Customers cannot reach the web UI (port 80/443)</td>
</tr>
<tr>
<td><strong>Outbound</strong></td>
<td>Server cannot download OS security patches</td>
</tr>
<tr>
<td><strong>Internal</strong></td>
<td>Database server unreachable from web tier</td>
</tr>
</tbody>
</table>
<p><strong>Your Goal:</strong> Restore connectivity while maintaining the <strong>principle of least privilege</strong> â€” don't open more than necessary.</p>
<hr />
<h2>ğŸ—ï¸ 1. Architecture: The "Broken" State</h2>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Public Internet&quot;
        User[End User]
        Update[Patch Server]
    end

    subgraph &quot;VPC: prod-net (Custom Mode)&quot;
        subgraph &quot;prod-subnet (10.0.1.0/24)&quot;
            VM[web-server]
        end
    end

    User --&quot;HTTP:80&quot;--&gt; |&quot;BLOCKED: No FW Rule&quot;| VM
    VM --&quot;HTTPS:443&quot;--&gt; |&quot;BLOCKED: No Route/NAT&quot;| Update

    style VM fill:#fee2e2,stroke:#991b1b
</code></pre>
<hr />
<h2>ğŸ› ï¸ 2. Step-by-Step Troubleshooting Flow</h2>
<blockquote>
<p>[!IMPORTANT]
<strong>Pro Tip:</strong> This is the exact logical path used by Google Cloud Support Engineers. Memorize this flow for the exam!</p>
</blockquote>
<h3>Phase A: Outbound Connectivity (The "NAT" Problem)</h3>
<table>
<thead>
<tr>
<th>Step</th>
<th>Check</th>
<th>If True</th>
<th>If False</th>
</tr>
</thead>
<tbody>
<tr>
<td>1ï¸âƒ£</td>
<td>Run <code>ping 8.8.8.8</code> from VM</td>
<td>Go to Step 2</td>
<td><strong>Problem found!</strong></td>
</tr>
<tr>
<td>2ï¸âƒ£</td>
<td>Does VM have External IP?</td>
<td>Check default route <code>0.0.0.0/0</code></td>
<td><strong>Add Cloud NAT + Cloud Router</strong></td>
</tr>
<tr>
<td>3ï¸âƒ£</td>
<td>Does route exist?</td>
<td>Check egress firewall rules</td>
<td>Add default internet gateway</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>ğŸ”’ Best Practice:</strong> Production VMs should <strong>NOT</strong> have public IPs. Use Cloud NAT for outbound-only access.</p>
</blockquote>
<h3>Phase B: Inbound Connectivity (The "Firewall" Problem)</h3>
<table>
<thead>
<tr>
<th>Step</th>
<th>Check</th>
<th>If True</th>
<th>If False</th>
</tr>
</thead>
<tbody>
<tr>
<td>1ï¸âƒ£</td>
<td>Run <code>curl http://[VM-IP]</code> from internet</td>
<td>App works!</td>
<td><strong>Problem found!</strong></td>
</tr>
<tr>
<td>2ï¸âƒ£</td>
<td>Is there a firewall rule for port 80/443?</td>
<td>Check target tags</td>
<td><strong>Create ingress rule</strong></td>
</tr>
<tr>
<td>3ï¸âƒ£</td>
<td>Does VM have the matching network tag?</td>
<td>Rule is misconfigured</td>
<td><strong>Add tag to VM</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>âš ï¸ Common Trap:</strong> The firewall rule targets <code>http-server</code> tag, but the VM has <code>web-server</code> tag. Always verify the exact tag name!</p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 3. The "Hero" Solution (Infrastructure as Code)</h2>
<p>Don't just fix it in the console. Codify the solution using Terraform to ensure it never breaks again.</p>
<pre><code class="language-hcl"># network.tf
resource &quot;google_compute_network&quot; &quot;prod_net&quot; {
  name                    = &quot;prod-net&quot;
  auto_create_subnetworks = false
}

resource &quot;google_compute_subnetwork&quot; &quot;web_subnet&quot; {
  name          = &quot;web-subnet&quot;
  ip_cidr_range = &quot;10.0.1.0/24&quot;
  region        = &quot;us-central1&quot;
  network       = google_compute_network.prod_net.id
}

# Fix 1: The Firewall (Inbound)
resource &quot;google_compute_firewall&quot; &quot;allow_http&quot; {
  name    = &quot;allow-http-ingress&quot;
  network = google_compute_network.prod_net.name

  allow {
    protocol = &quot;tcp&quot;
    ports    = [&quot;80&quot;]
  }
  source_ranges = [&quot;0.0.0.0/0&quot;] # Allowed from Internet
  target_tags   = [&quot;web-node&quot;]
}

# Fix 2: Cloud NAT (Outbound)
resource &quot;google_compute_router&quot; &quot;router&quot; {
  name    = &quot;web-router&quot;
  region  = &quot;us-central1&quot;
  network = google_compute_network.prod_net.id
}

resource &quot;google_compute_router_nat&quot; &quot;nat&quot; {
  name                               = &quot;web-nat&quot;
  router                             = google_compute_router.router.name
  region                             = &quot;us-central1&quot;
  nat_ip_allocate_option             = &quot;AUTO_ONLY&quot;
  source_subnetwork_ip_ranges_to_nat = &quot;ALL_SUBNETWORKS_ALL_IP_RANGES&quot;
}
</code></pre>
<hr />
<h2>ğŸ“ 4. Exam-Aligned Debugging Scenarios</h2>
<h3>Scenario 1: The "Hanging" SSH</h3>
<ul>
<li><strong>Problem:</strong> You can't SSH into the VM from the console <code>gcloud compute ssh</code>.</li>
<li><strong>Answer:</strong> You must allow <strong>TCP:22</strong> from the source range <code>35.235.240.0/20</code> (Identity-Aware Proxy range).</li>
</ul>
<h3>Scenario 2: The "Ping" Trap</h3>
<ul>
<li><strong>Problem:</strong> You allowed TCP:80, but you still can't <code>ping</code> the VM.</li>
<li><strong>Answer:</strong> <code>ping</code> uses <strong>ICMP</strong>, which is a different protocol. You must specifically allow ICMP in the firewall.</li>
</ul>
<hr />
<h2>ğŸ§  The ACE Troubleshooting Mindset (8% of Exam)</h2>
<p>Troubleshooting is 8% of the ACE exam. Use this systematic approach for any "something isn't working" scenario.</p>
<h3>The 4-Step Debug Framework</h3>
<table>
<thead>
<tr>
<th>Step</th>
<th>Question</th>
<th>Tools</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. <strong>Reproduce</strong></td>
<td>Can you consistently trigger the issue?</td>
<td>Console, gcloud</td>
</tr>
<tr>
<td>2. <strong>Isolate</strong></td>
<td>Is it Network? IAM? Application code?</td>
<td>Connectivity tests</td>
</tr>
<tr>
<td>3. <strong>Check Logs</strong></td>
<td>What do the logs say?</td>
<td>Cloud Logging, Error Reporting</td>
</tr>
<tr>
<td>4. <strong>Test Incrementally</strong></td>
<td>One change at a time</td>
<td>Don't change 5 things at once</td>
</tr>
</tbody>
</table>
<h3>Common ACE Troubleshooting Scenarios</h3>
<table>
<thead>
<tr>
<th>Symptom</th>
<th>Most Likely Cause</th>
<th>How to Check</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VM can't reach internet</strong></td>
<td>Missing Cloud NAT or no external IP</td>
<td><code>gcloud compute instances describe</code></td>
</tr>
<tr>
<td><strong>502 Bad Gateway on LB</strong></td>
<td>Firewall blocking health checks</td>
<td>Allow <code>130.211.0.0/22</code>, <code>35.191.0.0/16</code></td>
</tr>
<tr>
<td><strong>Permission denied</strong></td>
<td>Missing IAM role</td>
<td><code>gcloud projects get-iam-policy</code></td>
</tr>
<tr>
<td><strong>SSH timeout</strong></td>
<td>Firewall blocking port 22</td>
<td>Check firewall rules for TCP:22</td>
</tr>
<tr>
<td><strong>Can't ping VM</strong></td>
<td>ICMP not allowed</td>
<td>Allow ICMP protocol (separate from TCP)</td>
</tr>
<tr>
<td><strong>GKE pod can't reach API</strong></td>
<td>Missing Workload Identity</td>
<td>Check service account binding</td>
</tr>
<tr>
<td><strong>Cloud Function fails</strong></td>
<td>Missing service account permissions</td>
<td>Check function's SA roles</td>
</tr>
</tbody>
</table>
<h3>The "Why Not Working?" Flowchart</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Something Broken] --&gt; B{Can you ping it?}
    B --&gt;|No| C{Has external IP?}
    B --&gt;|Yes| D{Can you SSH?}

    C --&gt;|No| NAT[Add Cloud NAT]
    C --&gt;|Yes| FW1[Check egress firewall]

    D --&gt;|No| FW2[Check TCP:22 firewall + IAP range]
    D --&gt;|Yes| E{App responding?}

    E --&gt;|No| LOG[Check Cloud Logging]
    E --&gt;|Yes| IAM[Check IAM permissions]

    style NAT fill:#e8f5e9,stroke:#4caf50
    style FW2 fill:#fff3e0,stroke:#ff9800
</code></pre>
<blockquote>
<p><strong>ğŸ¯ ACE Tip:</strong> When troubleshooting, always check <strong>Network</strong> (firewalls, routes) before <strong>IAM</strong> (permissions), because network issues are more common.</p>
</blockquote>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You have a VM in a custom VPC with no external IP. It needs to download an OS update from the internet. What is the most secure way to enable this?</strong></p>
<ul>
<li>A. Assign a Static External IP.</li>
<li>B. <strong>Configure Cloud NAT and Cloud Router.</strong> âœ…</li>
<li>C. Create a VPC Peering connection to the Internet.</li>
<li>D. Open a firewall rule for 0.0.0.0/0.</li>
</ul>
</li>
<li>
<p><strong>A firewall rule allows traffic on port 80 with the target tag 'web-tier'. Your VM is not receiving traffic. What is the first thing to check?</strong></p>
<ul>
<li>A. If the VM is in the same project.</li>
<li>B. <strong>If the VM has the 'web-tier' network tag assigned.</strong> âœ…</li>
<li>C. If the VPC is in 'auto' mode.</li>
<li>D. The IAM Billing Account status.</li>
</ul>
</li>
<li>
<p><strong>Which IP range must be allowed in the firewall to use IAP (Identity-Aware Proxy) for browser-based SSH?</strong></p>
<ul>
<li>A. 0.0.0.0/0</li>
<li>B. <strong>35.235.240.0/20</strong> âœ…</li>
<li>C. 10.0.0.0/8</li>
<li>D. 127.0.0.1/32</li>
</ul>
</li>
<li>
<p><strong>What is the priority of the default 'Allow Egress' rule in a new VPC?</strong></p>
<ul>
<li>A. 0</li>
<li>B. 1000</li>
<li>C. <strong>65535</strong> âœ… (The lowest possible priority).</li>
<li>D. 1</li>
</ul>
</li>
<li>
<p><strong>True or False: Deleting the 'Default' network from a project removes all implied firewall rules.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False.</strong> âœ… (Implied rules exist in every VPC, even custom ones, and cannot be deleted).</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can distinguish between Inbound and Outbound connectivity issues.', checked: false },
        { text: 'I know how to configure Cloud NAT for private VMs.', checked: false },
        { text: 'I understand the role of Network Tags in firewall rules.', checked: false },
        { text: 'I can identify the IAP IP range for secure SSH.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 38 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_39_security_capstone">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 39: Security Capstone (The Red Team Audit)</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes<br />
<strong>Level:</strong> Advanced (Security Focus)<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Compliance &amp; Identity)</p>
<hr />
<h2>ğŸ•µï¸â€â™‚ï¸ The Scenario: "Shadow IT Leak"</h2>
<p>A high-growth startup has been building in "stealth mode". Their Lead Developer just quit, and you've been hired to audit their main project. You find a "working" application that is a <strong>Security Nightmare</strong>.</p>
<p><strong>Your Objective:</strong> Identify the "Crown Jewels" and lock them down before a breach occurs.</p>
<hr />
<h2>ğŸ—ï¸ 1. Architecture: The "Before" &amp; "After"</h2>
<h3>The Radioactive State (Before)</h3>
<pre><code class="language-mermaid">graph TD
    User[Any Internet User] --&quot;Access&quot;--&gt; Bucket[gs://customer-data: Public Read/Write]
    SA[Compute Engine SA] --&quot;Admin Access&quot;--&gt; Project[Project Owner Role]
    Dev[External Contractor] --&quot;Hardcoded Key&quot;--&gt; Code[GitHub Repo]

    style Bucket fill:#fee2e2,stroke:#991b1b
    style SA fill:#fee2e2,stroke:#991b1b
</code></pre>
<h3>The Hardened State (After)</h3>
<pre><code class="language-mermaid">graph TD
    User[Authorized User Only] --&quot;IAP / IAM&quot;--&gt; Bucket[gs://customer-data: Private]
    SA[Compute Engine SA] --&quot;Custom Role&quot;--&gt; Project[Least Privilege]
    Dev[Contractor] --&quot;Workload Identity&quot;--&gt; Code[GitHub Actions]

    style Bucket fill:#dcfce7,stroke:#15803d
    style SA fill:#dcfce7,stroke:#15803d
</code></pre>
<hr />
<h2>ğŸ› ï¸ 2. The Vulnerability Matrix (Audit Report)</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Issue</th>
<th style="text-align: left;">Severity</th>
<th style="text-align: left;">Fix</th>
<th style="text-align: left;">ACE Exam Tip</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>allUsers:Storage.Admin</strong></td>
<td style="text-align: left;">ğŸ›‘ Critical</td>
<td style="text-align: left;">Remove <code>allUsers</code> and <code>allAuthenticatedUsers</code>.</td>
<td style="text-align: left;"><code>allUsers</code> = The entire internet.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SA with roles/owner</strong></td>
<td style="text-align: left;">ğŸ›‘ Critical</td>
<td style="text-align: left;">Replace with Custom Role or specific Predefined roles.</td>
<td style="text-align: left;">Never grant <code>owner</code> to a Service Account.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>JSON Key in Code</strong></td>
<td style="text-align: left;">âš ï¸ High</td>
<td style="text-align: left;">Delete the key and use <strong>Service Account Impersonation</strong>.</td>
<td style="text-align: left;">JSON keys are "long-lived" and high risk.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>No MFA for Admin</strong></td>
<td style="text-align: left;">âš ï¸ High</td>
<td style="text-align: left;">Enforce <strong>Organization Policies</strong> for MFA.</td>
<td style="text-align: left;">Organization Policies trump project-level IAM.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 3. The "Zero Trust" Solution (IaC)</h2>
<p>Use Terraform to define a security perimeter that doesn't rely on "Lazy Admin" roles.</p>
<pre><code class="language-hcl"># iam.tf
# 1. Create a &quot;Least Privilege&quot; Custom Role
resource &quot;google_project_iam_custom_role&quot; &quot;app_executor&quot; {
  role_id     = &quot;app_executor&quot;
  title       = &quot;Application Executor&quot;
  permissions = [
    &quot;storage.objects.get&quot;,
    &quot;storage.objects.list&quot;,
    &quot;logging.logEntries.create&quot;
  ]
}

# 2. Create the Identity (Service Account)
resource &quot;google_service_account&quot; &quot;safe_sa&quot; {
  account_id   = &quot;prod-app-sa&quot;
  display_name = &quot;Secure App Service Account&quot;
}

# 3. Secure Binding (No 'AllUsers'!)
resource &quot;google_storage_bucket_iam_binding&quot; &quot;private_access&quot; {
  bucket = &quot;prod-customer-data&quot;
  role   = &quot;roles/storage.objectViewer&quot;
  members = [
    &quot;serviceAccount:${google_service_account.safe_sa.email}&quot;
  ]
}
</code></pre>
<hr />
<h2>ğŸš¨ 4. Pro-Grade Hardening: The "Defense in Depth"</h2>
<ol>
<li><strong>VPC Service Controls (VPC SC):</strong> Create a service perimeter to prevent data exfiltration. Even an admin can't copy data out of the project.</li>
<li><strong>Organization Policies:</strong> Disable "Service Account Key Creation" for the entire company.</li>
<li><strong>Cloud Armor:</strong> Protect your public endpoints from SQL injection and DDoS.</li>
</ol>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>You discover a Service Account with the 'Project Owner' role assigned to a VM. What is the most secure replacement?</strong></p>
<ul>
<li>A. Project Editor role.</li>
<li>B. Project Viewer role.</li>
<li>C. <strong>A Custom Role containing only the specific permissions needed by the app.</strong> âœ…</li>
<li>D. Remove the Service Account entirely.</li>
</ul>
</li>
<li>
<p><strong>Which IAM member type refers to anyone on the internet, including those without a Google account?</strong></p>
<ul>
<li>A. allAuthenticatedUsers</li>
<li>B. <strong>allUsers</strong> âœ…</li>
<li>C. anonymousUsers</li>
<li>D. publicAccess</li>
</ul>
</li>
<li>
<p><strong>An auditor wants to ensure that no developer can accidentally make a Cloud Storage bucket public. What is the best solution?</strong></p>
<ul>
<li>A. Set a weekly reminder to check permissions.</li>
<li>B. <strong>Enable the 'Enforce Public Access Prevention' Organization Policy.</strong> âœ…</li>
<li>C. Direct all developers to a training course.</li>
<li>D. Delete all public buckets.</li>
</ul>
</li>
<li>
<p><strong>How do you securely allow a developer to access a VM's terminal without a public IP or a VPN?</strong></p>
<ul>
<li>A. Tell them to use RDP over the internet.</li>
<li>B. <strong>Identity-Aware Proxy (IAP).</strong> âœ… (Google's zero-trust entry point).</li>
<li>C. Cloud Shell.</li>
<li>D. Deployment Manager.</li>
</ul>
</li>
<li>
<p><strong>What happens if a Service Account JSON key is committed to a public Git repository?</strong></p>
<ul>
<li>A. Nothing, keys are encrypted.</li>
<li>B. <strong>The account is compromised, and the attacker has all permissions of that SA.</strong> âœ…</li>
<li>C. Google automatically deletes the project.</li>
<li>D. The Git repo is hidden.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the difference between allUsers and allAuthenticatedUsers.', checked: false },
        { text: 'I can create a Custom Role with granular permissions.', checked: false },
        { text: 'I know how to identify and remediate overly permissive IAM roles.', checked: false },
        { text: 'I understand the value of Organization Policies for security.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 39 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_40_devops_capstone">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 40: DevOps Capstone (The "Broken Pipeline" Rescue)</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes<br />
<strong>Level:</strong> Advanced (Scenario-Based)<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (CI/CD &amp; Automation)</p>
<hr />
<h2>ğŸ•µï¸â€â™‚ï¸ The Scenario: "Dead on Arrival"</h2>
<p>The Lead DevOps Engineer has left the company midway through a migration to Cloud Run. Your goal is to take over a failing Cloud Build pipeline that refuses to deploy the application.</p>
<p><strong>The Symptom:</strong> Every build fails at the <code>pytest</code> or <code>deploy</code> step.
<strong>The Goal:</strong> Fix the pipeline, automate the trigger, and implement a "Zero-Downtime" deployment strategy.</p>
<hr />
<h2>ğŸ—ï¸ 1. Architecture: The CI/CD Lifecycle</h2>
<pre><code class="language-mermaid">graph LR
    Code[Developer Push] --&gt; Build[Cloud Build]
    Build --&gt; Test[Pytest / Lint]
    Test --&gt; Push[Artifact Registry]
    Push --&gt; Deploy[Cloud Run]

    style Build fill:#e0f2fe,stroke:#0369a1
    style Deploy fill:#dcfce7,stroke:#15803d
</code></pre>
<hr />
<h2>ğŸ› ï¸ 2. The DevOps Debugging Checklist</h2>
<p>When a build fails, follow this triage order:</p>
<h3>Phase 1: Environment Errors</h3>
<ul>
<li><strong>Error:</strong> <code>Command not found</code> or <code>File not found</code>.</li>
<li><strong>Check:</strong> Is the <code>cloudbuild.yaml</code> running in the correct directory? Are all files (.requirements.txt, Dockerfile) in the root?</li>
<li><strong>Fix:</strong> Ensure <code>COPY . .</code> is in your Dockerfile.</li>
</ul>
<h3>Phase 2: IAM Permissions (90% of failures)</h3>
<ul>
<li><strong>Error:</strong> <code>403 Permission Denied: Unable to act as service account</code>.</li>
<li><strong>Check:</strong> Does the <strong>Cloud Build Service Account</strong> have the <code>Cloud Run Admin</code> and <code>Service Account User</code> roles?</li>
<li><strong>ACE Exam Rule:</strong> Cloud Build is a separate identity that needs explicit permission to "hand over" a container to Cloud Run.</li>
</ul>
<hr />
<h2>ğŸ—ï¸ 3. The "Production-Ready" Pipeline (IaC)</h2>
<p>Upgrade the basic build to a professional-grade config.</p>
<pre><code class="language-yaml"># cloudbuild.yaml
steps:
  # 1. Static Analysis (Linting)
  - name: 'python:3.9-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        pip install flake8
        flake8 .

  # 2. Build and Tag with Commit SHA (Best Practice)
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:$SHORT_SHA', '.']

  # 3. Deploy to Cloud Run (Managed)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'my-service'
      - '--image'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:$SHORT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'

images:
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/my-repo/app:$SHORT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY
</code></pre>
<hr />
<h2>ğŸš€ 4. Deployment Strategies: Blue-Green vs. Canary</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: left;">Logic</th>
<th style="text-align: left;">Risk</th>
<th style="text-align: left;">Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Blue-Green</strong></td>
<td style="text-align: left;">Spin up a full new version (Green) and switch all traffic at once.</td>
<td style="text-align: left;">Low (Easy rollback).</td>
<td style="text-align: left;">Mission-critical apps.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Canary</strong></td>
<td style="text-align: left;">Send 5% of traffic to New, 95% to Old. Monitor for errors.</td>
<td style="text-align: left;">Very Low.</td>
<td style="text-align: left;">High-traffic web apps.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Rolling</strong></td>
<td style="text-align: left;">Update one instance at a time (Standard GKE/GCE).</td>
<td style="text-align: left;">Medium.</td>
<td style="text-align: left;">Standard internal apps.</td>
</tr>
</tbody>
</table>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 5. Knowledge Check</h2>
<ol>
<li>
<p><strong>Your Cloud Build pipeline fails at the 'Deploy' step with a 403 error. Which Service Account likely needs more permissions?</strong></p>
<ul>
<li>A. Your personal Google Account.</li>
<li>B. <strong>The Cloud Build Service Account ([NUMBER]@cloudbuild.gserviceaccount.com).</strong> âœ…</li>
<li>C. The Compute Engine Default SA.</li>
<li>D. The App Engine Default SA.</li>
</ul>
</li>
<li>
<p><strong>What is the benefit of using $SHORT_SHA in your container tags?</strong></p>
<ul>
<li>A. It makes the build faster.</li>
<li>B. <strong>It provides traceability between the deployed image and the specific Git commit.</strong> âœ…</li>
<li>C. It reduces storage costs.</li>
<li>D. It encrypts the image.</li>
</ul>
</li>
<li>
<p><strong>You want to ensure that a new version of your app is only released if it passes all unit tests. Where should the tests run?</strong></p>
<ul>
<li>A. On the developer's laptop.</li>
<li>B. <strong>As an early step in the Cloud Build pipeline.</strong> âœ…</li>
<li>C. After the app is deployed to Cloud Run.</li>
<li>D. Inside the Dockerfile.</li>
</ul>
</li>
<li>
<p><strong>A Cloud Build 'Trigger' allows you to automate builds based on which event?</strong></p>
<ul>
<li>A. A manual API call.</li>
<li>B. <strong>A push to a specific branch in GitHub/Bitbucket.</strong> âœ…</li>
<li>C. A change in the Billing account.</li>
<li>D. A user logging into the console.</li>
</ul>
</li>
<li>
<p><strong>Which deployment strategy involves running two identical environments but only sending traffic to one at a time?</strong></p>
<ul>
<li>A. Canary.</li>
<li>B. <strong>Blue-Green.</strong> âœ…</li>
<li>C. Rolling.</li>
<li>D. A/B Testing.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can troubleshoot 403 errors in Cloud Build.', checked: false },
        { text: 'I understand how to use substitution variables like $SHORT_SHA.', checked: false },
        { text: 'I know the difference between Blue-Green and Canary deployments.', checked: false },
        { text: 'I can define a multi-step pipeline in cloudbuild.yaml.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 40 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_41_cost_optimization">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Day 37: FinOps &amp; Sustained Cost Optimization</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Intermediate<br />
<strong>ACE Exam Weight:</strong> â­â­â­ High (Cost management questions appear frequently)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of this lesson, you will:</p>
<ul>
<li><strong>Implement</strong> the FinOps framework for cloud cost management</li>
<li><strong>Configure</strong> budgets, alerts, and quotas</li>
<li><strong>Apply</strong> committed use discounts and sustained use discounts</li>
<li><strong>Identify</strong> orphaned resources and cost leaks</li>
<li><strong>Use</strong> Recommender API for optimization insights</li>
</ul>
<hr />
<h2>ğŸ§  1. The FinOps Framework (Plain-English)</h2>
<p><strong>FinOps = Financial Operations for Cloud.</strong></p>
<p>Think of it like <strong>managing a household budget</strong>: You track spending, set limits, and find ways to save without sacrificing quality of life.</p>
<h3>ğŸ’¡ Real-World Analogy: Electricity Bill</h3>
<table>
<thead>
<tr>
<th>Home Management</th>
<th>Cloud FinOps</th>
</tr>
</thead>
<tbody>
<tr>
<td>Check monthly bill</td>
<td>Billing Reports</td>
</tr>
<tr>
<td>Set spending alerts</td>
<td>Budget Alerts</td>
</tr>
<tr>
<td>Turn off unused lights</td>
<td>Delete orphaned resources</td>
</tr>
<tr>
<td>Buy energy-efficient appliances</td>
<td>Use Committed Use Discounts</td>
</tr>
<tr>
<td>Assign costs to family members</td>
<td>Project/Label-based attribution</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š 2. The 4 Pillars of Cost Optimization</h2>
<pre><code class="language-mermaid">graph TD
    subgraph Pillars[&quot;FinOps Pillars&quot;]
        V[1. VISIBILITY&lt;br&gt;See what you spend]
        A[2. ACCOUNTABILITY&lt;br&gt;Know who spent it]
        C[3. CONTROL&lt;br&gt;Stop overspending]
        O[4. OPTIMIZATION&lt;br&gt;Spend smarter]
    end

    V --&gt; A --&gt; C --&gt; O
    O -.-&gt;|Continuous| V

    style V fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style A fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    style C fill:#ffebee,stroke:#f44336,stroke-width:2px
    style O fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
</code></pre>
<h3>Pillar Details</h3>
<table>
<thead>
<tr>
<th>Pillar</th>
<th>GCP Tools</th>
<th>Key Actions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Visibility</strong></td>
<td>Billing Reports, Cost Table, BigQuery Export</td>
<td>See spend by project, service, SKU</td>
</tr>
<tr>
<td><strong>Accountability</strong></td>
<td>Labels, Cost Attribution</td>
<td>Tag resources with team/owner</td>
</tr>
<tr>
<td><strong>Control</strong></td>
<td>Budgets, Quotas, IAM</td>
<td>Set spending limits</td>
</tr>
<tr>
<td><strong>Optimization</strong></td>
<td>Recommender, Discounts</td>
<td>Apply savings recommendations</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ’° 3. GCP Discount Types</h2>
<h3>Discount Comparison Matrix</h3>
<table>
<thead>
<tr>
<th>Discount Type</th>
<th>Savings</th>
<th>Commitment</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sustained Use Discounts (SUD)</strong></td>
<td>Up to 30%</td>
<td>None (automatic)</td>
<td>Steady workloads running &gt;25% of month</td>
</tr>
<tr>
<td><strong>Committed Use Discounts (CUD)</strong></td>
<td>Up to 57%</td>
<td>1 or 3 years</td>
<td>Predictable, long-term workloads</td>
</tr>
<tr>
<td><strong>Preemptible/Spot VMs</strong></td>
<td>Up to 91%</td>
<td>None (can be terminated)</td>
<td>Batch jobs, fault-tolerant workloads</td>
</tr>
<tr>
<td><strong>Free Tier</strong></td>
<td>100% (within limits)</td>
<td>None</td>
<td>Learning, small projects</td>
</tr>
</tbody>
</table>
<h3>Discount Selection Decision Tree</h3>
<pre><code class="language-mermaid">flowchart TD
    A[Need to Save Money?] --&gt; B{Workload Type?}
    B --&gt;|Steady, Predictable| C{How Long?}
    B --&gt;|Batch/Flexible| D[Spot VMs&lt;br&gt;Up to 91% off]
    B --&gt;|Variable| E[SUDs Automatic&lt;br&gt;Up to 30% off]

    C --&gt;|1-3 Years| F[CUDs&lt;br&gt;Up to 57% off]
    C --&gt;|Short Term| E

    style F fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style D fill:#fff3e0,stroke:#ff9800,stroke-width:2px
</code></pre>
<hr />
<h2>ğŸ” 4. Finding Cost Leaks</h2>
<h3>Common Orphaned Resources</h3>
<table>
<thead>
<tr>
<th>Resource Type</th>
<th>Problem</th>
<th>How to Find</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Unattached Disks</strong></td>
<td>VM deleted, disk remains</td>
<td><code>gcloud compute disks list --filter="NOT users:*"</code></td>
</tr>
<tr>
<td><strong>Static IPs</strong></td>
<td>Unused = charges apply</td>
<td><code>gcloud compute addresses list --filter="status=RESERVED"</code></td>
</tr>
<tr>
<td><strong>Old Snapshots</strong></td>
<td>Accumulate over time</td>
<td>Billing Reports â†’ Filter by Snapshot</td>
</tr>
<tr>
<td><strong>Idle VMs</strong></td>
<td>Running but no traffic</td>
<td>Recommender API or CPU &lt; 5%</td>
</tr>
<tr>
<td><strong>Oversized VMs</strong></td>
<td>More resources than needed</td>
<td>Recommender â†’ Right-sizing</td>
</tr>
</tbody>
</table>
<h3>Resource Cleanup Script</h3>
<pre><code class="language-bash">#!/bin/bash
# Find orphaned resources

echo &quot;=== Unattached Persistent Disks ===&quot;
gcloud compute disks list --filter=&quot;NOT users:*&quot; --format=&quot;table(name,zone,sizeGb,status)&quot;

echo &quot;&quot;
echo &quot;=== Reserved (Unused) Static IPs ===&quot;
gcloud compute addresses list --filter=&quot;status=RESERVED&quot; --format=&quot;table(name,region,address)&quot;

echo &quot;&quot;
echo &quot;=== Snapshots Older Than 90 Days ===&quot;
gcloud compute snapshots list --filter=&quot;creationTimestamp&lt;-P90D&quot; --format=&quot;table(name,diskSizeGb,creationTimestamp)&quot;
</code></pre>
<hr />
<h2>ğŸ› ï¸ 5. Hands-On Lab: Set Up Cost Controls</h2>
<p><strong>Mission:</strong> Configure budgets and alerts to prevent surprise bills.</p>
<h3>Step 1: Create a Budget</h3>
<pre><code class="language-bash"># Create a $100/month budget with alerts at 50%, 90%, 100%
gcloud billing budgets create \
    --billing-account=BILLING_ACCOUNT_ID \
    --display-name=&quot;Monthly Safety Net&quot; \
    --budget-amount=100USD \
    --threshold-rules=percent=0.5,basis=CURRENT_SPEND \
    --threshold-rules=percent=0.9,basis=CURRENT_SPEND \
    --threshold-rules=percent=1.0,basis=CURRENT_SPEND
</code></pre>
<h3>Step 2: Set Up Pub/Sub Notifications</h3>
<pre><code class="language-bash"># Create a topic for budget alerts
gcloud pubsub topics create budget-alerts

# Update budget to publish to topic
gcloud billing budgets update BUDGET_ID \
    --billing-account=BILLING_ACCOUNT_ID \
    --notifications-pubsub-topic=projects/PROJECT_ID/topics/budget-alerts
</code></pre>
<h3>Step 3: Create Alert Function</h3>
<pre><code class="language-python"># Cloud Function to send Slack notification
import base64
import json
import requests

def budget_alert(event, context):
    &quot;&quot;&quot;Triggered by Pub/Sub when budget threshold is exceeded.&quot;&quot;&quot;
    pubsub_data = base64.b64decode(event['data']).decode('utf-8')
    budget_data = json.loads(pubsub_data)

    cost = budget_data['costAmount']
    budget = budget_data['budgetAmount']
    percent = (cost / budget) * 100

    slack_message = {
        &quot;text&quot;: f&quot;âš ï¸ GCP Budget Alert: ${cost:.2f} spent ({percent:.0f}% of ${budget:.2f} budget)&quot;
    }

    requests.post(SLACK_WEBHOOK_URL, json=slack_message)
</code></pre>
<h3>Step 4: Apply Labels for Cost Attribution</h3>
<pre><code class="language-bash"># Label a VM with team and environment
gcloud compute instances add-labels my-vm \
    --labels=team=engineering,environment=production,cost-center=cc-1234

# Label a GCS bucket
gcloud storage buckets update gs://my-bucket \
    --update-labels=team=data,project=analytics
</code></pre>
<hr />
<h2>ğŸ“ˆ 6. Using the Recommender API</h2>
<h3>Available Recommendations</h3>
<table>
<thead>
<tr>
<th>Recommender</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VM Rightsizing</strong></td>
<td>Resize over/under-provisioned VMs</td>
</tr>
<tr>
<td><strong>Idle Resource</strong></td>
<td>Delete unused VMs, disks, IPs</td>
</tr>
<tr>
<td><strong>Commitment</strong></td>
<td>Suggest CUDs based on usage patterns</td>
</tr>
<tr>
<td><strong>Unattended Project</strong></td>
<td>Flag inactive projects</td>
</tr>
</tbody>
</table>
<h3>Get Recommendations via CLI</h3>
<pre><code class="language-bash"># Get VM rightsizing recommendations
gcloud recommender recommendations list \
    --project=PROJECT_ID \
    --location=us-central1-a \
    --recommender=google.compute.instance.MachineTypeRecommender \
    --format=&quot;table(name,primaryImpact.costProjection.cost.units)&quot;

# Get idle VM recommendations
gcloud recommender recommendations list \
    --project=PROJECT_ID \
    --location=us-central1-a \
    --recommender=google.compute.instance.IdleResourceRecommender
</code></pre>
<hr />
<h2>âš ï¸ 7. Common Pitfalls &amp; Pro Tips</h2>
<h3>âŒ Cost Traps</h3>
<table>
<thead>
<tr>
<th>Mistake</th>
<th>Cost Impact</th>
<th>Prevention</th>
</tr>
</thead>
<tbody>
<tr>
<td>Forgot to delete disk with VM</td>
<td>$5-50/month per disk</td>
<td>Use <code>--delete-disks=all</code></td>
</tr>
<tr>
<td>Left static IP unattached</td>
<td>$7.30/month per IP</td>
<td>Release unused IPs</td>
</tr>
<tr>
<td>Snapshot accumulation</td>
<td>Grows indefinitely</td>
<td>Use retention policies</td>
</tr>
<tr>
<td>Wrong storage class</td>
<td>2-10x cost difference</td>
<td>Match class to access pattern</td>
</tr>
<tr>
<td>No budget alerts</td>
<td>Unlimited spending</td>
<td>Always set budgets</td>
</tr>
</tbody>
</table>
<h3>âœ… Pro Tips</h3>
<ul>
<li><strong>Export billing to BigQuery</strong> for custom dashboards</li>
<li><strong>Use Spot VMs</strong> for batch jobs (91% savings!)</li>
<li><strong>Apply SUDs automatically</strong> - just run VMs &gt;25% of month</li>
<li><strong>Review Recommender weekly</strong> - low-hanging fruit awaits</li>
<li><strong>Label EVERYTHING</strong> - "If it's not labeled, it can't be attributed"</li>
</ul>
<hr />
<h2>ğŸ¯ 8. ACE Exam Focus</h2>
<h3>Key Facts to Memorize</h3>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Fact</th>
</tr>
</thead>
<tbody>
<tr>
<td>SUD threshold</td>
<td>Starts at <strong>25% monthly usage</strong></td>
</tr>
<tr>
<td>CUD terms</td>
<td><strong>1 year or 3 years</strong></td>
</tr>
<tr>
<td>Spot VM savings</td>
<td>Up to <strong>91%</strong></td>
</tr>
<tr>
<td>Budget alert default</td>
<td>Alerts at <strong>50%, 90%, 100%</strong></td>
</tr>
<tr>
<td>Unattached static IP cost</td>
<td><strong>$7.30/month</strong></td>
</tr>
</tbody>
</table>
<h3>Exam Traps</h3>
<ul>
<li>âš ï¸ <strong>Budgets DON'T stop spending</strong> - they only alert</li>
<li>âš ï¸ <strong>SUDs are automatic</strong> - no action required</li>
<li>âš ï¸ <strong>CUDs are non-refundable</strong> - plan carefully</li>
<li>âš ï¸ <strong>Labels â‰  Tags</strong> - Labels are for billing, Tags are for firewall</li>
</ul>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 9. Knowledge Check Quiz</h2>
<ol>
<li>
<p><strong>Which discount is applied automatically without any commitment?</strong></p>
<ul>
<li>A. Committed Use Discount</li>
<li>B. <strong>Sustained Use Discount</strong> âœ…</li>
<li>C. Spot VM Discount</li>
<li>D. Free Tier</li>
</ul>
</li>
<li>
<p><strong>You deleted a VM but your bill is still increasing. What's the most likely cause?</strong></p>
<ul>
<li>A. The VM is in a zombie state</li>
<li>B. <strong>You forgot to delete the attached Persistent Disk</strong> âœ…</li>
<li>C. Google charges a deletion fee</li>
<li>D. Budget alerts are misconfigured</li>
</ul>
</li>
<li>
<p><strong>What is the maximum savings from Spot VMs compared to regular VMs?</strong></p>
<ul>
<li>A. 30%</li>
<li>B. 57%</li>
<li>C. 70%</li>
<li>D. <strong>91%</strong> âœ…</li>
</ul>
</li>
<li>
<p><strong>A Budget Alert set at 100% will automatically do what?</strong></p>
<ul>
<li>A. Stop all resources</li>
<li>B. Disable the billing account</li>
<li>C. <strong>Send a notification only</strong> âœ…</li>
<li>D. Reduce VM sizes</li>
</ul>
</li>
<li>
<p><strong>Which GCP feature provides recommendations for idle or oversized resources?</strong></p>
<ul>
<li>A. Cloud Monitoring</li>
<li>B. Cost Table</li>
<li>C. <strong>Recommender API</strong> âœ…</li>
<li>D. Billing Export</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>âœ… Day 37 Checklist</h2>
<ul>
<li>[ ] Understand the 4 FinOps pillars</li>
<li>[ ] Know the difference between SUD and CUD</li>
<li>[ ] Set up a budget with alerts</li>
<li>[ ] Run the orphaned resource script</li>
<li>[ ] Check Recommender for savings opportunities</li>
</ul>
<hr />
<h3>ğŸš€ What's Next?</h3>
<p><strong>Day 38: Capstone - Multi-Region Network Lab</strong>
*   Design global VPC architecture
*   Implement Cloud Interconnect
*   Configure hybrid connectivity</p>
<!-- FLASHCARDS
[
  {"term": "FinOps", "def": "Financial Operations. Framework for managing cloud costs through visibility, accountability, control, and optimization."},
  {"term": "Sustained Use Discount", "def": "Automatic discount (up to 30%) for VMs running >25% of the month. No commitment required."},
  {"term": "Committed Use Discount", "def": "Up to 57% savings for 1-3 year commitments. Non-refundable."},
  {"term": "Spot VM", "def": "Preemptible compute at up to 91% discount. Can be terminated anytime. Best for batch jobs."},
  {"term": "Budget Alert", "def": "Notification when spending reaches threshold. Does NOT stop resources automatically."},
  {"term": "Recommender API", "def": "ML-powered suggestions for rightsizing, idle resources, and cost savings."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_41_data_capstone">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 41: Data Capstone (The $50 Query Rescue)</h1>
<p><strong>Duration:</strong> â±ï¸ 90 Minutes<br />
<strong>Level:</strong> Advanced (Scenario-Based)<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Data Analytics &amp; Cost)</p>
<hr />
<h2>ğŸ•µï¸â€â™‚ï¸ The Scenario: "The Runaway Dashboard"</h2>
<p>A Marketing Director is complaining that their internal dashboard has become "unusable." It used to load in seconds; now it takes minutes and has triggered a "Budget Alert" for the data team. Every time the dashboard refreshes, it costs the company $50 in BigQuery scan fees.</p>
<p><strong>The Symptom:</strong> 10 TB of data is being scanned per query to find just 10 GB of relevant info.
<strong>The Goal:</strong> Reduce the scan volume (and cost) by 99% using partitioning and clustering.</p>
<hr />
<h2>ğŸ—ï¸ 1. Architecture: BigQuery Columnar Storage</h2>
<p>BigQuery doesn't store data in rows like Excel. It stores it in <strong>Columns</strong>.</p>
<pre><code class="language-mermaid">graph TD
    subgraph &quot;Columnar Storage&quot;
        C1[Date Column]
        C2[Customer ID]
        C3[Amount]
        C4[Metadata...]
    end

    Query[SELECT Amount FROM Table] --&gt; C3
    Query -.-&gt; |&quot;SKIPS&quot;| C1
    Query -.-&gt; |&quot;SKIPS&quot;| C2
</code></pre>
<p><strong>The Lesson:</strong> If you <code>SELECT *</code>, you pay for <strong>every</strong> column, even the ones you don't use.</p>
<hr />
<h2>ğŸ› ï¸ 2. The Performance Audit (Dry Run)</h2>
<p>Before fixing the query, always calculate the damage. Use the <code>--dry_run</code> flag in the CLI:</p>
<pre><code class="language-bash">gcloud bq query --use_legacy_sql=false --dry_run \
&quot;SELECT * FROM sales.transactions_all WHERE date = '2025-01-01'&quot;
</code></pre>
<blockquote>
<p><strong>Output:</strong> "This query will process <strong>10.2 TB</strong>." -&gt; <strong>Estimated Cost: $51.00</strong></p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 3. The "Hero" Solution: Partitioning &amp; Clustering</h2>
<h3>Step 1: Create the Partitioned Table</h3>
<p>Partitioning splits the table into "mini-tables" by date.</p>
<pre><code class="language-sql">CREATE TABLE `sales.transactions_optimized`
PARTITION BY DATE(transaction_date)
CLUSTER BY customer_id
AS
SELECT * FROM `sales.transactions_all`
</code></pre>
<h3>Step 2: The Audit (After Fix)</h3>
<p>Run the same query against the <em>optimized</em> table:</p>
<pre><code class="language-bash">gcloud bq query --use_legacy_sql=false --dry_run \
&quot;SELECT amount FROM sales.transactions_optimized WHERE transaction_date = '2025-01-01'&quot;
</code></pre>
<blockquote>
<p><strong>Output:</strong> "This query will process <strong>12 GB</strong>." -&gt; <strong>Estimated Cost: $0.06</strong></p>
</blockquote>
<hr />
<h2>ğŸ’° 4. Performance vs. Cost Comparison</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Without Optimization</th>
<th style="text-align: left;">With Partitioning</th>
<th style="text-align: left;">With Partitioning + Clustering</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Scan Size</strong></td>
<td style="text-align: left;">10.2 TB</td>
<td style="text-align: left;">12.5 GB</td>
<td style="text-align: left;"><strong>2.1 GB</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Cost</strong></td>
<td style="text-align: left;">~$51.00</td>
<td style="text-align: left;">~$0.06</td>
<td style="text-align: left;"><strong>~$0.01</strong></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Latency</strong></td>
<td style="text-align: left;">240 seconds</td>
<td style="text-align: left;">12 seconds</td>
<td style="text-align: left;"><strong>3 seconds</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 5. The Job-Ready Solution (Terraform) ğŸ“‰</h2>
<p>Automate the data lifecycle to prevent "Resource Leakage."</p>
<pre><code class="language-hcl"># bigquery.tf
resource &quot;google_bigquery_dataset&quot; &quot;marketing&quot; {
  dataset_id = &quot;marketing_prod&quot;
  location   = &quot;US&quot;
}

resource &quot;google_bigquery_table&quot; &quot;sales&quot; {
  dataset_id = google_bigquery_dataset.marketing.dataset_id
  table_id   = &quot;optimized_sales&quot;

  # 1. Partitioning (By Date)
  time_partitioning {
    type  = &quot;DAY&quot;
    field = &quot;sale_timestamp&quot;
  }

  # 2. Clustering (By High-Cardinality Columns)
  clustering = [&quot;customer_id&quot;, &quot;store_id&quot;]

  # 3. Expiration (Compliance/Cost)
  expiration_time = 31536000000 # 365 Days
}
</code></pre>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 6. Knowledge Check</h2>
<ol>
<li>
<p><strong>Which BigQuery feature allows the query engine to completely skip entire blocks of data that don't match a time-based filter?</strong></p>
<ul>
<li>A. Clustering.</li>
<li>B. <strong>Partitioning.</strong> âœ… (Pruning happens at the partition level).</li>
<li>C. Indices.</li>
<li>D. Materialized Views.</li>
</ul>
</li>
<li>
<p><strong>You want to sort data within a partition to make filters like <code>WHERE customer_id = 123</code> faster. What should you use?</strong></p>
<ul>
<li>A. Primary Key.</li>
<li>B. <strong>Clustering.</strong> âœ… (Clustering organizes data within partitions).</li>
<li>C. Row Keys.</li>
<li>D. Cloud SQL.</li>
</ul>
</li>
<li>
<p><strong>True or False: Using <code>SELECT *</code> in BigQuery is a recommended practice because the query engine automatically optimizes out unused columns.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False.</strong> âœ… (BigQuery is columnar; <code>SELECT *</code> forces a scan of all columns, increasing cost).</li>
</ul>
</li>
<li>
<p><strong>How can you find out how much a query will cost without actually running it and incurring charges?</strong></p>
<ul>
<li>A. Run it and check the bill tomorrow.</li>
<li>B. <strong>Use the --dry_run flag in the CLI or 'Query Validator' in the Console.</strong> âœ…</li>
<li>C. Ask Google Support.</li>
<li>D. Check the Secret Manager.</li>
</ul>
</li>
<li>
<p><strong>What is the best way to handle data that is over 2 years old and no longer needed for daily reports?</strong></p>
<ul>
<li>A. Manually delete it.</li>
<li>B. <strong>Set a Table or Partition Expiration policy.</strong> âœ… (Automated lifecycle management).</li>
<li>C. Move it to a different project.</li>
<li>D. Encrypt it and forget the key.</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I understand the performance impact of Columnar Storage.', checked: false },
        { text: 'I can distinguish between Partitioning and Clustering.', checked: false },
        { text: 'I know how to use --dry_run to estimate query costs.', checked: false },
        { text: 'I can implement table expiration for data lifecycle management.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Day 41 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_42_week_6_review">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Week 6 Review: The Capstone Experience &amp; SRE Mindset</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Comprehensive<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ Critical (Scenario Synthesis)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Week 6 Takeaways)</strong><br />
You've mastered the capstone skills: Network troubleshooting (Cloud NAT, firewall tags), Security hardening (custom IAM roles, IAP tunnels), DevOps automation (Cloud Build, Artifact Registry), and Data optimization (BigQuery partitioning). <strong>SRE concepts</strong>: SLI = current metric, SLO = target goal, SLA = legal contract, Error Budget = permission to break things. Use your portfolio projects for interviews!</p>
</blockquote>
<hr />
<h2>ğŸ—ï¸ 1. The Capstone Skills Tree</h2>
<p>This week, you transitioned from a "student" to a "builder." You solved four real-world scenarios that mirrored the complexity of the ACE exam's highest-weighted questions.</p>
<pre><code class="language-mermaid">mindmap
  root((Week 6 Mastery))
    Networking
      &quot;Custom VPC Flow&quot;
      &quot;Cloud NAT/Router&quot;
      &quot;Firewall Tagging&quot;
    Security
      &quot;Least Privilege IAM&quot;
      &quot;Custom Roles&quot;
      &quot;IAP Tunnels&quot;
    DevOps
      &quot;Cloud Build YAML&quot;
      &quot;Artifact Registry&quot;
      &quot;Deployment Strategies&quot;
    Data
      &quot;BigQuery Partitioning&quot;
      &quot;Dry Run Auditing&quot;
      &quot;Columnar Optimization&quot;
</code></pre>
<hr />
<h2>ğŸ“ˆ 2. SRE: Balancing Reliability vs. Agility</h2>
<p>Site Reliability Engineering (SRE) is the "secret sauce" of Google's operations. The ACE exam expects you to understand how to balance innovation with stability.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Concept</th>
<th style="text-align: left;">The "Human" Definition</th>
<th style="text-align: left;">The "Exam" Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>SLI</strong></td>
<td style="text-align: left;">"How are we doing right now?"</td>
<td style="text-align: left;">A specific metric (Latency, Error Rate).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SLO</strong></td>
<td style="text-align: left;">"The goal we usually hit."</td>
<td style="text-align: left;">A target value for an SLI (99.9% success).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SLA</strong></td>
<td style="text-align: left;">"The contract with legal teeth."</td>
<td style="text-align: left;">A business agreement with financial penalties.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Error Budget</strong></td>
<td style="text-align: left;">"Permission to break things."</td>
<td style="text-align: left;">The amount of downtime allowed before stopping new features.</td>
</tr>
</tbody>
</table>
<p><strong>Pro Tip:</strong> If you have 100% of your Error Budget left, you are moving too slowly! Use that budget to push new features or perform risky migrations.</p>
<hr />
<h2>ğŸ’¼ 3. Career Pivot: Building Your Portfolio</h2>
<p>The projects you built this week aren't just for learning; they are for your resume.</p>
<ul>
<li><strong>Network Fix:</strong> Showcases your ability to troubleshoot complex hybrid-cloud connectivity.</li>
<li><strong>Hardened IAM:</strong> Demonstrates that you are a "Security-First" engineer.</li>
<li><strong>Automated Pipeline:</strong> Proves you can scale infrastructure without "ClickOps."</li>
<li><strong>Optimized BigQuery:</strong> Shows you understand cloud costs (FinOps).</li>
</ul>
<hr />
<h2>ğŸš€ Resume-Ready Project Ideas</h2>
<p>These projects demonstrate real cloud engineering skills to employers. Each is designed to be completed in 2-4 hours.</p>
<h3>ğŸ”¥ Tier 1: Foundation Projects (Add to GitHub)</h3>
<table>
<thead>
<tr>
<th>Project</th>
<th>Skills Demonstrated</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Auto-Healing Web Cluster</strong></td>
<td>MIG, Load Balancing, Health Checks</td>
<td>Regional MIG with HTTP LB. Simulate failure by deleting VM.</td>
</tr>
<tr>
<td><strong>Secure Static Website</strong></td>
<td>Cloud Storage, IAM, Cloud CDN</td>
<td>Host static site with signed URLs for private assets.</td>
</tr>
<tr>
<td><strong>Serverless API</strong></td>
<td>Cloud Run, Firestore, IAM</td>
<td>REST API with authentication using Cloud Run + Firestore.</td>
</tr>
</tbody>
</table>
<h3>ğŸ”¥ Tier 2: Intermediate Projects (Interview Ready)</h3>
<table>
<thead>
<tr>
<th>Project</th>
<th>Skills Demonstrated</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CI/CD Pipeline</strong></td>
<td>Cloud Build, Artifact Registry, GKE</td>
<td>Auto-deploy container to GKE on Git push.</td>
</tr>
<tr>
<td><strong>Cost Monitor</strong></td>
<td>Cloud Functions, Pub/Sub, Billing API</td>
<td>Alert Slack when daily spend exceeds threshold.</td>
</tr>
<tr>
<td><strong>Multi-Region DR</strong></td>
<td>Cloud SQL, Cross-region replication</td>
<td>Primary in US, failover replica in EU. Test failover.</td>
</tr>
</tbody>
</table>
<h3>ğŸ”¥ Tier 3: Advanced Capstone (Portfolio Highlight)</h3>
<table>
<thead>
<tr>
<th>Project</th>
<th>Skills Demonstrated</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Microservices Platform</strong></td>
<td>GKE, Cloud SQL, Pub/Sub, Monitoring</td>
<td>3-service app with async messaging and full observability.</td>
</tr>
<tr>
<td><strong>Data Lake Architecture</strong></td>
<td>Cloud Storage, Dataflow, BigQuery</td>
<td>Ingest CSV â†’ Transform â†’ Analytics dashboard.</td>
</tr>
<tr>
<td><strong>Zero-Trust Network</strong></td>
<td>VPC Service Controls, IAP, Private Google Access</td>
<td>Corporate-grade network with no public IPs.</td>
</tr>
</tbody>
</table>
<h3>How to Present on Resume</h3>
<pre><code>PROJECTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GCP Auto-Healing Web Infrastructure
â€¢ Deployed regional MIG with HTTP(S) Load Balancer
â€¢ Configured auto-healing with custom health checks
â€¢ Achieved 99.9% uptime simulation with zero manual intervention
â€¢ Technologies: Compute Engine, Cloud Load Balancing, Terraform
</code></pre>
<h3>GitHub Repository Structure</h3>
<pre><code>gcp-portfolio/
â”œâ”€â”€ README.md           # Overview with architecture diagrams
â”œâ”€â”€ auto-healing-mig/   # Project 1
â”‚   â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ README.md       # Setup instructions
â”œâ”€â”€ serverless-api/     # Project 2
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ cloudbuild.yaml
â””â”€â”€ data-pipeline/      # Project 3
    â””â”€â”€ dataflow/
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Pro Tip:</strong> Every project should have a README with:
1. Architecture diagram (Mermaid or image)
2. Problem it solves
3. How to deploy (step-by-step)
4. Cost estimate</p>
</blockquote>
<hr />
<h2>ğŸ¯ Capstone Mini-Projects (2-Hour Challenges)</h2>
<p>Complete these quick challenges to reinforce your skills:</p>
<h3>Challenge 1: The "Break-Fix" Lab</h3>
<p><strong>Time:</strong> 30 minutes | <strong>Difficulty:</strong> Medium</p>
<ol>
<li>Create a VM with no external IP</li>
<li>Try to SSH (it will fail)</li>
<li>Fix it using <strong>IAP tunnel</strong> without adding a public IP</li>
<li>Document the commands used</li>
</ol>
<h3>Challenge 2: The "Cost Optimizer"</h3>
<p><strong>Time:</strong> 45 minutes | <strong>Difficulty:</strong> Medium</p>
<ol>
<li>Create a Cloud Storage bucket with Standard class</li>
<li>Add a lifecycle rule: Move to Nearline after 30 days, Archive after 90 days</li>
<li>Upload test files and verify the rule applies</li>
<li>Calculate cost savings compared to keeping in Standard</li>
</ol>
<h3>Challenge 3: The "Incident Response"</h3>
<p><strong>Time:</strong> 60 minutes | <strong>Difficulty:</strong> Hard</p>
<ol>
<li>Deploy a simple web app on Cloud Run</li>
<li>Create an alerting policy for 5xx errors</li>
<li>Configure a Pub/Sub notification channel</li>
<li>Simulate an error and verify the alert fires</li>
</ol>
<h3>Challenge 4: The "Security Audit"</h3>
<p><strong>Time:</strong> 30 minutes | <strong>Difficulty:</strong> Easy</p>
<ol>
<li>Run <code>gcloud projects get-iam-policy [PROJECT]</code></li>
<li>Identify any Basic roles (Owner/Editor/Viewer) in use</li>
<li>Create a report recommending specific Predefined role replacements</li>
<li>Apply one recommendation to prove the concept</li>
</ol>
<h2>ğŸ“ 4. Advanced Mock Exam (Week 6)</h2>
<ol>
<li>
<p><strong>Your application has an SLO of 99.9% availability per month. You have experienced 40 minutes of downtime this month. Your monthly 'Error Budget' is 43 minutes. What should you do?</strong></p>
<ul>
<li>A. Stop all new feature releases immediately.</li>
<li>B. <strong>Proceed with caution. You have 3 minutes of budget left.</strong> âœ…</li>
<li>C. Ignore it; 40 minutes is close enough.</li>
<li>D. Delete the project and restart.</li>
</ul>
</li>
<li>
<p><strong>A team is using a basic 'roles/editor' permission for their Service Accounts. You recommend 'Custom Roles.' What is the primary benefit?</strong></p>
<ul>
<li>A. It reduces the monthly bill.</li>
<li>B. <strong>It reduces the 'Attack Surface' by following the Principle of Least Privilege.</strong> âœ…</li>
<li>C. It makes the build process faster.</li>
<li>D. It allows access to the Free Tier.</li>
</ul>
</li>
<li>
<p><strong>Which combination of services allows a private VM to download internet updates while blocking all direct inbound traffic?</strong></p>
<ul>
<li>A. VPC Peering + Cloud SQL.</li>
<li>B. <strong>Cloud NAT + Cloud Router + VPC Firewall (Default Egress).</strong> âœ…</li>
<li>C. Global Load Balancer + Cloud Armor.</li>
<li>D. App Engine + Secret Manager.</li>
</ul>
</li>
<li>
<p><strong>How does 'Partitioning' in BigQuery directly contribute to FinOps goals?</strong></p>
<ul>
<li>A. It encrypts data for free.</li>
<li>B. <strong>It allows the query engine to prune unrelated data, reducing the bytes scanned and thus lowering cost.</strong> âœ…</li>
<li>C. It makes the dashboard look better.</li>
<li>D. It increases the throughput of the API.</li>
</ul>
</li>
<li>
<p><strong>A developer committed a Service Account JSON key to a public GitHub repo. What is the immediate 'SRE' response?</strong></p>
<ul>
<li>A. Ask the developer to delete the file from Git.</li>
<li>B. <strong>Disable/Delete the key in GCP Console and rotate the credentials immediately.</strong> âœ…</li>
<li>C. Change the developer's password.</li>
<li>D. Do nothing; the repo is private now.</li>
</ul>
</li>
</ol>
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I can explain the relationship between SLIs and SLOs.', checked: false },
        { text: 'I know when to use an Error Budget to push features.', checked: false },
        { text: 'I understand why long-lived JSON keys are a security risk.', checked: false },
        { text: 'I can articulate the value of my capstone projects to an employer.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Week 6 Mastery Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_43_mock_exam_1">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 10 min read</div>
<h1>Day 45: Final Mock Exam &amp; Certification Readiness</h1>
<p><strong>Duration:</strong> â±ï¸ 120 Minutes<br />
<strong>Level:</strong> Simulation<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ 100% (The Grand Finale)</p>
<hr />
<h2>ğŸ The Final Simulation</h2>
<p>This is it. 20 high-fidelity questions that replicate the difficulty, phrasing, and technical depth of the Official Google Cloud Associate Cloud Engineer exam.</p>
<p><strong>Rules:</strong>
1.  <strong>Time Limit:</strong> 45 minutes.
2.  <strong>Passing Score:</strong> 16/20 (80%).
3.  <strong>Mindset:</strong> Think like an SREâ€”reliability and cost are everything.</p>
<hr />
<h2>ğŸ—ï¸ Domain 1: Setting up a Cloud Solution Environment</h2>
<ol>
<li>
<p><strong>Scenario: You have 3 projects (Dev, Test, Prod). You want to ensure that only the 'Prod' project has 'Billing Export' enabled to BigQuery to save on storage costs. Where do you configure this?</strong></p>
<ul>
<li>A. In each project's settings.</li>
<li>B. <strong>In the Billing Account settings.</strong> âœ… (Billing exports are configured at the Billing Account level).</li>
<li>C. In the Organization IAM.</li>
<li>D. In BigQuery Dataset properties.</li>
</ul>
</li>
<li>
<p><strong>You need to prevent any developer from creating a VM with an External IP in a specific folder. Which tool do you use?</strong></p>
<ul>
<li>A. VPC Firewall Rules.</li>
<li>B. <strong>Organization Policy (Constraints).</strong> âœ… (Org policies can restrict resource configurations).</li>
<li>C. IAM Custom Roles.</li>
<li>D. Cloud Armor.</li>
</ul>
</li>
</ol>
<h2>ğŸ’» Domain 2: Planning and Configuring</h2>
<ol>
<li>
<p><strong>Requirement: You need a database that handles global relational data with high availability (99.999%) and horizontal scaling. Cost is not the primary concern.</strong></p>
<ul>
<li>A. Cloud SQL.</li>
<li>B. <strong>Cloud Spanner.</strong> âœ… (The only global relational DB with that SLA).</li>
<li>C. Cloud Bigtable.</li>
<li>D. Firestore.</li>
</ul>
</li>
<li>
<p><strong>Requirement: A batch processing job runs for 10 hours but can be interrupted. You want to minimize cost.</strong></p>
<ul>
<li>A. E2-Standard-8.</li>
<li>B. <strong>Spot (Preemptible) VMs.</strong> âœ… (Up to 90% cheaper).</li>
<li>C. Committed Use Discounts.</li>
<li>D. App Engine Standard.</li>
</ul>
</li>
</ol>
<h2>ğŸš€ Domain 3: Deploying and Implementing</h2>
<ol>
<li>
<p><strong>How do you deploy a new version of an App Engine app without immediate traffic promotion?</strong></p>
<ul>
<li>A. <code>gcloud app deploy --promote</code>.</li>
<li>B. <strong><code>gcloud app deploy --no-promote</code>.</strong> âœ… (<code>--no-promote</code> keeps the new version at 0% traffic).</li>
<li>C. <code>kubectl apply -f app.yaml</code>.</li>
<li>D. Use Cloud Build.</li>
</ul>
</li>
<li>
<p><strong>Which command allows you to increase the number of nodes in a GKE cluster named 'my-cluster'?</strong></p>
<ul>
<li>A. <code>kubectl scale deployment ...</code></li>
<li>B. <strong><code>gcloud container clusters resize my-cluster --num-nodes=5</code>.</strong> âœ… (Cluster size is a GCP resource level action).</li>
<li>C. <code>gcloud compute instances scale</code>.</li>
<li>D. Edit the YAML in the console.</li>
</ul>
</li>
</ol>
<h2>ğŸ”’ Domain 4: Ensuring Successful Operation</h2>
<ol>
<li>
<p><strong>A VM is running out of disk space. You have increased the Persistent Disk size in the Console. What is the next step?</strong></p>
<ul>
<li>A. Restart the VM.</li>
<li>B. <strong>Resize the file system within the OS (e.g., <code>resize2fs</code>).</strong> âœ… (Increasing disk size doesn't auto-resize the partition).</li>
<li>C. Take a snapshot and create a new VM.</li>
<li>D. Use <code>gsutil</code>.</li>
</ul>
</li>
<li>
<p><strong>You need to find out why a specific user was granted the 'Owner' role 2 hours ago. Where do you look?</strong></p>
<ul>
<li>A. Cloud Monitoring.</li>
<li>B. <strong>Cloud Logging (Activity Logs).</strong> âœ… (Audit logs track "Who did What").</li>
<li>C. IAM Dashboard.</li>
<li>D. Security Command Center.</li>
</ul>
</li>
</ol>
<h2>ğŸ›¡ï¸ Domain 5: Security and Access</h2>
<ol>
<li>
<p><strong>Your application on a VM needs to access a private Cloud Storage bucket. What is the Google-recommended way to provide credentials?</strong></p>
<ul>
<li>A. Download a JSON key to the VM.</li>
<li>B. <strong>Assign a Service Account to the VM and use the Metadata Server.</strong> âœ… (No keys to manage).</li>
<li>C. Put the credentials in the metadata (labels).</li>
<li>D. Use your own user account.</li>
</ul>
</li>
<li>
<p><strong>A contractor needs access to a specific private object in GCS for 15 minutes. What should you generate?</strong></p>
<ul>
<li>A. A Service Account Key.</li>
<li>B. <strong>A Signed URL.</strong> âœ… (Temporary access without IAM changes).</li>
<li>C. A Public Link.</li>
<li>D. A VPN Tunnel.</li>
</ul>
</li>
</ol>
<h2>ğŸ§  Mixed Bag (The "Pro" Level)</h2>
<ol>
<li>
<p><strong>You are using Cloud Build to build a container. You want the build to trigger ONLY when a tag starting with 'v*' is pushed to Git. Where is this filter set?</strong></p>
<ul>
<li>A. In the <code>cloudbuild.yaml</code>.</li>
<li>B. <strong>In the Cloud Build Trigger configuration.</strong> âœ…</li>
<li>C. In GitHub settings.</li>
<li>D. In the VPC Firewall.</li>
</ul>
</li>
<li>
<p><strong>You want to connect an on-premises network to GCP with 10 Gbps of dedicated bandwidth. Which service?</strong></p>
<ul>
<li>A. Carrier Peering.</li>
<li>B. <strong>Dedicated Interconnect.</strong> âœ… (Physical direct fiber).</li>
<li>C. HA VPN.</li>
<li>D. VPC Peering.</li>
</ul>
</li>
<li>
<p><strong>Which BigQuery feature helps reduce the number of bytes scanned for queries that filter by a <code>timestamp</code> column?</strong></p>
<ul>
<li>A. Clustering.</li>
<li>B. <strong>Partitioning.</strong> âœ… (Pruning happens at the partition level).</li>
<li>C. Materialized Views.</li>
<li>D. SQL LIMIT.</li>
</ul>
</li>
<li>
<p><strong>You have multiple VPCs across different organizations that need to communicate. What is the best hub-and-spoke solution?</strong></p>
<ul>
<li>A. VPC Peering.</li>
<li>B. <strong>Network Connectivity Center.</strong> âœ… (Managed hub for multi-org/multi-vpc).</li>
<li>C. Shared VPC.</li>
<li>D. Cloud NAT.</li>
</ul>
</li>
<li>
<p><strong>A Cloud Run service is experiencing high latency. You suspect the cold start is the issue. How do you mitigate this?</strong></p>
<ul>
<li>A. Increase CPU.</li>
<li>B. <strong>Set 'Minimum Instances' to 1.</strong> âœ… (Keeps a container 'warm').</li>
<li>C. Use GKE.</li>
<li>D. Enable Cloud CDN.</li>
</ul>
</li>
<li>
<p><strong>You have 1 PB of data in GCS Standard. You won't touch it for 365 days. How do you save the MOST money?</strong></p>
<ul>
<li>A. Just leave it.</li>
<li>B. <strong>Move it to Archive Class.</strong> âœ… (Lowest storage cost for long-term data).</li>
<li>C. Delete it.</li>
<li>D. Compress it.</li>
</ul>
</li>
<li>
<p><strong>Which gcloud component is used to manage local docker authentication for Artifact Registry?</strong></p>
<ul>
<li>A. <code>gcloud auth login</code>.</li>
<li>B. <strong><code>gcloud auth configure-docker</code>.</strong> âœ…</li>
<li>C. <code>gcloud container clusters</code>.</li>
<li>D. <code>gsutil</code>.</li>
</ul>
</li>
<li>
<p><strong>A GKE pod is failing to pull an image from Artifact Registry. The Service Account has 'Viewer' role on the project. What is the likely missing permission?</strong></p>
<ul>
<li>A. <code>roles/artifactregistry.writer</code>.</li>
<li>B. <strong><code>roles/artifactregistry.reader</code> on the specific repository.</strong> âœ… (Project viewer doesn't always include granular resource access).</li>
<li>C. <code>roles/owner</code>.</li>
<li>D. The pod has no internet.</li>
</ul>
</li>
<li>
<p><strong>You need to store secrets for your application. You want them to be versioned and encrypted. Which service?</strong></p>
<ul>
<li>A. Cloud KMS.</li>
<li>B. <strong>Secret Manager.</strong> âœ… (Versions, audits, and simple API).</li>
<li>C. Metadata Server.</li>
<li>D. Environment Variables.</li>
</ul>
</li>
<li>
<p><strong>You are auditing a VPC. You see a route with destination <code>0.0.0.0/0</code> and next hop <code>default-internet-gateway</code>. What does this do?</strong></p>
<ul>
<li>A. Blocks all traffic.</li>
<li>B. <strong>Provides a path for outbound traffic to the public internet.</strong> âœ…</li>
<li>C. Connects to on-premises.</li>
<li>D. Enables VPC Peering.</li>
</ul>
</li>
<li>
<p><strong>Scenario: Your gcloud command is failing with "Insufficient permissions". You want to see which exact identity is being used. Which command do you run?</strong></p>
<ul>
<li>A. <code>gcloud auth login</code>.</li>
<li>B. <strong><code>gcloud config list</code> or <code>gcloud auth list</code>.</strong> âœ… (Shows the active account).</li>
<li>C. <code>kubectl auth can-i</code>.</li>
<li>D. <code>gcloud iam roles list</code>.</li>
</ul>
</li>
<li>
<p><strong>Requirement: You need to migrate a 10 TB SQL Server database from on-premises to GCP with minimal downtime. Which service should you choose?</strong></p>
<ul>
<li>A. Cloud Storage Transfer Service.</li>
<li>B. <strong>Database Migration Service (DMS).</strong> âœ… (Designed for minimal downtime migrations).</li>
<li>C. Manual export/import.</li>
<li>D. BigQuery Data Transfer Service.</li>
</ul>
</li>
<li>
<p><strong>You are using GKE Autopilot. You want to ensure your pod runs on a node with an SSD. How do you specify this?</strong></p>
<ul>
<li>A. Create a new Node Pool with SSDs.</li>
<li>B. <strong>Use a <code>nodeSelector</code> or <code>ephemeral-storage</code> request in your Pod spec.</strong> âœ… (Autopilot manages the underlying nodes based on Pod needs).</li>
<li>C. SSH into the node and mount the SSD.</li>
<li>D. You cannot use SSDs in Autopilot.</li>
</ul>
</li>
<li>
<p><strong>A team says they can't see the Cloud Console. You find out the Organization Policy "Disable Service Usage" is on. Where is this likely applied?</strong></p>
<ul>
<li>A. At the Project level.</li>
<li>B. <strong>At the Organization or Folder level.</strong> âœ… (Org policies are usually applied high up to set guardrails).</li>
<li>C. In the IAM Role.</li>
<li>D. Inside the VPC.</li>
</ul>
</li>
<li>
<p><strong>Which command is used to sync a local directory to a Cloud Storage bucket?</strong></p>
<ul>
<li>A. <code>gcloud storage cp</code>.</li>
<li>B. <strong><code>gcloud storage rsync</code>.</strong> âœ… (Syncs changes only, mirroring the local state).</li>
<li>C. <code>gsutil cat</code>.</li>
<li>D. <code>terraform apply</code>.</li>
</ul>
</li>
</ol>
<hr />
<h2>ğŸ“– Question Explanations (The Deep Dive)</h2>
<ol>
<li><strong>Billing Export:</strong> Billing is a <strong>Billing Account</strong> level resource. While projects <em>contain</em> resources, the billing account <em>pays</em> for them and holds the export settings.</li>
<li><strong>Org Policy:</strong> Firewalls control traffic (IPs), but <strong>Org Policies</strong> control resource creation rules (No External IPs allowed).</li>
<li><strong>Cloud Spanner:</strong> Relational + Global + 99.999% SLA = Spanner. Cloud SQL is regional. Bigtable is Non-relational.</li>
<li><strong>Spot VMs:</strong> Previously called Preemptible. They are 60-91% cheaper for interruptible jobs.</li>
<li><strong>App Engine Promote:</strong> The <code>--no-promote</code> flag is the standard for "Canary" or "Blue/Green" testing before moving 100% traffic.</li>
<li><strong>GKE Resize:</strong> Changing node count is a <strong>GCP</strong> infrastructure change, so use <code>gcloud</code>. <code>kubectl scale</code> changes pod counts inside K8s.</li>
<li><strong>Disk Resize:</strong> Increasing bits on a disk (GCP level) doesn't change the partition (OS level). You must tell the OS to use the new space.</li>
<li><strong>Logging:</strong> Audit logs are the "Forensics" of GCP. They answer "Who did what, where, and when?".</li>
<li><strong>Service Accounts:</strong> JSON keys are a security risk if leaked. <strong>Service Accounts</strong> attached to VMs use the metadata server to get temporary tokens automatically.</li>
<li><strong>Signed URL:</strong> For one-off, time-limited access to private objects for people without Google accounts.
11-20. [Summarized logic: Always choose the most managed, cost-effective, and secure option according to the Shared Responsibility Model.]</li>
<li><strong>gcloud identity:</strong> <code>gcloud config list</code> shows your active project, account, and zoneâ€”the FIRST place to check for permission errors.</li>
<li><strong>Migration:</strong> <strong>DMS</strong> handles the underlying replication (CDC) to keep the target in sync until you are ready to cut over.</li>
<li><strong>Autopilot SSD:</strong> In Autopilot, your Pod Spec IS your infrastructure request. Google provisions the right hardware to match your Pod demands.</li>
<li><strong>Org Policy Scope:</strong> These are almost always applied at the <strong>Org/Folder</strong> level to ensure "Inherited" compliance across all sub-projects.</li>
<li><strong>rsync:</strong> <code>cp</code> copies everything; <code>rsync</code> only copies what's different. Pro-choice for massive data moves.</li>
</ol>
<hr />
<h2>ğŸ Final Evaluation</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Score</th>
<th style="text-align: left;">Status</th>
<th style="text-align: left;">Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>18-20</strong></td>
<td style="text-align: left;">ğŸ† <strong>ACE MASTER</strong></td>
<td style="text-align: left;">You are ready. Book the exam today!</td>
</tr>
<tr>
<td style="text-align: left;"><strong>15-17</strong></td>
<td style="text-align: left;">ğŸ‘ <strong>READY</strong></td>
<td style="text-align: left;">Review your incorrect answers and scheduling.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>&lt; 15</strong></td>
<td style="text-align: left;">ğŸ“š <strong>MORE STUDY</strong></td>
<td style="text-align: left;">Re-read the Week reviews and Capstone retrospectives.</td>
</tr>
</tbody>
</table>
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I completed the final mock exam under timed conditions.', checked: false },
        { text: 'I understand why I got my incorrect answers wrong.', checked: false },
        { text: 'I have scheduled my official exam.', checked: false },
        { text: 'I am a Certified Cloud Engineer (In Progress)!', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Ready for Certification?
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_44_mock_exam_2">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 4 min read</div>
<h1>Day 44: Week 7 Review &amp; Course Completion (The Finish Line)</h1>
<p><strong>Duration:</strong> â±ï¸ 60 Minutes<br />
<strong>Level:</strong> Comprehensive Review<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ 100% (The Total Synthesis)</p>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<p>By the end of Day 44, you will be able to:
*   <strong>Recall</strong> the core services from all 5 GCP pillars.
*   <strong>Map</strong> complex business requirements to the correct architectural patterns.
*   <strong>Validate</strong> your readiness for the 2-hour official exam.
*   <strong>Navigate</strong> the post-certification career paths (Professional level exams).</p>
<hr />
<h2>ğŸ—ï¸ 1. The "Big Five" Pilar Recap</h2>
<p>This is the entire course in one diagram. If you understand these five connections, you are ready.</p>
<pre><code class="language-mermaid">graph TD
    Compute[1. Compute: GCE, GKE, Cloud Run] --&gt; Identity[2. Identity: IAM, IAP]
    Identity --&gt; Storage[3. Storage: GCS, Cloud SQL, Spanner]
    Storage --&gt; Data[4. Data: BigQuery, Pub/Sub, Dataflow]
    Data --&gt; Network[5. Network: VPC, LB, Interconnect]
    Network --&gt; Compute
</code></pre>
<table>
<thead>
<tr>
<th style="text-align: left;">Pillar</th>
<th style="text-align: left;">Key Service for ACE</th>
<th style="text-align: left;">"The Hook"</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Compute</strong></td>
<td style="text-align: left;"><strong>Compute Engine (MIGs)</strong></td>
<td style="text-align: left;">High availability &amp; Auto-scaling.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Identity</strong></td>
<td style="text-align: left;"><strong>IAM (Custom Roles)</strong></td>
<td style="text-align: left;">Least Privilege &amp; Resource Hierarchy.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Storage</strong></td>
<td style="text-align: left;"><strong>Cloud Storage (Classes)</strong></td>
<td style="text-align: left;">Lifecycle rules &amp; Cost reduction.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Data</strong></td>
<td style="text-align: left;"><strong>BigQuery</strong></td>
<td style="text-align: left;">Serverless SQL at petabyte scale.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Network</strong></td>
<td style="text-align: left;"><strong>VPC (Firewall Tags)</strong></td>
<td style="text-align: left;">Global isolation &amp; hybrid connectivity.</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ˆ 2. Domain Cheat Sheet (ACE Blueprint)</h2>
<ol>
<li><strong>Setting up a Cloud Solution:</strong> Focus on Billing Accounts, Projects, and gcloud config.</li>
<li><strong>Planning &amp; Configuring:</strong> Focus on pricing calculations and choosing between Compute options.</li>
<li><strong>Deploying &amp; Implementing:</strong> Focus on <code>gcloud</code>, <code>gsutil</code>, and <code>kubectl</code> basics.</li>
<li><strong>Ensuring Successful Operation:</strong> Focus on Cloud Monitoring, Logging, and quotas.</li>
<li><strong>Configuring Access &amp; Security:</strong> Focus on IAM, Audit Logs, and Service Accounts.</li>
</ol>
<hr />
<h2>ğŸ“ 3. Final Knowledge Check (Mixed Domains)</h2>
<ol>
<li>
<p><strong>A company wants to migrate an on-premises Hadoop cluster to GCP with minimal operational change. What is the best service?</strong></p>
<ul>
<li>A. Cloud Spanner.</li>
<li>B. <strong>Cloud Dataproc.</strong> âœ… (Managed Spark/Hadoop).</li>
<li>C. Dataflow.</li>
<li>D. Compute Engine with manual install.</li>
</ul>
</li>
<li>
<p><strong>You need to ensure that no developer can create a public Cloud Storage bucket in your entire organization. Where do you apply the policy?</strong></p>
<ul>
<li>A. On each individual bucket.</li>
<li>B. On each project.</li>
<li>C. <strong>At the Organization node (Organization Policy).</strong> âœ…</li>
<li>D. In the billing account.</li>
</ul>
</li>
<li>
<p><strong>What is the fastest way to migrate 100 TB of image data from an AWS S3 bucket to GCP?</strong></p>
<ul>
<li>A. <code>gsutil cp</code>.</li>
<li>B. <strong>Storage Transfer Service.</strong> âœ… (Managed, high-speed over the internet).</li>
<li>C. Transfer Appliance (Physical).</li>
<li>D. Cloud Build.</li>
</ul>
</li>
<li>
<p><strong>You want to serve a global application via a single IP address and ensure traffic is routed to the nearest regional GKE cluster. What do you use?</strong></p>
<ul>
<li>A. Regional Network LB.</li>
<li>B. <strong>Global External HTTP(S) Load Balancer.</strong> âœ…</li>
<li>C. VPC Peering.</li>
<li>D. Cloud DNS.</li>
</ul>
</li>
<li>
<p><strong>True or False: A Subscriber in Pub/Sub consumes messages from a 'Topic' directly.</strong></p>
<ul>
<li>A. True</li>
<li>B. <strong>False.</strong> âœ… (Subscribers always consume from a <strong>Subscription</strong>, which is linked to a Topic).</li>
</ul>
</li>
</ol>
<hr />
<h2>ğŸ“ 4. Next Steps: Beyond the ACE</h2>
<p>Congratulations! You have completed the 45-day curriculum. Here is how to keep the momentum:
1.  <strong>Take the Final Mock Exam (Day 45).</strong>
2.  <strong>Schedule your ACE Exam</strong> via <a href="https://www.webassessor.com/googlecloud/">Webassessor</a>.
3.  <strong>Plan your Professional Exam:</strong>
    *   <strong>Professional Cloud Architect:</strong> For designers.
    *   <strong>Professional Data Engineer:</strong> For data gurus.
    *   <strong>Professional Cloud Security Engineer:</strong> For security experts.</p>
<hr />
<div class="checklist-card" x-data="{ 
    items: [
        { text: 'I have completed all 45 days of the curriculum.', checked: false },
        { text: 'I can map requirements to GCP services with confidence.', checked: false },
        { text: 'I understand the ACE exam blueprint domains.', checked: false },
        { text: 'I am ready to tackle the final mock exam.', checked: false }
    ]
}">
    <h3>
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-blurple">
            <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
            <polyline points="22 4 12 14.01 9 11.01"></polyline>
        </svg>
        Course Completion Checklist
    </h3>
    <template x-for="(item, index) in items" :key="index">
        <div class="checklist-item" @click="item.checked = !item.checked">
            <div class="checklist-box" :class="{ 'checked': item.checked }">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round">
                    <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
            </div>
            <span x-text="item.text" :class="{ 'line-through text-slate-400': item.checked }"></span>
        </div>
    </template>
</div>

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="section_45_exam_strategy">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Day 45: The ACE Exam - Final Strategy &amp; Tips</h1>
<p><strong>Duration:</strong> â±ï¸ 45 Minutes<br />
<strong>Level:</strong> Expert Tactics<br />
<strong>ACE Exam Weight:</strong> â­â­â­â­â­ 100% (Everything leads here!)</p>
<hr />
<blockquote>
<p>[!TIP]
<strong>TL;DR (Your Exam Cheat Sheet)</strong><br />
When stuck between two answers: pick <strong>Managed over DIY</strong>, <strong>Serverless over Clusters</strong>, <strong>Predefined Role over Basic Role</strong>, and <strong>Groups over Users</strong>. Security is 19% of the exam (highest!). Pass score is 70%, not 100%. Time strategy: 60 min first pass, flag hard questions, 30 min review.</p>
</blockquote>
<hr />
<h2>ğŸ¯ Learning Objectives</h2>
<table>
<thead>
<tr>
<th>âœ… What You'll Master</th>
<th>How It Helps</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"Google Way" elimination</strong></td>
<td>Break ties between similar answers</td>
</tr>
<tr>
<td><strong>Keyword-to-service mapping</strong></td>
<td>Instantly recognize correct service</td>
</tr>
<tr>
<td><strong>Common exam traps</strong></td>
<td>Avoid the mistakes 80% of test-takers make</td>
</tr>
<tr>
<td><strong>Exam day strategy</strong></td>
<td>Manage time and reduce anxiety</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§  1. The "Google Way" Decision Hierarchy</h2>
<p>When multiple answers seem correct, Google wants you to choose:</p>
<pre><code class="language-mermaid">flowchart TD
    A[Multiple Correct Answers?] --&gt; B{Managed Service?}
    B --&gt;|Yes| C{Least Privilege?}
    B --&gt;|No| D[Eliminate: DIY usually wrong]

    C --&gt;|Yes| E{Minimal Effort?}
    C --&gt;|No| F[Eliminate: Over-permissioned]

    E --&gt;|Yes| PICK[âœ… Pick This Answer!]
    E --&gt;|No| G[Eliminate: Too complex]

    style PICK fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style D fill:#ffebee,stroke:#f44336
    style F fill:#ffebee,stroke:#f44336
</code></pre>
<h3>The Golden Rules</h3>
<table>
<thead>
<tr>
<th>Priority</th>
<th>Rule</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>1ï¸âƒ£</td>
<td><strong>Managed &gt; Self-managed</strong></td>
<td>Cloud SQL &gt; MySQL on GCE</td>
</tr>
<tr>
<td>2ï¸âƒ£</td>
<td><strong>Serverless &gt; Clusters</strong></td>
<td>Cloud Run &gt; GKE (for simple apps)</td>
</tr>
<tr>
<td>3ï¸âƒ£</td>
<td><strong>Specific Role &gt; Basic Role</strong></td>
<td><code>roles/storage.objectViewer</code> &gt; <code>roles/viewer</code></td>
</tr>
<tr>
<td>4ï¸âƒ£</td>
<td><strong>Groups &gt; Individual Users</strong></td>
<td>Manage 100 users via 1 group</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” 2. Keyword-to-Service Cheat Sheet</h2>
<table>
<thead>
<tr>
<th>When You See...</th>
<th>Think...</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Global, Relational, ACID"</td>
<td><strong>Cloud Spanner</strong></td>
</tr>
<tr>
<td>"Hadoop/Spark lift and shift"</td>
<td><strong>Dataproc</strong></td>
</tr>
<tr>
<td>"Sub-10ms NoSQL, high throughput"</td>
<td><strong>Bigtable</strong></td>
</tr>
<tr>
<td>"Petabyte analytics, SQL"</td>
<td><strong>BigQuery</strong></td>
</tr>
<tr>
<td>"Private fiber connection"</td>
<td><strong>Dedicated Interconnect</strong></td>
</tr>
<tr>
<td>"Event-driven, serverless"</td>
<td><strong>Cloud Functions / Eventarc</strong></td>
</tr>
<tr>
<td>"Container without cluster"</td>
<td><strong>Cloud Run</strong></td>
</tr>
<tr>
<td>"Kubernetes required"</td>
<td><strong>GKE</strong></td>
</tr>
<tr>
<td>"Store images, videos"</td>
<td><strong>Cloud Storage</strong></td>
</tr>
<tr>
<td>"Cache frequently accessed data"</td>
<td><strong>Memorystore (Redis)</strong></td>
</tr>
<tr>
<td>"Low RTO/RPO for Disaster Recovery"</td>
<td><strong>VPC Peering/VPN with Multi-Region GCS</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ 2.5 HA vs DR: The Resilience Duo</h2>
<p>For the "Best in Market" edge, understand the difference between High Availability and Disaster Recovery:</p>
<ul>
<li><strong>HA (High Availability):</strong> Active-Active. Keeping the system UP during failures (e.g., Multi-Zonal MIG).</li>
<li><strong>DR (Disaster Recovery):</strong> Active-Passive. Restoring the system AFTER a failure (e.g., Archive data, cross-region backups).</li>
<li><strong>RPO (Recovery Point Objective):</strong> How much data can you afford to lose? (Time since last backup).</li>
<li><strong>RTO (Recovery Time Objective):</strong> How quickly must you be back online? (Time to restore).</li>
</ul>
<blockquote>
<p>[!TIP]
<strong>ACE Rule:</strong> If they ask for "Global HA", look for <strong>Multi-Region</strong> or <strong>Global</strong> services like Spanner or Global LB.</p>
</blockquote>
<hr />
<h2>ğŸš¨ 3. Top Exam Traps (Avoid These!)</h2>
<blockquote>
<p>[!CAUTION]
These are the <strong>most common mistakes</strong> that cause people to fail. Memorize them!</p>
</blockquote>
<table>
<thead>
<tr>
<th>ğŸš© Trap</th>
<th>âŒ Wrong Answer</th>
<th>âœ… Right Answer</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>The LIMIT Myth</strong></td>
<td>Add <code>LIMIT 10</code> to reduce BigQuery cost</td>
<td>Use partitioning + select columns</td>
<td>LIMIT still scans all data first</td>
</tr>
<tr>
<td><strong>Public Bucket Shortcut</strong></td>
<td>Make bucket public for contractor</td>
<td>Generate a Signed URL</td>
<td>Public = security risk</td>
</tr>
<tr>
<td><strong>Private VM Internet</strong></td>
<td>Open firewall ports</td>
<td>Configure Cloud NAT</td>
<td>NAT = outbound only, more secure</td>
</tr>
<tr>
<td><strong>VPC Scope</strong></td>
<td>VPCs are Regional</td>
<td>VPCs are <strong>Global</strong></td>
<td>Subnets are regional, not VPCs</td>
</tr>
<tr>
<td><strong>Default SA</strong></td>
<td>Use default SA with Editor</td>
<td>Create custom SA with minimal perms</td>
<td>Least privilege principle</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š 4. Exam Domain Weight</h2>
<pre><code class="language-mermaid">pie title ACE Exam Domains
    &quot;Setting up cloud projects&quot; : 17
    &quot;Planning/configuring compute&quot; : 17
    &quot;Planning/configuring data&quot; : 14
    &quot;Planning/configuring network&quot; : 14
    &quot;Security implementation&quot; : 19
    &quot;Monitoring/logging&quot; : 11
    &quot;Troubleshooting&quot; : 8
</code></pre>
<h3>Focus Areas by Domain</h3>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Key Topics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Security (19%)</strong></td>
<td>IAM, Service Accounts, VPC firewalls, Cloud Armor</td>
</tr>
<tr>
<td><strong>Compute (17%)</strong></td>
<td>CE vs GKE vs Cloud Run vs Functions</td>
</tr>
<tr>
<td><strong>Projects (17%)</strong></td>
<td>Hierarchy, billing, quotas, labels</td>
</tr>
<tr>
<td><strong>Data (14%)</strong></td>
<td>Cloud SQL vs Spanner vs Bigtable vs BigQuery</td>
</tr>
<tr>
<td><strong>Networking (14%)</strong></td>
<td>VPCs, subnets, load balancing, VPN</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ• 5. Exam Day Strategy</h2>
<h3>Time Management</h3>
<table>
<thead>
<tr>
<th>Phase</th>
<th>Time</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>First Pass</strong></td>
<td>0-60 min</td>
<td>Answer confident questions</td>
</tr>
<tr>
<td><strong>Mark &amp; Skip</strong></td>
<td>If &gt;60 sec</td>
<td>Flag for review, move on</td>
</tr>
<tr>
<td><strong>Second Pass</strong></td>
<td>60-90 min</td>
<td>Return to flagged questions</td>
</tr>
<tr>
<td><strong>Final Review</strong></td>
<td>90-120 min</td>
<td>Double-check marked answers</td>
</tr>
</tbody>
</table>
<h3>Question Analysis Framework</h3>
<pre><code>1. Read LAST sentence first (what are they asking?)
2. Identify the CONSTRAINT (cost? latency? compliance?)
3. Eliminate 2 obviously wrong answers
4. Choose between remaining 2 based on constraint
</code></pre>
<hr />
<h2>âœ… 6. Final 24-Hour Checklist</h2>
<table>
<thead>
<tr>
<th>Time</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>T-24h</strong></td>
<td>Take final mock exam</td>
</tr>
<tr>
<td><strong>T-12h</strong></td>
<td>Review weak areas only</td>
</tr>
<tr>
<td><strong>T-4h</strong></td>
<td>Scan key gcloud commands</td>
</tr>
<tr>
<td><strong>T-1h</strong></td>
<td>Review resource hierarchy</td>
</tr>
<tr>
<td><strong>T-0</strong></td>
<td>Relax, trust your prep</td>
</tr>
</tbody>
</table>
<h3>Quick Reference Card</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Remember</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VPC</strong></td>
<td>Global. Subnets are Regional.</td>
</tr>
<tr>
<td><strong>Firewall</strong></td>
<td>Ingress blocked by default.</td>
</tr>
<tr>
<td><strong>IAM</strong></td>
<td>Least privilege. Groups &gt; Users.</td>
</tr>
<tr>
<td><strong>Storage</strong></td>
<td>Standard &gt; Nearline &gt; Coldline &gt; Archive</td>
</tr>
<tr>
<td><strong>LB</strong></td>
<td>HTTP(S) = Global. Network = Regional.</td>
</tr>
<tr>
<td><strong>Pass Score</strong></td>
<td>70% (not 100%!)</td>
</tr>
</tbody>
</table>
<hr />
<!-- QUIZ_START -->
<h2>ğŸ“ 7. Final Strategy Quiz</h2>
<ol>
<li>
<p><strong>A question asks for "MOST cost-effective" batch processing. What should you choose?</strong></p>
<ul>
<li>A. N1-Standard with CUDs</li>
<li>B. <strong>Spot/Preemptible VMs</strong> âœ…</li>
<li>C. App Engine Standard</li>
<li>D. Cloud Run always-on</li>
</ul>
</li>
<li>
<p><strong>You see two correct answers: one uses Predefined Role, another uses Custom Role. Which to prefer?</strong></p>
<ul>
<li>A. Custom Role (more precise)</li>
<li>B. <strong>Predefined Role (less management)</strong> âœ…</li>
<li>C. Basic Role (simpler)</li>
<li>D. No difference</li>
</ul>
</li>
<li>
<p><strong>During the exam, you're stuck on a long scenario question. Best strategy?</strong></p>
<ul>
<li>A. Spend 10+ minutes</li>
<li>B. Skip permanently</li>
<li>C. <strong>Mark for Review, return later</strong> âœ…</li>
<li>D. Pick C and move on</li>
</ul>
</li>
<li>
<p><strong>Which exam domain has the highest weight?</strong></p>
<ul>
<li>A. Compute resources</li>
<li>B. <strong>Security implementation (19%)</strong> âœ…</li>
<li>C. Networking</li>
<li>D. Data solutions</li>
</ul>
</li>
<li>
<p><strong>The exam says "minimum operational overhead." What type of solution?</strong></p>
<ul>
<li>A. Custom VM setup</li>
<li>B. <strong>Managed/Serverless service</strong> âœ…</li>
<li>C. Third-party tool</li>
<li>D. Open-source on GCE</li>
</ul>
</li>
</ol>
<!-- QUIZ_END -->

<hr />
<h2>ğŸš€ You Are Ready!</h2>
<p>Take a deep breath. You didn't just read about the cloudâ€”<strong>you built it.</strong></p>
<h3>Remember:</h3>
<ul>
<li><strong>70% to pass</strong> - You don't need perfection</li>
<li><strong>Mark for Review</strong> - Your best friend</li>
<li><strong>Managed &gt; DIY</strong> - When in doubt</li>
<li><strong>Trust your preparation</strong></li>
</ul>
<p><strong>Good luck! You've got this! ğŸ€</strong></p>
<!-- FLASHCARDS
[
  {"term": "50/50 Rule", "def": "Eliminate 2 wrong answers to double your odds."},
  {"term": "Business Constraint", "def": "Key requirement (cost, latency, compliance) that dictates the answer."},
  {"term": "Mark for Review", "def": "Flag difficult questions and return after completing easier ones."},
  {"term": "Managed Service", "def": "Always prefer managed over DIY when asked for 'minimum effort'."},
  {"term": "Pass Score", "def": "70%. You don't need to be perfect."},
  {"term": "Security Domain", "def": "Highest weight at 19%. Focus on IAM and firewalls."}
]
-->

<hr />
<h3>ğŸ—‘ï¸ Lab Cleanup (Mandatory)</h3>
<blockquote>
<p><strong>âš ï¸ Critical:</strong> Delete resources to avoid unecessary billing!</p>
</blockquote>
<ol>
<li><strong>Delete Project:</strong> (Fastest way)
    <code>bash
    gcloud projects delete $PROJECT_ID</code></li>
<li><strong>Or Delete Resources Individually:</strong>
    <code>bash
    # Example commands (verify before running)
    gcloud compute instances delete [INSTANCE_NAME] --quiet
    gcloud storage rm -r gs://[BUCKET_NAME]</code></li>
</ol>
</article>
<article id="mini_projects">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 10 min read</div>
<h1>GCP Mini-Projects Portfolio</h1>
<blockquote>
<p><strong>Build Your Portfolio:</strong> Complete these projects to demonstrate real cloud engineering skills.</p>
</blockquote>
<hr />
<h2>ğŸ“‹ Project Overview</h2>
<table>
<thead>
<tr>
<th>#</th>
<th>Project</th>
<th>Skills</th>
<th>Difficulty</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Static Website Hosting</td>
<td>GCS, IAM, CDN</td>
<td>â­ Beginner</td>
<td>30 min</td>
</tr>
<tr>
<td>2</td>
<td>Auto-Healing Web Cluster</td>
<td>MIG, Load Balancing, Health Checks</td>
<td>â­â­ Intermediate</td>
<td>60 min</td>
</tr>
<tr>
<td>3</td>
<td>Serverless API</td>
<td>Cloud Run, Secret Manager, Cloud SQL</td>
<td>â­â­ Intermediate</td>
<td>90 min</td>
</tr>
<tr>
<td>4</td>
<td>Event-Driven Pipeline</td>
<td>Pub/Sub, Cloud Functions, BigQuery</td>
<td>â­â­â­ Advanced</td>
<td>120 min</td>
</tr>
<tr>
<td>5</td>
<td>Infrastructure as Code</td>
<td>Terraform, VPC, Compute</td>
<td>â­â­â­ Advanced</td>
<td>90 min</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸŒ Project 1: Static Website Hosting</h2>
<p><strong>Skills:</strong> Cloud Storage, IAM, Signed URLs, (Optional) Cloud CDN</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">graph LR
    User[ğŸ‘¤ User] --&gt; CDN[Cloud CDN]
    CDN --&gt; GCS[(Cloud Storage)]
    GCS --&gt; Index[index.html]
    GCS --&gt; Assets[CSS/JS/Images]
</code></pre>
<h3>Objectives</h3>
<ul>
<li>[ ] Create a Cloud Storage bucket with website hosting</li>
<li>[ ] Upload HTML/CSS files</li>
<li>[ ] Configure public access via IAM</li>
<li>[ ] Generate Signed URL for private asset</li>
<li>[ ] (Bonus) Enable Cloud CDN</li>
</ul>
<h3>Steps</h3>
<pre><code class="language-bash"># 1. Create bucket
gcloud storage buckets create gs://my-portfolio-site-$PROJECT_ID \
    --location=us-central1 \
    --uniform-bucket-level-access

# 2. Enable website hosting
gcloud storage buckets update gs://my-portfolio-site-$PROJECT_ID \
    --web-main-page-suffix=index.html \
    --web-error-page=404.html

# 3. Grant public access
gcloud storage buckets add-iam-policy-binding gs://my-portfolio-site-$PROJECT_ID \
    --member=allUsers \
    --role=roles/storage.objectViewer

# 4. Upload files
gcloud storage cp index.html gs://my-portfolio-site-$PROJECT_ID/
gcloud storage cp styles.css gs://my-portfolio-site-$PROJECT_ID/

# 5. Test
echo &quot;Visit: https://storage.googleapis.com/my-portfolio-site-$PROJECT_ID/index.html&quot;
</code></pre>
<h3>Success Criteria</h3>
<ul>
<li>[ ] Website accessible via public URL</li>
<li>[ ] CSS/images load correctly</li>
<li>[ ] Signed URL works for private file</li>
</ul>
<h3>ğŸ¤ How to Explain This in an Interview</h3>
<blockquote>
<p><strong>Problem:</strong> "I needed a cost-effective way to host a static portfolio site."</p>
<p><strong>Why GCS:</strong> "Cloud Storage is pennies/month vs $7+/month for a VM. It scales automatically and integrates with CDN."</p>
<p><strong>Trade-off:</strong> "Public bucket is simple but less secure. For sensitive assets, I'd use Signed URLs or IAP."</p>
<p><strong>What I'd improve:</strong> "Add Cloud CDN for global latency, custom domain with Cloud DNS."</p>
</blockquote>
<h3>âš ï¸ What Can Break (&amp; How to Fix)</h3>
<table>
<thead>
<tr>
<th>Failure Scenario</th>
<th>Cause</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>403 Forbidden</td>
<td>Missing <code>allUsers</code> IAM binding</td>
<td>Add <code>Storage Object Viewer</code> role</td>
</tr>
<tr>
<td>CSS not loading</td>
<td>Incorrect Content-Type</td>
<td>Set proper MIME types on upload</td>
</tr>
<tr>
<td>Costs spiking</td>
<td>No lifecycle rules</td>
<td>Add lifecycle to delete old versions</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ–¥ï¸ Project 2: Auto-Healing Web Cluster</h2>
<p><strong>Skills:</strong> Instance Templates, Regional MIG, HTTP Load Balancer, Health Checks</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">graph TD
    User[ğŸ‘¤ Users] --&gt; GLB[Global Load Balancer]
    GLB --&gt; MIG[Regional MIG]

    subgraph &quot;MIG (3 zones)&quot;
        VM1[VM us-central1-a]
        VM2[VM us-central1-b]
        VM3[VM us-central1-c]
    end

    MIG --&gt; VM1 &amp; VM2 &amp; VM3
    HC[Health Check] --&gt; VM1 &amp; VM2 &amp; VM3
</code></pre>
<h3>Objectives</h3>
<ul>
<li>[ ] Create instance template with startup script</li>
<li>[ ] Create Regional MIG with auto-healing</li>
<li>[ ] Configure HTTP health check</li>
<li>[ ] Set up Global HTTP(S) Load Balancer</li>
<li>[ ] Test auto-healing by killing a VM</li>
</ul>
<h3>Steps</h3>
<pre><code class="language-bash"># 1. Create instance template
gcloud compute instance-templates create web-template \
    --machine-type=e2-micro \
    --tags=http-server \
    --metadata=startup-script='#!/bin/bash
apt-get update &amp;&amp; apt-get install -y apache2
HOSTNAME=$(hostname)
echo &quot;&lt;h1&gt;Hello from $HOSTNAME&lt;/h1&gt;&quot; &gt; /var/www/html/index.html
echo &quot;OK&quot; &gt; /var/www/html/health'

# 2. Create health check
gcloud compute health-checks create http web-hc \
    --port=80 \
    --request-path=/health

# 3. Create Regional MIG
gcloud compute instance-groups managed create web-mig \
    --template=web-template \
    --size=3 \
    --region=us-central1 \
    --health-check=web-hc \
    --initial-delay=60

# 4. Create backend service
gcloud compute backend-services create web-backend \
    --global \
    --health-checks=web-hc \
    --port-name=http

# 5. Add MIG to backend
gcloud compute backend-services add-backend web-backend \
    --global \
    --instance-group=web-mig \
    --instance-group-region=us-central1

# 6. Test auto-healing
gcloud compute instances delete &lt;VM_NAME&gt; --zone=us-central1-a --quiet
watch gcloud compute instance-groups managed list-instances web-mig --region=us-central1
</code></pre>
<h3>Success Criteria</h3>
<ul>
<li>[ ] Load balancer distributes traffic to all VMs</li>
<li>[ ] Health check shows green for all instances</li>
<li>[ ] Deleted VM auto-recreates within 2 minutes</li>
</ul>
<h3>ğŸ¤ How to Explain This in an Interview</h3>
<blockquote>
<p><strong>Problem:</strong> "I needed a web tier that survives zone failures and self-heals without manual intervention."</p>
<p><strong>Why Regional MIG:</strong> "Spreads VMs across 3 zones automatically. If one zone goes down, 2/3 capacity remains."</p>
<p><strong>Trade-off:</strong> "Regional MIG costs more than Zonal, but production SLA requires it. I'd use Zonal only for dev/test."</p>
<p><strong>What I'd improve:</strong> "Add Spot VMs in a separate node pool for cost savings, configure scheduled scaling for known traffic peaks."</p>
</blockquote>
<h3>âš ï¸ What Can Break (&amp; How to Fix)</h3>
<table>
<thead>
<tr>
<th>Failure Scenario</th>
<th>Cause</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>VMs keep recreating</td>
<td>Health check path wrong</td>
<td>Verify <code>/health</code> returns 200</td>
</tr>
<tr>
<td>Health checks failing</td>
<td>Firewall blocking probe IPs</td>
<td>Allow <code>35.191.0.0/16</code>, <code>130.211.0.0/22</code></td>
</tr>
<tr>
<td>LB returns 502</td>
<td>Backend not registered</td>
<td>Check <code>port-name</code> matches named port</td>
</tr>
<tr>
<td>VMs stuck CREATING</td>
<td>Quota exhausted</td>
<td>Request quota increase or reduce size</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸš€ Project 3: Serverless API with Cloud Run</h2>
<p><strong>Skills:</strong> Cloud Run, Secret Manager, Cloud SQL, Container Registry</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">graph LR
    User[ğŸ‘¤ Client] --&gt; Run[Cloud Run]
    Run --&gt; SQL[(Cloud SQL)]
    Run --&gt; SM[Secret Manager]
    SM --&gt; |DB Password| Run
</code></pre>
<h3>Objectives</h3>
<ul>
<li>[ ] Create Cloud SQL instance</li>
<li>[ ] Store credentials in Secret Manager</li>
<li>[ ] Build and deploy API to Cloud Run</li>
<li>[ ] Connect Run to SQL via private IP</li>
<li>[ ] Test CRUD operations</li>
</ul>
<h3>Steps</h3>
<pre><code class="language-bash"># 1. Create Cloud SQL instance
gcloud sql instances create demo-db \
    --database-version=POSTGRES_14 \
    --tier=db-f1-micro \
    --region=us-central1

# 2. Set password and store in Secret Manager
gcloud sql users set-password postgres \
    --instance=demo-db \
    --password=SuperSecret123

echo -n &quot;SuperSecret123&quot; | gcloud secrets create db-password --data-file=-

# 3. Build container (example Dockerfile needed)
gcloud builds submit --tag gcr.io/$PROJECT_ID/demo-api

# 4. Deploy to Cloud Run
gcloud run deploy demo-api \
    --image gcr.io/$PROJECT_ID/demo-api \
    --platform managed \
    --region us-central1 \
    --add-cloudsql-instances=$PROJECT_ID:us-central1:demo-db \
    --set-secrets=DB_PASS=db-password:latest
</code></pre>
<h3>Success Criteria</h3>
<ul>
<li>[ ] API accessible via Cloud Run URL</li>
<li>[ ] Database connection works</li>
<li>[ ] Secret not exposed in logs or environment</li>
</ul>
<h3>ğŸ¤ How to Explain This in an Interview</h3>
<blockquote>
<p><strong>Problem:</strong> "I needed a scalable API that connects to a database without managing servers."</p>
<p><strong>Why Cloud Run:</strong> "Scales to zero when idle, container-based so I control the runtime, built-in HTTPS."</p>
<p><strong>Trade-off:</strong> "Cloud Run has cold starts. For latency-critical APIs, I'd set min-instances=1 (costs more)."</p>
<p><strong>What I'd improve:</strong> "Add Cloud Armor for DDoS protection, implement connection pooling for Cloud SQL."</p>
</blockquote>
<h3>âš ï¸ What Can Break (&amp; How to Fix)</h3>
<table>
<thead>
<tr>
<th>Failure Scenario</th>
<th>Cause</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>Connection refused</td>
<td>Cloud SQL Auth Proxy not added</td>
<td>Use <code>--add-cloudsql-instances</code> flag</td>
</tr>
<tr>
<td>Secret not found</td>
<td>Wrong secret version</td>
<td>Use <code>:latest</code> or specific version number</td>
</tr>
<tr>
<td>Cold start &gt; 10s</td>
<td>Large container image</td>
<td>Use distroless/alpine, reduce dependencies</td>
</tr>
<tr>
<td>500 errors at scale</td>
<td>DB connection limit hit</td>
<td>Implement connection pooling</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š Project 4: Event-Driven Data Pipeline</h2>
<p><strong>Skills:</strong> Pub/Sub, Cloud Functions, BigQuery, Dead Letter Queue</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">graph LR
    Upload[ğŸ“ File Upload] --&gt; GCS[(Cloud Storage)]
    GCS --&gt; Notify[Pub/Sub Notification]
    Notify --&gt; Topic[Pub/Sub Topic]
    Topic --&gt; Sub[Subscription]
    Sub --&gt; CF[Cloud Function]
    CF --&gt; BQ[(BigQuery)]
    Sub --&gt; DLQ[Dead Letter Queue]
</code></pre>
<h3>Objectives</h3>
<ul>
<li>[ ] Create Pub/Sub topic with DLQ</li>
<li>[ ] Configure GCS notifications</li>
<li>[ ] Write Cloud Function to process files</li>
<li>[ ] Load data into BigQuery</li>
<li>[ ] Test error handling with DLQ</li>
</ul>
<h3>Steps</h3>
<pre><code class="language-bash"># 1. Create topics
gcloud pubsub topics create file-events
gcloud pubsub topics create file-events-dlq

# 2. Create subscription with DLQ
gcloud pubsub subscriptions create file-sub \
    --topic=file-events \
    --dead-letter-topic=file-events-dlq \
    --max-delivery-attempts=5

# 3. Create BigQuery dataset
bq mk --dataset my_dataset

# 4. Create Cloud Function
gcloud functions deploy process-file \
    --gen2 \
    --runtime=python310 \
    --trigger-topic=file-events \
    --entry-point=process \
    --region=us-central1

# 5. Configure GCS notification
gcloud storage buckets notifications create gs://my-data-bucket \
    --topic=file-events
</code></pre>
<h3>Success Criteria</h3>
<ul>
<li>[ ] Uploaded files trigger function</li>
<li>[ ] Data appears in BigQuery</li>
<li>[ ] Failed messages go to DLQ</li>
</ul>
<h3>ğŸ¤ How to Explain This in an Interview</h3>
<blockquote>
<p><strong>Problem:</strong> "I needed to process uploaded files automatically and load them into a data warehouse."</p>
<p><strong>Why Pub/Sub:</strong> "Decouples upload from processing. If BigQuery is slow, messages queue instead of failing."</p>
<p><strong>Trade-off:</strong> "At-least-once delivery means I handle duplicates. For exactly-once, I'd enable that feature."</p>
<p><strong>What I'd improve:</strong> "Add Dataflow for complex transformations, implement idempotent writes to BigQuery."</p>
</blockquote>
<h3>âš ï¸ What Can Break (&amp; How to Fix)</h3>
<table>
<thead>
<tr>
<th>Failure Scenario</th>
<th>Cause</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backlog growing</td>
<td>Function too slow</td>
<td>Increase memory/CPU, batch writes</td>
</tr>
<tr>
<td>DLQ filling up</td>
<td>Malformed files</td>
<td>Add validation, improve error handling</td>
</tr>
<tr>
<td>Duplicate rows</td>
<td>At-least-once delivery</td>
<td>Use BigQuery MERGE or deduplication</td>
</tr>
<tr>
<td>Function timeout</td>
<td>Large files</td>
<td>Stream data, don't load all in memory</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ—ï¸ Project 5: Infrastructure as Code</h2>
<p><strong>Skills:</strong> Terraform, VPC, Subnets, Firewall Rules, Compute Engine</p>
<h3>Architecture</h3>
<pre><code class="language-mermaid">graph TD
    TF[Terraform] --&gt; VPC[Custom VPC]
    VPC --&gt; Subnet1[Web Subnet]
    VPC --&gt; Subnet2[DB Subnet]
    Subnet1 --&gt; VM1[Web Server]
    Subnet2 --&gt; VM2[DB Server]
    FW[Firewall Rules] --&gt; VPC
</code></pre>
<h3>Objectives</h3>
<ul>
<li>[ ] Write Terraform config for custom VPC</li>
<li>[ ] Create 2 subnets (web, database)</li>
<li>[ ] Deploy VMs in each subnet</li>
<li>[ ] Configure firewall rules</li>
<li>[ ] Use remote state in GCS</li>
</ul>
<h3>Files to Create</h3>
<p><strong>main.tf:</strong>
- Provider configuration
- VPC resource
- 2 Subnet resources
- 2 VM resources
- Firewall rules</p>
<p><strong>variables.tf:</strong>
- project_id
- region
- environment</p>
<p><strong>backend.tf:</strong>
- GCS remote state</p>
<h3>Success Criteria</h3>
<ul>
<li>[ ] <code>terraform plan</code> shows expected resources</li>
<li>[ ] <code>terraform apply</code> creates all resources</li>
<li>[ ] VMs can communicate on internal IPs</li>
<li>[ ] State stored in GCS bucket</li>
</ul>
<h3>ğŸ¤ How to Explain This in an Interview</h3>
<blockquote>
<p><strong>Problem:</strong> "I needed repeatable infrastructure that multiple team members could collaborate on."</p>
<p><strong>Why Terraform:</strong> "Multi-cloud, huge community, state management with locking prevents conflicts."</p>
<p><strong>Trade-off:</strong> "Terraform requires learning HCL. For GCP-only, Deployment Manager is an option but less popular."</p>
<p><strong>What I'd improve:</strong> "Add modules for reusability, implement Terragrunt for DRY configs, add policy checks with Sentinel."</p>
</blockquote>
<h3>âš ï¸ What Can Break (&amp; How to Fix)</h3>
<table>
<thead>
<tr>
<th>Failure Scenario</th>
<th>Cause</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>State lock error</td>
<td>Concurrent runs</td>
<td>Wait for lock or break manually (carefully)</td>
</tr>
<tr>
<td>Drift detected</td>
<td>Manual console changes</td>
<td>Import changes or reset to known state</td>
</tr>
<tr>
<td>Destroy fails</td>
<td>Resource dependencies</td>
<td>Use <code>terraform destroy -target</code> carefully</td>
</tr>
<tr>
<td>API errors</td>
<td>APIs not enabled</td>
<td>Enable Compute API, IAM API first</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ Portfolio Submission Checklist</h2>
<p>When showcasing these projects:</p>
<ul>
<li>[ ] Screenshot of working architecture</li>
<li>[ ] GitHub repo with code</li>
<li>[ ] Cost estimate (use Google Cloud Pricing Calculator)</li>
<li>[ ] What I learned section</li>
<li>[ ] Improvements I would make</li>
</ul>
<h3>Resume Bullet Examples</h3>
<blockquote>
<p>"Deployed auto-scaling web cluster on GCP with Regional MIG, achieving 99.9% uptime through auto-healing health checks"</p>
<p>"Built event-driven data pipeline processing 10K+ events/day using Pub/Sub and Cloud Functions"</p>
<p>"Implemented Infrastructure as Code with Terraform, reducing deployment time from 2 hours to 5 minutes"</p>
</blockquote>
</article>
<article id="capstone_1_static_website">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Capstone Project 1: Production-Grade Static Website</h1>
<p><strong>Duration:</strong> â±ï¸ 3-4 hours<br />
<strong>Level:</strong> Intermediate<br />
<strong>Skills:</strong> Cloud Storage, Cloud CDN, Load Balancing, Cloud DNS, SSL Certificates</p>
<hr />
<h2>ğŸ¯ Project Objective</h2>
<p>Build a <strong>production-ready static website</strong> with global CDN, HTTPS, custom domain, and monitoringâ€”exactly how real companies deploy web properties.</p>
<h3>What You'll Learn</h3>
<ul>
<li>âœ… Configure Cloud Storage for static website hosting</li>
<li>âœ… Set up Cloud CDN for global performance</li>
<li>âœ… Configure HTTPS with Google-managed SSL certificates</li>
<li>âœ… Use Cloud DNS for custom domain routing</li>
<li>âœ… Implement Cloud Monitoring and logging</li>
<li>âœ… Follow production security and performance best practices</li>
</ul>
<hr />
<h2>ğŸ—ï¸ Architecture</h2>
<pre><code class="language-mermaid">graph TB
    User[ğŸ‘¤ Global Users] --&gt; DNS[Cloud DNS&lt;br/&gt;yourdomain.com]
    DNS --&gt; GLB[Global Load Balancer&lt;br/&gt;HTTPS]
    GLB --&gt; SSL[Managed SSL Cert]
    GLB --&gt; CDN[Cloud CDN&lt;br/&gt;Edge Caching]
    CDN --&gt; Backend[Backend Bucket]
    Backend --&gt; GCS[(Cloud Storage&lt;br/&gt;Website Files)]

    Monitor[Cloud Monitoring] -.-&gt; GLB
    Monitor -.-&gt; CDN

    style GLB fill:#4285f4
    style CDN fill:#34a853
    style GCS fill:#fbbc04
</code></pre>
<hr />
<h2>ğŸ“‹ Prerequisites</h2>
<ul>
<li>[ ] Active GCP project with billing enabled</li>
<li>[ ] Basic HTML/CSS skills</li>
<li>[ ] Domain name (optional but recommended)</li>
<li>[ ] Completed: Cloud Storage, Load Balancing modules</li>
</ul>
<hr />
<h2>ğŸš€ Implementation Guide</h2>
<h3>Phase 1: Create Website Content (30 min)</h3>
<h4>Step 1: Prepare Website Files</h4>
<p>Create a simple portfolio website locally:</p>
<pre><code class="language-bash"># Create project directory
mkdir gcp-static-site
cd gcp-static-site

# Create index.html
cat &gt; index.html &lt;&lt; 'EOF'
&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
    &lt;title&gt;My GCP Portfolio&lt;/title&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;header&gt;
        &lt;h1&gt;Welcome to My Cloud Portfolio&lt;/h1&gt;
        &lt;p&gt;Deployed on Google Cloud Platform&lt;/p&gt;
    &lt;/header&gt;
    &lt;main&gt;
        &lt;section&gt;
            &lt;h2&gt;About This Project&lt;/h2&gt;
            &lt;p&gt;This static website demonstrates production-grade cloud architecture:&lt;/p&gt;
            &lt;ul&gt;
                &lt;li&gt;âœ… Global CDN distribution&lt;/li&gt;
                &lt;li&gt;âœ… HTTPS with managed certificates&lt;/li&gt;
                &lt;li&gt;âœ… Custom domain routing&lt;/li&gt;
                &lt;li&gt;âœ… Cloud monitoring integration&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/section&gt;
    &lt;/main&gt;
    &lt;footer&gt;
        &lt;p&gt;Hosted on Google Cloud Storage | Powered by Cloud CDN&lt;/p&gt;
    &lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
EOF

# Create styles.css
cat &gt; styles.css &lt;&lt; 'EOF'
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: 'Segoe UI', sans-serif; line-height: 1.6; color: #333; }
header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
         color: white; padding: 60px 20px; text-align: center; }
main { max-width: 800px; margin: 40px auto; padding: 20px; }
section { background: #f8f9fa; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
footer { text-align: center; padding: 20px; background: #333; color: white; margin-top: 40px; }
EOF

# Create 404 page
cat &gt; 404.html &lt;&lt; 'EOF'
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;&lt;title&gt;404 - Page Not Found&lt;/title&gt;&lt;/head&gt;
&lt;body style=&quot;text-align:center; padding:100px; font-family:Arial;&quot;&gt;
    &lt;h1&gt;404&lt;/h1&gt;
    &lt;p&gt;Page not found. &lt;a href=&quot;/&quot;&gt;Go home&lt;/a&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
EOF
</code></pre>
<hr />
<h3>Phase 2: Cloud Storage Setup (30 min)</h3>
<h4>Step 2: Create Storage Bucket</h4>
<pre><code class="language-bash"># Set variables
PROJECT_ID=$(gcloud config get-value project)
BUCKET_NAME=&quot;www-${PROJECT_ID}&quot;

# Create bucket with uniform access
gcloud storage buckets create gs://${BUCKET_NAME} \
    --location=us-central1 \
    --uniform-bucket-level-access \
    --public-access-prevention

# Upload website files
gcloud storage cp index.html gs://${BUCKET_NAME}/
gcloud storage cp styles.css gs://${BUCKET_NAME}/
gcloud storage cp 404.html gs://${BUCKET_NAME}/

# Verify upload
gcloud storage ls gs://${BUCKET_NAME}/
</code></pre>
<h4>Step 3: Configure Website Settings</h4>
<pre><code class="language-bash"># Set main page and 404 page
gcloud storage buckets update gs://${BUCKET_NAME} \
    --web-main-page-suffix=index.html \
    --web-error-page=404.html
</code></pre>
<hr />
<h3>Phase 3: Load Balancer + CDN Setup (60 min)</h3>
<h4>Step 4: Reserve Static IP Address</h4>
<pre><code class="language-bash"># Reserve global static IP for HTTPS load balancer
gcloud compute addresses create website-ip \
    --ip-version=IPV4 \
    --global

# Get the IP address
gcloud compute addresses describe website-ip --global --format=&quot;get(address)&quot;
</code></pre>
<h4>Step 5: Create Backend Bucket</h4>
<pre><code class="language-bash"># Create backend bucket pointing to GCS
gcloud compute backend-buckets create website-backend \
    --gcs-bucket-name=${BUCKET_NAME} \
    --enable-cdn \
    --cache-mode=CACHE_ALL_STATIC \
    --default-ttl=3600 \
    --max-ttl=86400
</code></pre>
<h4>Step 6: Create URL Map</h4>
<pre><code class="language-bash"># Create URL map
gcloud compute url-maps create website-url-map \
    --default-backend-bucket=website-backend
</code></pre>
<h4>Step 7: Create Managed SSL Certificate</h4>
<pre><code class="language-bash"># For custom domain (replace with your domain)
DOMAIN=&quot;example.com&quot;  # Change this!

gcloud compute ssl-certificates create website-ssl-cert \
    --domains=${DOMAIN},www.${DOMAIN} \
    --global

# Check provisioning status (takes 15-30 minutes)
gcloud compute ssl-certificates describe website-ssl-cert --global
</code></pre>
<h4>Step 8: Create HTTPS Proxy</h4>
<pre><code class="language-bash"># Create target HTTPS proxy
gcloud compute target-https-proxies create website-https-proxy \
    --url-map=website-url-map \
    --ssl-certificates=website-ssl-cert
</code></pre>
<h4>Step 9: Create Forwarding Rule</h4>
<pre><code class="language-bash"># Create global forwarding rule
gcloud compute forwarding-rules create website-https-rule \
    --address=website-ip \
    --global \
    --target-https-proxy=website-https-proxy \
    --ports=443
</code></pre>
<hr />
<h3>Phase 4: DNS Configuration (30 min)</h3>
<h4>Step 10: Configure Cloud DNS</h4>
<pre><code class="language-bash"># Create DNS zone
gcloud dns managed-zones create mywebsite-zone \
    --dns-name=${DOMAIN}. \
    --description=&quot;My website DNS zone&quot;

# Get name servers
gcloud dns managed-zones describe mywebsite-zone \
    --format=&quot;get(nameServers)&quot;

# Create A records
LOAD_BALANCER_IP=$(gcloud compute addresses describe website-ip --global --format=&quot;get(address)&quot;)

gcloud dns record-sets create ${DOMAIN}. \
    --zone=mywebsite-zone \
    --type=A \
    --ttl=300 \
    --rrdatas=${LOAD_BALANCER_IP}

gcloud dns record-sets create www.${DOMAIN}. \
    --zone=mywebsite-zone \
    --type=A \
    --ttl=300 \
    --rrdatas=${LOAD_BALANCER_IP}
</code></pre>
<blockquote>
<p><strong>â³ Important:</strong> Update your domain registrar's name servers to the ones provided by Cloud DNS.</p>
</blockquote>
<hr />
<h3>Phase 5: Security &amp; IAM (20 min)</h3>
<h4>Step 11: Configure Bucket IAM</h4>
<pre><code class="language-bash"># Make bucket publicly readable (required for website hosting)
gcloud storage buckets add-iam-policy-binding gs://${BUCKET_NAME} \
    --member=allUsers \
    --role=roles/storage.objectViewer
</code></pre>
<h4>Step 12: Enable Cloud Armor (Optional - DDoS Protection)</h4>
<pre><code class="language-bash"># Create security policy
gcloud compute security-policies create website-security-policy \
    --description=&quot;Basic DDoS protection&quot;

# Add rate limiting rule
gcloud compute security-policies rules create 1000 \
    --security-policy=website-security-policy \
    --expression=&quot;true&quot; \
    --action=rate-based-ban \
    --rate-limit-threshold-count=100 \
    --rate-limit-threshold-interval-sec=60 \
    --ban-duration-sec=600

# Attach to backend
gcloud compute backend-buckets update website-backend \
    --security-policy=website-security-policy
</code></pre>
<hr />
<h3>Phase 6: Monitoring &amp; Logging (30 min)</h3>
<h4>Step 13: Create Uptime Check</h4>
<pre><code class="language-bash"># Create uptime check
gcloud monitoring uptime create website-uptime \
    --resource-type=uptime-url \
    --display-name=&quot;Website Uptime&quot; \
    --http-check-path=&quot;/&quot; \
    --monitored-resource-host=${DOMAIN}
</code></pre>
<h4>Step 14: Create Alert Policy</h4>
<pre><code class="language-bash"># Create alerting policy for downtime
gcloud alpha monitoring policies create \
    --notification-channels=&lt;YOUR_EMAIL_CHANNEL&gt; \
    --display-name=&quot;Website Down Alert&quot; \
    --condition-display-name=&quot;Uptime check failed&quot; \
    --condition-threshold-value=1 \
    --condition-threshold-duration=60s
</code></pre>
<h4>Step 15: Enable CDN Logging</h4>
<pre><code class="language-bash"># Enable Cloud CDN logging
gcloud compute backend-buckets update website-backend \
    --enable-logging \
    --logging-sample-rate=1.0
</code></pre>
<hr />
<h2>âœ… Verification Checklist</h2>
<h3>Functionality Tests</h3>
<ul>
<li>[ ] Visit <code>https://yourdomain.com</code> â†’ Shows your website</li>
<li>[ ] Visit <code>https://www.yourdomain.com</code> â†’ Shows your website</li>
<li>[ ] Visit non-existent page â†’ Shows 404.html</li>
<li>[ ] Check SSL certificate â†’ Green lock icon in browser</li>
<li>[ ] Test from different geographic regions â†’ Fast load times</li>
</ul>
<h3>Security Tests</h3>
<pre><code class="language-bash"># Check SSL grade
curl -I https://${DOMAIN}

# Verify HTTPS redirect
curl -I http://${DOMAIN}  # Should redirect to HTTPS

# Check CSP headers (if configured)
curl -I https://${DOMAIN} | grep -i security
</code></pre>
<h3>Performance Tests</h3>
<pre><code class="language-bash"># Check CDN cache hits
gcloud logging read &quot;resource.type=http_load_balancer&quot; --limit=10 \
    --format=&quot;table(httpRequest.requestUrl, httpRequest.cacheHit)&quot;

# View CDN metrics
gcloud monitoring time-series list \
    --filter='metric.type=&quot;loadbalancing.googleapis.com/https/backend_request_count&quot;' \
    --format=json
</code></pre>
<hr />
<h2>ğŸ“ Interview Prep: How to Explain This Project</h2>
<h3>Problem Statement</h3>
<blockquote>
<p>"I needed to deploy a production-grade static website with global reach, HTTPS security, and enterprise-level reliability."</p>
</blockquote>
<h3>Why This Architecture?</h3>
<table>
<thead>
<tr>
<th>Decision</th>
<th>Rationale</th>
<th>Alternative Considered</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Storage</td>
<td>Cost-effective ($0.026/GB/month vs $7+/month for VM)</td>
<td>Compute Engine (too expensive)</td>
</tr>
<tr>
<td>Cloud CDN</td>
<td>Reduces latency globally (150+ edge locations)</td>
<td>No CDN (slower for global users)</td>
</tr>
<tr>
<td>Managed SSL</td>
<td>Auto-renewal, no certificate management</td>
<td>Self-signed cert (browser warnings)</td>
</tr>
<tr>
<td>Load Balancer</td>
<td>Required for HTTPS + CDN integration</td>
<td>Direct bucket access (no HTTPS)</td>
</tr>
</tbody>
</table>
<h3>Trade-offs Made</h3>
<ul>
<li><strong>Higher initial complexity</strong> vs simple bucket hosting â†’ Worth it for production</li>
<li><strong>Cost of Load Balancer</strong> ($18/month) â†’ Required for HTTPS</li>
<li><strong>DNS propagation delay</strong> (15-60 min) â†’ One-time setup cost</li>
</ul>
<h3>What I'd Improve Next</h3>
<ol>
<li><strong>Add Cloud Armor WAF rules</strong> for common attack patterns</li>
<li><strong>Implement Cache-Control headers</strong> for better CDN efficiency</li>
<li><strong>Add custom logging</strong> to BigQuery for analytics</li>
<li><strong>Set up multi-region failover</strong> with Traffic Director</li>
</ol>
<hr />
<h2>ğŸ’° Cost Breakdown</h2>
<table>
<thead>
<tr>
<th>Resource</th>
<th>Monthly Cost (est.)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Storage (10 GB)</td>
<td>$0.26</td>
</tr>
<tr>
<td>Load Balancer</td>
<td>$18.00</td>
</tr>
<tr>
<td>Cloud CDN (100 GB egress)</td>
<td>$8.00</td>
</tr>
<tr>
<td>Cloud DNS (1 zone)</td>
<td>$0.20</td>
</tr>
<tr>
<td>Managed SSL cert</td>
<td><strong>FREE</strong></td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>~$27/month</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p>ğŸ’¡ <strong>Cost Optimization Tip:</strong> Use Cloud Storage lifecycle rules to delete old versions and reduce storage costs.</p>
</blockquote>
<hr />
<h2>ğŸ§¹ Cleanup (When Done)</h2>
<pre><code class="language-bash"># Delete forwarding rule
gcloud compute forwarding-rules delete website-https-rule --global --quiet

# Delete proxy
gcloud compute target-https-proxies delete website-https-proxy --quiet

# Delete URL map
gcloud compute url-maps delete website-url-map --quiet

# Delete SSL certificate
gcloud compute ssl-certificates delete website-ssl-cert --global --quiet

# Delete backend bucket
gcloud compute backend-buckets delete website-backend --quiet

# Delete storage bucket
gcloud storage rm -r gs://${BUCKET_NAME}

# Release IP
gcloud compute addresses delete website-ip --global --quiet

# Delete DNS zone (first delete all records)
gcloud dns managed-zones delete mywebsite-zone --quiet
</code></pre>
<hr />
<h2>ğŸ“š Portfolio Submission</h2>
<h3>README.md Template</h3>
<pre><code class="language-markdown"># Production Static Website on GCP

## Architecture
- Cloud Storage for hosting
- Cloud CDN for global distribution
- HTTPS Load Balancer with managed SSL
- Cloud DNS for domain routing
- Cloud Monitoring for uptime

## Live Demo
https://yourdomain.com

## What I Learned
- Configuring GCP networking stack
- SSL certificate management
- CDN cache optimization
- Production security best practices
</code></pre>
<hr />
<h2>ğŸ¯ Resume Bullet Example</h2>
<blockquote>
<p>"Architected and deployed a production-grade static website on GCP using Cloud Storage, Cloud CDN, and HTTPS Load Balancer, achieving &lt;100ms global latency and 99.9% uptime with managed SSL certificates."</p>
</blockquote>
</article>
<article id="capstone_2_serverless_api">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 7 min read</div>
<h1>Capstone Project 2: Production Serverless API</h1>
<p><strong>Duration:</strong> â±ï¸ 3-4 hours<br />
<strong>Level:</strong> Advanced<br />
<strong>Skills:</strong> Cloud Run, Cloud SQL, Secret Manager, Cloud Build, IAM, Logging</p>
<hr />
<h2>ğŸ¯ Project Objective</h2>
<p>Build a <strong>production-ready RESTful API</strong> using serverless architecture with database persistence, secure secrets management, CI/CD pipeline, and comprehensive monitoring.</p>
<h3>What You'll Learn</h3>
<ul>
<li>âœ… Deploy containerized APIs with Cloud Run</li>
<li>âœ… Connect to Cloud SQL with private IP</li>
<li>âœ… Manage secrets securely with Secret Manager</li>
<li>âœ… Implement JWT authentication</li>
<li>âœ… Set up CI/CD with Cloud Build</li>
<li>âœ… Configure structured logging and error reporting</li>
<li>âœ… Implement production security best practices</li>
</ul>
<hr />
<h2>ğŸ—ï¸ Architecture</h2>
<pre><code class="language-mermaid">graph TB
    Client[ğŸ‘¤ API Clients] --&gt; Run[Cloud Run&lt;br/&gt;REST API]
    Run --&gt; SM[Secret Manager&lt;br/&gt;DB Credentials]
    Run --&gt; SQL[(Cloud SQL&lt;br/&gt;PostgreSQL)]
    Run --&gt; Logs[Cloud Logging]
    Run --&gt; Errors[Error Reporting]

    GitHub[GitHub Repo] --&gt; Build[Cloud Build&lt;br/&gt;CI/CD]
    Build --&gt; AR[Artifact Registry]
    AR --&gt; Run

    style Run fill:#4285f4
    style SQL fill:#34a853
    style SM fill:#fbbc04
</code></pre>
<hr />
<h2>ğŸ“‹ Prerequisites</h2>
<ul>
<li>[ ] Completed: Cloud Run, Cloud SQL modules</li>
<li>[ ] Basic Python/Node.js knowledge</li>
<li>[ ] GitHub account</li>
<li>[ ] Docker basics (helpful but not required)</li>
</ul>
<hr />
<h2>ğŸš€ Implementation Guide</h2>
<h3>Phase 1: Database Setup (30 min)</h3>
<h4>Step 1: Create Cloud SQL Instance</h4>
<pre><code class="language-bash"># Set variables
PROJECT_ID=$(gcloud config get-value project)
REGION=&quot;us-central1&quot;
INSTANCE_NAME=&quot;todo-api-db&quot;

# Create PostgreSQL instance
gcloud sql instances create ${INSTANCE_NAME} \
    --database-version=POSTGRES_15 \
    --tier=db-f1-micro \
    --region=${REGION} \
    --network=default \
    --no-assign-ip \
    --enable-google-private-path

# Create database
gcloud sql databases create tododb \
    --instance=${INSTANCE_NAME}

# Set root password
DB_PASSWORD=$(openssl rand -base64 32)
gcloud sql users set-password postgres \
    --instance=${INSTANCE_NAME} \
    --password=${DB_PASSWORD}

echo &quot;Database password: ${DB_PASSWORD}&quot;
</code></pre>
<h4>Step 2: Store Credentials in Secret Manager</h4>
<pre><code class="language-bash"># Enable Secret Manager API
gcloud services enable secretmanager.googleapis.com

# Create secrets
echo -n &quot;${DB_PASSWORD}&quot; | gcloud secrets create db-password --data-file=-
echo -n &quot;postgres&quot; | gcloud secrets create db-user --data-file=-
echo -n &quot;tododb&quot; | gcloud secrets create db-name --data-file=-
echo -n &quot;${INSTANCE_NAME}&quot; | gcloud secrets create db-instance --data-file=-

# Verify secrets created
gcloud secrets list
</code></pre>
<hr />
<h3>Phase 2: Build the API (60 min)</h3>
<h4>Step 3: Create API Application</h4>
<p>Create <code>app.py</code>:</p>
<pre><code class="language-python">from flask import Flask, request, jsonify
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from google.cloud import secretmanager
import logging

app = Flask(__name__)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Secret Manager client
def access_secret(secret_id):
    client = secretmanager.SecretManagerServiceClient()
    project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')
    name = f&quot;projects/{project_id}/secrets/{secret_id}/versions/latest&quot;
    response = client.access_secret_version(request={&quot;name&quot;: name})
    return response.payload.data.decode('UTF-8')

# Database connection
def get_db_conn():
    return psycopg2.connect(
        host=f&quot;/cloudsql/{access_secret('db-instance')}&quot;,
        database=access_secret('db-name'),
        user=access_secret('db-user'),
        password=access_secret('db-password')
    )

# Initialize database
def init_db():
    conn = get_db_conn()
    cur = conn.cursor()
    cur.execute('''
        CREATE TABLE IF NOT EXISTS todos (
            id SERIAL PRIMARY KEY,
            title VARCHAR(200) NOT NULL,
            completed BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    cur.close()
    conn.close()
    logger.info(&quot;Database initialized&quot;)

@app.route('/health', methods=['GET'])
def health():
    return jsonify({&quot;status&quot;: &quot;healthy&quot;}), 200

@app.route('/api/todos', methods=['GET'])
def get_todos():
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute('SELECT * FROM todos ORDER BY created_at DESC')
        todos = cur.fetchall()
        cur.close()
        conn.close()
        return jsonify(todos), 200
    except Exception as e:
        logger.error(f&quot;Error fetching todos: {e}&quot;)
        return jsonify({&quot;error&quot;: str(e)}), 500

@app.route('/api/todos', methods=['POST'])
def create_todo():
    try:
        data = request.get_json()
        if not data or 'title' not in data:
            return jsonify({&quot;error&quot;: &quot;Title required&quot;}), 400

        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute(
            'INSERT INTO todos (title) VALUES (%s) RETURNING *',
            (data['title'],)
        )
        todo = cur.fetchone()
        conn.commit()
        cur.close()
        conn.close()

        logger.info(f&quot;Created todo: {todo['id']}&quot;)
        return jsonify(todo), 201
    except Exception as e:
        logger.error(f&quot;Error creating todo: {e}&quot;)
        return jsonify({&quot;error&quot;: str(e)}), 500

@app.route('/api/todos/&lt;int:todo_id&gt;', methods=['DELETE'])
def delete_todo(todo_id):
    try:
        conn = get_db_conn()
        cur = conn.cursor()
        cur.execute('DELETE FROM todos WHERE id = %s', (todo_id,))
        conn.commit()
        cur.close()
        conn.close()

        logger.info(f&quot;Deleted todo: {todo_id}&quot;)
        return '', 204
    except Exception as e:
        logger.error(f&quot;Error deleting todo: {e}&quot;)
        return jsonify({&quot;error&quot;: str(e)}), 500

if __name__ == '__main__':
    init_db()
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)
</code></pre>
<p>Create <code>requirements.txt</code>:</p>
<pre><code>Flask==3.0.0
psycopg2-binary==2.9.9
google-cloud-secret-manager==2.16.4
gunicorn==21.2.0
</code></pre>
<p>Create <code>Dockerfile</code>:</p>
<pre><code class="language-dockerfile">FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY app.py .

# Run with gunicorn
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 app:app
</code></pre>
<hr />
<h3>Phase 3: Deploy to Cloud Run (45 min)</h3>
<h4>Step 4: Build and Push Container</h4>
<pre><code class="language-bash"># Enable APIs
gcloud services enable run.googleapis.com
gcloud services enable artifactregistry.googleapis.com

# Create Artifact Registry repository
gcloud artifacts repositories create cloud-run-apps \
    --repository-format=docker \
    --location=${REGION}

# Build and push
gcloud builds submit \
    --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-apps/todo-api:v1
</code></pre>
<h4>Step 5: Deploy to Cloud Run</h4>
<pre><code class="language-bash"># Get Cloud SQL connection name
SQL_CONN=$(gcloud sql instances describe ${INSTANCE_NAME} --format=&quot;value(connectionName)&quot;)

# Deploy with secrets and SQL connection
gcloud run deploy todo-api \
    --image ${REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-apps/todo-api:v1 \
    --platform managed \
    --region ${REGION} \
    --allow-unauthenticated \
    --set-cloudsql-instances=${SQL_CONN} \
    --set-secrets=DB_PASSWORD=db-password:latest,DB_USER=db-user:latest,DB_NAME=db-name:latest,DB_INSTANCE=db-instance:latest \
    --memory=512Mi \
    --cpu=1 \
    --max-instances=10 \
    --min-instances=0

# Get service URL
SERVICE_URL=$(gcloud run services describe todo-api --region=${REGION} --format=&quot;value(status.url)&quot;)
echo &quot;API URL: ${SERVICE_URL}&quot;
</code></pre>
<hr />
<h3>Phase 4: CI/CD Pipeline (45 min)</h3>
<h4>Step 6: Create Cloud Build Configuration</h4>
<p>Create <code>cloudbuild.yaml</code>:</p>
<pre><code class="language-yaml">steps:
  # Build the container image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/cloud-run-apps/todo-api:$COMMIT_SHA'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/cloud-run-apps/todo-api:latest'
      - '.'

  # Push to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/cloud-run-apps/todo-api'

  # Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'todo-api'
      - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/cloud-run-apps/todo-api:$COMMIT_SHA'
      - '--region=${_REGION}'
      - '--platform=managed'

substitutions:
  _REGION: us-central1

options:
  logging: CLOUD_LOGGING_ONLY
</code></pre>
<h4>Step 7: Connect GitHub Repository</h4>
<pre><code class="language-bash"># Connect repository (opens browser)
gcloud builds triggers create github \
    --name=&quot;todo-api-deploy&quot; \
    --repo-name=&quot;YOUR_REPO_NAME&quot; \
    --repo-owner=&quot;YOUR_GITHUB_USERNAME&quot; \
    --branch-pattern=&quot;^main$&quot; \
    --build-config=&quot;cloudbuild.yaml&quot;
</code></pre>
<hr />
<h3>Phase 5: Security &amp; Monitoring (30 min)</h3>
<h4>Step 8: Configure IAM Roles</h4>
<pre><code class="language-bash"># Grant Cloud Run invoke permission to specific users
gcloud run services add-iam-policy-binding todo-api \
    --region=${REGION} \
    --member=&quot;user:colleague@example.com&quot; \
    --role=&quot;roles/run.invoker&quot;

# Service account for Cloud Run
SA_EMAIL=$(gcloud iam service-accounts list --filter=&quot;displayName:Compute Engine default service account&quot; --format=&quot;value(email)&quot;)

# Grant Secret Manager access
gcloud secrets add-iam-policy-binding db-password \
    --member=&quot;serviceAccount:${SA_EMAIL}&quot; \
    --role=&quot;roles/secretmanager.secretAccessor&quot;
</code></pre>
<h4>Step 9: Enable Error Reporting</h4>
<pre><code class="language-bash"># Errors are automatically reported with structured logging
# View in console: https://console.cloud.google.com/errors
</code></pre>
<h4>Step 10: Create Monitoring Dashboard</h4>
<pre><code class="language-bash"># Create uptime check
gcloud monitoring uptime create api-health \
    --resource-type=uptime-url \
    --display-name=&quot;Todo API Health&quot; \
    --http-check-path=&quot;/health&quot; \
    --monitored-resource-host=&quot;${SERVICE_URL#https://}&quot;
</code></pre>
<hr />
<h2>âœ… Verification Checklist</h2>
<h3>API Tests</h3>
<pre><code class="language-bash"># Health check
curl ${SERVICE_URL}/health

# Create a todo
curl -X POST ${SERVICE_URL}/api/todos \
    -H &quot;Content-Type: application/json&quot; \
    -d '{&quot;title&quot;: &quot;Test Cloud Run deployment&quot;}'

# Get all todos
curl ${SERVICE_URL}/api/todos

# Delete a todo
curl -X DELETE ${SERVICE_URL}/api/todos/1
</code></pre>
<h3>Load Testing</h3>
<pre><code class="language-bash"># Install Apache Bench
# On Ubuntu/Debian: sudo apt-get install apache2-utils

# Send 1000 requests with 10 concurrent connections
ab -n 1000 -c 10 ${SERVICE_URL}/api/todos
</code></pre>
<p>Expected results:
- âœ… 99%+ success rate
- âœ… Average response time &lt;200ms
- âœ… Auto-scaling handles load</p>
<hr />
<h2>ğŸ“ Interview Prep</h2>
<h3>Architecture Decisions</h3>
<table>
<thead>
<tr>
<th>Decision</th>
<th>Why</th>
<th>Trade-off</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Run over GKE</td>
<td>No cluster management, pay-per-use</td>
<td>Less control over infrastructure</td>
</tr>
<tr>
<td>Cloud SQL private IP</td>
<td>Enhanced security, no public exposure</td>
<td>Requires connector for Cloud Run</td>
</tr>
<tr>
<td>Secret Manager</td>
<td>Automatic rotation, audit logging</td>
<td>Small API call latency</td>
</tr>
<tr>
<td>Gunicorn</td>
<td>Production-grade WSGI server</td>
<td>More complex than Flask dev server</td>
</tr>
</tbody>
</table>
<h3>What I'd Improve</h3>
<ol>
<li><strong>Add authentication</strong> with Firebase Auth or Cloud Identity Platform</li>
<li><strong>Implement caching</strong> with Memorystore (Redis)</li>
<li><strong>Add rate limiting</strong> with Cloud Armor</li>
<li><strong>Database connection pooling</strong> for better performance</li>
<li><strong>Blue/green deployments</strong> with traffic splitting</li>
</ol>
<hr />
<h2>ğŸ’° Monthly Cost Estimate</h2>
<table>
<thead>
<tr>
<th>Resource</th>
<th>Usage</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Run</td>
<td>1M requests, 100 GB-sec</td>
<td>~$2.00</td>
</tr>
<tr>
<td>Cloud SQL (f1-micro)</td>
<td>Always on</td>
<td>~$8.75</td>
</tr>
<tr>
<td>Secret Manager</td>
<td>5 secrets, 10K accesses</td>
<td>~$0.30</td>
</tr>
<tr>
<td>Cloud Build</td>
<td>120 min/month</td>
<td>FREE (first 120 min)</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td></td>
<td><strong>~$11/month</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§¹ Cleanup</h2>
<pre><code class="language-bash">gcloud run services delete todo-api --region=${REGION} --quiet
gcloud sql instances delete ${INSTANCE_NAME} --quiet
gcloud secrets delete db-password --quiet
gcloud secrets delete db-user --quiet
gcloud secrets delete db-name --quiet
gcloud secrets delete db-instance --quiet
gcloud artifacts repositories delete cloud-run-apps --location=${REGION} --quiet
</code></pre>
<hr />
<h2>ğŸ¯ Resume Bullet</h2>
<blockquote>
<p>"Designed and deployed a serverless REST API on Cloud Run with Cloud SQL PostgreSQL backend, implementing secret management, CI/CD pipeline with Cloud Build, and achieving 99.9% uptime with auto-scaling to handle 10K+ requests/day."</p>
</blockquote>
</article>
<article id="capstone_3_enterprise_network">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 9 min read</div>
<h1>Capstone Project 3: Enterprise Network Setup</h1>
<p><strong>Duration:</strong> â±ï¸ 3-4 hours<br />
<strong>Level:</strong> Advanced<br />
<strong>Skills:</strong> VPC, IAM, Firewall Rules, Cloud NAT, Private Google Access, Logging</p>
<hr />
<h2>ğŸ¯ Project Objective</h2>
<p>Design and implement an <strong>enterprise-grade VPC network</strong> with multi-tier architecture, security best practices, and comprehensive monitoringâ€”exactly how Fortune 500 companies structure their cloud environments.</p>
<h3>What You'll Learn</h3>
<ul>
<li>âœ… Design custom VPC with multiple subnets</li>
<li>âœ… Implement least-privilege IAM policies</li>
<li>âœ… Configure firewall rules with service accounts</li>
<li>âœ… Set up Cloud NAT for private subnet access</li>
<li>âœ… Enable Private Google Access</li>
<li>âœ… Implement VPC Flow Logs and monitoring</li>
<li>âœ… Apply enterprise security controls</li>
</ul>
<hr />
<h2>ğŸ—ï¸ Architecture</h2>
<pre><code class="language-mermaid">graph TB
    Internet[ğŸŒ Internet] --&gt; LB[Load Balancer&lt;br/&gt;Public Subnet]
    LB --&gt; Web[Web Tier&lt;br/&gt;Public Subnet&lt;br/&gt;10.0.1.0/24]
    Web --&gt; App[App Tier&lt;br/&gt;Private Subnet&lt;br/&gt;10.0.2.0/24]
    App --&gt; DB[DB Tier&lt;br/&gt;Private Subnet&lt;br/&gt;10.0.3.0/24]

    App --&gt; NAT[Cloud NAT]
    NAT --&gt; Internet
    App --&gt; PGA[Private Google Access]
    PGA --&gt; GCS[(Cloud Storage)]

    FW1[Firewall:&lt;br/&gt;Allow HTTP/HTTPS] --&gt; Web
    FW2[Firewall:&lt;br/&gt;App Only] --&gt; App
    FW3[Firewall:&lt;br/&gt;DB Only] --&gt; DB

    Logs[VPC Flow Logs] -.-&gt; Web
    Logs -.-&gt; App
    Logs -.-&gt; DB

    style Web fill:#4285f4
    style App fill:#fbbc04
    style DB fill:#ea4335
</code></pre>
<hr />
<h2>ğŸ“‹ Prerequisites</h2>
<ul>
<li>[ ] Completed: VPC Networking, IAM, Load Balancing modules</li>
<li>[ ] Understanding of network security concepts</li>
<li>[ ] Familiarity with firewall rules</li>
</ul>
<hr />
<h2>ğŸš€ Implementation Guide</h2>
<h3>Phase 1: VPC &amp; Subnet Design (30 min)</h3>
<h4>Step 1: Create Custom VPC</h4>
<pre><code class="language-bash"># Set variables
PROJECT_ID=$(gcloud config get-value project)
REGION=&quot;us-central1&quot;

# Create custom VPC (auto mode is NOT recommended for production)
gcloud compute networks create enterprise-vpc \
    --subnet-mode=custom \
    --bgp-routing-mode=regional

# Verify creation
gcloud compute networks describe enterprise-vpc
</code></pre>
<h4>Step 2: Create Multi-Tier Subnets</h4>
<pre><code class="language-bash"># Web tier subnet (public)
gcloud compute networks subnets create web-subnet \
    --network=enterprise-vpc \
    --region=${REGION} \
    --range=10.0.1.0/24 \
    --enable-flow-logs \
    --logging-aggregation-interval=interval-5-sec

# App tier subnet (private)
gcloud compute networks subnets create app-subnet \
    --network=enterprise-vpc \
    --region=${REGION} \
    --range=10.0.2.0/24 \
    --enable-private-ip-google-access \
    --enable-flow-logs \
    --logging-aggregation-interval=interval-5-sec

# DB tier subnet (private)
gcloud compute networks subnets create db-subnet \
    --network=enterprise-vpc \
    --region=${REGION} \
    --range=10.0.3.0/24 \
    --enable-private-ip-google-access \
    --enable-flow-logs \
    --logging-aggregation-interval=interval-5-sec

# Management subnet (for bastion/admin access)
gcloud compute networks subnets create mgmt-subnet \
    --network=enterprise-vpc \
    --region=${REGION} \
    --range=10.0.10.0/24 \
    --enable-flow-logs
</code></pre>
<hr />
<h3>Phase 2: Firewall Rules (45 min)</h3>
<h4>Step 3: Create Service Accounts (for secure firewall targeting)</h4>
<pre><code class="language-bash"># Web tier service account
gcloud iam service-accounts create web-tier-sa \
    --display-name=&quot;Web Tier Service Account&quot;

# App tier service account
gcloud iam service-accounts create app-tier-sa \
    --display-name=&quot;App Tier Service Account&quot;

# DB tier service account
gcloud iam service-accounts create db-tier-sa \
    --display-name=&quot;DB Tier Service Account&quot;
</code></pre>
<h4>Step 4: Implement Firewall Rules</h4>
<pre><code class="language-bash"># DENY all ingress by default (implicit, but good to document)
# NOTE: GCP has implicit deny-all at lowest priority

# Allow HTTP/HTTPS to web tier from internet
gcloud compute firewall-rules create allow-web-ingress \
    --network=enterprise-vpc \
    --action=ALLOW \
    --direction=INGRESS \
    --source-ranges=0.0.0.0/0 \
    --target-service-accounts=web-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --rules=tcp:80,tcp:443 \
    --priority=1000

# Allow web tier to app tier ONLY
gcloud compute firewall-rules create allow-web-to-app \
    --network=enterprise-vpc \
    --action=ALLOW \
    --direction=INGRESS \
    --source-service-accounts=web-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --target-service-accounts=app-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --rules=tcp:8080 \
    --priority=1000

# Allow app tier to DB tier ONLY
gcloud compute firewall-rules create allow-app-to-db \
    --network=enterprise-vpc \
    --action=ALLOW \
    --direction=INGRESS \
    --source-service-accounts=app-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --target-service-accounts=db-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --rules=tcp:5432 \
    --priority=1000

# Allow SSH from IAP (Google's identity-aware proxy)
gcloud compute firewall-rules create allow-iap-ssh \
    --network=enterprise-vpc \
    --action=ALLOW \
    --direction=INGRESS \
    --source-ranges=35.235.240.0/20 \
    --rules=tcp:22 \
    --priority=1000

# Allow internal health checks
gcloud compute firewall-rules create allow-health-checks \
    --network=enterprise-vpc \
    --action=ALLOW \
    --direction=INGRESS \
    --source-ranges=35.191.0.0/16,130.211.0.0/22 \
    --rules=tcp:80,tcp:443,tcp:8080 \
    --priority=1000
</code></pre>
<hr />
<h3>Phase 3: Cloud NAT Setup (30 min)</h3>
<h4>Step 5: Create Cloud Router</h4>
<pre><code class="language-bash"># Create router for Cloud NAT
gcloud compute routers create enterprise-router \
    --network=enterprise-vpc \
    --region=${REGION}
</code></pre>
<h4>Step 6: Configure Cloud NAT</h4>
<pre><code class="language-bash"># Create Cloud NAT (for private subnets to access internet)
gcloud compute routers nats create enterprise-nat \
    --router=enterprise-router \
    --region=${REGION} \
    --nat-custom-subnet-ip-ranges=app-subnet,db-subnet \
    --auto-allocate-nat-external-ips \
    --enable-logging

# Verify NAT configuration
gcloud compute routers nats describe enterprise-nat \
    --router=enterprise-router \
    --region=${REGION}
</code></pre>
<hr />
<h3>Phase 4: Deploy Test VMs (45 min)</h3>
<h4>Step 7: Create VMs in Each Tier</h4>
<pre><code class="language-bash"># Web tier VM (public IP)
gcloud compute instances create web-vm-1 \
    --zone=${REGION}-a \
    --machine-type=e2-micro \
    --subnet=web-subnet \
    --service-account=web-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --scopes=cloud-platform \
    --tags=web-tier \
    --metadata=startup-script='#!/bin/bash
apt-get update
apt-get install -y nginx
echo &quot;&lt;h1&gt;Web Tier - Enterprise VPC&lt;/h1&gt;&quot; &gt; /var/www/html/index.html'

# App tier VM (private IP only)
gcloud compute instances create app-vm-1 \
    --zone=${REGION}-a \
    --machine-type=e2-micro \
    --subnet=app-subnet \
    --no-address \
    --service-account=app-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --scopes=cloud-platform \
    --tags=app-tier

# DB tier VM (private IP only)
gcloud compute instances create db-vm-1 \
    --zone=${REGION}-a \
    --machine-type=e2-micro \
    --subnet=db-subnet \
    --no-address \
    --service-account=db-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --scopes=cloud-platform \
    --tags=db-tier
</code></pre>
<hr />
<h3>Phase 5: IAM Configuration (30 min)</h3>
<h4>Step 8: Implement Least-Privilege IAM</h4>
<pre><code class="language-bash"># Web tier: Read-only access to Cloud Storage
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member=serviceAccount:web-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --role=roles/storage.objectViewer

# App tier: Read/Write to specific Cloud Storage bucket
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member=serviceAccount:app-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --role=roles/storage.objectAdmin \
    --condition='resource.name.startsWith(&quot;projects/_/buckets/app-data-&quot;)'

# DB tier: Cloud SQL Client
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member=serviceAccount:db-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --role=roles/cloudsql.client

# Grant engineers IAP tunnel access (for SSH)
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member=user:engineer@example.com \
    --role=roles/iap.tunnelResourceAccessor
</code></pre>
<hr />
<h3>Phase 6: Monitoring &amp; Logging (30 min)</h3>
<h4>Step 9: Create Log Sink for Security Analysis</h4>
<pre><code class="language-bash"># Create BigQuery dataset for logs
bq mk --dataset ${PROJECT_ID}:network_logs

# Create log sink
gcloud logging sinks create vpc-flow-logs-sink \
    bigquery.googleapis.com/projects/${PROJECT_ID}/datasets/network_logs \
    --log-filter='resource.type=&quot;gce_subnetwork&quot; AND logName=&quot;projects/'${PROJECT_ID}'/logs/compute.googleapis.com%2Fvpc_flows&quot;'
</code></pre>
<h4>Step 10: Create Monitoring Dashboard</h4>
<pre><code class="language-bash"># Create sample uptime check for web tier
gcloud monitoring uptime create web-tier-uptime \
    --resource-type=gce-instance \
    --display-name=&quot;Web Tier Health&quot;
</code></pre>
<hr />
<h2>âœ… Verification Checklist</h2>
<h3>Connectivity Tests</h3>
<pre><code class="language-bash"># Test 1: Web VM can reach internet
gcloud compute ssh web-vm-1 --zone=${REGION}-a --tunnel-through-iap -- \
    curl -I https://www.google.com

# Test 2: App VM can reach internet via Cloud NAT
gcloud compute ssh app-vm-1 --zone=${REGION}-a --tunnel-through-iap -- \
    curl -I https://www.google.com

# Test 3: App VM can access Cloud Storage via Private Google Access
gcloud compute ssh app-vm-1 --zone=${REGION}-a --tunnel-through-iap -- \
    gsutil ls gs://

# Test 4: Verify firewall blocks direct external access to app tier
# This should FAIL (timeout):
curl http://[APP_VM_INTERNAL_IP]:8080  # Should not work

# Test 5: Check VPC Flow Logs
gcloud logging read &quot;resource.type=gce_subnetwork&quot; --limit=5
</code></pre>
<h3>Security Audit</h3>
<pre><code class="language-bash"># List all firewall rules
gcloud compute firewall-rules list --filter=&quot;network:enterprise-vpc&quot;

# Check for overly permissive rules (look for 0.0.0.0/0 source ranges)
gcloud compute firewall-rules list --format=&quot;table(name,sourceRanges,allowed)&quot;

# Verify no VMs have default service account
gcloud compute instances list --format=&quot;table(name,serviceAccounts.email)&quot;
</code></pre>
<hr />
<h2>ğŸ“ Interview Prep</h2>
<h3>Architecture Decisions</h3>
<table>
<thead>
<tr>
<th>Decision</th>
<th>Why</th>
<th>Alternative Considered</th>
</tr>
</thead>
<tbody>
<tr>
<td>Custom VPC</td>
<td>Full control over IP ranges</td>
<td>Auto-mode (not production-ready)</td>
</tr>
<tr>
<td>Service Account-based firewall</td>
<td>More secure than tag-based</td>
<td>Network tags (easier to misconfigure)</td>
</tr>
<tr>
<td>Cloud NAT</td>
<td>Private VMs need internet access</td>
<td>Public IPs (security risk)</td>
</tr>
<tr>
<td>Private Google Access</td>
<td>Access GCS without internet</td>
<td>VPN to on-prem (slower)</td>
</tr>
<tr>
<td>VPC Flow Logs</td>
<td>Required for security compliance</td>
<td>No logging (blind spot)</td>
</tr>
</tbody>
</table>
<h3>Common Interview Questions</h3>
<p><strong>Q: "Why not use the default VPC?"</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "Default VPC uses auto-mode subnets which auto-create subnets in every region, wasting IP space. Custom VPC lets me design IP ranges that don't overlap with on-prem networks and create subnets only where needed."</p>
</blockquote>
<p><strong>Q: "How do you troubleshoot a VM that can't reach the internet?"</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong>
1. Check if VM has external IP (<code>gcloud compute instances describe</code>)
2. If no external IP, verify Cloud NAT exists in subnet's region
3. Check firewall allows egress (implicit allow, but verify no deny rules)
4. Check routes (<code>gcloud compute routes list</code>)
5. Test with <code>curl -v</code> to see exact failure point</p>
</blockquote>
<p><strong>Q: "What's the difference between network tags and service accounts for firewall rules?"</strong></p>
<blockquote>
<p><strong>Strong Answer:</strong> "Network tags are easier but less secureâ€”any VM can add a tag. Service accounts are IAM-controlled, so only authorized users can assign them. In production, I use service accounts for least-privilege."</p>
</blockquote>
<hr />
<h2>ğŸ’¡ Production Best Practices</h2>
<h3>Security Hardening</h3>
<ul>
<li>[ ] <strong>No default service account:</strong> Always create custom SAs</li>
<li>[ ] <strong>Deny all by default:</strong> Only allow specific required traffic</li>
<li>[ ] <strong>No 0.0.0.0/0 source:</strong> Except load balancer health checks</li>
<li>[ ] <strong>Enable VPC Flow Logs:</strong> Required for compliance and incident response</li>
<li>[ ] <strong>Use IAP for SSH:</strong> Never expose port 22 to internet</li>
</ul>
<h3>Cost Optimization</h3>
<ul>
<li>[ ] <strong>Right-size subnets:</strong> Don't create /16 when /24 is enough</li>
<li>[ ] <strong>Minimize Cloud NAT:</strong> Only apply to private subnets that need it</li>
<li>[ ] <strong>Flow log sampling:</strong> Use 50% sampling in prod (vs 100% in dev)</li>
</ul>
<h3>Disaster Recovery</h3>
<ul>
<li>[ ] <strong>Multi-region:</strong> For critical apps, deploy to 2+ regions</li>
<li>[ ] <strong>Backup firewall config:</strong> Export rules to Terraform</li>
<li>[ ] <strong>Test failover:</strong> Regularly test Cloud NAT and routing</li>
</ul>
<hr />
<h2>ğŸ’° Monthly Cost Estimate</h2>
<table>
<thead>
<tr>
<th>Resource</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>VPC (custom)</td>
<td><strong>FREE</strong></td>
</tr>
<tr>
<td>3 VMs (e2-micro)</td>
<td>~$12</td>
</tr>
<tr>
<td>Cloud NAT</td>
<td>~$45 (1 gateway)</td>
</tr>
<tr>
<td>VPC Flow Logs (100 GB/month)</td>
<td>~$5</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>~$62/month</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ§¹ Cleanup</h2>
<pre><code class="language-bash"># Delete VMs
gcloud compute instances delete web-vm-1 app-vm-1 db-vm-1 \
    --zone=${REGION}-a --quiet

# Delete Cloud NAT
gcloud compute routers nats delete enterprise-nat \
    --router=enterprise-router --region=${REGION} --quiet

# Delete router
gcloud compute routers delete enterprise-router \
    --region=${REGION} --quiet

# Delete firewall rules
for rule in $(gcloud compute firewall-rules list --filter=&quot;network:enterprise-vpc&quot; --format=&quot;value(name)&quot;); do
    gcloud compute firewall-rules delete $rule --quiet
done

# Delete subnets
gcloud compute networks subnets delete web-subnet app-subnet db-subnet mgmt-subnet \
    --region=${REGION} --quiet

# Delete VPC
gcloud compute networks delete enterprise-vpc --quiet

# Delete service accounts
gcloud iam service-accounts delete web-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com --quiet
gcloud iam service-accounts delete app-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com --quiet
gcloud iam service-accounts delete db-tier-sa@${PROJECT_ID}.iam.gserviceaccount.com --quiet
</code></pre>
<hr />
<h2>ğŸ¯ Resume Bullet</h2>
<blockquote>
<p>"Architected enterprise-grade VPC network on GCP with multi-tier subnet design, least-privilege IAM policies, service account-based firewall rules, and comprehensive VPC Flow Logs for security compliance, serving 10K+ daily users with 99.95% uptime."</p>
</blockquote>
<hr />
<h2>ğŸš€ Next Steps</h2>
<p>After completing this project, you can:
1. <strong>Add VPC Peering</strong> to another project
2. <strong>Configure Cloud VPN</strong> to on-prem network
3. <strong>Implement Private Service Connect</strong> for managed services
4. <strong>Create custom routes</strong> for advanced traffic steering
5. <strong>Setup Traffic Director</strong> for service mesh</p>
</article>
<article id="decision_tables">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>GCP Service Decision Tables</h1>
<blockquote>
<p><strong>Quick reference guide</strong> for choosing the right GCP service for your workload.</p>
</blockquote>
<hr />
<h2>ğŸ–¥ï¸ Compute: When to Use What</h2>
<table>
<thead>
<tr>
<th>If you need...</th>
<th>Use</th>
<th>Why</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Full control over OS</strong></td>
<td>Compute Engine</td>
<td>SSH access, custom kernels, GPUs</td>
<td>Legacy apps, HPC, gaming servers</td>
</tr>
<tr>
<td><strong>Stateless web apps</strong></td>
<td>Cloud Run</td>
<td>Zero config, pay-per-request, fastest deploy</td>
<td>APIs, microservices, webhooks</td>
</tr>
<tr>
<td><strong>Kubernetes workloads</strong></td>
<td>GKE Autopilot</td>
<td>Managed nodes, lower cost than Standard</td>
<td>Microservices, batch jobs</td>
</tr>
<tr>
<td><strong>Complex K8s (privileged pods)</strong></td>
<td>GKE Standard</td>
<td>Full cluster control</td>
<td>Multi-tenant, custom networking</td>
</tr>
<tr>
<td><strong>Simple web/mobile app</strong></td>
<td>App Engine Standard</td>
<td>Instant auto-scale, zero infra management</td>
<td>Startups, prototypes</td>
</tr>
<tr>
<td><strong>Containerized long-running</strong></td>
<td>App Engine Flexible</td>
<td>Docker support, SSH access</td>
<td>Background workers</td>
</tr>
<tr>
<td><strong>Event-driven functions</strong></td>
<td>Cloud Functions</td>
<td>Sub-second cold start, event triggers</td>
<td>Image resize, Pub/Sub processing</td>
</tr>
<tr>
<td><strong>High-traffic web tier</strong></td>
<td>MIG + Load Balancer</td>
<td>Auto-healing, multi-zone HA</td>
<td>Production websites</td>
</tr>
</tbody>
</table>
<h3>âš ï¸ Common Mistakes</h3>
<ul>
<li>âŒ Using GKE for a single stateless app â†’ Use Cloud Run</li>
<li>âŒ Using Compute Engine VMs as "pets" â†’ Use instance templates + MIGs</li>
<li>âŒ Cloud Functions for long-running jobs â†’ Max 60 min timeout</li>
</ul>
<hr />
<h2>ğŸ’¾ Storage: When to Use What</h2>
<table>
<thead>
<tr>
<th>Data Type</th>
<th>Service</th>
<th>Why</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Object storage (images, videos)</strong></td>
<td>Cloud Storage</td>
<td>11 9's durability, global CDN integration</td>
<td>$0.020/GB</td>
</tr>
<tr>
<td><strong>VM boot/data disk</strong></td>
<td>Persistent Disk (SSD)</td>
<td>Low-latency block storage</td>
<td>$0.17/GB</td>
</tr>
<tr>
<td><strong>NFS file shares</strong></td>
<td>Filestore</td>
<td>POSIX, existing apps need filesystem</td>
<td>$0.20/GB</td>
</tr>
<tr>
<td><strong>Mission-critical file shares</strong></td>
<td>Filestore Enterprise</td>
<td>99.99% SLA, regional HA</td>
<td>$0.30/GB</td>
</tr>
<tr>
<td><strong>Archive (rarely accessed)</strong></td>
<td>Cloud Storage Archive</td>
<td>Cheapest, retrieval fee</td>
<td>$0.0012/GB</td>
</tr>
</tbody>
</table>
<h3>Decision Tree</h3>
<pre><code class="language-mermaid">graph TD
    Start[What type of data?] --&gt; Object{Object&lt;br/&gt;files?}
    Object --&gt;|Yes| Freq{Access&lt;br/&gt;frequency?}
    Freq --&gt;|Daily| GCS[Cloud Storage&lt;br/&gt;Standard]
    Freq --&gt;|Weekly| Near[Cloud Storage&lt;br/&gt;Nearline]
    Freq --&gt;|Yearly| Cold[Cloud Storage&lt;br/&gt;Archive]

    Object --&gt;|No| Block{Block&lt;br/&gt;storage?}
    Block --&gt;|Yes| VM{For VM?}
    VM --&gt;|Yes| PD[Persistent&lt;br/&gt;Disk]
    VM --&gt;|No| Local[Local SSD]

    Block --&gt;|No| File[Filestore&lt;br/&gt;NFS]
</code></pre>
<hr />
<h2>ğŸ—„ï¸ Database: When to Use What</h2>
<table>
<thead>
<tr>
<th>Workload Type</th>
<th>Service</th>
<th>Why</th>
<th>Scale Limit</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Relational (OLTP)</strong></td>
<td>Cloud SQL</td>
<td>Managed MySQL/Postgres/SQL Server</td>
<td>~64 TB</td>
</tr>
<tr>
<td><strong>Global transactions</strong></td>
<td>Cloud Spanner</td>
<td>99.999% SLA, horizontal scale</td>
<td>Petabytes</td>
</tr>
<tr>
<td><strong>NoSQL documents</strong></td>
<td>Firestore</td>
<td>Real-time sync, mobile SDKs</td>
<td>Millions docs/sec</td>
</tr>
<tr>
<td><strong>Analytics (OLAP)</strong></td>
<td>BigQuery</td>
<td>Serverless data warehouse</td>
<td>Exabytes</td>
</tr>
<tr>
<td><strong>Key-value (high throughput)</strong></td>
<td>Firestore / Memorystore</td>
<td>Low latency &lt;1ms</td>
<td>Petabytes</td>
</tr>
<tr>
<td><strong>Time-series / IoT</strong></td>
<td>Bigtable</td>
<td>Millions ops/sec, HBase-compatible</td>
<td>Petabytes</td>
</tr>
<tr>
<td><strong>In-memory cache</strong></td>
<td>Memorystore (Redis)</td>
<td>&lt;1ms read, pub/sub</td>
<td>300 GB</td>
</tr>
</tbody>
</table>
<h3>âš ï¸ Common Mistakes</h3>
<ul>
<li>âŒ BigQuery for OLTP â†’ it's for analytics, not transactions</li>
<li>âŒ Cloud SQL for &gt;10 TB â†’ migrate to Spanner</li>
<li>âŒ Firestore for analytics â†’ export to BigQuery</li>
</ul>
<hr />
<h2>ğŸŒ Networking: When to Use What</h2>
<table>
<thead>
<tr>
<th>Need</th>
<th>Service</th>
<th>Why</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hybrid cloud (secure)</strong></td>
<td>Cloud VPN</td>
<td>Encrypted tunnel, easy setup</td>
<td>Dev/test environments</td>
</tr>
<tr>
<td><strong>Hybrid cloud (high bandwidth)</strong></td>
<td>Dedicated Interconnect</td>
<td>10-100 Gbps, low latency</td>
<td>Production data sync</td>
</tr>
<tr>
<td><strong>Hybrid cloud (partner)</strong></td>
<td>Partner Interconnect</td>
<td>Partner-managed connection</td>
<td>No local datacenter</td>
</tr>
<tr>
<td><strong>Private VMs need internet</strong></td>
<td>Cloud NAT</td>
<td>No public IPs required</td>
<td>Security compliance</td>
</tr>
<tr>
<td><strong>Access Google APIs privately</strong></td>
<td>Private Google Access</td>
<td>No internet egress costs</td>
<td>Production VPCs</td>
</tr>
<tr>
<td><strong>Connect 2 VPCs</strong></td>
<td>VPC Peering</td>
<td>Low latency, no egress charges</td>
<td>Shared services</td>
</tr>
<tr>
<td><strong>DNS for apps</strong></td>
<td>Cloud DNS</td>
<td>100% SLA, global anycast</td>
<td>Production domains</td>
</tr>
<tr>
<td><strong>Global content delivery</strong></td>
<td>Cloud CDN</td>
<td>150+ edge locations</td>
<td>Static assets, videos</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” Security: When to Use What</h2>
<table>
<thead>
<tr>
<th>Security Need</th>
<th>Service</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Encrypt data at rest</strong></td>
<td>CMEK (KMS)</td>
<td>You control key rotation</td>
</tr>
<tr>
<td><strong>Bring your own keys</strong></td>
<td>Cloud HSM</td>
<td>FIPS 140-2 Level 3</td>
</tr>
<tr>
<td><strong>Secret storage</strong></td>
<td>Secret Manager</td>
<td>Auto-rotation, audit logs</td>
</tr>
<tr>
<td><strong>DDoS protection</strong></td>
<td>Cloud Armor</td>
<td>WAF, rate limiting</td>
</tr>
<tr>
<td><strong>OAuth/SSO</strong></td>
<td>Cloud Identity</td>
<td>Centralized user management</td>
</tr>
<tr>
<td><strong>Service-to-service auth</strong></td>
<td>Workload Identity</td>
<td>No JSON keys needed</td>
</tr>
<tr>
<td><strong>SSH access without public IP</strong></td>
<td>IAP</td>
<td>Zero trust tunneling</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“Š Data &amp; Analytics: When to Use What</h2>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Service</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Async messaging</strong></td>
<td>Pub/Sub</td>
<td>Decouples services, at-least-once delivery</td>
</tr>
<tr>
<td><strong>Task queues</strong></td>
<td>Cloud Tasks</td>
<td>Exactly-once, rate limiting</td>
</tr>
<tr>
<td><strong>Batch data processing</strong></td>
<td>Dataflow</td>
<td>Fully managed Apache Beam</td>
</tr>
<tr>
<td><strong>Hadoop/Spark jobs</strong></td>
<td>Dataproc</td>
<td>Lift-and-shift from on-prem</td>
</tr>
<tr>
<td><strong>Real-time streaming</strong></td>
<td>Dataflow</td>
<td>Sub-second latency</td>
</tr>
<tr>
<td><strong>Data warehouse</strong></td>
<td>BigQuery</td>
<td>Serverless, petabyte-scale queries</td>
</tr>
<tr>
<td><strong>ML model training</strong></td>
<td>Vertex AI</td>
<td>AutoML, custom training</td>
</tr>
</tbody>
</table>
<h3>Pub/Sub vs Cloud Tasks</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Pub/Sub</th>
<th>Cloud Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Delivery</strong></td>
<td>At-least-once (duplicates possible)</td>
<td>Exactly-once</td>
</tr>
<tr>
<td><strong>Ordering</strong></td>
<td>No guarantee</td>
<td>Guaranteed</td>
</tr>
<tr>
<td><strong>Rate limiting</strong></td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Best for</strong></td>
<td>Fan-out, lossy OK</td>
<td>Crit workflows</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸš€ DevOps: When to Use What</h2>
<table>
<thead>
<tr>
<th>Need</th>
<th>Service</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CI/CD pipelines</strong></td>
<td>Cloud Build</td>
<td>Native GCP integration, cheap</td>
</tr>
<tr>
<td><strong>Container registry</strong></td>
<td>Artifact Registry</td>
<td>Vulnerability scanning, access control</td>
</tr>
<tr>
<td><strong>Infrastructure as Code</strong></td>
<td>Terraform</td>
<td>Multi-cloud, huge community</td>
</tr>
<tr>
<td><strong>Config management</strong></td>
<td>Config Connector</td>
<td>Kubernetes-style GCP management</td>
</tr>
<tr>
<td><strong>Policy enforcement</strong></td>
<td>Organization Policies</td>
<td>Centralized governance</td>
</tr>
<tr>
<td><strong>Release management</strong></td>
<td>Cloud Deploy</td>
<td>Progressive delivery, rollbacks</td>
</tr>
</tbody>
</table>
<hr />
<h2>â±ï¸ Real-Time Decision Tool</h2>
<pre><code>Step 1: What's the primary need?
â”œâ”€ Compute â†’ Is it stateless? â†’ Yes: Cloud Run | No: GCE/GKE
â”œâ”€ Storage â†’ Is it objects? â†’ Yes: Cloud Storage | No: Persistent Disk
â”œâ”€ Database â†’ Is it analytics? â†’ Yes: BigQuery | No: Cloud SQL/Spanner
â””â”€ Networking â†’ Is it hybrid? â†’ Yes: VPN/Interconnect | No: VPC

Step 2: Check constraints
â”œâ”€ Cost-sensitive? â†’ Choose serverless/managed
â”œâ”€ Compliance (HIPAA/PCI)? â†’ Enable encryption, audit logs
â”œâ”€ Global users? â†’ Use multi-region/CDN
â””â”€ Existing tools? â†’ Check compatibility

Step 3: Validate with production checklist
(See production_checklists.md)
</code></pre>
<hr />
<h2>ğŸ¯ Interview Tips</h2>
<p>When asked "Why did you choose X over Y?":</p>
<p><strong>Strong Answer Format:</strong>
1. <strong>State requirement:</strong> "The app needed [specific need]"
2. <strong>Explain choice:</strong> "I chose [X] because [specific reason]"
3. <strong>Compare alternative:</strong> "I considered [Y], but it would require [trade-off]"
4. <strong>Mention trade-off:</strong> "The downside is [honest limitation], but we mitigated by [action]"</p>
<p><strong>Example:</strong></p>
<blockquote>
<p>"The app needed to process 10K events/second with guaranteed ordering. I chose <strong>Cloud Tasks</strong> because it provides exactly-once delivery and built-in ordering. I considered <strong>Pub/Sub</strong>, but it doesn't guarantee order and allows duplicates. The trade-off with Tasks is lower throughput (500 QPS per queue), but we solved this by creating multiple queues with consistent hashing."</p>
</blockquote>
<hr />
<h2>ğŸ“š Quick Reference Cards</h2>
<p>Print these out or keep them handy:</p>
<p><strong>Compute Decision Card:</strong></p>
<pre><code>Stateless? â†’ Cloud Run
K8s? â†’ GKE Autopilot
Legacy app? â†’ Compute Engine
Event-driven? â†’ Cloud Functions
</code></pre>
<p><strong>Storage Decision Card:</strong></p>
<pre><code>Objects? â†’ Cloud Storage
VM disks? â†’ Persistent Disk
File shares? â†’ Filestore
Archive? â†’ Cloud Storage Archive
</code></pre>
<p><strong>Database Decision Card:</strong></p>
<pre><code>&lt;10 TB relational? â†’ Cloud SQL
Global relational? â†’ Spanner
Analytics? â†’ BigQuery
NoSQL? â†’ Firestore
Time-series? â†’ Bigtable
</code></pre>
</article>
<article id="production_checklists">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>Production-Ready Checklists</h1>
<p>This document contains production deployment checklists for each major GCP service. Use these before deploying to production environments.</p>
<hr />
<h2>â˜‘ï¸ Compute Engine Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Machine Type:</strong> Right-sized for workload (not over-provisioned)</li>
<li>[ ] <strong>Disk Type:</strong> SSD for database/high-IOPS workloads</li>
<li>[ ] <strong>Preemptibility:</strong> Only for fault-tolerant batch jobs</li>
<li>[ ] <strong>Instance Template:</strong> Created for reproducibility</li>
<li>[ ] <strong>Startup Script:</strong> Tested independently</li>
<li>[ ] <strong>Service Account:</strong> Custom SA with least-privilege (not default)</li>
<li>[ ] <strong>Scopes:</strong> Specific scopes, not <code>cloud-platform</code></li>
<li>[ ] <strong>Labels:</strong> Applied for cost tracking</li>
<li>[ ] <strong>Metadata:</strong> SSH keys removed (use OS Login)</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>No Public IP:</strong> Unless absolutely required</li>
<li>[ ] <strong>Firewall Rules:</strong> Service account-based, not tag-based</li>
<li>[ ] <strong>OS Patch Management:</strong> Enabled OS Config agent</li>
<li>[ ] <strong>Shielded VM:</strong> Enabled for compliance workloads</li>
<li>[ ] <strong>Serial Console:</strong> Disabled in production</li>
</ul>
<h3>High Availability</h3>
<ul>
<li>[ ] <strong>Regional MIG:</strong> For multi-zone redundancy</li>
<li>[ ] <strong>Health Checks:</strong> Configured with proper thresholds</li>
<li>[ ] <strong>Auto-Healing:</strong> Enabled with realistic initial delay</li>
<li>[ ] <strong>Auto-Scaling:</strong> Based on actual metrics (CPU/custom)</li>
<li>[ ] <strong>Load Balancer:</strong> Configured for distribution</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>Ops Agent:</strong> Installed for enhanced metrics</li>
<li>[ ] <strong>Log Aggregation:</strong> Logs sent to Cloud Logging</li>
<li>[ ] <strong>Alerting:</strong> Set up for CPU, disk, network</li>
<li>[ ] <strong>Uptime Checks:</strong> Configured</li>
</ul>
<hr />
<h2>â˜‘ï¸ Cloud Storage Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Bucket Naming:</strong> Follows DNS naming convention</li>
<li>[ ] <strong>Location:</strong> Multi-region for HA, regional for cost</li>
<li>[ ] <strong>Storage Class:</strong> Matches access pattern</li>
<li>[ ] <strong>Uniform Access:</strong> Enabled (bucket-only IAM)</li>
<li>[ ] <strong>Public Access Prevention:</strong> Enabled unless public website</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>IAM Roles:</strong> Least-privilege (not <code>allUsers</code>)</li>
<li>[ ] <strong>Signed URLs:</strong> For temporary access</li>
<li>[ ] <strong>Encryption:</strong> CMEK for sensitive data</li>
<li>[ ] <strong>Retention Policy:</strong> Set for compliance</li>
<li>[ ] <strong>Object Versioning:</strong> Enabled for critical data</li>
</ul>
<h3>Cost Optimization</h3>
<ul>
<li>[ ] <strong>Lifecycle Rules:</strong> Transition to Nearline/Coldline/Archive</li>
<li>[ ] <strong>Autoclass:</strong> Enabled for automatic class transitions</li>
<li>[ ] <strong>Deletion Rules:</strong> Auto-delete temporary files</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>Audit Logs:</strong> Admin/Data Access enabled</li>
<li>[ ] <strong>Metrics:</strong> Monitoring bucket size &amp; request count</li>
<li>[ ] <strong>Alerting:</strong> Set up for unusually high costs</li>
</ul>
<hr />
<h2>â˜‘ï¸ Cloud Run Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Container Image:</strong> Built with distroless/alpine base</li>
<li>[ ] <strong>Min Instances:</strong> â‰¥1 for latency-critical apps</li>
<li>[ ] <strong>Max Instances:</strong> Set to prevent cost overrun</li>
<li>[ ] <strong>CPU Allocation:</strong> "Always allocated" for background tasks</li>
<li>[ ] <strong>Memory:</strong> Right-sized (512MB-2GB typical)</li>
<li>[ ] <strong>Request Timeout:</strong> Realistic for workload</li>
<li>[ ] <strong>Concurrency:</strong> Tuned (80 default, 1 for stateful)</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>IAM:</strong> Not <code>allUsers</code> unless public API</li>
<li>[ ] <strong>Service Account:</strong> Custom SA with minimal permissions</li>
<li>[ ] <strong>Secrets:</strong> Stored in Secret Manager, not env vars</li>
<li>[ ] <strong>VPC Connector:</strong> For private DB/service access</li>
<li>[ ] <strong>Ingress:</strong> Internal-only if not public-facing</li>
</ul>
<h3>Reliability</h3>
<ul>
<li>[ ] <strong>Health Checks:</strong> /health endpoint implemented</li>
<li>[ ] <strong>Graceful Shutdown:</strong> SIGTERM handled properly</li>
<li>[ ] <strong>Connection Pooling:</strong> For database connections</li>
<li>[ ] <strong>Retry Logic:</strong> Exponential backoff for external calls</li>
<li>[ ] <strong>Circuit Breaker:</strong> For failing dependencies</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>Structured Logging:</strong> JSON format</li>
<li>[ ] <strong>Error Reporting:</strong> Exceptions sent automatically</li>
<li>[ ] <strong>Trace:</strong> Enabled for latency debugging</li>
<li>[ ] <strong>Custom Metrics:</strong> Business metrics exported</li>
</ul>
<hr />
<h2>â˜‘ï¸ Cloud SQL Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Instance Tier:</strong> Sized for peak load</li>
<li>[ ] <strong>High Availability:</strong> HA configured (failover)</li>
<li>[ ] <strong>Region:</strong> Same as app for latency</li>
<li>[ ] <strong>Private IP:</strong> Enabled for security</li>
<li>[ ] <strong>No Public IP:</strong> Unless absolutely required</li>
<li>[ ] <strong>Maintenance Window:</strong> Set to low-traffic hours</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>SSL/TLS:</strong> Required for connections</li>
<li>[ ] <strong>Authorized Networks:</strong> Minimal (prefer Cloud SQL Proxy)</li>
<li>[ ] <strong>IAM Database Auth:</strong> Enabled</li>
<li>[ ] <strong>Encryption:</strong> CMEK for compliance</li>
<li>[ ] <strong>Backup Encryption:</strong> Enabled</li>
</ul>
<h3>Backup &amp; Recovery</h3>
<ul>
<li>[ ] <strong>Automated Backups:</strong> Enabled (7-365 days)</li>
<li>[ ] <strong>Point-in-Time Recovery:</strong> Enabled for MySQL/PostgreSQL</li>
<li>[ ] <strong>Backup Location:</strong> Multi-region for disaster recovery</li>
<li>[ ] <strong>Backup Testing:</strong> Restore tested quarterly</li>
</ul>
<h3>Performance</h3>
<ul>
<li>[ ] <strong>Read Replicas:</strong> For read-heavy workloads</li>
<li>[ ] <strong>Connection Pooling:</strong> App-side or Cloud SQL Proxy</li>
<li>[ ] <strong>Query Insights:</strong> Enabled for slow query detection</li>
<li>[ ] <strong>Database Flags:</strong> Tuned for workload</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>Uptime Checks:</strong> For database connectivity</li>
<li>[ ] <strong>Alerting:</strong> CPU, memory, storage capacity</li>
<li>[ ] <strong>Log Export:</strong> To Cloud Logging/BigQuery</li>
<li>[ ] <strong>Performance Dashboard:</strong> Created in Monitoring</li>
</ul>
<hr />
<h2>â˜‘ï¸ VPC Network Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Custom VPC:</strong> Not auto-mode</li>
<li>[ ] <strong>Subnet Sizing:</strong> Right-sized CIDR blocks</li>
<li>[ ] <strong>IP Range Planning:</strong> No overlap with on-prem</li>
<li>[ ] <strong>Regional Subnets:</strong> Not global (for isolation)</li>
<li>[ ] <strong>Private Google Access:</strong> Enabled for private VMs</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>Firewall Rules:</strong> Service account-based</li>
<li>[ ] <strong>Default Deny:</strong> All ingress denied except allowed</li>
<li>[ ] <strong>No 0.0.0.0/0:</strong> Except load balancer health checks</li>
<li>[ ] <strong>IAP for SSH:</strong> No TCP:22 from internet</li>
<li>[ ] <strong>VPC Flow Logs:</strong> Enabled for compliance</li>
</ul>
<h3>Connectivity</h3>
<ul>
<li>[ ] <strong>Cloud NAT:</strong> For private VMs internet access</li>
<li>[ ] <strong>Cloud VPN/Interconnect:</strong> For hybrid cloud</li>
<li>[ ] <strong>VPC Peering:</strong> For cross-project access</li>
<li>[ ] <strong>Shared VPC:</strong> For org-wide connectivity</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>Flow Logs:</strong> Exported to BigQuery</li>
<li>[ ] <strong>Firewall Rules Logging:</strong> Enabled</li>
<li>[ ] <strong>Packet Mirroring:</strong> For security analysis (if needed)</li>
<li>[ ] <strong>Network Intelligence:</strong> Checked for topology</li>
</ul>
<hr />
<h2>â˜‘ï¸ IAM Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>No Owner Role:</strong> In production projects</li>
<li>[ ] <strong>No Editor Role:</strong> Too permissive</li>
<li>[ ] <strong>Predefined Roles:</strong> Used instead of primitive</li>
<li>[ ] <strong>Custom Roles:</strong> For fine-grained access</li>
<li>[ ] <strong>Service Accounts:</strong> Per service, not per user</li>
<li>[ ] <strong>Groups:</strong> Used for user management</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>No JSON Keys:</strong> Use Workload Identity Federation</li>
<li>[ ] <strong>Key Rotation:</strong> Automated for any keys</li>
<li>[ ] <strong>Least Privilege:</strong> Minimal roles assigned</li>
<li>[ ] <strong>IAM Conditions:</strong> Time/IP/resource-based</li>
<li>[ ] <strong>Organization Policies:</strong> Domain restriction enabled</li>
</ul>
<h3>Audit</h3>
<ul>
<li>[ ] <strong>Admin Activity Logs:</strong> Always enabled (default)</li>
<li>[ ] <strong>Data Access Logs:</strong> Enabled for sensitive data</li>
<li>[ ] <strong>Log Sinks:</strong> Exported to SIEM</li>
<li>[ ] <strong>IAM Recommender:</strong> Reviewed quarterly</li>
<li>[ ] <strong>Policy Analyzer:</strong> Checked for over-permissions</li>
</ul>
<hr />
<h2>â˜‘ï¸ GKE Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Autopilot vs Standard:</strong> Decision documented</li>
<li>[ ] <strong>Regional Cluster:</strong> For high availability</li>
<li>[ ] <strong>Release Channel:</strong> Stable or Regular (not Rapid)</li>
<li>[ ] <strong>Workload Identity:</strong> Enabled (not metadata server)</li>
<li>[ ] <strong>Binary Authorization:</strong> For container security</li>
<li>[ ] <strong>Private Cluster:</strong> Enabled</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>Shielded Nodes:</strong> Enabled</li>
<li>[ ] <strong>Network Policy:</strong> Enabled</li>
<li>[ ] <strong>Pod Security Standards:</strong> enforced</li>
<li>[ ] <strong>RBAC:</strong> Configured with least-privilege</li>
<li>[ ] <strong>Secret Management:</strong> External Secrets Operator</li>
</ul>
<h3>Reliability</h3>
<ul>
<li>[ ] <strong>Node Auto-Repair:</strong> Enabled</li>
<li>[ ] <strong>Node Auto-Upgrade:</strong> Enabled (maintenance window set)</li>
<li>[ ] <strong>Pod Disruption Budgets:</strong> Configured</li>
<li>[ ] <strong>Horizontal Pod Autoscaler:</strong> Configured</li>
<li>[ ] <strong>Liveness/Readiness Probes:</strong> All pods have them</li>
</ul>
<h3>Monitoring</h3>
<ul>
<li>[ ] <strong>GKE Monitoring:</strong> Enabled</li>
<li>[ ] <strong>Workload Metrics:</strong> Configured</li>
<li>[ ] <strong>Logging:</strong> Structured JSON format</li>
<li>[ ] <strong>Alerting:</strong> For pod crashes, node issues</li>
</ul>
<hr />
<h2>â˜‘ï¸ BigQuery Production Checklist</h2>
<h3>Before Launch</h3>
<ul>
<li>[ ] <strong>Dataset Location:</strong> Matches data residency requirements</li>
<li>[ ] <strong>Table Partitioning:</strong> By date for time-series data</li>
<li>[ ] <strong>Clustering:</strong> On frequently filtered columns</li>
<li>[ ] <strong>Expiration:</strong> Set for temp tables</li>
<li>[ ] <strong>Authorized Views:</strong> For row-level security</li>
</ul>
<h3>Cost Control</h3>
<ul>
<li>[ ] <strong>Query Cost Estimate:</strong> Used before running</li>
<li>[ ] <strong>Maximum Bytes Billed:</strong> Set on queries</li>
<li>[ ] <strong>BI Engine:</strong> Enabled for dashboards</li>
<li>[ ] <strong>Slot Reservations:</strong> For predictable costs &gt;$10k/month</li>
<li>[ ] <strong>Cost Monitoring:</strong> Alerts set for unusual spend</li>
</ul>
<h3>Security</h3>
<ul>
<li>[ ] <strong>Column-Level Security:</strong> For PII data</li>
<li>[ ] <strong>Data Masking:</strong> For sensitive fields</li>
<li>[ ] <strong>Encryption:</strong> CMEK for compliance</li>
<li>[ ] <strong>Audit Logs:</strong> Data Access enabled</li>
<li>[ ] <strong>VPC Service Controls:</strong> For data exfiltration prevention</li>
</ul>
<h3>Performance</h3>
<ul>
<li>[ ] <strong>Avoid SELECT *:</strong> Only query needed columns</li>
<li>[ ] <strong>Use Clustering:</strong> For filter/aggregate queries</li>
<li>[ ] <strong>Approximate Aggregation:</strong> For huge datasets</li>
<li>[ ] <strong>Materialized Views:</strong> For repeated queries</li>
<li>[ ] <strong>INFORMATION_SCHEMA:</strong> Checked for expensive queries</li>
</ul>
<hr />
<h2>ğŸ“ Using These Checklists</h2>
<h3>When to Use</h3>
<ul>
<li><strong>Pre-Deployment Review:</strong> Week before go-live</li>
<li><strong>Security Audit:</strong> Quarterly</li>
<li><strong>Incident Postmortem:</strong> After outages</li>
<li><strong>Compliance:</strong> Before audits</li>
</ul>
<h3>How to Track</h3>
<pre><code class="language-bash"># Create a checklist issue in GitHub
gh issue create --title &quot;Production Checklist: Cloud Run Service&quot; --body &quot;$(cat checklist.md)&quot;

# Or use project management tools
# Jira, Asana, Monday.com, etc.
</code></pre>
<h3>Automation Tips</h3>
<p>Many checklist items can be automated with:
- <strong>Terraform:</strong> Enforce configurations
- <strong>Sentinel/OPA:</strong> Policy as code
- <strong>Cloud Build:</strong> Pre-deployment checks
- <strong>Config Connector:</strong> Kubernetes-style management</p>
</article>
<article id="interview_question_bank">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 8 min read</div>
<h1>GCP Interview Question Bank</h1>
<blockquote>
<p><strong>Master Collection:</strong> 60+ interview questions organized by topic and difficulty level.</p>
</blockquote>
<hr />
<h2>ğŸ“Š Question Distribution</h2>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Beginner</th>
<th>Intermediate</th>
<th>Advanced</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>IAM &amp; Security</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>9</td>
</tr>
<tr>
<td>VPC Networking</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>9</td>
</tr>
<tr>
<td>Compute Engine</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td>Containers &amp; GKE</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td>Storage</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td>Serverless</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td>Data Services</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>7</td>
</tr>
<tr>
<td>DevOps &amp; IaC</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>6</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>18</strong></td>
<td><strong>23</strong></td>
<td><strong>18</strong></td>
<td><strong>59</strong></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ” IAM &amp; Security</h2>
<h3>Beginner</h3>
<p><strong>Q1: What is the difference between a Role and a Permission?</strong></p>
<blockquote>
<p>"A permission is a single action like <code>storage.objects.get</code>. A role is a collection of permissions. I use predefined roles for maintainability."</p>
</blockquote>
<p><strong>Q2: Why avoid Basic Roles (Owner/Editor/Viewer)?</strong></p>
<blockquote>
<p>"They're too broad. Editor grants write to almost everything. I use predefined roles like <code>roles/compute.instanceAdmin</code> for specific access."</p>
</blockquote>
<p><strong>Q3: What is a Service Account?</strong></p>
<blockquote>
<p>"An identity for applications to make API calls. I use them instead of user accounts for VMs and workloads."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q4: When create Custom Role vs Predefined Role?</strong></p>
<blockquote>
<p>"Predefined 95% of timeâ€”Google maintains them. Custom only when predefined is too permissive and no narrower option exists."</p>
</blockquote>
<p><strong>Q5: How decide between users vs Google Groups for permissions?</strong></p>
<blockquote>
<p>"Always Groups. Scales betterâ€”update group membership, not IAM. Cleaner audit trail."</p>
</blockquote>
<p><strong>Q6: What is Workload Identity Federation?</strong></p>
<blockquote>
<p>"Exchange external tokens (GitHub, AWS) for GCP access. Eliminates JSON keys for CI/CD."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q7: Your CI/CD needs to deploy to GKE. Set this up securely.</strong></p>
<blockquote>
<p>"Workload Identity Federation â†’ Pool for GitHub â†’ SA with <code>container.developer</code> role â†’ No JSON keys."</p>
</blockquote>
<p><strong>Q8: Developer gets 'Permission Denied' creating VM. Troubleshoot.</strong></p>
<blockquote>
<p>"1. Check <code>gcloud auth list</code> 2. Check project 3. Check IAM binding 4. Test permissions 5. Check Org Policies"</p>
</blockquote>
<p><strong>Q9: JSON key leaked to GitHub. Immediate response?</strong></p>
<blockquote>
<p>"Disable key â†’ Delete key â†’ Check audit logs â†’ Create new SA with least privilege â†’ Implement Workload Identity"</p>
</blockquote>
<hr />
<h2>ğŸŒ VPC Networking</h2>
<h3>Beginner</h3>
<p><strong>Q1: Difference between VPC and Subnet in GCP?</strong></p>
<blockquote>
<p>"VPC is global network spanning all regions. Subnet is regionalâ€”VMs are placed in subnets. Unlike AWS, GCP VPCs are global."</p>
</blockquote>
<p><strong>Q2: What happens with no firewall rules in new VPC?</strong></p>
<blockquote>
<p>"Ingress blocked by default, egress allowed. Must explicitly allow HTTP/HTTPS."</p>
</blockquote>
<p><strong>Q3: What is Private Google Access?</strong></p>
<blockquote>
<p>"Allows VMs without external IPs to reach Google APIs privately."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q4: VPC Peering vs Shared VPC?</strong></p>
<blockquote>
<p>"Peering connects separate VPCs across orgs. Shared VPC is one org with central network control. Shared for control, Peering for isolation."</p>
</blockquote>
<p><strong>Q5: VM needs internet access but no public IP. How?</strong></p>
<blockquote>
<p>"Cloud NAT with Cloud Router. Outbound-only access without exposing VM."</p>
</blockquote>
<p><strong>Q6: Load balancer health checks failing but can curl backend. Why?</strong></p>
<blockquote>
<p>"Health checks come from 35.191.0.0/16 and 130.211.0.0/22. Need firewall rule allowing these ranges."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q7: VMs in VPC-A can't reach VPC-B with peering. Troubleshoot.</strong></p>
<blockquote>
<p>"1. Check peering ACTIVE both sides 2. Check route export/import 3. Verify no CIDR overlap 4. Check firewalls BOTH VPCs 5. Verify routes"</p>
</blockquote>
<p><strong>Q8: Design network for 50 projects, 3 teams, central control.</strong></p>
<blockquote>
<p>"Shared VPC with Host Project. Platform team owns VPC. Service Projects for each team. Subnets per team/env."</p>
</blockquote>
<p><strong>Q9: What is IAP tunneling and when to use it?</strong></p>
<blockquote>
<p>"Identity-Aware Proxy for SSH without opening port 22 to internet. Source range 35.235.240.0/20. Secure alternative to public SSH."</p>
</blockquote>
<hr />
<h2>ğŸ’» Compute Engine</h2>
<h3>Beginner</h3>
<p><strong>Q1: E2 vs N2 machine types?</strong></p>
<blockquote>
<p>"E2 cheapest, variable performanceâ€”dev/test. N2 consistent performanceâ€”production, SLAs."</p>
</blockquote>
<p><strong>Q2: What is Spot VM?</strong></p>
<blockquote>
<p>"60-91% discount, can be preempted with 30s notice. Use for fault-tolerant batch jobs."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: VM needs to survive host maintenance. Configure it.</strong></p>
<blockquote>
<p>"Live Migration (default). Google moves VM to healthy hardware &lt;1s downtime. GPU VMs must restart."</p>
</blockquote>
<p><strong>Q4: Custom images vs startup scripts?</strong></p>
<blockquote>
<p>"Images: faster boot, production. Scripts: flexible, dev/test. My pattern: base image + scripts for env config."</p>
</blockquote>
<p><strong>Q5: MIG auto-healing vs auto-scaling?</strong></p>
<blockquote>
<p>"Healing replaces unhealthy VMs. Scaling adds/removes based on load. Different features."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q6: Design solution for 1000 videos/day encoding, cost-optimized.</strong></p>
<blockquote>
<p>"Spot VMs C2, autoscaling MIG â†’ 0, Pub/Sub queue, checkpoint every 5min to GCS."</p>
</blockquote>
<p><strong>Q7: VM performance degrades every afternoon. Troubleshoot.</strong></p>
<blockquote>
<p>"Check Monitoring graphs, E2 vs N2, noisy neighbor, scheduled jobs, network quotas."</p>
</blockquote>
<hr />
<h2>ğŸ³ Containers &amp; GKE</h2>
<h3>Beginner</h3>
<p><strong>Q1: Why containers start faster than VMs?</strong></p>
<blockquote>
<p>"Containers share host kernel, virtualize at OS level. VMs boot full OS."</p>
</blockquote>
<p><strong>Q2: GKE Autopilot vs Standard?</strong></p>
<blockquote>
<p>"Autopilot: Google manages nodes, per-pod billing. Standard: you manage, more control."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: What is Workload Identity in GKE?</strong></p>
<blockquote>
<p>"Link Kubernetes Service Account to GCP Service Account. Pods authenticate without JSON keys."</p>
</blockquote>
<p><strong>Q4: Pod is CrashLoopBackOff. Troubleshoot.</strong></p>
<blockquote>
<p>"<code>kubectl describe pod</code>, <code>kubectl logs</code>, check liveness probe, image pull issues, resource limits."</p>
</blockquote>
<p><strong>Q5: When GKE vs Compute Engine?</strong></p>
<blockquote>
<p>"GKE for microservices, container-native. Compute for monoliths, legacy, licensing."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q6: Design microservices deployment on GKE.</strong></p>
<blockquote>
<p>"Autopilot for simplicity, Workload Identity, horizontal pod autoscaler, Cloud SQL with Auth Proxy."</p>
</blockquote>
<p><strong>Q7: Node pool considerations for ML workloads.</strong></p>
<blockquote>
<p>"GPU node pool, preemptible for cost, taints/tolerations, cluster autoscaler."</p>
</blockquote>
<hr />
<h2>ğŸ’¾ Storage</h2>
<h3>Beginner</h3>
<p><strong>Q1: Which storage class for rarely accessed backups?</strong></p>
<blockquote>
<p>"Coldline (90 days) or Archive (365 days). Cheaper storage, higher retrieval cost."</p>
</blockquote>
<p><strong>Q2: What is Signed URL?</strong></p>
<blockquote>
<p>"Time-limited URL granting temporary access. No Google account needed. Max 7 days."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: How reduce storage costs for old data?</strong></p>
<blockquote>
<p>"Lifecycle rules: Standard â†’ Nearline (30d) â†’ Coldline (90d) â†’ Archive."</p>
</blockquote>
<p><strong>Q4: Versioning enabled, costs jumped. Why?</strong></p>
<blockquote>
<p>"Paying for all versions. Add lifecycle rule to delete versions older than N days."</p>
</blockquote>
<p><strong>Q5: Persistent Disk vs Local SSD?</strong></p>
<blockquote>
<p>"PD network-attached, survives restart. Local SSD physically attached, data wiped on stop."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q6: Design data lake with cost optimization.</strong></p>
<blockquote>
<p>"Standard for hot data, lifecycle to Archive, partitioned folders, BigQuery external tables."</p>
</blockquote>
<p><strong>Q7: Need 7-year retention, no deletion possible. Solution?</strong></p>
<blockquote>
<p>"Bucket Lock with Retention Policy. WORM storage. Irreversible."</p>
</blockquote>
<hr />
<h2>âš¡ Serverless (Cloud Run / Functions)</h2>
<h3>Beginner</h3>
<p><strong>Q1: Cloud Run vs Cloud Functions?</strong></p>
<blockquote>
<p>"Functions for simple events. Run for complex apps, containers. Both serverless."</p>
</blockquote>
<p><strong>Q2: What causes cold starts?</strong></p>
<blockquote>
<p>"New container instance initialization. Set min-instances=1 to keep warm."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: 1st Gen vs 2nd Gen Cloud Functions?</strong></p>
<blockquote>
<p>"2nd Gen: 60min timeout (vs 9min), 1000 concurrency, Eventarc, built on Cloud Run."</p>
</blockquote>
<p><strong>Q4: Cloud Run concurrency setting impact?</strong></p>
<blockquote>
<p>"Higher = fewer instances, lower cost. Lower = more isolation. Balance based on workload."</p>
</blockquote>
<p><strong>Q5: How secure secrets in serverless?</strong></p>
<blockquote>
<p>"Secret Manager integration. Reference secrets in deployment, mounted at runtime."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q6: Design event-driven image processing pipeline.</strong></p>
<blockquote>
<p>"GCS upload â†’ Pub/Sub â†’ Cloud Function â†’ Process â†’ Store result. DLQ for failures."</p>
</blockquote>
<p><strong>Q7: Canary deployment on Cloud Run.</strong></p>
<blockquote>
<p>"Deploy new revision, split traffic 90/10, monitor errors, gradually shift."</p>
</blockquote>
<hr />
<h2>ğŸ“Š Data Services (BigQuery / Pub/Sub)</h2>
<h3>Beginner</h3>
<p><strong>Q1: BigQuery pricing model?</strong></p>
<blockquote>
<p>"On-demand: $5/TB scanned. Flat-rate: slots for predictable cost."</p>
</blockquote>
<p><strong>Q2: Push vs Pull subscription in Pub/Sub?</strong></p>
<blockquote>
<p>"Push for webhooks, real-time. Pull for batch, rate control, no public endpoint."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: How reduce BigQuery query costs?</strong></p>
<blockquote>
<p>"Partition by date, cluster by frequent filters, SELECT only needed columns."</p>
</blockquote>
<p><strong>Q4: Dead Letter Queue in Pub/Sub?</strong></p>
<blockquote>
<p>"Catches messages that fail after N retries. Prevents poison messages from blocking."</p>
</blockquote>
<p><strong>Q5: BigQuery vs Cloud SQL?</strong></p>
<blockquote>
<p>"BigQuery for analytics (OLAP). Cloud SQL for transactions (OLTP)."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q6: Design real-time analytics pipeline.</strong></p>
<blockquote>
<p>"Dataflow streaming â†’ BigQuery. Pub/Sub input â†’ Transform â†’ BigQuery sink."</p>
</blockquote>
<p><strong>Q7: Exactly-once processing requirement. Solution?</strong></p>
<blockquote>
<p>"Pub/Sub exactly-once delivery + idempotent processing. Dataflow handles this."</p>
</blockquote>
<hr />
<h2>ğŸ”§ DevOps &amp; IaC</h2>
<h3>Beginner</h3>
<p><strong>Q1: terraform plan vs terraform apply?</strong></p>
<blockquote>
<p>"Plan shows preview. Apply makes changes. Always review plan first."</p>
</blockquote>
<p><strong>Q2: Where store Terraform state?</strong></p>
<blockquote>
<p>"Remote backend (GCS bucket). Never commit to gitâ€”contains secrets."</p>
</blockquote>
<h3>Intermediate</h3>
<p><strong>Q3: Cloud Build trigger types?</strong></p>
<blockquote>
<p>"GitHub push, PR, schedule, manual. Branch patterns for filtering."</p>
</blockquote>
<p><strong>Q4: Terraform modules benefit?</strong></p>
<blockquote>
<p>"Reusable, DRY, version controlled. Share across teams via module registry."</p>
</blockquote>
<h3>Advanced</h3>
<p><strong>Q5: Design CI/CD for GKE deployment.</strong></p>
<blockquote>
<p>"GitHub â†’ Cloud Build â†’ Build image â†’ Push to Artifact Registry â†’ Cloud Deploy to GKE."</p>
</blockquote>
<p><strong>Q6: GitOps workflow for infrastructure.</strong></p>
<blockquote>
<p>"PR to change Terraform â†’ Review â†’ Merge â†’ Cloud Build auto-applies. State in GCS."</p>
</blockquote>
<hr />
<h2>ğŸ’¡ Interview Tips</h2>
<h3>Before the Interview</h3>
<ul>
<li>Review this question bank</li>
<li>Practice explaining WHY, not just WHAT</li>
<li>Prepare 2-3 real project examples</li>
</ul>
<h3>During the Interview</h3>
<ul>
<li>Start with simple answer, then elaborate</li>
<li>Admit gaps: "I haven't used X, but my approach would be..."</li>
<li>Ask clarifying questions for scenarios</li>
</ul>
</article>
<article id="interview_guide">
<div style="margin-bottom: 20px; font-size: 0.85rem; color: var(--text); opacity: 0.7;">â±ï¸ 6 min read</div>
<h1>How GCP Interviews Are Run</h1>
<blockquote>
<p><strong>Insider Guide:</strong> What to expect and how to prepare for each interview round.</p>
</blockquote>
<hr />
<h2>ğŸ“‹ Interview Round Structure</h2>
<p>Most GCP/Cloud Engineer interviews follow this structure:</p>
<table>
<thead>
<tr>
<th>Round</th>
<th>Duration</th>
<th>Focus</th>
<th>Weight</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Phone Screen</strong></td>
<td>30-45 min</td>
<td>Resume, basics, motivation</td>
<td>20%</td>
</tr>
<tr>
<td><strong>Technical Deep-Dive</strong></td>
<td>45-60 min</td>
<td>Core concepts, troubleshooting</td>
<td>30%</td>
</tr>
<tr>
<td><strong>System Design</strong></td>
<td>45-60 min</td>
<td>Architecture, trade-offs</td>
<td>30%</td>
</tr>
<tr>
<td><strong>Behavioral</strong></td>
<td>30-45 min</td>
<td>Teamwork, conflict, growth</td>
<td>20%</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ“ Round 1: Phone Screen</h2>
<h3>What to Expect</h3>
<ul>
<li>Recruiter or hiring manager</li>
<li>High-level technical questions</li>
<li>"Tell me about yourself"</li>
<li>Why this company/role?</li>
</ul>
<h3>Sample Questions</h3>
<ul>
<li>"Walk me through a GCP project you've worked on"</li>
<li>"What's the difference between Cloud Run and GKE?"</li>
<li>"How would you explain VPC to a non-technical person?"</li>
</ul>
<h3>Success Pattern</h3>
<pre><code>âœ… 30-second intro, then ask &quot;Should I go deeper?&quot;
âœ… Connect your experience to the job description
âœ… Show enthusiasm for cloud, not just &quot;I need a job&quot;
</code></pre>
<hr />
<h2>ğŸ”§ Round 2: Technical Deep-Dive</h2>
<h3>What to Expect</h3>
<ul>
<li>Senior engineer or team lead</li>
<li>Troubleshooting scenarios</li>
<li>"You did X, but what if Y happened?"</li>
<li>Live debugging (sometimes)</li>
</ul>
<h3>Question Categories</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>% of Questions</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Conceptual</strong></td>
<td>30%</td>
<td>"What is Workload Identity?"</td>
</tr>
<tr>
<td><strong>Trade-off</strong></td>
<td>30%</td>
<td>"When Cloud SQL vs Spanner?"</td>
</tr>
<tr>
<td><strong>Troubleshooting</strong></td>
<td>40%</td>
<td>"VM can't reach internet. Debug this."</td>
</tr>
</tbody>
</table>
<h3>Troubleshooting Framework (Use This!)</h3>
<pre><code>1. CLARIFY the symptom
   â†’ &quot;Can you describe the exact error?&quot;

2. ISOLATE the layer
   â†’ Network? IAM? Application? Configuration?

3. LIST possible causes
   â†’ &quot;This could be firewall, route, or IAM...&quot;

4. VERIFY methodically
   â†’ &quot;I'd run `gcloud compute instances describe...`&quot;

5. FIX and VALIDATE
   â†’ &quot;After fixing, I'd test with `curl` and check logs&quot;
</code></pre>
<h3>Sample Deep-Dive Questions</h3>
<p><strong>IAM:</strong></p>
<blockquote>
<p>"Developer says 'Permission Denied' when deploying to Cloud Run. Walk me through your debugging."</p>
</blockquote>
<p><strong>Strong Answer:</strong></p>
<pre><code>1. Check identity: `gcloud auth list`
2. Check project: `gcloud config list project`
3. Check role: needs `roles/run.developer` or `roles/run.admin`
4. Check if org policy blocks public services
5. Test: `gcloud projects get-iam-policy PROJECT_ID`
</code></pre>
<p><strong>Networking:</strong></p>
<blockquote>
<p>"VM in private subnet can't pull Docker images. Debug this."</p>
</blockquote>
<p><strong>Strong Answer:</strong></p>
<pre><code>1. No external IP? â†’ Need Cloud NAT or Private Google Access
2. Check route to 0.0.0.0/0 through NAT
3. Check firewall allows egress on 443
4. For gcr.io: Enable Private Google Access on subnet
5. Test: `curl -v https://gcr.io`
</code></pre>
<hr />
<h2>ğŸ—ï¸ Round 3: System Design</h2>
<h3>What to Expect</h3>
<ul>
<li>Whiteboard or virtual diagram</li>
<li>Open-ended requirements</li>
<li>"Design a system that..."</li>
<li>Trade-off discussions</li>
</ul>
<h3>The 5-Step Framework</h3>
<pre><code>1. CLARIFY requirements (2-3 min)
   â†’ Users? Scale? Latency? Budget? Compliance?

2. HIGH-LEVEL design (5 min)
   â†’ Draw boxes: User â†’ LB â†’ App â†’ DB

3. DEEP-DIVE components (15 min)
   â†’ Pick 2-3 areas to detail

4. TRADE-OFFS (10 min)
   â†’ &quot;I chose X over Y because...&quot;

5. FUTURE improvements (5 min)
   â†’ &quot;To scale further, I'd add...&quot;
</code></pre>
<h3>Sample Design Questions</h3>
<table>
<thead>
<tr>
<th>Question</th>
<th>Key Services</th>
<th>Watch For</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Design a web app with 99.9% uptime"</td>
<td>Regional MIG, GLB, Cloud SQL HA</td>
<td>Auto-healing, multi-zone</td>
</tr>
<tr>
<td>"Design a data pipeline for 1M events/day"</td>
<td>Pub/Sub, Dataflow, BigQuery</td>
<td>DLQ, partitioning, costs</td>
</tr>
<tr>
<td>"Design a CI/CD pipeline"</td>
<td>Cloud Build, Artifact Registry, GKE</td>
<td>Security, rollback, testing</td>
</tr>
</tbody>
</table>
<h3>Design Answer Template</h3>
<pre><code class="language-markdown">## Requirements I'm Assuming
- X users, Y requests/second
- 99.9% availability target
- Budget: cost-optimized

## Architecture
[Draw diagram]
- Users â†’ Cloud CDN â†’ Global LB
- LB â†’ Regional MIG (3 zones)
- App â†’ Cloud SQL (HA replica)
- Secrets â†’ Secret Manager

## Why These Choices
| Decision | Why | Alternative Considered |
|----------|-----|------------------------|
| Regional MIG | Zone failure tolerance | Zonal (cheaper but risky) |
| Cloud SQL HA | Built-in failover | Self-managed Postgres (more work) |

## Trade-offs
- Higher cost for HA vs single-zone
- More complexity for reliability

## Future Improvements
- Add Cloud Armor for DDoS
- Move to GKE for microservices
</code></pre>
<hr />
<h2>ğŸ¤ Round 4: Behavioral</h2>
<h3>What to Expect</h3>
<ul>
<li>STAR format (Situation, Task, Action, Result)</li>
<li>Focus on collaboration and conflict</li>
<li>Growth mindset signals</li>
</ul>
<h3>Common Questions</h3>
<table>
<thead>
<tr>
<th>Question</th>
<th>What They're Testing</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Tell me about a production outage"</td>
<td>Calm under pressure, learning</td>
</tr>
<tr>
<td>"Disagreement with a teammate"</td>
<td>Conflict resolution</td>
</tr>
<tr>
<td>"Mistake you made and learned from"</td>
<td>Accountability</td>
</tr>
<tr>
<td>"Project you're proud of"</td>
<td>Impact, ownership</td>
</tr>
</tbody>
</table>
<h3>STAR Answer Template</h3>
<pre><code>SITUATION: &quot;We had a production database failure during peak traffic...&quot;

TASK: &quot;I was the on-call engineer responsible for restoring service...&quot;

ACTION: &quot;I first checked Cloud Monitoring, then...&quot;
- Specific technical steps
- Collaboration with team
- Communication to stakeholders

RESULT: &quot;Service was restored in 45 minutes, and we...&quot;
- Quantify impact
- What you learned
- Process improvement made
</code></pre>
<hr />
<h2>ğŸ’¡ Interview Tips by Role</h2>
<h3>ğŸ” Cloud Engineer Lens</h3>
<table>
<thead>
<tr>
<th>Focus On</th>
<th>De-emphasize</th>
</tr>
</thead>
<tbody>
<tr>
<td>Infrastructure: VM, VPC, IAM</td>
<td>Complex data pipelines</td>
</tr>
<tr>
<td>Troubleshooting skills</td>
<td>ML/AI services</td>
</tr>
<tr>
<td>Cost optimization</td>
<td>Deep Kubernetes internals</td>
</tr>
</tbody>
</table>
<h3>ğŸ” DevOps Engineer Lens</h3>
<table>
<thead>
<tr>
<th>Focus On</th>
<th>De-emphasize</th>
</tr>
</thead>
<tbody>
<tr>
<td>CI/CD pipelines</td>
<td>Data warehousing</td>
</tr>
<tr>
<td>Terraform, automation</td>
<td>BigQuery optimization</td>
</tr>
<tr>
<td>Container deployment</td>
<td>Network design</td>
</tr>
</tbody>
</table>
<h3>ğŸ” Data Engineer Lens</h3>
<table>
<thead>
<tr>
<th>Focus On</th>
<th>De-emphasize</th>
</tr>
</thead>
<tbody>
<tr>
<td>BigQuery, Dataflow, Pub/Sub</td>
<td>VM troubleshooting</td>
</tr>
<tr>
<td>Data modeling, ETL</td>
<td>Firewall rules</td>
</tr>
<tr>
<td>Cost optimization for data</td>
<td>Compute pricing</td>
</tr>
</tbody>
</table>
<hr />
<h2>âœ… Pre-Interview Checklist</h2>
<h3>1 Week Before</h3>
<ul>
<li>[ ] Review all 18 enhanced modules</li>
<li>[ ] Complete 3+ mini-projects</li>
<li>[ ] Practice 10 interview questions out loud</li>
</ul>
<h3>Day Before</h3>
<ul>
<li>[ ] Review your resume projects in detail</li>
<li>[ ] Prepare 3 STAR stories</li>
<li>[ ] Get a good night's sleep</li>
</ul>
<h3>1 Hour Before</h3>
<ul>
<li>[ ] Have water ready</li>
<li>[ ] Test video/audio</li>
<li>[ ] Have pen and paper for notes</li>
</ul>
<h3>During Interview</h3>
<ul>
<li>[ ] Ask clarifying questions</li>
<li>[ ] Think out loud</li>
<li>[ ] Admit what you don't know, then explain your approach</li>
<li>[ ] Relate answers to real experience when possible</li>
</ul>
<hr />
<h2>ğŸš« Red Flags to Avoid</h2>
<table>
<thead>
<tr>
<th>Don't Say</th>
<th>Why It's Bad</th>
<th>Say Instead</th>
</tr>
</thead>
<tbody>
<tr>
<td>"I've never used that"</td>
<td>Shuts down conversation</td>
<td>"I haven't used X, but based on my understanding..."</td>
</tr>
<tr>
<td>"That's easy"</td>
<td>Sounds arrogant</td>
<td>"I've done something similar..."</td>
</tr>
<tr>
<td>"I don't know" (alone)</td>
<td>No effort shown</td>
<td>"I'd approach it by first checking..."</td>
</tr>
<tr>
<td>"We did it" (always)</td>
<td>No individual contribution</td>
<td>"My role was..." then "The team also..."</td>
</tr>
</tbody>
</table>
</article>

    </main>
    
    <button class="back-to-top" onclick="scrollToTop()">â†‘</button>
    
    <script>
        function initApp() {
            hljs.highlightAll();
            setupIntersectionObserver();
            setupKeyboardShortcuts();
            generateTOC();
            loadProgress();
            loadTheme();
            addCopyButtons();
        }

        // 1. Generate TOC with Checkboxes
        function generateTOC() {
            const articles = document.querySelectorAll('article');
            const toc = document.getElementById('toc');
            
            articles.forEach(article => {
                const h1 = article.querySelector('h1');
                if (h1) {
                    const li = document.createElement('li');
                    
                    // Checkbox
                    const check = document.createElement('input');
                    check.type = 'checkbox';
                    check.className = 'progress-check';
                    check.dataset.id = article.id;
                    check.onclick = (e) => saveProgress(article.id, e.target.checked);
                    
                    // Link
                    const a = document.createElement('a');
                    a.textContent = h1.textContent.replace('# ', '').replace('Module ', '');
                    a.href = '#' + article.id;
                    a.title = h1.textContent;
                    
                    li.appendChild(check);
                    li.appendChild(a);
                    toc.appendChild(li);
                }
            });
        }

        // 2. Progress Tracking (LocalStorage)
        function saveProgress(id, isChecked) {
            let progress = JSON.parse(localStorage.getItem('gcp_progress') || '{}');
            progress[id] = isChecked;
            localStorage.setItem('gcp_progress', JSON.stringify(progress));
            updateProgressUI();
        }

        function loadProgress() {
            let progress = JSON.parse(localStorage.getItem('gcp_progress') || '{}');
            document.querySelectorAll('.progress-check').forEach(box => {
                if (progress[box.dataset.id]) box.checked = true;
            });
            updateProgressUI();
        }
        
        function updateProgressUI() {
            const total = document.querySelectorAll('.progress-check').length;
            const checked = document.querySelectorAll('.progress-check:checked').length;
            const percent = total === 0 ? 0 : Math.round((checked / total) * 100);
            
            document.title = `GCP Course (${percent}%)`;
            
            // Update Sidebar Stats
            const countEl = document.getElementById('progress-count');
            const percentEl = document.getElementById('progress-percent');
            const fillEl = document.getElementById('progress-fill');
            
            if(countEl) countEl.textContent = `${checked}/${total} Modules`;
            if(percentEl) percentEl.textContent = `${percent}%`;
            if(fillEl) fillEl.style.width = `${percent}%`;
        }
        
        function resetProgress() {
            if(confirm('Reset all progress?')) {
                localStorage.removeItem('gcp_progress');
                location.reload();
            }
        }

        // 3. Dark Mode
        function toggleTheme() {
            document.body.classList.toggle('dark');
            localStorage.setItem('theme', document.body.classList.contains('dark') ? 'dark' : 'light');
        }

        function loadTheme() {
            if (localStorage.getItem('theme') === 'dark') {
                document.body.classList.add('dark');
            }
        }

        // 4. Search
        function filterModules() {
            const query = document.getElementById('search-input').value.toLowerCase();
            const items = document.querySelectorAll('#toc li');
            
            items.forEach(li => {
                const text = li.querySelector('a').textContent.toLowerCase();
                li.style.display = text.includes(query) ? 'flex' : 'none';
            });
        }

        // 5. Copy Buttons
        function addCopyButtons() {
            document.querySelectorAll('pre').forEach(pre => {
                const btn = document.createElement('button');
                btn.className = 'copy-btn';
                btn.textContent = 'Copy';
                btn.onclick = () => {
                    navigator.clipboard.writeText(pre.innerText);
                    btn.textContent = 'Copied!';
                    setTimeout(() => btn.textContent = 'Copy', 2000);
                };
                pre.appendChild(btn);
            });
        }
    </script>
    <script>
        // 6. Intersection Observer for Active TOC
        function setupIntersectionObserver() {
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        // Remove active class from all
                        document.querySelectorAll('#toc a').forEach(a => a.classList.remove('active'));
                        
                        // Add to current
                        const id = entry.target.id;
                        const link = document.querySelector(`#toc a[href="#${id}"]`);
                        if (link) {
                            link.classList.add('active');
                            // Auto-scroll TOC if needed
                            link.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                        }
                    }
                });
            }, { threshold: 0.1, rootMargin: "-100px 0px -60% 0px" });

            document.querySelectorAll('article').forEach(section => observer.observe(section));
        }

        // 7. Back to Top
        window.onscroll = () => {
            const btn = document.querySelector('.back-to-top');
            if (btn) {
                if (document.documentElement.scrollTop > 300) {
                    btn.classList.add('visible');
                } else {
                    btn.classList.remove('visible');
                }
            }
        };

        function scrollToTop() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // 8. Mobile Sidebar
        function toggleSidebar() {
            document.getElementById('sidebar').classList.toggle('open');
        }
        
        // Close sidebar when clicking a link on mobile
        document.addEventListener('click', (e) => {
            if (window.innerWidth < 768 && e.target.closest('#toc a')) {
                document.getElementById('sidebar').classList.remove('open');
            }
        });

        // 9. Keyboard Shortcuts
        function setupKeyboardShortcuts() {
            document.addEventListener('keydown', (e) => {
                // Search: /
                if (e.key === '/' && document.activeElement !== document.getElementById('search-input')) {
                    e.preventDefault();
                    document.getElementById('search-input').focus();
                }
                
                // Escape to blur
                if (e.key === 'Escape') {
                    if(document.activeElement === document.getElementById('search-input')) {
                        document.activeElement.blur();
                    }
                }
                
                // Theme: t
                if (e.key === 't' && document.activeElement.tagName !== 'INPUT') {
                    toggleTheme();
                }

                // Next/Prev: n / p
                if ((e.key === 'n' || e.key === 'p') && document.activeElement.tagName !== 'INPUT') {
                    // Find active active article or first visible
                    const articles = Array.from(document.querySelectorAll('article'));
                    let currentIdx = 0;
                    
                    // Simple heuristic: top of element is near top of viewport
                    for(let i=0; i<articles.length; i++) {
                        const rect = articles[i].getBoundingClientRect();
                        if(rect.top >= -100 && rect.top < 500) {
                            currentIdx = i;
                            break;
                        }
                    }

                    if (e.key === 'n' && currentIdx < articles.length - 1) {
                         const next = articles[currentIdx + 1];
                         // Offset for padding
                         const y = next.getBoundingClientRect().top + window.pageYOffset - 20;
                         window.scrollTo({top: y, behavior: 'smooth'});
                    }
                    if (e.key === 'p' && currentIdx > 0) {
                         const prev = articles[currentIdx - 1];
                         const y = prev.getBoundingClientRect().top + window.pageYOffset - 20;
                         window.scrollTo({top: y, behavior: 'smooth'});
                    }
                }
            });
        }
    </script>
    </body></html>
    